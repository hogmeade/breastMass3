######################## Epoch 0 - Batch 1 ########################
IDs in batch 1: tensor([1761,  496, 4232, 2452, 4011,  198, 4264, 3996, 3268, 3516,  639, 2094,
        1575,  959, 2729, 4141])
Epoch: 0, Training Loss: 1.11, Validation Loss: 1.10, accuracy = 0.30
######################## Epoch 1 - Batch 1 ########################
IDs in batch 1: tensor([2023, 1081,  828, 1219, 2461,  214, 1999, 3395, 1682, 2228, 3467, 2149,
        2823,  289,  636, 2447])
Epoch: 1, Training Loss: 1.08, Validation Loss: 1.10, accuracy = 0.30
######################## Epoch 2 - Batch 1 ########################
IDs in batch 1: tensor([1003, 3433, 3763, 1793, 2306, 3859,  603, 4196, 2341, 2777, 3234, 1619,
        2542, 2519, 1224, 3147])
Epoch: 2, Training Loss: 1.03, Validation Loss: 1.10, accuracy = 0.30
######################## Epoch 3 - Batch 1 ########################
IDs in batch 1: tensor([ 809, 2663, 1221,  409, 3473, 2883, 1181, 2024, 1279, 4110,  360, 3958,
        2461, 3834,   64, 2322])
Epoch: 3, Training Loss: 1.11, Validation Loss: 1.10, accuracy = 0.31
######################## Epoch 4 - Batch 1 ########################
IDs in batch 1: tensor([2660, 3208, 2257,  516,  256,  314, 3027, 3792, 3397, 3458,  975,  284,
        3035, 1835, 3733,  104])
Epoch: 4, Training Loss: 1.04, Validation Loss: 1.10, accuracy = 0.31
######################## Epoch 5 - Batch 1 ########################
IDs in batch 1: tensor([1037,  819, 1450, 1391,  873,   96, 1752, 1375, 3818, 3842,   84, 3211,
        2700, 1047, 3873, 2131])
Epoch: 5, Training Loss: 1.14, Validation Loss: 1.10, accuracy = 0.32
######################## Epoch 6 - Batch 1 ########################
IDs in batch 1: tensor([1698, 1778, 4143,  689, 3478, 2354, 1381, 2363, 2966,  835, 3060,  604,
         735, 1110, 3270, 4135])
Epoch: 6, Training Loss: 1.09, Validation Loss: 1.10, accuracy = 0.33
######################## Epoch 7 - Batch 1 ########################
IDs in batch 1: tensor([  81, 4050, 2118,  415, 1948,  992, 3032, 1938, 3760, 3790,  419,  344,
         155, 2248, 1484, 2153])
Epoch: 7, Training Loss: 1.14, Validation Loss: 1.10, accuracy = 0.33
######################## Epoch 8 - Batch 1 ########################
IDs in batch 1: tensor([2544, 4135, 1379, 2905, 3176, 3221, 2449, 3284, 1320,  533, 1076,  970,
        3437, 1429, 1459, 3492])
Epoch: 8, Training Loss: 1.13, Validation Loss: 1.10, accuracy = 0.34
######################## Epoch 9 - Batch 1 ########################
IDs in batch 1: tensor([4103, 1120,  787, 1704, 1168, 1086, 3939,  989, 2610, 1274, 1294,  797,
        1861, 2173, 3338, 3214])
Epoch: 9, Training Loss: 1.11, Validation Loss: 1.10, accuracy = 0.37
######################## Epoch 10 - Batch 1 ########################
IDs in batch 1: tensor([2648, 1563,  881,   82, 2656, 1239, 2144, 3309, 2504,   42,  510,  365,
        1343, 2873,  934,  904])
Epoch: 10, Training Loss: 1.10, Validation Loss: 1.09, accuracy = 0.39
######################## Epoch 11 - Batch 1 ########################
IDs in batch 1: tensor([2951,  880, 3363, 2839, 1525, 2087,  130, 2428, 2797, 2354, 1155, 2183,
         152, 1685, 1168, 3072])
Epoch: 11, Training Loss: 1.05, Validation Loss: 1.09, accuracy = 0.41
######################## Epoch 12 - Batch 1 ########################
IDs in batch 1: tensor([ 625, 2897, 3282, 1054, 1673, 2709, 1728, 3257, 1182, 1899,  350,  350,
        1125, 3259, 2417, 2372])
Epoch: 12, Training Loss: 1.13, Validation Loss: 1.09, accuracy = 0.41
######################## Epoch 13 - Batch 1 ########################
IDs in batch 1: tensor([1313, 2065, 3604,  568, 4222,  409, 2645, 2638, 3488, 1155, 1592, 1193,
        4234, 4086, 3123, 1331])
Epoch: 13, Training Loss: 1.09, Validation Loss: 1.09, accuracy = 0.43
######################## Epoch 14 - Batch 1 ########################
IDs in batch 1: tensor([2027, 2274, 1140,  471, 3021,  126,  434, 1626, 3256, 1822, 2891, 4124,
         202, 2855,  914,  863])
Epoch: 14, Training Loss: 1.04, Validation Loss: 1.08, accuracy = 0.45
######################## Epoch 15 - Batch 1 ########################
IDs in batch 1: tensor([2455, 3873,  819, 3782,  258, 2415, 3869, 3458, 3376, 4105, 2296, 3540,
        3180, 1855, 4037, 2022])
Epoch: 15, Training Loss: 1.08, Validation Loss: 1.08, accuracy = 0.45
######################## Epoch 16 - Batch 1 ########################
IDs in batch 1: tensor([1364, 1180, 1830, 3022, 3727,  101, 1223, 4190,  361, 2776, 1485, 2444,
        2290, 3660,  956, 3078])
Epoch: 16, Training Loss: 1.04, Validation Loss: 1.08, accuracy = 0.45
######################## Epoch 17 - Batch 1 ########################
IDs in batch 1: tensor([2228,  455, 3547,  186, 2327,   32, 2597,  736, 1252, 2489, 1660, 3392,
        3202, 3795, 3443, 4232])
Epoch: 17, Training Loss: 1.08, Validation Loss: 1.08, accuracy = 0.47
######################## Epoch 18 - Batch 1 ########################
IDs in batch 1: tensor([2755, 2561, 3400, 4187, 4190, 2156,  476, 2022, 3475,  615, 2483, 1970,
        1099, 3698, 3024,  318])
Epoch: 18, Training Loss: 1.08, Validation Loss: 1.08, accuracy = 0.47
######################## Epoch 19 - Batch 1 ########################
IDs in batch 1: tensor([3927, 3369, 3321,  225, 1317, 2388, 1408,  725, 3211, 4027,  232, 3160,
        1773, 3723,  627, 3846])
Epoch: 19, Training Loss: 1.08, Validation Loss: 1.07, accuracy = 0.48
######################## Epoch 20 - Batch 1 ########################
IDs in batch 1: tensor([3567, 3807, 1319, 3120,  342,   43, 2348, 2331, 2367,  382, 1334, 2461,
        2544, 3386, 3094, 3526])
Epoch: 20, Training Loss: 1.01, Validation Loss: 1.07, accuracy = 0.48
######################## Epoch 21 - Batch 1 ########################
IDs in batch 1: tensor([3009,  723, 1566, 1347, 3425, 2339, 4099, 2805, 3327, 2541, 2551,  785,
         658, 2098, 3898, 3133])
Epoch: 21, Training Loss: 1.09, Validation Loss: 1.07, accuracy = 0.48
######################## Epoch 22 - Batch 1 ########################
IDs in batch 1: tensor([1592, 1583, 4096, 1242, 3671,  583,  154, 1453, 3216, 4085, 4157,  259,
         340, 1901, 3921, 2405])
Epoch: 22, Training Loss: 1.11, Validation Loss: 1.07, accuracy = 0.47
######################## Epoch 23 - Batch 1 ########################
IDs in batch 1: tensor([1054, 1340,  553, 3135, 2624,  681, 3786, 2024, 4197,  213, 2618, 2842,
        1012, 2721,  160, 1981])
Epoch: 23, Training Loss: 1.04, Validation Loss: 1.07, accuracy = 0.48
######################## Epoch 24 - Batch 1 ########################
IDs in batch 1: tensor([1324, 4093,   25, 2193, 1197,  292, 2717, 1677, 3702, 2146, 2902, 3771,
        2153, 2102,  684, 2500])
Epoch: 24, Training Loss: 1.10, Validation Loss: 1.07, accuracy = 0.47
######################## Epoch 25 - Batch 1 ########################
IDs in batch 1: tensor([  42, 1923, 2745, 1732, 1234, 3040,  121, 4188,  575, 1601, 1241, 1932,
         969,  269, 1878, 1335])
Epoch: 25, Training Loss: 1.08, Validation Loss: 1.07, accuracy = 0.48
######################## Epoch 26 - Batch 1 ########################
IDs in batch 1: tensor([2399, 2589, 3875, 2964, 2126,  281, 1951, 2483, 2127, 2590, 2856,  900,
        1934, 2327, 1882, 2167])
Epoch: 26, Training Loss: 1.04, Validation Loss: 1.06, accuracy = 0.48
######################## Epoch 27 - Batch 1 ########################
IDs in batch 1: tensor([ 990, 3254, 3989, 1232,   14, 1630,  481,  623, 1349, 2867, 2870, 2833,
         484, 2109, 1224, 3369])
Epoch: 27, Training Loss: 1.05, Validation Loss: 1.06, accuracy = 0.48
######################## Epoch 28 - Batch 1 ########################
IDs in batch 1: tensor([2969, 1352,   64, 2173,  259, 2663,  985,  365, 2447,  895, 1627, 2188,
        1223,  819, 2937, 3078])
Epoch: 28, Training Loss: 0.98, Validation Loss: 1.06, accuracy = 0.49
######################## Epoch 29 - Batch 1 ########################
IDs in batch 1: tensor([2829, 3904,  970, 3536, 1121, 2631, 3992, 3156,  575, 3894,  198, 1932,
        2290, 2356, 3865, 2102])
Epoch: 29, Training Loss: 1.09, Validation Loss: 1.06, accuracy = 0.49
######################## Epoch 30 - Batch 1 ########################
IDs in batch 1: tensor([1316, 1675, 4056, 3052,  824, 1968, 2899, 2103, 2425,  874, 2636, 1833,
        3135,  337, 1473, 2067])
Epoch: 30, Training Loss: 1.05, Validation Loss: 1.06, accuracy = 0.49
######################## Epoch 31 - Batch 1 ########################
IDs in batch 1: tensor([2014, 4179, 3407, 1204, 2810,  996, 3881, 4116, 1332, 3282, 3593, 1310,
        2010, 1521, 2858, 2251])
Epoch: 31, Training Loss: 1.03, Validation Loss: 1.06, accuracy = 0.49
######################## Epoch 32 - Batch 1 ########################
IDs in batch 1: tensor([3317, 1152, 4037, 1131, 2771, 2305, 2097, 1746,  171, 1819, 1110, 2526,
        3314, 2453, 3287, 1396])
Epoch: 32, Training Loss: 1.00, Validation Loss: 1.06, accuracy = 0.48
######################## Epoch 33 - Batch 1 ########################
IDs in batch 1: tensor([2836, 3021, 1846, 3437, 2672,  933, 3747, 1216, 1096,   64, 1001, 3524,
        2045, 1233, 1352,  591])
Epoch: 33, Training Loss: 1.04, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 34 - Batch 1 ########################
IDs in batch 1: tensor([3161, 1605,  380, 2905, 3177, 3516, 1647, 2564, 3998,  637,  491, 3841,
        1249, 1985,  419, 1675])
Epoch: 34, Training Loss: 1.04, Validation Loss: 1.05, accuracy = 0.47
######################## Epoch 35 - Batch 1 ########################
IDs in batch 1: tensor([2831, 1042, 1160,  637,   37, 2802, 4016, 2045, 3187, 1580, 1085, 2710,
        2050,  787, 3991, 4032])
Epoch: 35, Training Loss: 1.03, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 36 - Batch 1 ########################
IDs in batch 1: tensor([1122, 4116, 3739, 1228,  489, 1039, 4189, 4103,  251, 3609, 1415, 3400,
        1862, 1877, 2711, 3023])
Epoch: 36, Training Loss: 1.12, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 37 - Batch 1 ########################
IDs in batch 1: tensor([3697, 4035, 3470, 1655, 3585,  726, 1365, 3185, 2016, 2363, 3190,  923,
        2304, 2364, 1751,  792])
Epoch: 37, Training Loss: 0.99, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 38 - Batch 1 ########################
IDs in batch 1: tensor([1294, 1619, 3760,   84, 4189,  933, 3244, 2065, 3815, 3862,  335, 1579,
          50, 1225, 1812, 2711])
Epoch: 38, Training Loss: 1.05, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 39 - Batch 1 ########################
IDs in batch 1: tensor([2203, 3029, 2870, 1575,  444,  415, 4222, 3543, 4006, 1985, 4003, 2213,
        1364, 3697, 1183, 2439])
Epoch: 39, Training Loss: 1.08, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 40 - Batch 1 ########################
IDs in batch 1: tensor([1948, 3131, 2725, 3767, 2524,  930,  137, 1357, 2840, 2521, 4037, 2969,
        3370, 3530, 4172, 3610])
Epoch: 40, Training Loss: 1.12, Validation Loss: 1.05, accuracy = 0.47
######################## Epoch 41 - Batch 1 ########################
IDs in batch 1: tensor([  38, 2357,  873,   72, 2052, 1575,  714, 1810,  762, 2489, 1635, 3146,
        1883, 3466,  440,  729])
Epoch: 41, Training Loss: 0.97, Validation Loss: 1.05, accuracy = 0.47
######################## Epoch 42 - Batch 1 ########################
IDs in batch 1: tensor([1234,  450, 3509, 3040, 2405,  603, 2854, 2284, 1960, 2833, 1347, 1235,
         482, 3568, 2485,  872])
Epoch: 42, Training Loss: 1.03, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 43 - Batch 1 ########################
IDs in batch 1: tensor([3114, 3711, 2400, 2535, 3577, 2322, 3989, 1283, 2802, 1292,  277,  726,
        1787, 3841,  872, 4119])
Epoch: 43, Training Loss: 1.06, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 44 - Batch 1 ########################
IDs in batch 1: tensor([2407, 2869, 4187, 2088, 1751, 3323, 3907, 1010, 2796, 1094, 3451, 3486,
        1196, 4226,  448,  661])
Epoch: 44, Training Loss: 1.13, Validation Loss: 1.04, accuracy = 0.48
######################## Epoch 45 - Batch 1 ########################
IDs in batch 1: tensor([1451, 1596, 2783, 1315, 2469, 1656, 3435, 1186, 2364, 3659, 1842, 4197,
         478, 2090, 3939, 2709])
Epoch: 45, Training Loss: 1.05, Validation Loss: 1.04, accuracy = 0.48
######################## Epoch 46 - Batch 1 ########################
IDs in batch 1: tensor([1189,  955, 2807, 4214, 1596, 1501, 4135,  512, 2103, 1082, 4126,  977,
         710, 2890, 2745, 4078])
Epoch: 46, Training Loss: 1.03, Validation Loss: 1.04, accuracy = 0.48
######################## Epoch 47 - Batch 1 ########################
IDs in batch 1: tensor([3157, 1626, 3652, 3196, 3206, 1570, 2024,   30,  441, 1961, 2991,  275,
        1482, 2398, 1679, 1310])
Epoch: 47, Training Loss: 1.05, Validation Loss: 1.04, accuracy = 0.48
######################## Epoch 48 - Batch 1 ########################
IDs in batch 1: tensor([2349, 2511, 2154, 2284,  658,  269, 3436, 1076,   10, 4223, 1232, 2645,
         400, 1030, 3436, 2287])
Epoch: 48, Training Loss: 1.04, Validation Loss: 1.04, accuracy = 0.48
######################## Epoch 49 - Batch 1 ########################
IDs in batch 1: tensor([3833, 1140, 1796, 2204, 1267, 1706, 3458, 3223, 2957, 2796, 4249,   26,
        2661, 1764, 2736,  959])
Epoch: 49, Training Loss: 0.98, Validation Loss: 1.04, accuracy = 0.49
######################## Epoch 50 - Batch 1 ########################
IDs in batch 1: tensor([ 322, 2535, 3356, 2535, 1772,  531, 3994, 4061, 2051, 1675, 1375, 1233,
        3755, 1063,  403, 2648])
Epoch: 50, Training Loss: 1.03, Validation Loss: 1.04, accuracy = 0.49
######################## Epoch 51 - Batch 1 ########################
IDs in batch 1: tensor([1085, 3630, 2317, 1645, 2144, 1456,  642, 2899, 2261,   77, 2724, 2732,
        2736, 2550, 4113, 3182])
Epoch: 51, Training Loss: 1.04, Validation Loss: 1.04, accuracy = 0.50
######################## Epoch 52 - Batch 1 ########################
IDs in batch 1: tensor([4072,  180, 1618,   41, 1835, 3818,  900, 1020,  110, 1024,  415,  454,
         483,  688, 1200, 3131])
Epoch: 52, Training Loss: 1.02, Validation Loss: 1.04, accuracy = 0.49
######################## Epoch 53 - Batch 1 ########################
IDs in batch 1: tensor([2449, 1920, 1087, 4220, 2591,  312,  665, 4179, 2517, 1186, 2541, 2926,
        3021,  207, 3920, 2562])
Epoch: 53, Training Loss: 1.03, Validation Loss: 1.03, accuracy = 0.49
######################## Epoch 54 - Batch 1 ########################
IDs in batch 1: tensor([3771, 2589,  207, 4058, 1632, 4080, 4099, 3077,  435, 3914, 1857,  505,
        2016,  908, 3925,  427])
Epoch: 54, Training Loss: 1.05, Validation Loss: 1.03, accuracy = 0.49
######################## Epoch 55 - Batch 1 ########################
IDs in batch 1: tensor([1643, 1290,  730,  247, 2317,  485, 2719, 1675, 4149, 2993,  417, 3202,
         974,  531,  127,   71])
Epoch: 55, Training Loss: 1.02, Validation Loss: 1.03, accuracy = 0.49
######################## Epoch 56 - Batch 1 ########################
IDs in batch 1: tensor([1787, 1686,  177, 2363, 1736, 3917,  909, 4051, 2924, 4249,  111, 1248,
        2010, 3478, 2663, 2618])
Epoch: 56, Training Loss: 1.00, Validation Loss: 1.03, accuracy = 0.50
######################## Epoch 57 - Batch 1 ########################
IDs in batch 1: tensor([2860, 4070, 4072,   86, 2064,  875, 4089,  362,  454, 2003, 1388,  538,
        2552, 4157, 1418,  674])
Epoch: 57, Training Loss: 1.06, Validation Loss: 1.03, accuracy = 0.50
######################## Epoch 58 - Batch 1 ########################
IDs in batch 1: tensor([1389, 1869,  900, 1345, 1567, 1748,  320, 4011, 1260, 2473,   86, 3995,
        3071, 3188, 2775, 1067])
Epoch: 58, Training Loss: 1.01, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 59 - Batch 1 ########################
IDs in batch 1: tensor([2652, 3933, 1835, 4085, 2544, 1032, 3091, 1022, 2009, 3077, 2350, 2822,
         466, 1618, 1872, 2536])
Epoch: 59, Training Loss: 1.00, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 60 - Batch 1 ########################
IDs in batch 1: tensor([1383, 2636, 2548, 1618, 2407,  997, 4010, 2258, 1996, 1056, 3478, 1311,
        3057, 1985, 3922,  355])
Epoch: 60, Training Loss: 1.01, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 61 - Batch 1 ########################
IDs in batch 1: tensor([3976, 1111, 3985,  630,  388, 1957, 4255,  863, 4000,  644, 3379, 1671,
        2664, 1745, 2664, 1287])
Epoch: 61, Training Loss: 1.03, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 62 - Batch 1 ########################
IDs in batch 1: tensor([1698, 2681, 1817,   62, 4161,   84, 2157, 4133, 2610, 2285, 2723, 2440,
         129, 3838,  936, 2031])
Epoch: 62, Training Loss: 1.03, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 63 - Batch 1 ########################
IDs in batch 1: tensor([1809, 3960,   22, 3497, 4236, 2188,  357, 1530, 2016,  321,   20,   43,
        1286, 4082, 1383, 3424])
Epoch: 63, Training Loss: 1.04, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 64 - Batch 1 ########################
IDs in batch 1: tensor([3028, 1126, 2238, 3379,  455, 2295, 3701, 1250, 2075, 2360, 3951, 2060,
        1055, 3489, 2706, 3439])
Epoch: 64, Training Loss: 0.97, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 65 - Batch 1 ########################
IDs in batch 1: tensor([4143, 1086, 3922, 3161,  427, 3875, 4127, 2125, 2982, 2413,  359,  678,
         637, 1988, 2415, 1602])
Epoch: 65, Training Loss: 0.99, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 66 - Batch 1 ########################
IDs in batch 1: tensor([1080,  164, 3521, 3787, 2755, 1911, 3904,  554, 3108, 1954, 3252,  478,
        2121, 2663, 2314, 3356])
Epoch: 66, Training Loss: 1.00, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 67 - Batch 1 ########################
IDs in batch 1: tensor([2370, 1556,  729, 1099,  148, 3948, 2049, 2304, 3632, 3475, 4245,  507,
        2092, 1996, 3570, 3742])
Epoch: 67, Training Loss: 1.09, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 68 - Batch 1 ########################
IDs in batch 1: tensor([ 173, 1312, 4257, 2249, 3798, 1633, 1372, 1698, 2119, 3593,  749, 2387,
         276, 3582, 2913, 2866])
Epoch: 68, Training Loss: 1.10, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 69 - Batch 1 ########################
IDs in batch 1: tensor([1766, 3407, 2664, 2280, 1443, 4115, 1334, 1897,  987, 1335, 1835,  417,
        1500, 3493, 1318,  389])
Epoch: 69, Training Loss: 1.02, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 70 - Batch 1 ########################
IDs in batch 1: tensor([3429, 1345,  224, 3917,  718, 2917,  483, 1047, 1982,  946, 2210, 1877,
        2285, 3306, 4253,  832])
Epoch: 70, Training Loss: 1.01, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 71 - Batch 1 ########################
IDs in batch 1: tensor([4099, 2797,   49, 2817, 1001, 1585,  494,  483, 2241, 3581, 1154, 2619,
        2638,  736, 3272,   97])
Epoch: 71, Training Loss: 0.98, Validation Loss: 1.01, accuracy = 0.53
######################## Epoch 72 - Batch 1 ########################
IDs in batch 1: tensor([1980, 4060, 2990, 4148, 2538, 3217, 4005, 2301, 3141, 2122, 2765, 1901,
        1795, 3999, 2964,  726])
Epoch: 72, Training Loss: 1.08, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 73 - Batch 1 ########################
IDs in batch 1: tensor([1599, 2732, 3564, 3908, 3265, 1859, 2977, 1355, 4099, 1065, 2574, 1292,
        2495,  628, 2770, 3486])
Epoch: 73, Training Loss: 0.99, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 74 - Batch 1 ########################
IDs in batch 1: tensor([3446, 1612,  398, 1566, 2159, 2036,  792, 1803, 3636,  352, 3530,  164,
        1497,  704,  807, 1832])
Epoch: 74, Training Loss: 0.95, Validation Loss: 1.01, accuracy = 0.51
######################## Epoch 75 - Batch 1 ########################
IDs in batch 1: tensor([ 613, 2833, 3563, 2796, 4110,  809, 1707, 4036, 3101, 1429, 4002,  796,
        3409, 4235,  186, 2871])
Epoch: 75, Training Loss: 1.09, Validation Loss: 1.01, accuracy = 0.51
######################## Epoch 76 - Batch 1 ########################
IDs in batch 1: tensor([3810, 1174, 3718, 3436, 4240,  134, 2377, 1263, 2212, 2732, 3004, 2359,
        2723, 2692,   60, 1746])
Epoch: 76, Training Loss: 0.99, Validation Loss: 1.01, accuracy = 0.51
######################## Epoch 77 - Batch 1 ########################
IDs in batch 1: tensor([3607, 2860, 2212, 3111, 3410, 4076, 1379, 1925, 3180, 3410,  701,  389,
         753, 3636, 3591, 1228])
Epoch: 77, Training Loss: 0.98, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 78 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 2682, 2366, 2446,  245, 1429, 2317, 2907,  425, 2964, 1428, 3858,
         195,  417, 4101, 3594])
Epoch: 78, Training Loss: 1.01, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 79 - Batch 1 ########################
IDs in batch 1: tensor([3203, 2353, 2088, 2595, 3503,  982,  533, 3976,  944, 2114, 1084,  206,
        4168,  219, 3913, 3958])
Epoch: 79, Training Loss: 1.07, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 80 - Batch 1 ########################
IDs in batch 1: tensor([ 287, 1476, 1053, 1937,  913, 3930, 2418, 3372, 2499, 2895, 1098, 1774,
        3102, 2072, 2150, 1020])
Epoch: 80, Training Loss: 0.92, Validation Loss: 1.00, accuracy = 0.51
######################## Epoch 81 - Batch 1 ########################
IDs in batch 1: tensor([ 136, 2161, 2086, 1482,  729, 2276,   97, 2831, 1704, 3973, 2145, 2989,
        2522, 1257, 2799, 4220])
Epoch: 81, Training Loss: 0.97, Validation Loss: 1.00, accuracy = 0.52
######################## Epoch 82 - Batch 1 ########################
IDs in batch 1: tensor([1445, 4131, 3499, 2346,  524,  315, 3252, 2956, 2301, 2552, 1004, 1379,
        1633,  133,  789,  545])
Epoch: 82, Training Loss: 1.04, Validation Loss: 1.00, accuracy = 0.52
######################## Epoch 83 - Batch 1 ########################
IDs in batch 1: tensor([3982,  484, 1979,  891, 1599, 3601, 3190,  781, 3372, 2284, 4018, 2926,
        1994, 2797,  172, 3389])
Epoch: 83, Training Loss: 0.96, Validation Loss: 1.00, accuracy = 0.52
######################## Epoch 84 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 3764, 2648, 1324, 4230, 3701, 2824,  981, 2989, 1443, 1938, 3456,
         139, 3337, 3526,   70])
Epoch: 84, Training Loss: 0.93, Validation Loss: 1.00, accuracy = 0.53
######################## Epoch 85 - Batch 1 ########################
IDs in batch 1: tensor([  88, 4198, 4038,  622, 3852, 3345,   46, 1862, 2034, 3016, 2482,  804,
         591, 4220, 1508, 2641])
Epoch: 85, Training Loss: 0.97, Validation Loss: 1.00, accuracy = 0.53
######################## Epoch 86 - Batch 1 ########################
IDs in batch 1: tensor([ 960,  740, 2587, 3465, 2104, 1178,  317, 2754,  921, 2464,  312, 1773,
        3429, 1537,   73, 2219])
Epoch: 86, Training Loss: 0.93, Validation Loss: 1.00, accuracy = 0.53
######################## Epoch 87 - Batch 1 ########################
IDs in batch 1: tensor([ 803, 3833,  963, 2094, 4187,  890, 1766,  970, 4127,  900, 1818, 2349,
         155,  620, 2837, 2794])
Epoch: 87, Training Loss: 1.04, Validation Loss: 0.99, accuracy = 0.53
######################## Epoch 88 - Batch 1 ########################
IDs in batch 1: tensor([3204, 1485, 1299,  182, 3143, 2978, 1196,  871, 3241, 2064, 1429, 1472,
        3542, 3282, 3321, 3355])
Epoch: 88, Training Loss: 0.87, Validation Loss: 0.99, accuracy = 0.54
######################## Epoch 89 - Batch 1 ########################
IDs in batch 1: tensor([2619, 3162, 2700, 3432,  623, 1221, 3728,  596, 4181, 2371, 3244,  373,
        4110,  787, 1182, 1146])
Epoch: 89, Training Loss: 0.92, Validation Loss: 0.99, accuracy = 0.54
######################## Epoch 90 - Batch 1 ########################
IDs in batch 1: tensor([1961,  913, 3006, 4056,  456, 3545, 1167, 2669, 3984,  933, 2078, 2511,
        1282,  394, 2045,  779])
Epoch: 90, Training Loss: 1.03, Validation Loss: 0.99, accuracy = 0.54
######################## Epoch 91 - Batch 1 ########################
IDs in batch 1: tensor([ 220,  161, 2833, 2170, 3882, 2339, 2703,  351, 1467, 1052, 3021,  924,
        3810, 3042,  822,   51])
Epoch: 91, Training Loss: 0.95, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 92 - Batch 1 ########################
IDs in batch 1: tensor([3407, 3142, 2793, 1526, 1379, 3312, 2591, 4264, 3777, 1802, 2038,  982,
         346, 2247, 2583, 2990])
Epoch: 92, Training Loss: 0.93, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 93 - Batch 1 ########################
IDs in batch 1: tensor([2737, 1182,  846, 3920,  645, 1266, 2031, 3749, 3553, 2856, 1143, 3020,
        1509, 2275, 1160,  971])
Epoch: 93, Training Loss: 0.98, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 94 - Batch 1 ########################
IDs in batch 1: tensor([ 361, 3878,  485, 4125, 2544, 2282, 1094, 2653,  986,  409, 1552, 1793,
        3591, 1177, 2461,  224])
Epoch: 94, Training Loss: 0.98, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 95 - Batch 1 ########################
IDs in batch 1: tensor([2185, 3488, 4113,  188, 3478, 1508, 3975,  452, 3277, 2710,   86, 3256,
        2094, 4037, 1297, 1179])
Epoch: 95, Training Loss: 0.94, Validation Loss: 0.98, accuracy = 0.55
######################## Epoch 96 - Batch 1 ########################
IDs in batch 1: tensor([ 318, 1296, 2898, 1384,  403,  276, 2945, 3441, 2414, 3112,  741, 2399,
         537,  855,  553, 1740])
Epoch: 96, Training Loss: 0.92, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 97 - Batch 1 ########################
IDs in batch 1: tensor([1480, 4087, 2539, 1229,  627,  384, 2696, 3406, 1645, 4149, 1633, 3474,
        2426, 2892,  325, 2856])
Epoch: 97, Training Loss: 0.97, Validation Loss: 0.98, accuracy = 0.57
######################## Epoch 98 - Batch 1 ########################
IDs in batch 1: tensor([1007, 1386, 1093, 2870, 1103,  899, 3132, 3318,  171, 3222, 3060, 1891,
        3632, 2973, 1784, 1935])
Epoch: 98, Training Loss: 0.96, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 99 - Batch 1 ########################
IDs in batch 1: tensor([2925, 2950, 1552, 3968, 2228, 2894, 2106, 4146,  171, 4049,  881,  795,
        3705,  388, 2326, 1795])
Epoch: 99, Training Loss: 1.04, Validation Loss: 0.97, accuracy = 0.57
######################## Epoch 100 - Batch 1 ########################
IDs in batch 1: tensor([3947, 1316, 2809, 3286, 1794, 1972, 1524, 2690,  956, 3564, 3847, 1935,
        2819,   97,  395, 4220])
Epoch: 100, Training Loss: 1.06, Validation Loss: 0.97, accuracy = 0.57
######################## Epoch 101 - Batch 1 ########################
IDs in batch 1: tensor([2182, 3549, 2740,   39, 1206, 2873, 2999, 2798, 1154, 2748, 2210, 1044,
        3176, 3343,  988, 4217])
Epoch: 101, Training Loss: 0.88, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 102 - Batch 1 ########################
IDs in batch 1: tensor([1700, 2255, 3802, 1498,  102, 3977, 3112,  315, 1147,  688, 3738,  628,
        3672,  450,  244,   88])
Epoch: 102, Training Loss: 1.03, Validation Loss: 0.97, accuracy = 0.57
######################## Epoch 103 - Batch 1 ########################
IDs in batch 1: tensor([3701, 4038, 1787, 2173, 3938, 2246, 2509, 2618, 3235,  317, 1012, 2678,
        3827, 1122,  515,  379])
Epoch: 103, Training Loss: 0.98, Validation Loss: 0.97, accuracy = 0.57
######################## Epoch 104 - Batch 1 ########################
IDs in batch 1: tensor([ 184, 1944,  964, 3669,   27,  276, 2927,  732, 3543, 2544, 1562, 1388,
        3795, 1740, 2002, 3440])
Epoch: 104, Training Loss: 0.90, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 105 - Batch 1 ########################
IDs in batch 1: tensor([1672, 2276, 2120, 1633, 1647, 2689, 2670, 2614, 3802, 2456, 1808, 1611,
        3540, 3000, 3484, 2951])
Epoch: 105, Training Loss: 0.86, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 106 - Batch 1 ########################
IDs in batch 1: tensor([1693, 3498, 3108, 3635,  776,  206, 2317, 1845,  218, 4125, 3769, 2014,
        1429, 4232, 1233,  407])
Epoch: 106, Training Loss: 0.97, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 107 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 3980, 3467,  766, 1612, 3354,  967,  390, 1343, 2869,  890, 1751,
        1402, 3870, 3349, 2470])
Epoch: 107, Training Loss: 0.98, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 108 - Batch 1 ########################
IDs in batch 1: tensor([ 100, 2284,  978,  106,  878,   41,  358, 2984, 3832, 1070, 2377, 2993,
        2723,  622, 1213, 2108])
Epoch: 108, Training Loss: 0.99, Validation Loss: 0.97, accuracy = 0.58
######################## Epoch 109 - Batch 1 ########################
IDs in batch 1: tensor([1208,  821, 3398, 2144, 3360, 4184, 2492,  981, 3426, 4103, 3010, 4058,
        3075,  226, 4101, 2973])
Epoch: 109, Training Loss: 0.99, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 110 - Batch 1 ########################
IDs in batch 1: tensor([4061,  371, 3873, 4152, 2189, 1484,  858,  195, 3382, 3261, 2807, 3803,
        1003, 1897, 3869,  462])
Epoch: 110, Training Loss: 1.04, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 111 - Batch 1 ########################
IDs in batch 1: tensor([2497, 1931, 2344, 2485,  139,  342, 1685,  279,  583, 4144, 3117, 2915,
        1990, 2961, 1644,  811])
Epoch: 111, Training Loss: 0.90, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 112 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 3109,  635, 3860,  346,  462, 1576,  970, 3674, 1961, 1463, 1740,
        3298, 4236, 1690,  959])
Epoch: 112, Training Loss: 0.96, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 113 - Batch 1 ########################
IDs in batch 1: tensor([ 623, 1818,  837, 1284, 3706, 1980, 2212, 4085, 2063, 1156, 3597,  424,
        3023, 3853, 1680, 3728])
Epoch: 113, Training Loss: 1.12, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 114 - Batch 1 ########################
IDs in batch 1: tensor([ 622, 2737, 3707,  481, 3074, 1846, 3190, 2884, 3806,  122, 1684,  459,
        3461,  968, 2553,  483])
Epoch: 114, Training Loss: 0.88, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 115 - Batch 1 ########################
IDs in batch 1: tensor([2052, 3503, 2539, 3989,  617, 1156, 1975, 2734,  103, 1685,  352, 1014,
        1065, 2157, 2171, 2459])
Epoch: 115, Training Loss: 0.79, Validation Loss: 0.96, accuracy = 0.59
######################## Epoch 116 - Batch 1 ########################
IDs in batch 1: tensor([2045,  814, 1444, 2895, 3448, 1457, 1147, 2666, 1173, 1761, 3222, 4144,
        2967, 3094, 3951, 2237])
Epoch: 116, Training Loss: 0.91, Validation Loss: 0.96, accuracy = 0.59
######################## Epoch 117 - Batch 1 ########################
IDs in batch 1: tensor([ 736, 2485, 3207, 3275, 2331, 1281,  418,  305, 4181, 4046, 1290,  536,
         155, 3356,  735, 2295])
Epoch: 117, Training Loss: 0.94, Validation Loss: 0.95, accuracy = 0.59
######################## Epoch 118 - Batch 1 ########################
IDs in batch 1: tensor([ 202, 3453,  340, 4032, 1690, 1309, 2892, 3238, 2591, 3667, 3101, 3345,
        1605,  128,  485,  644])
Epoch: 118, Training Loss: 0.86, Validation Loss: 0.95, accuracy = 0.59
######################## Epoch 119 - Batch 1 ########################
IDs in batch 1: tensor([1417, 1770, 4084,  736, 3754, 1947,  710,  683, 3975, 2839, 4107, 3699,
        1789,  409, 3183,  636])
Epoch: 119, Training Loss: 1.13, Validation Loss: 0.95, accuracy = 0.59
######################## Epoch 120 - Batch 1 ########################
IDs in batch 1: tensor([ 583,  526,  674, 1199, 2423, 3489, 2317, 1484,  306, 1979, 3234, 2781,
        3233, 1277, 2606, 1054])
Epoch: 120, Training Loss: 0.83, Validation Loss: 0.95, accuracy = 0.60
######################## Epoch 121 - Batch 1 ########################
IDs in batch 1: tensor([2516, 3408, 4215, 2429, 3949, 1420, 1976, 3146, 1175, 3547, 3789, 2760,
        1682, 2660,   21,  928])
Epoch: 121, Training Loss: 0.92, Validation Loss: 0.95, accuracy = 0.59
######################## Epoch 122 - Batch 1 ########################
IDs in batch 1: tensor([3223, 2886, 3919, 2999, 2505,  300, 3842,  557,  354, 3777, 2998, 2712,
        2167, 3424, 3886, 3628])
Epoch: 122, Training Loss: 1.06, Validation Loss: 0.95, accuracy = 0.60
######################## Epoch 123 - Batch 1 ########################
IDs in batch 1: tensor([3827, 1954, 2732, 2688,  413, 1685, 3610, 2782, 3101,  604,  459,  656,
        1084, 2414,  755, 2244])
Epoch: 123, Training Loss: 0.97, Validation Loss: 0.95, accuracy = 0.60
######################## Epoch 124 - Batch 1 ########################
IDs in batch 1: tensor([1404, 1375, 4186, 1972,  896, 4086,  137, 3707,  676, 1344, 1313,  909,
         482, 3721, 2590, 2964])
Epoch: 124, Training Loss: 1.03, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 125 - Batch 1 ########################
IDs in batch 1: tensor([2433,  825, 1010, 4217,  862, 2655, 1371,  200, 4204,   61, 2417, 2169,
         251,  177, 1977,  148])
Epoch: 125, Training Loss: 0.88, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 126 - Batch 1 ########################
IDs in batch 1: tensor([3152, 3157, 1067, 1552, 4144,  517, 3199, 1324,  910, 1221,  714, 3911,
        2561,   11,  961, 3099])
Epoch: 126, Training Loss: 0.97, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 127 - Batch 1 ########################
IDs in batch 1: tensor([2063, 1677, 1786,  160, 2327, 3029, 1899, 3128,  354, 3051, 3435, 3953,
        1255, 2998, 3333, 3589])
Epoch: 127, Training Loss: 0.85, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 128 - Batch 1 ########################
IDs in batch 1: tensor([2005, 4195, 3498, 2053, 1764, 1693,  923, 2081, 1665, 1524, 3532, 1794,
         687,  983, 2087, 1682])
Epoch: 128, Training Loss: 0.85, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 129 - Batch 1 ########################
IDs in batch 1: tensor([1170, 3934, 3496, 3980, 1871, 2996, 3057, 1045, 3544, 1882, 3790, 4179,
        4246,  726, 1942, 2681])
Epoch: 129, Training Loss: 1.08, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 130 - Batch 1 ########################
IDs in batch 1: tensor([ 955,  402, 1734, 3543, 2523, 1326,  960, 1324,  523, 1308, 1415, 2885,
        1798, 4126, 2328, 2053])
Epoch: 130, Training Loss: 1.01, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 131 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 1597, 1409, 1672, 3434, 4120, 4165, 2761, 4139, 2997, 3486, 2663,
         862, 4198, 1767,  133])
Epoch: 131, Training Loss: 0.96, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 132 - Batch 1 ########################
IDs in batch 1: tensor([ 770,   30,  977, 4263, 4117, 2031,  683,  981, 3216, 1965, 3094, 3894,
        2804,  816, 2529, 2456])
Epoch: 132, Training Loss: 0.96, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 133 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 2973, 2821, 3003, 1627,  959, 3925,   43, 3771, 2807, 3121,  518,
         918,  467, 2104, 4103])
Epoch: 133, Training Loss: 0.92, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 134 - Batch 1 ########################
IDs in batch 1: tensor([2998,  330, 2172, 3479, 1128, 2876, 2840, 2997, 1269, 1931, 3548,  363,
        2328, 2443, 2892, 2631])
Epoch: 134, Training Loss: 0.78, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 135 - Batch 1 ########################
IDs in batch 1: tensor([2286,  858, 2795, 1545, 3808, 2131, 3553, 3869, 3827, 3772, 2326,  367,
         403,  843,  752,  269])
Epoch: 135, Training Loss: 1.07, Validation Loss: 0.94, accuracy = 0.60
######################## Epoch 136 - Batch 1 ########################
IDs in batch 1: tensor([2804, 2508, 3933, 2924, 3898, 1470, 2804, 1605, 4013, 3858,  838,  255,
        3587,  393, 1128,  986])
Epoch: 136, Training Loss: 1.04, Validation Loss: 0.93, accuracy = 0.61
######################## Epoch 137 - Batch 1 ########################
IDs in batch 1: tensor([ 827, 1730, 1010, 3568,   31,  693, 1185,  601, 1134,  721, 3060, 3055,
        2056,  205, 1363,  452])
Epoch: 137, Training Loss: 1.08, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 138 - Batch 1 ########################
IDs in batch 1: tensor([ 228, 4195, 1747, 2784, 2119, 1512,  989, 3544, 1234,  876, 1445, 2871,
        4185, 2853, 1566, 3667])
Epoch: 138, Training Loss: 0.94, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 139 - Batch 1 ########################
IDs in batch 1: tensor([2826, 2451, 1482, 2519,  886, 1311,  639,  362, 1069, 1116,  184, 2446,
        1179, 3808, 1132, 1755])
Epoch: 139, Training Loss: 0.86, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 140 - Batch 1 ########################
IDs in batch 1: tensor([2070, 3421,  266, 2038,  747, 4157, 4040,  928, 3021,  864, 2040, 1166,
        3476, 2412, 2641,  108])
Epoch: 140, Training Loss: 0.90, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 141 - Batch 1 ########################
IDs in batch 1: tensor([3541, 2403, 3527, 2306,  147,  545, 1730, 3664, 1690, 1537, 3127, 1177,
        1728, 2041, 3534, 1456])
Epoch: 141, Training Loss: 0.80, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 142 - Batch 1 ########################
IDs in batch 1: tensor([1305, 3313, 3453, 1495, 2743, 4076, 3919, 1062,  126, 3342, 3349,   19,
        1877, 2349, 1980, 1429])
Epoch: 142, Training Loss: 0.93, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 143 - Batch 1 ########################
IDs in batch 1: tensor([3637,  790, 3351, 3837,  875, 2360, 1869, 3333, 3643, 1292, 4050, 1676,
        3479, 3287, 3227, 2059])
Epoch: 143, Training Loss: 0.90, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 144 - Batch 1 ########################
IDs in batch 1: tensor([3136, 2067, 3500, 4186,   59, 3789,  673, 2349, 3481,  225, 3082, 1972,
        2736, 2287, 1489, 1567])
Epoch: 144, Training Loss: 0.93, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 145 - Batch 1 ########################
IDs in batch 1: tensor([ 466, 1613, 1146, 3014, 2428, 2827, 3082,  360,  430, 2967,  796, 2312,
        2646, 3900, 4175, 1024])
Epoch: 145, Training Loss: 0.88, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 146 - Batch 1 ########################
IDs in batch 1: tensor([3903,  108, 1241, 3377, 1282, 1225, 3753, 2724, 1132,  398, 2559,   84,
        3856, 1877, 1336, 3456])
Epoch: 146, Training Loss: 0.90, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 147 - Batch 1 ########################
IDs in batch 1: tensor([1167,  872,  894, 1567,   47, 2552, 2440, 1257, 2991, 1868, 3807, 1004,
        3493, 2433, 4245, 2732])
Epoch: 147, Training Loss: 0.94, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 148 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 1677, 2568, 1218,  673, 3922, 3850, 1434, 1186, 3709, 1887, 4085,
        3695,  512, 1751, 3287])
Epoch: 148, Training Loss: 1.01, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 149 - Batch 1 ########################
IDs in batch 1: tensor([1152,  725, 2026, 1648,  651, 1141,  151, 2854, 3554,  452, 1651, 1420,
        1882, 2368, 3554, 2498])
Epoch: 149, Training Loss: 0.94, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 150 - Batch 1 ########################
IDs in batch 1: tensor([1636, 1763,  678, 1118, 1604, 2723, 1273, 2151, 3597,  991, 1773, 1418,
         588, 1081, 3475, 1456])
Epoch: 150, Training Loss: 0.87, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 151 - Batch 1 ########################
IDs in batch 1: tensor([1233, 1052, 2907,   34, 3545,  327, 1952, 2326,  628, 1098,  726, 3065,
         224, 1176, 2991,  214])
Epoch: 151, Training Loss: 0.81, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 152 - Batch 1 ########################
IDs in batch 1: tensor([3376, 3381,  229, 1160, 2391, 3604, 1521, 1195, 3275, 3098,  170, 3790,
        1161, 2143, 3985,  685])
Epoch: 152, Training Loss: 0.97, Validation Loss: 0.93, accuracy = 0.60
######################## Epoch 153 - Batch 1 ########################
IDs in batch 1: tensor([3677, 3421,  430, 1732,  308, 1405, 3995, 2489,  796, 1614,  857, 4027,
        2937, 3203, 1125, 1381])
Epoch: 153, Training Loss: 0.85, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 154 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 3843, 3851,  221, 2364,  785, 1491,   25, 2258, 1110, 2108, 3763,
        1793, 3604, 2350, 2691])
Epoch: 154, Training Loss: 0.94, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 155 - Batch 1 ########################
IDs in batch 1: tensor([1176,  403,   34, 2122, 1537,  330, 1828,  264, 1119, 3753, 4196, 2476,
        1672, 2551, 3094,   59])
Epoch: 155, Training Loss: 0.82, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 156 - Batch 1 ########################
IDs in batch 1: tensor([ 280, 3333, 3123, 4136, 1434, 3782,  281, 1170, 3643, 3028, 1811,  651,
        3105, 3994,  620, 1780])
Epoch: 156, Training Loss: 1.02, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 157 - Batch 1 ########################
IDs in batch 1: tensor([ 262,  266,  895,  994,  907,  224,   15, 3807, 1868,  769, 1881,  718,
        2051,   86, 3689, 3928])
Epoch: 157, Training Loss: 0.91, Validation Loss: 0.92, accuracy = 0.62
######################## Epoch 158 - Batch 1 ########################
IDs in batch 1: tensor([2851, 2338, 2828, 1918, 2544, 2399, 3558, 2189, 2567, 4127, 1278, 2789,
        2475, 2363, 3436,  412])
Epoch: 158, Training Loss: 0.94, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 159 - Batch 1 ########################
IDs in batch 1: tensor([2030, 1272, 3779, 3676, 2670, 2442, 2091, 3017, 3829, 2317,   98, 1885,
        3982, 1309, 3549, 2091])
Epoch: 159, Training Loss: 0.94, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 160 - Batch 1 ########################
IDs in batch 1: tensor([3963,  676, 1635, 3002, 3228, 1206, 3785,  305, 3474,  439,  437,  418,
        2228,  578, 3121, 2092])
Epoch: 160, Training Loss: 0.84, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 161 - Batch 1 ########################
IDs in batch 1: tensor([1451, 3245,  821, 1146, 1869, 1961, 4136,  809, 3030, 2046, 1954,  335,
        1604, 2506, 2091, 4205])
Epoch: 161, Training Loss: 0.78, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 162 - Batch 1 ########################
IDs in batch 1: tensor([3945, 2661,  132, 3105,  520,  897, 2353, 2046, 2326, 3352, 1154, 1083,
        4093, 1597, 1281, 4070])
Epoch: 162, Training Loss: 1.01, Validation Loss: 0.91, accuracy = 0.63
######################## Epoch 163 - Batch 1 ########################
IDs in batch 1: tensor([1354, 2833, 1137,  658, 2954,  757, 2555, 1175, 1643, 1551, 2034, 2562,
        3370, 3259, 2272, 3024])
Epoch: 163, Training Loss: 0.74, Validation Loss: 0.91, accuracy = 0.63
######################## Epoch 164 - Batch 1 ########################
IDs in batch 1: tensor([2697,  474, 2292,  688, 2823, 4087, 3826, 1302, 4146, 2014,  101, 1649,
        1925, 1281, 3111,  490])
Epoch: 164, Training Loss: 0.94, Validation Loss: 0.91, accuracy = 0.63
######################## Epoch 165 - Batch 1 ########################
IDs in batch 1: tensor([3291,  399,  401,  440, 2495,  566, 1611, 2841, 3717, 4027,  252, 1250,
        3912, 3557,  131,  193])
Epoch: 165, Training Loss: 0.96, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 166 - Batch 1 ########################
IDs in batch 1: tensor([ 134, 3739,  610, 2206, 3514, 3118,  953,  121, 1803,  183, 1440,  477,
        1602, 2960, 4125,  303])
Epoch: 166, Training Loss: 0.75, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 167 - Batch 1 ########################
IDs in batch 1: tensor([1521, 1360,  217, 3022, 1623, 1140, 2085, 2362, 2385, 3693, 2940, 3719,
        3253, 1200, 3131, 3328])
Epoch: 167, Training Loss: 0.85, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 168 - Batch 1 ########################
IDs in batch 1: tensor([1548, 1097, 3180, 1159, 1975, 2236, 1496, 2115,  683, 3830, 3509, 3254,
        4267, 2312, 3234, 1297])
Epoch: 168, Training Loss: 0.82, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 169 - Batch 1 ########################
IDs in batch 1: tensor([1491, 2425,  609, 1706,  330,  642, 1723, 4080, 3755, 1185,  726, 1015,
         841, 1512, 1777, 1004])
Epoch: 169, Training Loss: 0.91, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 170 - Batch 1 ########################
IDs in batch 1: tensor([ 590,  591,  167, 3572, 3483, 1642, 1521,   11, 1536, 1287, 3032, 2789,
        3227, 2688, 2763, 4101])
Epoch: 170, Training Loss: 0.85, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 171 - Batch 1 ########################
IDs in batch 1: tensor([2418, 2777, 2776, 2131, 4107, 3005, 3115, 2692, 2265,   27, 1471, 1976,
        3087, 3878, 2065, 1853])
Epoch: 171, Training Loss: 0.89, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 172 - Batch 1 ########################
IDs in batch 1: tensor([4240, 2292, 1086, 4140, 2595, 3676, 3407, 3490, 1568, 1693, 1551, 2004,
        4179, 1611, 2369, 1370])
Epoch: 172, Training Loss: 0.98, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 173 - Batch 1 ########################
IDs in batch 1: tensor([3721, 2016, 2828, 1321, 3433, 3540, 2126, 2173, 3407, 3082,  276, 2678,
        3178, 2796, 3618, 1899])
Epoch: 173, Training Loss: 0.92, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 174 - Batch 1 ########################
IDs in batch 1: tensor([3240, 2463, 2209, 1014, 2371, 1645, 2734, 1530,  152, 3570,  190, 2170,
        3398, 1745, 2213,  635])
Epoch: 174, Training Loss: 0.79, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 175 - Batch 1 ########################
IDs in batch 1: tensor([ 739, 1832, 1111, 3423, 2040,  894,  676, 2620, 3634, 1231, 2764,  225,
        3987, 1484, 3557,  755])
Epoch: 175, Training Loss: 0.96, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 176 - Batch 1 ########################
IDs in batch 1: tensor([3726, 2754,   19, 2322, 4143, 2567, 3850, 2717, 2135, 1281, 2166, 2839,
        3446,  202, 1870, 4110])
Epoch: 176, Training Loss: 1.00, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 177 - Batch 1 ########################
IDs in batch 1: tensor([ 828, 2295, 4154,  636, 1306,  164, 1234, 3569, 2066, 3452, 3818, 1363,
        2453, 2254, 1731, 3136])
Epoch: 177, Training Loss: 0.86, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 178 - Batch 1 ########################
IDs in batch 1: tensor([ 843, 3157, 1804,  949, 3217, 3603, 1762, 1927, 1471, 1167,  196, 1087,
        1189, 2015, 2553, 3610])
Epoch: 178, Training Loss: 0.77, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 179 - Batch 1 ########################
IDs in batch 1: tensor([3767, 2680, 2400, 2718, 3081, 2166, 3497,  820,  154, 1578, 3851, 1130,
        3654, 1628,  228, 1285])
Epoch: 179, Training Loss: 0.87, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 180 - Batch 1 ########################
IDs in batch 1: tensor([2073, 4212,  609, 3233, 4031,  526, 3392, 1657, 4124, 3947,  691, 2819,
        2014, 3572, 1096,  387])
Epoch: 180, Training Loss: 1.11, Validation Loss: 0.90, accuracy = 0.61
######################## Epoch 181 - Batch 1 ########################
IDs in batch 1: tensor([1819, 1778,  723, 1216,   85, 2496, 2788,  475, 1658, 2663, 2956, 1597,
        1388,  902,  275, 3494])
Epoch: 181, Training Loss: 0.73, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 182 - Batch 1 ########################
IDs in batch 1: tensor([4011,  213,   28,  602,  184,  399, 1904, 2272, 3363, 3203,  390,  143,
        2052, 2472, 4016, 2159])
Epoch: 182, Training Loss: 0.75, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 183 - Batch 1 ########################
IDs in batch 1: tensor([ 584, 1199, 2795, 4004, 1176, 3754, 1183, 3996,  886, 3726, 1761, 2516,
         485, 2500, 3029,  497])
Epoch: 183, Training Loss: 0.89, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 184 - Batch 1 ########################
IDs in batch 1: tensor([ 503, 1306, 2022, 1193, 1373, 1373, 2465,  239, 1710, 2189,  824, 3529,
         522, 2403,  933, 1975])
Epoch: 184, Training Loss: 0.82, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 185 - Batch 1 ########################
IDs in batch 1: tensor([1222,  904,  379, 3355, 4048, 4055, 3476, 3524, 1183, 2678,  400,  771,
        2564, 2710, 4002, 4175])
Epoch: 185, Training Loss: 0.89, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 186 - Batch 1 ########################
IDs in batch 1: tensor([2951, 1144,  968, 1349,  755, 1310,  683, 2538, 1684, 2278, 2863, 2912,
        3234, 3930, 4264, 2261])
Epoch: 186, Training Loss: 0.90, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 187 - Batch 1 ########################
IDs in batch 1: tensor([3661, 4172, 3351, 3060, 3468, 1123, 1892, 3227, 4140, 1182, 2363, 3006,
          82, 3813, 2393,  556])
Epoch: 187, Training Loss: 1.10, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 188 - Batch 1 ########################
IDs in batch 1: tensor([ 436,  290,  538, 3581, 3072, 3300,  517, 1284,   56, 2431, 3127, 3087,
        1319,  763, 4232, 2124])
Epoch: 188, Training Loss: 0.84, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 189 - Batch 1 ########################
IDs in batch 1: tensor([3604,  866, 1590, 3218, 2925, 3367, 1727, 3934, 1693,  488,  494, 1136,
        1625, 2300, 1795, 1573])
Epoch: 189, Training Loss: 0.84, Validation Loss: 0.89, accuracy = 0.63
######################## Epoch 190 - Batch 1 ########################
IDs in batch 1: tensor([3181, 2787, 3885, 3953, 2724,  481, 4057,  454,  778, 4065,  833, 1920,
        1020, 2724, 3976,  218])
Epoch: 190, Training Loss: 1.01, Validation Loss: 0.89, accuracy = 0.63
######################## Epoch 191 - Batch 1 ########################
IDs in batch 1: tensor([1315, 1003,  524, 3354, 2207, 3055, 1291,  805, 2809, 4163,  413, 4144,
         389, 2209, 1684, 1364])
Epoch: 191, Training Loss: 0.69, Validation Loss: 0.89, accuracy = 0.63
######################## Epoch 192 - Batch 1 ########################
IDs in batch 1: tensor([3032,   13, 2107, 2476, 1499, 1226,  505,  538,  915, 3806, 3810,  552,
        3583,  583,  407,  119])
Epoch: 192, Training Loss: 0.93, Validation Loss: 0.89, accuracy = 0.63
######################## Epoch 193 - Batch 1 ########################
IDs in batch 1: tensor([2332, 1383, 3746, 2823, 3885, 1299, 1911, 2286, 2617, 3351, 4186, 3506,
        4156, 2419, 1198,  672])
Epoch: 193, Training Loss: 0.96, Validation Loss: 0.88, accuracy = 0.63
######################## Epoch 194 - Batch 1 ########################
IDs in batch 1: tensor([2121, 2823,  866,   41, 1171, 4218,  965,  950,  871, 2670,  673, 2977,
        2432, 4220, 3236,  954])
Epoch: 194, Training Loss: 0.87, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 195 - Batch 1 ########################
IDs in batch 1: tensor([ 670, 1826, 1623, 3242, 1113, 2691, 1990, 2670,  219,  895,  955, 4096,
        2986, 3208,  281, 4215])
Epoch: 195, Training Loss: 0.94, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 196 - Batch 1 ########################
IDs in batch 1: tensor([2761, 4061, 3542, 1213, 2980, 1684, 2579, 3065, 3394, 1575, 2690, 4176,
        3778, 2869, 3673, 2915])
Epoch: 196, Training Loss: 1.00, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 197 - Batch 1 ########################
IDs in batch 1: tensor([ 140, 2181, 2276, 3314, 2535, 2260, 2015, 1082, 1384,  613, 3197, 2833,
          82,  411, 1083, 3656])
Epoch: 197, Training Loss: 0.74, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 198 - Batch 1 ########################
IDs in batch 1: tensor([ 609, 4097, 3468, 1153, 2674,   52, 2258, 1026, 2408, 1069, 2285, 1798,
        1977, 2098, 2078, 1312])
Epoch: 198, Training Loss: 0.70, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 199 - Batch 1 ########################
IDs in batch 1: tensor([1961, 3607, 3616, 1182,  855, 3287, 4061, 1618, 2070, 2407, 2584, 2247,
         989, 1170, 1349, 1882])
Epoch: 199, Training Loss: 0.86, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 200 - Batch 1 ########################
IDs in batch 1: tensor([2926, 1879, 2181, 3950, 2624, 2763,  679, 3216, 2538, 1575, 2286, 3553,
        3004, 1746, 1984, 1592])
Epoch: 200, Training Loss: 0.86, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 201 - Batch 1 ########################
IDs in batch 1: tensor([ 850,  193, 2431, 2741, 4125,  996, 2378, 1985,   74, 3943, 4139, 4152,
        3451, 2555,  651,  762])
Epoch: 201, Training Loss: 0.90, Validation Loss: 0.88, accuracy = 0.65
######################## Epoch 202 - Batch 1 ########################
IDs in batch 1: tensor([3038, 3732, 1948, 1233, 3415, 2306, 2476, 2901, 3317, 2746, 3256, 2960,
        1885,  477, 1128, 2938])
Epoch: 202, Training Loss: 0.87, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 203 - Batch 1 ########################
IDs in batch 1: tensor([3813, 1592, 2884, 1094, 2982, 1681, 1623,  756,  332, 2159, 4181, 3726,
        3481, 2739, 4086, 3943])
Epoch: 203, Training Loss: 1.07, Validation Loss: 0.88, accuracy = 0.64
######################## Epoch 204 - Batch 1 ########################
IDs in batch 1: tensor([ 869, 2661, 2405, 2614, 2951, 1886, 2831, 1948, 2590, 2800, 3845, 3467,
         717, 3497, 2198,  774])
Epoch: 204, Training Loss: 0.80, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 205 - Batch 1 ########################
IDs in batch 1: tensor([4223, 4117, 1132, 3025,  448,  220,  874, 2353, 1351,  425, 2938, 3843,
        3563, 2433, 1374,  893])
Epoch: 205, Training Loss: 0.83, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 206 - Batch 1 ########################
IDs in batch 1: tensor([ 244,  601, 2455, 2484, 3203,  824,  712, 2640,  894, 2069, 2247,  890,
        2154, 2526, 2010, 1853])
Epoch: 206, Training Loss: 0.71, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 207 - Batch 1 ########################
IDs in batch 1: tensor([1443, 4180,  424, 1761,  264, 3227, 2400, 4097, 2915, 1774,  531, 3740,
         411,  161, 2271, 3472])
Epoch: 207, Training Loss: 0.91, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 208 - Batch 1 ########################
IDs in batch 1: tensor([1317,  109,  738, 2149,  988, 2110, 1107, 1214, 1706,  180,  187, 3539,
         398, 3371, 3009, 2435])
Epoch: 208, Training Loss: 0.62, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 209 - Batch 1 ########################
IDs in batch 1: tensor([ 921, 2919, 2309,  974, 2146, 3494, 2144,  699, 1704,  117,  413,  830,
        1944,  449, 3843, 2863])
Epoch: 209, Training Loss: 0.84, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 210 - Batch 1 ########################
IDs in batch 1: tensor([3197, 1349, 2734, 1313,  752, 3853, 4225,  874, 1618,   39,  993, 3618,
         529, 3409, 1319, 3120])
Epoch: 210, Training Loss: 0.80, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 211 - Batch 1 ########################
IDs in batch 1: tensor([1868, 1271, 2827, 3397, 2872, 2636,  342, 3021, 2121, 3503,  455, 1438,
         131, 3131,  612, 2072])
Epoch: 211, Training Loss: 0.70, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 212 - Batch 1 ########################
IDs in batch 1: tensor([1297, 2879, 1575, 2849, 3440,  894, 1450,  378, 2993, 2248, 3141, 2482,
        3886, 2258, 1222, 3831])
Epoch: 212, Training Loss: 0.65, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 213 - Batch 1 ########################
IDs in batch 1: tensor([3345, 3534, 1781,  113, 1419, 4069, 4100, 1911,  631, 3117, 3615, 1346,
        3668,  947, 3532, 3816])
Epoch: 213, Training Loss: 0.97, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 214 - Batch 1 ########################
IDs in batch 1: tensor([1892, 2431, 2870, 1591, 1379, 2845, 2738,  402, 1376,  399,  251, 1566,
        3598, 4065,  237, 2019])
Epoch: 214, Training Loss: 0.80, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 215 - Batch 1 ########################
IDs in batch 1: tensor([ 790, 3846, 2060, 1583, 1931, 4268, 1456, 3715, 1862,  673, 1060,  482,
        2453, 1010, 1914, 3258])
Epoch: 215, Training Loss: 0.90, Validation Loss: 0.87, accuracy = 0.64
######################## Epoch 216 - Batch 1 ########################
IDs in batch 1: tensor([2295, 2940,  642, 2258, 3728, 4108, 3374, 2700, 2095, 4166, 1896, 2387,
        1984, 1991, 2092, 3764])
Epoch: 216, Training Loss: 1.11, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 217 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 2425, 2193, 2378, 2653, 2676, 3051, 3698, 4257, 1640, 2133, 3733,
         136, 3989, 3127, 1923])
Epoch: 217, Training Loss: 0.95, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 218 - Batch 1 ########################
IDs in batch 1: tensor([1951, 1376, 4062, 2331, 3275, 3313, 1445, 3268, 3000, 2783, 4158, 2748,
        1634, 2618, 3490, 1049])
Epoch: 218, Training Loss: 0.86, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 219 - Batch 1 ########################
IDs in batch 1: tensor([1962,  456, 2373, 1195, 2461, 1456, 1113,  361, 1161, 2028, 1558, 2522,
         182, 2371, 4194, 3182])
Epoch: 219, Training Loss: 0.82, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 220 - Batch 1 ########################
IDs in batch 1: tensor([1189, 3027, 3615, 2223, 2940, 2921,  732, 2452, 2091,  388,  838, 3588,
        2919, 2433, 3434, 1269])
Epoch: 220, Training Loss: 0.87, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 221 - Batch 1 ########################
IDs in batch 1: tensor([2797,  538, 2738, 3958, 1051, 2951, 1485,  351,  402, 2405, 1693,  862,
        1157, 3911, 1732,  138])
Epoch: 221, Training Loss: 0.83, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 222 - Batch 1 ########################
IDs in batch 1: tensor([1015, 1752,  368,  228, 1283, 3981, 2996, 3443, 3029, 2624,  583, 2313,
        2236,  218, 3664, 1836])
Epoch: 222, Training Loss: 0.76, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 223 - Batch 1 ########################
IDs in batch 1: tensor([2552, 1794,  279, 2290, 1397,  337,  625, 3340, 4022,  896, 2064, 2659,
         582,  786,  771,  220])
Epoch: 223, Training Loss: 0.72, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 224 - Batch 1 ########################
IDs in batch 1: tensor([ 672,  824, 2142, 1511, 2212,  739, 2363, 1555, 2739,  952, 1395, 4101,
        4251, 2559, 4056, 4236])
Epoch: 224, Training Loss: 0.84, Validation Loss: 0.86, accuracy = 0.63
######################## Epoch 225 - Batch 1 ########################
IDs in batch 1: tensor([2782, 4141, 2134, 3654, 2809, 2258, 1962, 3810,  660, 2247, 1583, 1585,
         384, 1317, 3569,  569])
Epoch: 225, Training Loss: 0.93, Validation Loss: 0.86, accuracy = 0.63
######################## Epoch 226 - Batch 1 ########################
IDs in batch 1: tensor([3821, 4246, 1213, 1176,   59,  401, 2407, 2751, 4032, 3218, 2870, 2767,
         440, 2091, 3219, 1295])
Epoch: 226, Training Loss: 0.85, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 227 - Batch 1 ########################
IDs in batch 1: tensor([3885, 3490, 1727, 2049, 2470, 1075,  815, 3044,  941, 1699, 3729, 1153,
        1458, 1385, 2344, 2410])
Epoch: 227, Training Loss: 0.84, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 228 - Batch 1 ########################
IDs in batch 1: tensor([3424, 3101, 3196, 3547,  526,  482, 2947,   25, 4101, 2257, 1574, 3607,
        1218,  365, 1287, 2155])
Epoch: 228, Training Loss: 0.84, Validation Loss: 0.86, accuracy = 0.64
######################## Epoch 229 - Batch 1 ########################
IDs in batch 1: tensor([3871,  594, 2388,  214, 2204, 2678, 3695,  472,  819, 2112,  657, 3962,
         812, 2036, 1126, 1658])
Epoch: 229, Training Loss: 0.79, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 230 - Batch 1 ########################
IDs in batch 1: tensor([ 223, 2315,  763, 2185, 1090,  900, 3822, 4253, 1774, 2013, 1308, 3935,
        2912, 1084,  994,  232])
Epoch: 230, Training Loss: 0.91, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 231 - Batch 1 ########################
IDs in batch 1: tensor([2295, 1842, 4010, 1120, 2919, 1933, 2027,   35,   26, 3192, 3873, 1866,
        4035, 3514, 1005, 4217])
Epoch: 231, Training Loss: 0.84, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 232 - Batch 1 ########################
IDs in batch 1: tensor([1501, 1916, 3072, 3551, 1627, 1853, 2653, 1122,  382, 3816,  352, 3131,
        4257,  827, 2433, 3635])
Epoch: 232, Training Loss: 0.89, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 233 - Batch 1 ########################
IDs in batch 1: tensor([3968,  186, 2855, 2894, 2379,  330, 2631,  795, 3326, 1977,  434, 1591,
         974, 3544, 1302, 1388])
Epoch: 233, Training Loss: 0.66, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 234 - Batch 1 ########################
IDs in batch 1: tensor([2826, 3935, 2420,   73,  145, 1283, 3963, 2417, 2953, 2953, 1140, 2791,
        3463, 2797, 1934, 3196])
Epoch: 234, Training Loss: 0.90, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 235 - Batch 1 ########################
IDs in batch 1: tensor([1859, 1789, 2681, 1945, 2446, 1933, 2693,  786, 1817,  875, 1846, 1085,
        3638, 2324, 2248, 2337])
Epoch: 235, Training Loss: 0.70, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 236 - Batch 1 ########################
IDs in batch 1: tensor([3935, 2412, 2681, 3697, 2081, 3911, 1846, 4030, 2873, 2748,  603, 2892,
        2440,  456, 2235,  491])
Epoch: 236, Training Loss: 1.00, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 237 - Batch 1 ########################
IDs in batch 1: tensor([2360, 2159, 2597,  338, 2967,  183, 2727,  710, 2876, 3131, 2544, 1632,
        2027, 1452, 1333, 2363])
Epoch: 237, Training Loss: 0.71, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 238 - Batch 1 ########################
IDs in batch 1: tensor([3022, 3357,  945,   26, 2002,  424, 2960, 2924,   96, 3740, 4128, 1376,
        1961,  507, 1269, 4108])
Epoch: 238, Training Loss: 0.74, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 239 - Batch 1 ########################
IDs in batch 1: tensor([4139,  350, 1123, 1540, 3591, 2902, 3548, 1185,  476, 2378, 3184,  610,
        3524, 2905, 2358,  214])
Epoch: 239, Training Loss: 0.64, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 240 - Batch 1 ########################
IDs in batch 1: tensor([4026,  804, 4005,  721, 3287,  281, 2545, 1045,  850, 4195, 3150,  575,
        1351, 3147, 2219, 3712])
Epoch: 240, Training Loss: 0.93, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 241 - Batch 1 ########################
IDs in batch 1: tensor([2876, 3018, 3056, 1031, 3083, 1950, 2425,  630,  982,  997, 3156, 1489,
        4024, 2590, 4218, 3541])
Epoch: 241, Training Loss: 0.82, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 242 - Batch 1 ########################
IDs in batch 1: tensor([ 419,  975,  609, 4267, 2776,  789, 3474, 1899, 1131,  976, 1824, 2317,
         573, 2689, 3394, 2932])
Epoch: 242, Training Loss: 0.68, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 243 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3234, 2760, 3496, 2956, 3704, 1047, 2754, 1432, 2734, 1308, 2726,
        2022,  100, 3972, 3391])
Epoch: 243, Training Loss: 0.70, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 244 - Batch 1 ########################
IDs in batch 1: tensor([4004, 3236, 2874, 2863,  970, 1011, 3554, 1234, 3680, 1817,  399, 3261,
         593, 2086, 2316, 2763])
Epoch: 244, Training Loss: 0.96, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 245 - Batch 1 ########################
IDs in batch 1: tensor([2417,  206, 1057, 3099, 2122, 3257, 1490, 1088, 1599, 3960, 1306, 2663,
        2008, 3621,  150, 2192])
Epoch: 245, Training Loss: 0.70, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 246 - Batch 1 ########################
IDs in batch 1: tensor([1712,  751, 3831, 4204,  400,   24, 4008, 4115, 3317,  904, 2112, 2828,
        3751, 3638,  870, 3176])
Epoch: 246, Training Loss: 1.07, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 247 - Batch 1 ########################
IDs in batch 1: tensor([3139, 1080, 2367, 1204, 2770, 1140, 4072, 3881, 1945,  492, 3535, 2329,
         511, 2443, 2391, 2627])
Epoch: 247, Training Loss: 0.78, Validation Loss: 0.85, accuracy = 0.66
######################## Epoch 248 - Batch 1 ########################
IDs in batch 1: tensor([ 138, 1962, 2536,   92, 1480, 3534, 3615, 1157,  396, 1799,  358, 3256,
         566, 3152, 1419, 2604])
Epoch: 248, Training Loss: 0.67, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 249 - Batch 1 ########################
IDs in batch 1: tensor([4076, 2723, 3949, 3614, 3077, 2343, 3507, 3478,  881, 2558, 2872,  474,
         635, 3914, 1537, 1373])
Epoch: 249, Training Loss: 0.78, Validation Loss: 0.84, accuracy = 0.66
######################## Epoch 250 - Batch 1 ########################
IDs in batch 1: tensor([1676,  234, 1356,  128, 2281, 2219, 3333, 1312, 1290, 2961, 1972, 1060,
         721, 3874,  399, 1344])
Epoch: 250, Training Loss: 0.70, Validation Loss: 0.84, accuracy = 0.66
######################## Epoch 251 - Batch 1 ########################
IDs in batch 1: tensor([2161,  214, 2660, 3016, 3734, 1094, 2749,   72, 1517, 3841,  327, 2167,
        3570, 3251,  295, 2382])
Epoch: 251, Training Loss: 0.72, Validation Loss: 0.84, accuracy = 0.66
######################## Epoch 252 - Batch 1 ########################
IDs in batch 1: tensor([2470,  482, 3311, 2261,  874, 1054, 1965, 3888, 2030, 3309,  594, 3630,
        2669, 1267, 2618, 1406])
Epoch: 252, Training Loss: 0.88, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 253 - Batch 1 ########################
IDs in batch 1: tensor([ 308,  961,  944, 2806, 1041, 2724, 3648, 1610,  140, 3630,   18, 3261,
        1679, 3101, 1673, 2193])
Epoch: 253, Training Loss: 0.84, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 254 - Batch 1 ########################
IDs in batch 1: tensor([2060, 3553, 3238,  870, 1274, 1548, 2099, 1097, 2954,  837,  325, 4126,
        4148, 3278, 1057, 1190])
Epoch: 254, Training Loss: 0.91, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 255 - Batch 1 ########################
IDs in batch 1: tensor([2943,  226, 2942, 3485, 1198, 3911, 3570, 3980,  827, 2451, 2356, 2671,
         724, 3663, 3435, 1413])
Epoch: 255, Training Loss: 1.03, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 256 - Batch 1 ########################
IDs in batch 1: tensor([ 693, 1214, 1351, 4232, 1057, 1260, 1641, 3567, 2122, 2954, 2793, 3592,
        2050, 2597, 1803,  805])
Epoch: 256, Training Loss: 0.81, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 257 - Batch 1 ########################
IDs in batch 1: tensor([1755, 2737, 2755, 2973, 3108, 3184,  904, 4152, 4134, 2382, 4107, 3018,
        4245,  439, 2331, 1954])
Epoch: 257, Training Loss: 0.91, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 258 - Batch 1 ########################
IDs in batch 1: tensor([3245, 2403, 1107,  989, 2567,  602, 2412, 1967, 2245, 3358,  755,    4,
        1139, 2653, 4205, 2710])
Epoch: 258, Training Loss: 0.71, Validation Loss: 0.83, accuracy = 0.66
######################## Epoch 259 - Batch 1 ########################
IDs in batch 1: tensor([1862, 3157, 3922, 2886, 2672, 2188, 1498, 3256, 1887, 2356, 1306, 1463,
        3344, 2356, 1119, 4257])
Epoch: 259, Training Loss: 0.73, Validation Loss: 0.84, accuracy = 0.66
######################## Epoch 260 - Batch 1 ########################
IDs in batch 1: tensor([2431, 3440, 2876, 3372, 1250, 2341, 1041,  306,  740, 2595,  526, 4057,
        3386,  767, 1193, 2715])
Epoch: 260, Training Loss: 0.67, Validation Loss: 0.83, accuracy = 0.66
######################## Epoch 261 - Batch 1 ########################
IDs in batch 1: tensor([1632, 3542,  384, 2663, 3353, 2604, 3467, 2599,  206, 1555, 2978, 3216,
         167, 1311, 2844, 3683])
Epoch: 261, Training Loss: 0.68, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 262 - Batch 1 ########################
IDs in batch 1: tensor([ 435, 1851, 3573, 1439, 1003,  388, 1491, 3627, 1233, 2724, 1994, 1658,
        3594, 3807, 1600, 2260])
Epoch: 262, Training Loss: 0.91, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 263 - Batch 1 ########################
IDs in batch 1: tensor([ 165, 2260, 1099, 1080,  778,  106, 3643,  596, 2203, 4235, 2304, 3933,
        3124, 2153,  265,  679])
Epoch: 263, Training Loss: 0.80, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 264 - Batch 1 ########################
IDs in batch 1: tensor([1341, 2008, 1160,  729, 2982, 2388,  699, 1224, 3111,  308, 2210, 1020,
          51, 4004,  757, 2073])
Epoch: 264, Training Loss: 0.79, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 265 - Batch 1 ########################
IDs in batch 1: tensor([2733,  596, 3417, 1862, 4126, 1032, 2815, 1828, 1038, 2640, 1899, 3777,
        2880, 3898, 1972,  590])
Epoch: 265, Training Loss: 0.85, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 266 - Batch 1 ########################
IDs in batch 1: tensor([1306, 4078, 2604, 3099, 3938, 2013, 1731, 3475,  459,  424,  909, 2732,
         491, 2304,  794, 1668])
Epoch: 266, Training Loss: 0.68, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 267 - Batch 1 ########################
IDs in batch 1: tensor([3661, 1684, 3518, 2957, 1097, 1826, 4234, 3424, 3516,  583, 1911, 2583,
        1384, 2257,   77, 2844])
Epoch: 267, Training Loss: 0.82, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 268 - Batch 1 ########################
IDs in batch 1: tensor([ 591,  989, 1458, 1340,  844, 3196, 4097, 1851, 1592, 2866, 1931, 2134,
        3018,  275, 2681, 1604])
Epoch: 268, Training Loss: 0.61, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 269 - Batch 1 ########################
IDs in batch 1: tensor([4267, 3091, 2153,  944,  143, 2974, 1650, 2169, 3947,  234,   84,  282,
        1414, 2348, 1844, 3118])
Epoch: 269, Training Loss: 0.74, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 270 - Batch 1 ########################
IDs in batch 1: tensor([3339,  776, 2159, 2137, 4011, 3598, 3883,  134, 2957, 4087,  247, 3982,
        2254,  522, 3239, 3689])
Epoch: 270, Training Loss: 0.90, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 271 - Batch 1 ########################
IDs in batch 1: tensor([2372, 2279, 3655, 2198, 3218, 3719, 3922, 2727, 1331, 2870, 3414, 2655,
         596, 1901,  644, 2034])
Epoch: 271, Training Loss: 0.96, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 272 - Batch 1 ########################
IDs in batch 1: tensor([2225, 2364, 4242,  430, 3333,  182, 1804, 1237, 1308, 1432, 2365, 3484,
        2664,  112, 3199, 2198])
Epoch: 272, Training Loss: 0.58, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 273 - Batch 1 ########################
IDs in batch 1: tensor([4038, 1285,  713, 3251,  660, 1295, 2436, 2173, 3879, 1956, 3261, 1882,
        3192, 1579, 1836, 1229])
Epoch: 273, Training Loss: 0.93, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 274 - Batch 1 ########################
IDs in batch 1: tensor([2166, 1844, 2287, 3870, 1242, 1174, 3938,  969, 1685,  407, 2244,  503,
        1722, 1993, 3353,  255])
Epoch: 274, Training Loss: 0.71, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 275 - Batch 1 ########################
IDs in batch 1: tensor([ 526,   61,  875, 3895, 1223, 3700, 3567, 3549,  886,   22, 2688, 2601,
        2690, 3537, 3113, 1976])
Epoch: 275, Training Loss: 0.87, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 276 - Batch 1 ########################
IDs in batch 1: tensor([ 533,  622, 1962,  900, 2406,  466, 2056,  426, 2053, 1777, 2044, 2605,
        4055, 1321, 1367,  970])
Epoch: 276, Training Loss: 0.75, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 277 - Batch 1 ########################
IDs in batch 1: tensor([2372, 3942, 3838, 4261, 4161, 4115, 2989,  111, 2069,  426,  566, 2758,
        3481, 1181, 3853, 1282])
Epoch: 277, Training Loss: 1.15, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 278 - Batch 1 ########################
IDs in batch 1: tensor([ 512,  991, 3182, 2784, 2664, 3764, 1830, 3458, 2425, 4228, 1819, 3190,
        4010, 1190,  786, 4199])
Epoch: 278, Training Loss: 0.76, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 279 - Batch 1 ########################
IDs in batch 1: tensor([ 552,  775, 3481, 1624,  462, 2751,  316, 2669, 1413,   42, 1056,  881,
        3065,   42,  139, 1143])
Epoch: 279, Training Loss: 0.71, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 280 - Batch 1 ########################
IDs in batch 1: tensor([3526,  975, 4018, 1897, 2905,  886, 3692, 2489, 3234, 1221, 3756, 3583,
        1009, 4265, 2739, 2807])
Epoch: 280, Training Loss: 0.89, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 281 - Batch 1 ########################
IDs in batch 1: tensor([2871,  516, 2730, 2212, 3640, 2848, 3362, 2133,  326, 2448, 3468,  582,
        2028, 1289,  207, 2967])
Epoch: 281, Training Loss: 0.75, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 282 - Batch 1 ########################
IDs in batch 1: tensor([1290, 2618, 3244, 3624, 3187,  636, 1434,  517, 3954, 2436,  263,  723,
        3598, 3765, 2550, 4018])
Epoch: 282, Training Loss: 0.81, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 283 - Batch 1 ########################
IDs in batch 1: tensor([2943, 1130, 3777, 3994, 1007,  408,  758, 3343, 2796, 1986, 4108, 3037,
        1913,  346, 3390, 4007])
Epoch: 283, Training Loss: 0.90, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 284 - Batch 1 ########################
IDs in batch 1: tensor([2431, 3303,  809, 1464, 1754, 2745, 3182, 4084, 1107, 2261, 3373, 3624,
        1031, 1295, 3831, 1271])
Epoch: 284, Training Loss: 0.68, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 285 - Batch 1 ########################
IDs in batch 1: tensor([3529, 4227, 1569, 3181, 2281,  659, 3493, 3829, 1213,  962,   56, 4158,
         409, 1388,  635, 2133])
Epoch: 285, Training Loss: 0.91, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 286 - Batch 1 ########################
IDs in batch 1: tensor([ 762, 2927, 4070, 2659,  573, 1825, 3406,  933, 1331, 2521,  200, 2687,
        4080, 1168, 3905, 2185])
Epoch: 286, Training Loss: 0.78, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 287 - Batch 1 ########################
IDs in batch 1: tensor([3700, 4222,  315, 3945, 1722, 2295, 2470, 3793, 3146, 1592, 1808,  818,
        3660,  201,  126,  555])
Epoch: 287, Training Loss: 0.93, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 288 - Batch 1 ########################
IDs in batch 1: tensor([2672,  545,  338, 1707, 2378, 1628, 3330, 2797, 3276, 2968, 2526,  234,
         218, 3099, 3711, 4266])
Epoch: 288, Training Loss: 0.72, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 289 - Batch 1 ########################
IDs in batch 1: tensor([ 145, 3252, 3987, 1968, 3178, 1042, 4115,  723, 2123,  335, 3822, 4217,
        3700, 1464, 4245, 2845])
Epoch: 289, Training Loss: 1.06, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 290 - Batch 1 ########################
IDs in batch 1: tensor([4119, 2572,  829,  371, 3503, 1372, 1439, 3398,  908, 3531, 1817, 2370,
        1224, 1566, 1935, 1216])
Epoch: 290, Training Loss: 0.60, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 291 - Batch 1 ########################
IDs in batch 1: tensor([ 909, 1937, 3839,  658, 1239, 2236, 1373, 2067, 4218, 3276,  874, 1573,
        2065, 3878, 2644,  907])
Epoch: 291, Training Loss: 0.93, Validation Loss: 0.82, accuracy = 0.65
######################## Epoch 292 - Batch 1 ########################
IDs in batch 1: tensor([2220, 2912, 2444, 2697,  926, 1850, 2209, 2885, 3071, 3255,   82, 3181,
        2764, 2141, 2044,  914])
Epoch: 292, Training Loss: 0.75, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 293 - Batch 1 ########################
IDs in batch 1: tensor([2667, 3177,  854, 1277, 3234,  904,  701, 3859, 2116, 3381, 3841,  317,
        2073,  185,  950, 3306])
Epoch: 293, Training Loss: 0.69, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 294 - Batch 1 ########################
IDs in batch 1: tensor([4189,  265, 1417, 3421,  289,  832, 1158, 2026, 1693, 3951, 1440, 2276,
        3683, 3523,  185, 3661])
Epoch: 294, Training Loss: 0.80, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 295 - Batch 1 ########################
IDs in batch 1: tensor([2950, 3338, 1754, 1647, 3101, 1266, 1649, 1530, 3110, 1328, 3677, 3426,
        3287,  987, 1860, 2617])
Epoch: 295, Training Loss: 0.67, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 296 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 1306, 1352, 1137, 2112, 2433, 4011, 1137, 2937, 1044, 1374, 2420,
         534, 3871, 3300, 2456])
Epoch: 296, Training Loss: 0.73, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 297 - Batch 1 ########################
IDs in batch 1: tensor([ 490, 2751, 2224, 1760, 2382,  314,  188,  131,  104, 3982, 3553, 3168,
        2298, 2363,  694,  575])
Epoch: 297, Training Loss: 0.63, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 298 - Batch 1 ########################
IDs in batch 1: tensor([2998, 2327,  352,  239, 2425, 2676, 3309, 3506,  755, 2326, 3424, 1404,
        2754, 1354, 2465, 2072])
Epoch: 298, Training Loss: 0.62, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 299 - Batch 1 ########################
IDs in batch 1: tensor([ 854,  684,  402, 3993, 4258, 3516, 2942, 2085, 2832,  109, 3984, 3327,
        3194, 1793, 3843, 3671])
Epoch: 299, Training Loss: 0.99, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 300 - Batch 1 ########################
IDs in batch 1: tensor([4108, 2663, 2919, 4197, 3807, 1869,  498, 3220, 4266, 2192, 1155,  111,
        1493, 1122, 1777, 2159])
Epoch: 300, Training Loss: 0.72, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 301 - Batch 1 ########################
IDs in batch 1: tensor([2195, 1810, 2234, 1363, 1636,  770, 2192,  588, 2721, 2555, 1950, 2112,
        1128,  261, 1504, 2890])
Epoch: 301, Training Loss: 0.48, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 302 - Batch 1 ########################
IDs in batch 1: tensor([4148,  852, 2715,  827, 1415,  490,  987, 3330, 3638, 2650, 2942, 1478,
        1097, 2429, 2371, 3183])
Epoch: 302, Training Loss: 0.72, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 303 - Batch 1 ########################
IDs in batch 1: tensor([3071, 3451,  199, 2603, 2661,  182, 3873, 1413, 3387, 1388, 2008,   92,
         797, 3035,  141,   11])
Epoch: 303, Training Loss: 0.58, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 304 - Batch 1 ########################
IDs in batch 1: tensor([2312,  384, 1506, 1103, 1059, 2871, 3248,  465, 3933, 2729, 2363, 1158,
         990, 1570, 1958, 1500])
Epoch: 304, Training Loss: 0.53, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 305 - Batch 1 ########################
IDs in batch 1: tensor([3545, 3151, 3150, 2870, 2572, 4004, 2655, 1032, 3533, 2383, 2038, 1916,
        3898, 2300,   31, 1467])
Epoch: 305, Training Loss: 0.73, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 306 - Batch 1 ########################
IDs in batch 1: tensor([1778, 2468, 3874, 2279, 3421,  377, 1730,  558,  171, 3147,  170, 3035,
        3563, 1153,  160, 2104])
Epoch: 306, Training Loss: 0.74, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 307 - Batch 1 ########################
IDs in batch 1: tensor([1088, 4011, 3913, 3394, 1093, 2360, 1045, 2196,  879, 2407, 1545, 4057,
        1432, 3875, 2856, 1093])
Epoch: 307, Training Loss: 0.89, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 308 - Batch 1 ########################
IDs in batch 1: tensor([3558, 1283, 3258, 2632, 1657,  507, 2385, 4026, 2137,  379, 3667, 4189,
        2149, 2678, 3527, 3839])
Epoch: 308, Training Loss: 0.81, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 309 - Batch 1 ########################
IDs in batch 1: tensor([2306, 3904, 1092,   63, 3782, 1850, 2937, 2824, 2581, 1736, 1675, 2701,
        3395, 2582, 1196, 4188])
Epoch: 309, Training Loss: 0.76, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 310 - Batch 1 ########################
IDs in batch 1: tensor([3005, 1858, 2446, 2451,  679, 1630,  378, 1521, 2246,  726, 2199, 2255,
        3065, 1760, 1708, 3453])
Epoch: 310, Training Loss: 0.52, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 311 - Batch 1 ########################
IDs in batch 1: tensor([ 245,  563,  869,  532, 1247, 1219, 2584, 2660, 3681, 2487, 2063,  661,
        2497, 2251,  120,  762])
Epoch: 311, Training Loss: 0.73, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 312 - Batch 1 ########################
IDs in batch 1: tensor([3992, 3016, 2324,  400,  988,  202, 1004, 1452, 1774, 4226,  533, 1599,
         513, 4040,  993, 3438])
Epoch: 312, Training Loss: 0.99, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 313 - Batch 1 ########################
IDs in batch 1: tensor([ 755,  276, 1302, 3241,  511,  936,  444, 3989, 2059, 3839, 2074, 2740,
        4036, 1673, 3111,  121])
Epoch: 313, Training Loss: 0.87, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 314 - Batch 1 ########################
IDs in batch 1: tensor([3241, 2352,  985, 3532, 1585,  855, 4213,  848, 1426, 3753, 3650, 2703,
         842, 3609,  725, 1248])
Epoch: 314, Training Loss: 0.96, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 315 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 2500, 1390, 4094, 4014, 4086, 1005, 2921, 1428, 3279, 1326, 1971,
        3751,  835, 2664, 1167])
Epoch: 315, Training Loss: 0.96, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 316 - Batch 1 ########################
IDs in batch 1: tensor([2026,  709,  967,  874, 4242, 1249, 2041, 3526, 3369, 1942, 2840,   98,
        1099, 1276, 2539, 3135])
Epoch: 316, Training Loss: 0.53, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 317 - Batch 1 ########################
IDs in batch 1: tensor([2836,  106,   50,  966, 1377,  785, 4110, 1380,  320, 2035, 2352, 3056,
        1613, 1255, 1651,  550])
Epoch: 317, Training Loss: 0.72, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 318 - Batch 1 ########################
IDs in batch 1: tensor([ 113, 2991, 1346, 3852,  488, 1872, 2650, 2135,  417, 3729,  438, 3528,
         437, 3028, 1136, 2841])
Epoch: 318, Training Loss: 0.87, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 319 - Batch 1 ########################
IDs in batch 1: tensor([3757, 1177, 3252, 1632,  278, 1471, 2583,  886, 1167,  400, 1180,  893,
         140, 3245, 3821,  441])
Epoch: 319, Training Loss: 0.79, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 320 - Batch 1 ########################
IDs in batch 1: tensor([4215, 2328, 3446,  604, 1281, 3261, 4180,  869, 1826, 2180, 1128, 1517,
        1657,  201, 1986, 3992])
Epoch: 320, Training Loss: 0.68, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 321 - Batch 1 ########################
IDs in batch 1: tensor([  22, 3818,  129, 1035, 3018, 4070,  588,  538, 3838, 2326, 1833, 1634,
        3223, 3792, 1448, 4226])
Epoch: 321, Training Loss: 1.06, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 322 - Batch 1 ########################
IDs in batch 1: tensor([3100,  151, 2823,  150,  937, 2432, 3589, 1841, 3523, 1734, 2125,  225,
         971, 3047,  893, 3180])
Epoch: 322, Training Loss: 0.62, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 323 - Batch 1 ########################
IDs in batch 1: tensor([2149, 2807, 2841,  466,  613, 2236, 3609,  862,  368, 1273, 3882, 3628,
        3071, 2271, 4199, 3101])
Epoch: 323, Training Loss: 0.73, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 324 - Batch 1 ########################
IDs in batch 1: tensor([1745, 4003,  694, 4118, 2942, 3695, 3786,  380,  451, 3839, 3981, 2719,
         417, 3291,  605, 2643])
Epoch: 324, Training Loss: 0.92, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 325 - Batch 1 ########################
IDs in batch 1: tensor([2169, 2281, 1139, 4033, 2234, 1297, 3714,  393, 2102, 2746,  262, 2726,
        3029, 1175, 1467,  952])
Epoch: 325, Training Loss: 0.64, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 326 - Batch 1 ########################
IDs in batch 1: tensor([3207, 3749, 3590, 3002, 2106, 1470,  497, 1589, 1604, 3127,  930, 1931,
        1585, 1110,  496, 1119])
Epoch: 326, Training Loss: 0.74, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 327 - Batch 1 ########################
IDs in batch 1: tensor([ 753,  902,  132, 3216, 1496, 1241, 2247, 3074, 1241,  631, 1229, 2171,
        2697, 2426, 1734, 1153])
Epoch: 327, Training Loss: 0.48, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 328 - Batch 1 ########################
IDs in batch 1: tensor([1957, 1285,   49, 4195, 3241, 2080, 2887, 3898, 1452,  207, 2461, 3767,
         154, 2659, 1152, 3377])
Epoch: 328, Training Loss: 0.71, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 329 - Batch 1 ########################
IDs in batch 1: tensor([ 466, 2121, 3885, 3028,  456, 1356, 3714, 2649, 2161, 1264, 1510, 3723,
        2046,  565, 3142, 2879])
Epoch: 329, Training Loss: 0.65, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 330 - Batch 1 ########################
IDs in batch 1: tensor([1935, 2306, 1977, 1921, 2414, 3878, 3603, 4035, 3166, 3087, 1455, 4097,
        3478, 2742, 3856, 1521])
Epoch: 330, Training Loss: 1.09, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 331 - Batch 1 ########################
IDs in batch 1: tensor([ 105, 1508,   73, 1497, 3157,  855, 3228,  717, 1679, 3151, 2746, 4046,
        2018, 2144, 3154, 3024])
Epoch: 331, Training Loss: 0.68, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 332 - Batch 1 ########################
IDs in batch 1: tensor([3569, 4184, 1286, 3162,  740, 1972, 2279, 4121, 2189, 3547, 2022,  359,
        2369, 2476, 1782, 2487])
Epoch: 332, Training Loss: 0.68, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 333 - Batch 1 ########################
IDs in batch 1: tensor([2773, 2328, 1219, 2235, 3634, 2024,  879, 1456, 3518, 1747, 3947, 3900,
        1836,  350, 4205,  361])
Epoch: 333, Training Loss: 0.85, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 334 - Batch 1 ########################
IDs in batch 1: tensor([ 712,  425, 1178, 2027, 4050, 1404, 2592, 3060, 2403, 3547, 1967, 1880,
        3873,  997, 2729,  491])
Epoch: 334, Training Loss: 0.82, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 335 - Batch 1 ########################
IDs in batch 1: tensor([4016, 2841, 1272,  846, 3497, 3200, 1224, 1457, 3949, 3435,  224, 1599,
        3386, 1779, 3634, 3429])
Epoch: 335, Training Loss: 0.70, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 336 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 1228, 3376, 4190, 4256,  211, 3219, 4268, 1970, 2030, 2978,   50,
         790, 2019,  881, 1279])
Epoch: 336, Training Loss: 0.70, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 337 - Batch 1 ########################
IDs in batch 1: tensor([1330, 4126, 1977, 1684,  730, 1231, 1967, 1381, 1274, 2504, 3049, 1488,
        3831, 3060, 1774, 3570])
Epoch: 337, Training Loss: 0.85, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 338 - Batch 1 ########################
IDs in batch 1: tensor([3839,  632, 2443,  372, 1925, 2715, 3226, 3765,  191,  440, 4033, 2783,
        2142, 3298, 2640, 3951])
Epoch: 338, Training Loss: 0.86, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 339 - Batch 1 ########################
IDs in batch 1: tensor([4242, 2690,  818, 3447,  362, 3478, 1346, 1147, 2157, 1685, 2782, 1634,
        3262, 1802,  201, 4174])
Epoch: 339, Training Loss: 0.71, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 340 - Batch 1 ########################
IDs in batch 1: tensor([2535, 1102, 2535,  441, 2600, 2572, 2856, 4080, 2538, 2559, 3075, 3234,
         530, 3974, 2284,  173])
Epoch: 340, Training Loss: 0.80, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 341 - Batch 1 ########################
IDs in batch 1: tensor([3810, 4017, 2772, 4125, 1482, 3490, 3795, 3029, 3168, 2341, 1665, 3879,
        2568,  390,  384, 1937])
Epoch: 341, Training Loss: 0.96, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 342 - Batch 1 ########################
IDs in batch 1: tensor([1143, 3010,   56, 1891,  946,  586,  186,  214, 2260, 1558, 1047, 3501,
        1363, 2897, 2841, 1736])
Epoch: 342, Training Loss: 0.54, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 343 - Batch 1 ########################
IDs in batch 1: tensor([2798, 1619, 2223, 3833, 1634, 2306,  489, 2674, 4188, 1576, 3323, 1271,
        1568, 1322,  794, 1439])
Epoch: 343, Training Loss: 0.62, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 344 - Batch 1 ########################
IDs in batch 1: tensor([2203, 3105, 1506,  792,  835, 3567, 2097,  826, 3401, 2954, 1702,  295,
        2223, 2780, 4082, 4048])
Epoch: 344, Training Loss: 0.81, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 345 - Batch 1 ########################
IDs in batch 1: tensor([1069, 3256, 2402,  511, 2151, 2773, 3047,  820, 2213,  148, 1965, 4136,
        2579, 2718, 1853, 1050])
Epoch: 345, Training Loss: 0.71, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 346 - Batch 1 ########################
IDs in batch 1: tensor([2891, 3152, 1458,   82,  196,   86, 3395, 3009, 3092,  250, 2542, 1178,
        2619, 2414, 2743, 1937])
Epoch: 346, Training Loss: 0.62, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 347 - Batch 1 ########################
IDs in batch 1: tensor([1395, 1409, 4255,  379, 3925, 1158, 1334, 1346, 3244,   35,  688, 1779,
        1526, 3490, 2271, 1390])
Epoch: 347, Training Loss: 0.74, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 348 - Batch 1 ########################
IDs in batch 1: tensor([2115,  133,  787,   61, 3168,  777, 1642, 3674, 4227, 2521, 1087,  512,
         730, 3635, 2111, 2954])
Epoch: 348, Training Loss: 0.84, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 349 - Batch 1 ########################
IDs in batch 1: tensor([3057, 3481, 3256, 4126,  893, 3860,  896, 3143,  346,  854,  769,  749,
        2835, 1698, 3098, 2839])
Epoch: 349, Training Loss: 0.61, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 350 - Batch 1 ########################
IDs in batch 1: tensor([ 609, 3908, 4011, 2761,  583,  145, 1546,  582, 2232, 1335, 1056,  497,
        4027, 3698, 1957, 2252])
Epoch: 350, Training Loss: 0.84, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 351 - Batch 1 ########################
IDs in batch 1: tensor([3073, 1583, 3982, 1381, 3443, 1062, 1278, 3334,  953, 1732,  879, 1299,
        1840,  394, 2189, 2234])
Epoch: 351, Training Loss: 0.64, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 352 - Batch 1 ########################
IDs in batch 1: tensor([1842, 2081, 1464, 2797,  436,  498, 1241, 2426, 2485,  733, 1784, 1953,
        1284,  193,  724, 2447])
Epoch: 352, Training Loss: 0.51, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 353 - Batch 1 ########################
IDs in batch 1: tensor([3744, 2366,  466, 1189,  890, 2870, 1247,  919, 1012, 1185, 2522, 3239,
        1980, 2670, 1852, 1685])
Epoch: 353, Training Loss: 0.55, Validation Loss: 0.80, accuracy = 0.64
######################## Epoch 354 - Batch 1 ########################
IDs in batch 1: tensor([1493, 1294, 1143, 2898, 4257, 1418, 2185,  264, 4135, 1134, 2391, 3831,
        3463, 1862,  472,  787])
Epoch: 354, Training Loss: 0.67, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 355 - Batch 1 ########################
IDs in batch 1: tensor([1663, 1337,  738, 1155, 3161, 1374, 2371, 1851, 2410, 2153, 1052,  537,
        3354, 3194, 2812, 2226])
Epoch: 355, Training Loss: 0.49, Validation Loss: 0.80, accuracy = 0.64
######################## Epoch 356 - Batch 1 ########################
IDs in batch 1: tensor([3558,   47,  830, 3729, 3123,  792, 3583, 2196, 3424, 4165, 2545, 3642,
        2989,  261, 3956, 1163])
Epoch: 356, Training Loss: 1.07, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 357 - Batch 1 ########################
IDs in batch 1: tensor([1278, 1487,  605, 2746, 1200, 2378, 1690, 3956, 1548, 1508, 3071, 1877,
        1953,  105, 3272, 1423])
Epoch: 357, Training Loss: 0.62, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 358 - Batch 1 ########################
IDs in batch 1: tensor([ 758, 4027,  779, 4015,   25, 3891,  556, 3683, 3841, 2034, 3437, 1567,
         150,  223,  762, 3159])
Epoch: 358, Training Loss: 1.01, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 359 - Batch 1 ########################
IDs in batch 1: tensor([4114, 3121, 2365, 2461, 3367, 4138, 2095, 3713,  884, 3044,  445, 1396,
        1334,  522, 1877, 2868])
Epoch: 359, Training Loss: 0.84, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 360 - Batch 1 ########################
IDs in batch 1: tensor([2218, 2575, 1562,  134, 3919, 2917, 3101, 2522, 4186, 2595, 1938, 2499,
        2400,  881,  892,  522])
Epoch: 360, Training Loss: 0.70, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 361 - Batch 1 ########################
IDs in batch 1: tensor([2437, 1647,  992, 1043, 2220, 2274, 1490, 3040, 1345, 3371, 2776, 2473,
        1872,  167, 3856, 4140])
Epoch: 361, Training Loss: 0.76, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 362 - Batch 1 ########################
IDs in batch 1: tensor([ 112,  888,  191,  134, 2499,  481, 2577, 3042, 1954, 1343, 1101, 3190,
        4122, 2578,  717, 3271])
Epoch: 362, Training Loss: 0.70, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 363 - Batch 1 ########################
IDs in batch 1: tensor([4117, 3036, 3912,  224, 1585, 2207, 1599, 2271, 1045, 2015, 2137, 2663,
         603, 2537,  459,  721])
Epoch: 363, Training Loss: 0.60, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 364 - Batch 1 ########################
IDs in batch 1: tensor([3632, 1141, 1387,  512, 3159, 3234,  816, 1156,  223,  989,  355, 2367,
        1469, 3997, 1553,  338])
Epoch: 364, Training Loss: 0.83, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 365 - Batch 1 ########################
IDs in batch 1: tensor([3119, 2483, 4080, 1661,  996,  724, 1506, 3429, 4058,  531,  401, 1062,
        1804, 3764, 1702, 2510])
Epoch: 365, Training Loss: 0.76, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 366 - Batch 1 ########################
IDs in batch 1: tensor([1798, 2378, 2674, 3120, 1177, 3693, 2183, 3540, 1504, 1263, 1421,  943,
        1010,  180, 3563,  441])
Epoch: 366, Training Loss: 0.86, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 367 - Batch 1 ########################
IDs in batch 1: tensor([2036, 3537, 4128, 1842,  482, 3590,  258, 1490, 1592, 3480, 3252, 1208,
        2666, 1225, 2791, 2035])
Epoch: 367, Training Loss: 0.76, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 368 - Batch 1 ########################
IDs in batch 1: tensor([2740,  523, 2776, 3527, 4067, 1067, 2600,  225, 3856, 3683, 1140,  452,
        1385, 1060,  729,  109])
Epoch: 368, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 369 - Batch 1 ########################
IDs in batch 1: tensor([ 129, 1141,  838, 1623, 1306, 1633, 2135, 3395, 3098, 3499,  138, 3262,
        4140, 3547, 3987, 3990])
Epoch: 369, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 370 - Batch 1 ########################
IDs in batch 1: tensor([3255, 1810, 1965,  635, 3128, 1781, 3661, 2350, 1896, 3075, 1880, 1942,
         878, 2711, 3661, 2156])
Epoch: 370, Training Loss: 0.93, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 371 - Batch 1 ########################
IDs in batch 1: tensor([3598, 2377,  491,  295, 2671, 1803, 1590,  627, 3458, 2280, 1278, 1250,
        2936, 2717, 3630,  173])
Epoch: 371, Training Loss: 0.56, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 372 - Batch 1 ########################
IDs in batch 1: tensor([1171, 2676, 1436, 2718, 3728, 2548, 2476, 3376,  946, 2453, 3740, 3772,
        2821, 1087,  395, 1811])
Epoch: 372, Training Loss: 1.06, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 373 - Batch 1 ########################
IDs in batch 1: tensor([1833, 3664, 1777, 3261, 3905,  149,  907, 1157, 3751, 2595, 3410, 1093,
        3183, 3643, 1389, 3131])
Epoch: 373, Training Loss: 0.75, Validation Loss: 0.76, accuracy = 0.68
Save best Model_1 @ epoch 373 acc: 0.6834701055099648
Email sent!
######################## Epoch 374 - Batch 1 ########################
IDs in batch 1: tensor([ 893, 1283, 1235, 2212,  961, 3113, 2078, 1944, 2458, 1639, 3157, 2074,
        3913, 3544, 1396, 3927])
Epoch: 374, Training Loss: 0.85, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 375 - Batch 1 ########################
IDs in batch 1: tensor([4170, 2382, 1216, 1055,  739,  109, 3035, 1802, 1218, 1761, 2296, 1193,
        1328, 1451, 1853, 2350])
Epoch: 375, Training Loss: 0.62, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 376 - Batch 1 ########################
IDs in batch 1: tensor([2463, 1421, 2682, 1295,  991, 1727, 1731,  546,  526, 3235, 4037,  201,
        1921, 3950, 4135,  229])
Epoch: 376, Training Loss: 0.77, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 377 - Batch 1 ########################
IDs in batch 1: tensor([1180, 1174, 4065,  546, 3139, 3970, 2018, 1306, 3207, 2036, 2819, 1193,
        2831, 1927, 2765,  470])
Epoch: 377, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 378 - Batch 1 ########################
IDs in batch 1: tensor([1178,  196, 2794, 1410,  103, 1961, 1251,  390, 1363,  105,  921, 1845,
        3996, 4113, 3154,  212])
Epoch: 378, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 379 - Batch 1 ########################
IDs in batch 1: tensor([ 977,  409,  111, 2350,  691, 4077, 2050,  909, 2805, 1160, 3154, 1951,
        1680, 4039,  106,  946])
Epoch: 379, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 380 - Batch 1 ########################
IDs in batch 1: tensor([ 207, 1072,  455, 1567, 4072, 2182, 2661,  224, 2539, 2996, 3692, 2977,
        1316, 2426, 3003, 2121])
Epoch: 380, Training Loss: 0.63, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 381 - Batch 1 ########################
IDs in batch 1: tensor([3298, 1361,   43, 1428, 3038, 1332, 1925, 1869, 1632, 4014,  721, 4065,
        4157, 2659,  266,  258])
Epoch: 381, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.69
Save best Model_1 @ epoch 381 acc: 0.6858147713950762
Email sent!
######################## Epoch 382 - Batch 1 ########################
IDs in batch 1: tensor([3342, 3289,  854, 1866, 4095, 1010, 3262, 2540, 2223,  398,  437, 3698,
        1760, 2956, 4026,   88])
Epoch: 382, Training Loss: 0.66, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 383 - Batch 1 ########################
IDs in batch 1: tensor([1777, 1979, 2827, 2841, 1911, 2489, 1728, 1458,  628, 3683, 2619,  531,
         933, 1671,  704,  978])
Epoch: 383, Training Loss: 0.56, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 384 - Batch 1 ########################
IDs in batch 1: tensor([3838, 4051,  238, 3400,  834, 3112, 1082,  886, 3217, 3827, 2306,  902,
        1763,  574, 1384, 1200])
Epoch: 384, Training Loss: 0.86, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 385 - Batch 1 ########################
IDs in batch 1: tensor([3243, 3423, 2730, 3038, 3914, 1464, 1281, 1330,  775, 2008, 3100, 2238,
         348,  688, 2324, 1290])
Epoch: 385, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 386 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 2832, 4154, 1003, 3627, 1379, 3507, 1727,  413,  851, 2159, 2284,
        1916, 2860, 1489, 3676])
Epoch: 386, Training Loss: 0.69, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 387 - Batch 1 ########################
IDs in batch 1: tensor([ 851,  238, 2320,   43, 2749, 2967, 3570,  532, 2371, 2840, 3689, 1163,
        3786, 2592, 1512, 2426])
Epoch: 387, Training Loss: 0.81, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 388 - Batch 1 ########################
IDs in batch 1: tensor([ 723, 3672, 2104, 1944, 2795, 1845, 1199, 2592, 2781,  265,  749, 4062,
        1955,   13, 4032, 2154])
Epoch: 388, Training Loss: 0.78, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 389 - Batch 1 ########################
IDs in batch 1: tensor([3974, 2945, 3938, 3156, 1385,  545, 3291, 2226, 1384, 1384,  832, 4222,
        2526,  812,  451, 2489])
Epoch: 389, Training Loss: 0.83, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 390 - Batch 1 ########################
IDs in batch 1: tensor([ 612, 3133, 1196, 1555, 2327, 2993, 3084, 2574,  196, 2331, 3349, 2652,
        1900,  265, 1849, 3283])
Epoch: 390, Training Loss: 0.62, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 391 - Batch 1 ########################
IDs in batch 1: tensor([1292,  777, 1101, 2553, 3996,  518, 2869, 3179, 4174, 2780, 3831,  907,
         871, 2446, 2261,  878])
Epoch: 391, Training Loss: 0.77, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 392 - Batch 1 ########################
IDs in batch 1: tensor([2390, 3816, 3533, 2653,  332, 2080, 2398,  858,   24, 1942, 2284, 3997,
        3878,  187, 4110, 2542])
Epoch: 392, Training Loss: 0.91, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 393 - Batch 1 ########################
IDs in batch 1: tensor([3367, 1984,  819, 2839, 3428, 2030, 1726, 2526, 2110, 1139,  962,   98,
        1932, 2805, 2631,  680])
Epoch: 393, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 394 - Batch 1 ########################
IDs in batch 1: tensor([ 977, 3261, 1977, 2990, 2937, 2225, 1982, 1328, 3922, 1580, 1173, 2859,
        3879, 2710, 2717, 1144])
Epoch: 394, Training Loss: 0.66, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 395 - Batch 1 ########################
IDs in batch 1: tensor([2755,  839,  522, 2107, 2466, 2475,  749, 4048, 4119, 1341, 2505, 1762,
         306,  481, 2773, 2060])
Epoch: 395, Training Loss: 0.60, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 396 - Batch 1 ########################
IDs in batch 1: tensor([ 858,  976, 4072,  321, 1299, 2772, 2610, 1444, 1344, 1331, 3740, 1044,
        2984, 3894, 4082, 3952])
Epoch: 396, Training Loss: 0.84, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 397 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 3156,  482,  341,  900, 3039, 1845, 1766, 3084, 3507,  586,  223,
        4035, 2836, 1072, 2428])
Epoch: 397, Training Loss: 0.57, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 398 - Batch 1 ########################
IDs in batch 1: tensor([2450, 1375, 1720, 3804, 3241, 3963,  950, 3544, 2577, 2343,  965, 3995,
        2107,  315, 1896, 3017])
Epoch: 398, Training Loss: 0.72, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 399 - Batch 1 ########################
IDs in batch 1: tensor([ 924, 4013, 2519, 2448,  739,  218, 2966, 2078, 3739,  857, 2178, 1204,
         829, 4075, 2648, 1341])
Epoch: 399, Training Loss: 0.67, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 400 - Batch 1 ########################
IDs in batch 1: tensor([1794, 1752, 1842,  942, 1540, 1346, 1595, 1999, 1367, 2235, 4108, 1174,
        3051, 3190, 3717, 2274])
Epoch: 400, Training Loss: 0.88, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 401 - Batch 1 ########################
IDs in batch 1: tensor([2913, 1030, 3798, 3771,  182, 3308,  375, 2761, 1185, 4181, 3764, 3792,
        2660, 2180,  102, 3488])
Epoch: 401, Training Loss: 0.95, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 402 - Batch 1 ########################
IDs in batch 1: tensor([1308, 1003, 2450, 1937, 2883, 3470, 3053,  376, 2660, 3614, 3473, 1208,
        2621, 3176, 3267, 2924])
Epoch: 402, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 403 - Batch 1 ########################
IDs in batch 1: tensor([4163, 1733,  324, 1364, 3914, 3440,  532, 3404, 1828, 2177, 3376, 1960,
        3283, 3407, 1317, 4062])
Epoch: 403, Training Loss: 0.70, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 404 - Batch 1 ########################
IDs in batch 1: tensor([3968, 2440, 3148, 3604, 1976, 3925, 3543, 2064, 4073, 2011, 1942,  133,
        1120, 1128, 4168, 3446])
Epoch: 404, Training Loss: 0.94, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 405 - Batch 1 ########################
IDs in batch 1: tensor([1489, 3162, 1409,  843, 2449,  213, 3291, 1297, 1024, 1299, 2050, 1999,
        1242, 1963, 3826, 2018])
Epoch: 405, Training Loss: 0.53, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 406 - Batch 1 ########################
IDs in batch 1: tensor([ 953, 1160, 3456, 1504, 3094, 3908, 3998, 3374,  758, 3688,  426, 3806,
        2247,  284, 1530,  566])
Epoch: 406, Training Loss: 0.86, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 407 - Batch 1 ########################
IDs in batch 1: tensor([2734, 1872,  789, 2848, 3600, 2458, 1419, 4000, 3078, 1707, 1500,  758,
        4108,  482, 3926,  427])
Epoch: 407, Training Loss: 0.92, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 408 - Batch 1 ########################
IDs in batch 1: tensor([2668, 3846, 1439, 1355, 2429, 4037,  612, 2448,  937, 2484, 1163, 2833,
        1212, 3648, 3398,   26])
Epoch: 408, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 409 - Batch 1 ########################
IDs in batch 1: tensor([2004, 3498, 1090, 1020, 1396,  430, 2153, 2649, 2036, 3900, 1296, 2957,
        1909, 2907, 2794, 3200])
Epoch: 409, Training Loss: 0.77, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 410 - Batch 1 ########################
IDs in batch 1: tensor([2736, 1381, 3568, 1589,  602, 1306, 1282,  942, 2641,   43, 3440, 2976,
        2936, 4040,  161, 2451])
Epoch: 410, Training Loss: 0.68, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 411 - Batch 1 ########################
IDs in batch 1: tensor([1325,  602, 2712, 3374,  662, 3465,  766, 1574, 2961,  556, 2940, 3052,
        3728, 3368, 1161, 2451])
Epoch: 411, Training Loss: 0.51, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 412 - Batch 1 ########################
IDs in batch 1: tensor([ 184, 1984, 2603, 2671, 2485, 2646, 1886, 2683, 4213, 2883,  492, 1426,
        1650, 3706,  985,  978])
Epoch: 412, Training Loss: 0.47, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 413 - Batch 1 ########################
IDs in batch 1: tensor([3628, 3728, 1445, 2359, 3710, 1476,  688, 4224,  829, 3459, 2449, 1870,
        1025,  809,  338, 3150])
Epoch: 413, Training Loss: 0.63, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 414 - Batch 1 ########################
IDs in batch 1: tensor([3253, 4080,  986,  674, 4225, 1471,  887, 3239, 2250, 3808, 4037, 3338,
        3943, 1204, 4242, 2114])
Epoch: 414, Training Loss: 1.02, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 415 - Batch 1 ########################
IDs in batch 1: tensor([3254, 1482, 3121, 1097, 2151, 1334, 3973, 1270, 3712, 4121, 3226, 1295,
        3356, 1218, 2489, 2891])
Epoch: 415, Training Loss: 0.78, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 416 - Batch 1 ########################
IDs in batch 1: tensor([2398,  471, 2690, 2674, 3493, 2973, 1975, 3404, 1272, 3593, 3330,  394,
         622,  126,  207, 2483])
Epoch: 416, Training Loss: 0.52, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 417 - Batch 1 ########################
IDs in batch 1: tensor([  42, 2349,  884, 2056, 2823,  834, 3407, 3721, 1846,  963,  539, 3675,
         149, 4070, 3051,  356])
Epoch: 417, Training Loss: 0.71, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 418 - Batch 1 ########################
IDs in batch 1: tensor([2504,  966, 4016, 3233, 2693, 2292, 1563,  872, 3972,  625, 2148, 4226,
         106, 2198, 3525,  887])
Epoch: 418, Training Loss: 0.69, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 419 - Batch 1 ########################
IDs in batch 1: tensor([2723, 4128, 1335, 1174, 3806, 3500, 3878, 2260,  290, 4108, 3754,   57,
          78, 2671, 4033, 3630])
Epoch: 419, Training Loss: 1.00, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 420 - Batch 1 ########################
IDs in batch 1: tensor([2984, 3497, 2116, 2629, 1484, 3497, 2418,  781, 3429,  763,  120,  318,
        3922, 3223,  135, 1821])
Epoch: 420, Training Loss: 0.91, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 421 - Batch 1 ########################
IDs in batch 1: tensor([ 403, 1089, 4188, 2148,  136,  488, 3073, 3355, 3451, 1976, 1195, 2498,
        1511, 1663,  260, 4100])
Epoch: 421, Training Loss: 0.70, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 422 - Batch 1 ########################
IDs in batch 1: tensor([ 214,  822, 2627, 2150,  187, 3321,  884,  220, 2540, 3368, 1623, 1510,
        4107,  419, 2367, 4126])
Epoch: 422, Training Loss: 0.51, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 423 - Batch 1 ########################
IDs in batch 1: tensor([3455, 1737, 3265, 2822, 2669, 3299,  444, 4113, 3398,   71,  651, 3621,
        1452, 3535,  520, 2323])
Epoch: 423, Training Loss: 0.69, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 424 - Batch 1 ########################
IDs in batch 1: tensor([2364,  928,   13, 1974, 2497,   44, 1887, 3374, 1968, 2328, 2103, 1842,
        1453, 4161,  470, 2574])
Epoch: 424, Training Loss: 0.66, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 425 - Batch 1 ########################
IDs in batch 1: tensor([3055, 2291, 1543,  541, 3706,  196, 3069, 3832, 3539, 1035,  195,  471,
         835, 3755,  578, 1352])
Epoch: 425, Training Loss: 0.84, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 426 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3246, 1844, 2627,  282,  985, 3133, 1834,  181, 1746, 3549, 2563,
        2305, 3926, 3994, 3415])
Epoch: 426, Training Loss: 0.75, Validation Loss: 0.75, accuracy = 0.69
Save best Model_1 @ epoch 426 acc: 0.6869871043376319
Email sent!
######################## Epoch 427 - Batch 1 ########################
IDs in batch 1: tensor([4218, 1488, 4218, 1601, 1575, 1451,  758, 2997,  344, 3374, 3239, 1558,
        2645, 3542,  917, 1796])
Epoch: 427, Training Loss: 0.53, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 428 - Batch 1 ########################
IDs in batch 1: tensor([1007, 3310,  306, 3498, 1545, 1823, 2943, 4117, 2258, 1884, 3370, 2135,
        3934,  167, 1443, 3810])
Epoch: 428, Training Loss: 0.68, Validation Loss: 0.75, accuracy = 0.69
Save best Model_1 @ epoch 428 acc: 0.6881594372801876
Email sent!
######################## Epoch 429 - Batch 1 ########################
IDs in batch 1: tensor([ 407, 1949, 1910,  635, 3985, 2190, 4008, 3471, 3908, 2462,  726, 3078,
         779, 1573,  132, 2538])
Epoch: 429, Training Loss: 0.71, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 430 - Batch 1 ########################
IDs in batch 1: tensor([4190, 3975, 1580,  435,  651, 1657,  491,  274, 2113, 2506, 1948,  132,
         923, 3968, 3557, 3499])
Epoch: 430, Training Loss: 0.90, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 431 - Batch 1 ########################
IDs in batch 1: tensor([2218,  672, 2144, 3018, 2661, 3704, 4185,  263, 2018, 2072, 1895, 1973,
         991, 2891, 1375, 3999])
Epoch: 431, Training Loss: 0.69, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 432 - Batch 1 ########################
IDs in batch 1: tensor([1850, 3993, 1231, 1319, 3254, 2202,  554, 2575,  636, 4253, 4189, 3710,
        1457, 1780, 3860, 3313])
Epoch: 432, Training Loss: 0.79, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 433 - Batch 1 ########################
IDs in batch 1: tensor([2970,  361, 3300, 4108, 3726, 3698,   28, 2331, 1081,  907, 2793, 2075,
        4026, 1140, 1200, 4099])
Epoch: 433, Training Loss: 0.79, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 434 - Batch 1 ########################
IDs in batch 1: tensor([3648, 1389, 1390, 3647, 3554,  465, 3553, 2449,  384, 1845, 1645, 1066,
        4032,  662,  866, 2782])
Epoch: 434, Training Loss: 0.95, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 435 - Batch 1 ########################
IDs in batch 1: tensor([1886,  214, 1089, 1111, 2334, 2234,  596, 1728, 2563, 2245, 2499,  727,
        1340, 3200, 2346, 2529])
Epoch: 435, Training Loss: 0.49, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 436 - Batch 1 ########################
IDs in batch 1: tensor([2126, 2542, 4128,  752, 3812, 3480, 2660,  890, 1294, 2148,  544, 2876,
        3630, 2760, 2146, 4110])
Epoch: 436, Training Loss: 0.60, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 437 - Batch 1 ########################
IDs in batch 1: tensor([2086, 4056, 1979, 3424, 3069, 2734,  627, 1601, 1826,  467, 3527, 1965,
        1179, 3240, 1668, 2026])
Epoch: 437, Training Loss: 0.62, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 438 - Batch 1 ########################
IDs in batch 1: tensor([2462, 1844, 1256, 1508, 1732, 3997, 1391, 1218, 1851, 1510, 4213, 2196,
        2260, 1321, 2135,  206])
Epoch: 438, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.69
Save best Model_1 @ epoch 438 acc: 0.694021101992966
Email sent!
######################## Epoch 439 - Batch 1 ########################
IDs in batch 1: tensor([2854, 4075, 4215, 1026,  376,  620, 3637, 2137, 3289, 3025, 2242, 3032,
        1473, 3492, 3932,  640])
Epoch: 439, Training Loss: 0.84, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 440 - Batch 1 ########################
IDs in batch 1: tensor([ 305, 3438,  565, 3087, 2151,  989,   71,  499, 2667, 4053, 2461,  758,
        2563, 3246, 3659, 3920])
Epoch: 440, Training Loss: 0.66, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 441 - Batch 1 ########################
IDs in batch 1: tensor([ 575,  602, 4146, 2455, 2017,   41, 2003, 2067, 2024,  108, 3718, 1994,
         615,  809, 2003, 3589])
Epoch: 441, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 442 - Batch 1 ########################
IDs in batch 1: tensor([2837,  519,  136, 1551, 1869, 1849, 2039, 2568, 3732, 3308, 2638, 1141,
         945, 2402, 2459, 3352])
Epoch: 442, Training Loss: 0.58, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 443 - Batch 1 ########################
IDs in batch 1: tensor([ 823, 2832, 2748, 3785, 1035, 2358, 2367,  110,  218, 3671, 1496, 2960,
        1484,  777, 3078, 2426])
Epoch: 443, Training Loss: 0.64, Validation Loss: 0.73, accuracy = 0.70
Save best Model_1 @ epoch 443 acc: 0.6951934349355217
Email sent!
######################## Epoch 444 - Batch 1 ########################
IDs in batch 1: tensor([ 882, 4085, 1976,  606, 2281, 3527, 1823, 1975, 2777, 1798, 3826, 1313,
        1467, 2342, 2854,  305])
Epoch: 444, Training Loss: 0.46, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 445 - Batch 1 ########################
IDs in batch 1: tensor([2279, 3851,  126, 3430,  452, 2773, 3757, 2898, 2023, 3056,  161, 3357,
        2660, 1271,  121, 3218])
Epoch: 445, Training Loss: 0.50, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 446 - Batch 1 ########################
IDs in batch 1: tensor([4039,  960, 3340, 3882,  910, 1015, 2645,  173, 3240, 2540, 1519, 3920,
        2109, 2106, 2848, 3336])
Epoch: 446, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 447 - Batch 1 ########################
IDs in batch 1: tensor([1031, 1571, 3017, 2322, 2088, 1948, 2620, 4161,  407, 1571, 2314, 2636,
        2640, 2355, 3154, 4012])
Epoch: 447, Training Loss: 0.64, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 448 - Batch 1 ########################
IDs in batch 1: tensor([3933, 1380,  324, 1478, 1570,  709, 1367, 2989,  173,  225, 1833, 1425,
        3545, 3852, 3697, 2690])
Epoch: 448, Training Loss: 0.72, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 449 - Batch 1 ########################
IDs in batch 1: tensor([  77, 3369, 2213, 3733, 2874, 1786, 2546, 3509, 3964,  320, 2360, 3675,
        2687,  660, 3962, 1418])
Epoch: 449, Training Loss: 0.91, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 450 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 2387, 1041, 3005, 3312, 2572, 4173, 4085, 1183, 3947, 3113, 3308,
        1242, 2156,  165, 2540])
Epoch: 450, Training Loss: 0.64, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 451 - Batch 1 ########################
IDs in batch 1: tensor([4198, 4175, 1825, 2587,  194, 2223, 1174, 2385, 3111, 1334,  432, 1325,
        1499, 2087, 1976, 4076])
Epoch: 451, Training Loss: 0.67, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 452 - Batch 1 ########################
IDs in batch 1: tensor([1559,  981, 1747, 3465, 1628, 2511, 1490, 2688, 4068,  435,  661, 4254,
        2387, 3298, 3328, 2597])
Epoch: 452, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 453 - Batch 1 ########################
IDs in batch 1: tensor([2659, 3385,  245, 1318, 1147, 2544, 2524,  825, 1473, 2368, 2508, 2191,
        1595, 1499, 1623, 2387])
Epoch: 453, Training Loss: 0.37, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 454 - Batch 1 ########################
IDs in batch 1: tensor([ 256, 3415, 3713, 2202, 1336, 2154, 2252,  794, 2399, 2804,  994, 1490,
         400, 3049, 4227,   99])
Epoch: 454, Training Loss: 0.61, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 455 - Batch 1 ########################
IDs in batch 1: tensor([2199, 2179, 1147,  625, 2278, 1777, 2154,  892, 2936, 4199,  977, 2545,
        1302, 2444, 2387, 1575])
Epoch: 455, Training Loss: 0.58, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 456 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 4100, 1822, 2839, 1877, 1250, 4197, 2831, 3334,  712,  730, 2413,
        3769, 2257,  766, 2363])
Epoch: 456, Training Loss: 0.70, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 457 - Batch 1 ########################
IDs in batch 1: tensor([1745,  661, 1904, 3018,  609,  399, 3514, 1166,  660,  762, 2324, 2282,
        1710, 4116,  516, 2465])
Epoch: 457, Training Loss: 0.56, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 458 - Batch 1 ########################
IDs in batch 1: tensor([2701, 1337, 3161, 1540, 2632,  767,  693, 3207, 1276, 2617,  544, 1781,
        1802, 1228, 2060, 2372])
Epoch: 458, Training Loss: 0.45, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 459 - Batch 1 ########################
IDs in batch 1: tensor([3661, 2484, 1618,  590, 1502, 2867, 1967, 1309, 3717, 1290,  360, 1779,
        2842, 2115, 3264, 1853])
Epoch: 459, Training Loss: 0.66, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 460 - Batch 1 ########################
IDs in batch 1: tensor([1957,  878, 2755, 3240,  928, 2794, 2297, 3808, 2090,  832, 1950,  893,
        2545, 1501, 2482, 2737])
Epoch: 460, Training Loss: 0.59, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 461 - Batch 1 ########################
IDs in batch 1: tensor([1160, 1913, 3709, 1859, 1152,  750, 3142, 3418, 3797, 3313,  814,  663,
        3014,  909, 2066, 1426])
Epoch: 461, Training Loss: 0.53, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 462 - Batch 1 ########################
IDs in batch 1: tensor([ 335, 1180, 3466, 2260, 1933,  743, 3751, 3199, 2936, 3414, 2443, 2775,
        3160, 3863, 1656,  952])
Epoch: 462, Training Loss: 0.70, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 463 - Batch 1 ########################
IDs in batch 1: tensor([1756, 2924, 2562, 1781,   50, 3330, 2895,  198, 4068, 3950,  726, 2957,
        4107, 1229,  909,  520])
Epoch: 463, Training Loss: 0.82, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 464 - Batch 1 ########################
IDs in batch 1: tensor([3601,   24, 1026, 1220, 1055,  792,   86, 2299, 2350, 1878, 1484, 2317,
        1918, 1649, 3878, 3524])
Epoch: 464, Training Loss: 0.50, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 465 - Batch 1 ########################
IDs in batch 1: tensor([ 172, 3552, 2106, 1604,  308, 2937,  623, 2064, 3199,  887, 2827, 1428,
        3052, 4184, 2230, 4026])
Epoch: 465, Training Loss: 0.74, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 466 - Batch 1 ########################
IDs in batch 1: tensor([4007, 1496, 2412, 3179, 2185, 3142, 1728, 2810, 1562, 3418, 1337,  191,
        1099, 3943, 2052, 3253])
Epoch: 466, Training Loss: 0.43, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 467 - Batch 1 ########################
IDs in batch 1: tensor([3663, 3983, 3714, 2063, 1087, 3317,  917, 1269,  280, 2691,  333, 1212,
        3525, 1139, 3894, 4076])
Epoch: 467, Training Loss: 0.72, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 468 - Batch 1 ########################
IDs in batch 1: tensor([3822, 1024, 3953,  275, 3025, 1863,  983, 3873, 3020, 4222, 3962, 1878,
        2672, 3511, 2656, 4076])
Epoch: 468, Training Loss: 0.93, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 469 - Batch 1 ########################
IDs in batch 1: tensor([1498, 3160, 4065, 4120, 1641,  252,  814, 2483, 1630, 4070,   35, 4189,
        2839, 2965, 3745,  689])
Epoch: 469, Training Loss: 0.89, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 470 - Batch 1 ########################
IDs in batch 1: tensor([ 141,  996, 3376, 3264, 3984, 2035, 2621,  434,  908,  828, 3919,  505,
        4261,  727, 3693,  237])
Epoch: 470, Training Loss: 0.84, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 471 - Batch 1 ########################
IDs in batch 1: tensor([ 843, 1518,  171,  269, 3157,  399, 2600,  584, 2234,  774,  682,  196,
        2245,  603,  658, 1126])
Epoch: 471, Training Loss: 0.60, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 472 - Batch 1 ########################
IDs in batch 1: tensor([2884, 1658,  626, 3037,  887, 1569, 1023, 2244, 1731, 1011,  342, 2237,
        1777, 1916,  289,  377])
Epoch: 472, Training Loss: 0.56, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 473 - Batch 1 ########################
IDs in batch 1: tensor([2723, 4224, 1083, 2171, 1096, 3398, 1386, 3480,   21, 1923, 3399, 3440,
        1942, 2238, 3548, 3389])
Epoch: 473, Training Loss: 0.65, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 474 - Batch 1 ########################
IDs in batch 1: tensor([ 796,  941,  949, 3369,  201, 2291, 1352, 1134, 1239, 4198, 3719, 1594,
        2472,  732, 3998, 1053])
Epoch: 474, Training Loss: 0.74, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 475 - Batch 1 ########################
IDs in batch 1: tensor([2493,  797, 1859,  766, 2719, 3456, 2738, 2123, 3453, 4012,  394, 1470,
        1979, 2196, 1836, 4263])
Epoch: 475, Training Loss: 0.58, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 476 - Batch 1 ########################
IDs in batch 1: tensor([3183, 1872, 2708, 2195, 1498, 3648, 2035, 3603,  747, 1076, 2731,  437,
        4263,  821, 2328, 1524])
Epoch: 476, Training Loss: 0.65, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 477 - Batch 1 ########################
IDs in batch 1: tensor([3834, 3991,   20,  656, 3536, 2514, 1181, 3905,  996,  214,  171, 2827,
        1278, 3311, 1507, 3385])
Epoch: 477, Training Loss: 0.73, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 478 - Batch 1 ########################
IDs in batch 1: tensor([3651, 1804, 1133, 3683, 1163,  602, 3388, 4159,  239, 1628, 3781, 3772,
        1656, 3723, 3184, 2932])
Epoch: 478, Training Loss: 0.92, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 479 - Batch 1 ########################
IDs in batch 1: tensor([3883, 2141, 1351, 1730, 1496, 2375, 2832, 4154,  467, 3176, 2777, 1255,
        3078,  874, 3262, 1273])
Epoch: 479, Training Loss: 0.55, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 480 - Batch 1 ########################
IDs in batch 1: tensor([ 630, 3130, 1373, 3058, 1811,  337,  994, 3939,  545, 3142,  213,  245,
        2157, 3782, 4100,  284])
Epoch: 480, Training Loss: 0.62, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 481 - Batch 1 ########################
IDs in batch 1: tensor([3751, 2151, 2829, 1975, 1634, 3540, 1369, 3711, 4238,  362, 1668, 4069,
         870, 1638, 3157, 2886])
Epoch: 481, Training Loss: 0.65, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 482 - Batch 1 ########################
IDs in batch 1: tensor([3934, 1954, 1638,  202,  466, 2372, 2328,   86, 2606, 1200, 1781, 3655,
        1648, 2661, 2492, 4049])
Epoch: 482, Training Loss: 0.66, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 483 - Batch 1 ########################
IDs in batch 1: tensor([1938,  645, 1031, 3002,  869, 2312, 1673, 2871, 1161, 2023, 3357,  996,
        1780, 2331, 3326, 1174])
Epoch: 483, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 484 - Batch 1 ########################
IDs in batch 1: tensor([3971, 2191, 2234, 2712, 3414, 3707, 3991,   10,  658, 3421, 3802, 1794,
        2535, 3521, 4097, 1325])
Epoch: 484, Training Loss: 1.06, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 485 - Batch 1 ########################
IDs in batch 1: tensor([4166,  709, 3885, 1380, 3139, 2398, 2793,  593, 3279, 1270, 2721, 2583,
         738, 3427,  426, 1235])
Epoch: 485, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 486 - Batch 1 ########################
IDs in batch 1: tensor([1887, 1141, 2571,  122, 2597, 2429,  180, 1337,  835, 2579, 3193, 2315,
         205, 1568,  615,  454])
Epoch: 486, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 487 - Batch 1 ########################
IDs in batch 1: tensor([3401,  691,  862,  547, 3590,  809,  829,  263, 3242, 3793, 3681, 1113,
         332, 3121, 4249, 1279])
Epoch: 487, Training Loss: 0.85, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 488 - Batch 1 ########################
IDs in batch 1: tensor([2369,  436, 2112, 4027,  615, 4189, 2969, 3707, 1131, 2880, 3939, 4266,
        2708, 1360, 1178, 3017])
Epoch: 488, Training Loss: 0.74, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 489 - Batch 1 ########################
IDs in batch 1: tensor([2517, 3763, 2610, 3187, 3360, 3449, 1991, 3234,  862,  442, 2731, 1754,
        3194, 2172, 1883,  527])
Epoch: 489, Training Loss: 0.66, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 490 - Batch 1 ########################
IDs in batch 1: tensor([1747, 3509, 2627, 1961, 2066,  316, 1282, 2666, 4235, 3051, 1925, 2444,
        1619, 4005, 2973, 2088])
Epoch: 490, Training Loss: 0.80, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 491 - Batch 1 ########################
IDs in batch 1: tensor([ 989, 3500, 2810, 3935, 1045, 2847,  119, 1970, 3336, 2642,  891, 3387,
        1841,  568, 3077,  913])
Epoch: 491, Training Loss: 0.54, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 492 - Batch 1 ########################
IDs in batch 1: tensor([3712,   14, 4110, 1592, 3278, 1285, 2770, 4093, 3333, 2890, 2706,  955,
        3102,  635, 3378, 2262])
Epoch: 492, Training Loss: 0.71, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 493 - Batch 1 ########################
IDs in batch 1: tensor([1756, 3003,   11, 1789, 1374, 3787, 1811,  623, 2306, 2991, 2009,  550,
        3600,  862, 2249,  321])
Epoch: 493, Training Loss: 0.73, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 494 - Batch 1 ########################
IDs in batch 1: tensor([1708, 3564, 1808,  838,  755, 2326,   71, 3456, 1351, 2447, 1600, 2869,
         516, 1199, 3252, 2890])
Epoch: 494, Training Loss: 0.53, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 495 - Batch 1 ########################
IDs in batch 1: tensor([2917, 3841, 2616, 3879,  586, 4122, 1426, 4039,  426,  247, 3998, 3907,
        3701, 1526, 1371,  578])
Epoch: 495, Training Loss: 0.90, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 496 - Batch 1 ########################
IDs in batch 1: tensor([ 148, 2984, 1825, 3860,  923, 3020, 2475,  341, 3435, 4181, 4061,  148,
        3902,  863, 2040, 1322])
Epoch: 496, Training Loss: 0.71, Validation Loss: 0.72, accuracy = 0.70
Save best Model_1 @ epoch 496 acc: 0.6975381008206331
Email sent!
######################## Epoch 497 - Batch 1 ########################
IDs in batch 1: tensor([1878, 3262,  436, 4143, 2049, 2151,  805, 1272, 2137, 3214, 2418,  883,
        3434, 1386, 2514, 3547])
Epoch: 497, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.70
Save best Model_1 @ epoch 497 acc: 0.7022274325908558
Email sent!
######################## Epoch 498 - Batch 1 ########################
IDs in batch 1: tensor([3079, 2541, 2833, 2960, 3961, 2782, 3882, 2660, 3762, 1817,  915, 4114,
         812, 3187, 3521, 4133])
Epoch: 498, Training Loss: 0.93, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 499 - Batch 1 ########################
IDs in batch 1: tensor([ 247, 1292, 3962, 1918, 2458,   84, 3885, 1711, 1556, 4007, 2969, 2601,
        2947,  595, 2371, 2817])
Epoch: 499, Training Loss: 0.63, Validation Loss: 0.72, accuracy = 0.70
Save best Model_1 @ epoch 499 acc: 0.7033997655334114
Email sent!
######################## Epoch 500 - Batch 1 ########################
IDs in batch 1: tensor([1404, 2238, 1799,  918, 3003, 3265, 4069, 3379,  886,  538,  516, 1650,
        3615, 1087, 2578, 3932])
Epoch: 500, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 501 - Batch 1 ########################
IDs in batch 1: tensor([1836, 4096, 1260, 2841, 2387, 3695, 2652, 2696, 3732, 2833, 1137, 2292,
        1853, 1777, 3706, 3530])
Epoch: 501, Training Loss: 0.86, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 502 - Batch 1 ########################
IDs in batch 1: tensor([2107, 1372, 2285, 1299,   68, 1067, 2831, 1372, 2387, 1737, 2141, 3535,
         809,  848, 1206, 3392])
Epoch: 502, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 503 - Batch 1 ########################
IDs in batch 1: tensor([  19, 1509, 2977, 3272,  390, 2996, 2825, 2305, 2051, 2274,  538, 2477,
        4056, 1072, 2191,  185])
Epoch: 503, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 504 - Batch 1 ########################
IDs in batch 1: tensor([3760, 3706,  129, 3711, 3330, 3746,  774,  843,  874,  276, 3053, 1904,
        3821, 3494, 2232, 1464])
Epoch: 504, Training Loss: 0.79, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 505 - Batch 1 ########################
IDs in batch 1: tensor([1177,  155,  997, 2098, 1226, 2650, 3079,   15,  317,  247,  367, 2552,
         393, 1537, 3000,  170])
Epoch: 505, Training Loss: 0.60, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 506 - Batch 1 ########################
IDs in batch 1: tensor([ 826,  449, 2682, 1007, 1260,  907,  665, 3395, 2069, 2317,  886, 4173,
         756, 2853, 2857, 2782])
Epoch: 506, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 507 - Batch 1 ########################
IDs in batch 1: tensor([1032,  352,   44, 1471, 3265,  767, 1948, 3911,  334, 3698, 3856, 1537,
         195, 2408,  503,  515])
Epoch: 507, Training Loss: 0.81, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 508 - Batch 1 ########################
IDs in batch 1: tensor([1085, 4165,  941, 1556,  440, 3088, 1311,  862, 4255, 2317,  322, 3436,
         886, 2844,  595, 1601])
Epoch: 508, Training Loss: 0.75, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 509 - Batch 1 ########################
IDs in batch 1: tensor([ 659, 4194, 2755, 2937, 4110, 1044, 3183,  709, 2856,  155, 4037, 2567,
        1059, 3458, 4012, 3786])
Epoch: 509, Training Loss: 0.59, Validation Loss: 0.72, accuracy = 0.68
######################## Epoch 510 - Batch 1 ########################
IDs in batch 1: tensor([ 960, 3003,  439,  378, 2973, 2522, 3998, 3640,  512, 3582, 2561, 2799,
        1297, 4011, 2945, 3858])
Epoch: 510, Training Loss: 0.86, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 511 - Batch 1 ########################
IDs in batch 1: tensor([1099, 3004,  214,  103, 1414, 2313, 2522, 3009, 2963, 1979, 2342,  976,
        1306, 1208, 3732, 3876])
Epoch: 511, Training Loss: 0.47, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 512 - Batch 1 ########################
IDs in batch 1: tensor([2537, 3812, 2086,  918,  804,  101, 2466, 2767,  644,  771, 1312,  465,
        1650,  584, 1009, 3950])
Epoch: 512, Training Loss: 0.60, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 513 - Batch 1 ########################
IDs in batch 1: tensor([3300, 1589, 3337,  140, 3180, 1221, 2973, 2284, 2234,  415, 3248, 1369,
        2582, 1179, 1180, 1316])
Epoch: 513, Training Loss: 0.37, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 514 - Batch 1 ########################
IDs in batch 1: tensor([ 954, 1330, 3802, 3832, 3219, 1504, 1850, 1156, 2710,  358, 1469, 2605,
        3879,  188, 2359, 1933])
Epoch: 514, Training Loss: 0.68, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 515 - Batch 1 ########################
IDs in batch 1: tensor([1156, 2837,  887,  280, 1731, 1655, 2378, 2339, 1748, 2587, 1008, 1595,
         388, 3599, 1490, 3328])
Epoch: 515, Training Loss: 0.53, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 516 - Batch 1 ########################
IDs in batch 1: tensor([3693, 3704, 1045, 2004, 3878, 2954, 2719, 1386, 3102, 4175, 1375, 2715,
        3717, 3547,  539, 2575])
Epoch: 516, Training Loss: 0.82, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 517 - Batch 1 ########################
IDs in batch 1: tensor([1060, 4146, 2342, 1670, 2921, 2784,  182, 4044, 2143,  269, 2965,  846,
        2178, 2304, 2821, 2143])
Epoch: 517, Training Loss: 0.69, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 518 - Batch 1 ########################
IDs in batch 1: tensor([2691, 4057, 2945, 2810, 3047, 1727,  792, 3713, 2718, 1643, 1271, 3394,
        1237, 1380, 4140, 1158])
Epoch: 518, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 519 - Batch 1 ########################
IDs in batch 1: tensor([2370,  214, 1086, 3991, 3060, 1171, 3311, 3345, 2965, 3430, 2598, 3972,
        2188, 2565, 4049, 2866])
Epoch: 519, Training Loss: 0.88, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 520 - Batch 1 ########################
IDs in batch 1: tensor([4084,  263, 2842, 3688, 2997,  234, 3970, 3618, 4180, 1526, 1488, 2541,
        2815,  360, 3162, 1053])
Epoch: 520, Training Loss: 0.93, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 521 - Batch 1 ########################
IDs in batch 1: tensor([3108, 4035, 2210, 3072,  678,  574, 1213, 3771,  155, 1464,  351, 2692,
        3421, 4088, 1512, 3037])
Epoch: 521, Training Loss: 0.63, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 522 - Batch 1 ########################
IDs in batch 1: tensor([2521, 2205, 1601, 1066, 3259, 1124, 4148, 1111, 2499,  937,  596, 1417,
        2870, 1143, 1824,  637])
Epoch: 522, Training Loss: 0.45, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 523 - Batch 1 ########################
IDs in batch 1: tensor([2826, 4198, 2188,  879, 2252, 2277, 3826, 3371, 1201, 3745,  785, 2989,
        2323, 3289, 2616, 3930])
Epoch: 523, Training Loss: 0.69, Validation Loss: 0.71, accuracy = 0.71
Save best Model_1 @ epoch 523 acc: 0.7069167643610785
Email sent!
######################## Epoch 524 - Batch 1 ########################
IDs in batch 1: tensor([3132, 1039, 3199, 3200, 3908, 1720, 2323,  606, 2624,  615, 3554, 2856,
        1841, 2902, 3974, 1047])
Epoch: 524, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 525 - Batch 1 ########################
IDs in batch 1: tensor([3635, 1822, 1257,  505, 1065,  578,  183, 1178, 1671, 3832, 3985,  622,
        2108, 2416,  538, 4133])
Epoch: 525, Training Loss: 0.83, Validation Loss: 0.70, accuracy = 0.71
Save best Model_1 @ epoch 525 acc: 0.7104337631887456
Email sent!
######################## Epoch 526 - Batch 1 ########################
IDs in batch 1: tensor([3756,  388, 3299, 1463, 3627, 2627, 1624, 2690, 3572,  529,  478, 1958,
        1819, 3945, 2831, 1138])
Epoch: 526, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 527 - Batch 1 ########################
IDs in batch 1: tensor([ 300, 3428,  710, 2546, 2213, 2925, 2812, 2907, 1223, 1614, 3902, 4255,
        3993, 3962, 3245, 3533])
Epoch: 527, Training Loss: 0.76, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 528 - Batch 1 ########################
IDs in batch 1: tensor([1678, 2391, 1445, 2740,  730, 2884, 1367, 2036,  333, 3516, 1671, 3382,
        3847,  444, 2313, 3038])
Epoch: 528, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 529 - Batch 1 ########################
IDs in batch 1: tensor([2095, 3932, 3607, 1381, 4036,  326, 3207, 1052, 1020,  966,  829, 3433,
        1317,  844,  470, 3192])
Epoch: 529, Training Loss: 0.71, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 530 - Batch 1 ########################
IDs in batch 1: tensor([2993, 2195,  105, 1305, 3693,  839, 1896, 1793,  866, 2366,  828, 1102,
         577, 1481, 3564,  517])
Epoch: 530, Training Loss: 0.70, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 531 - Batch 1 ########################
IDs in batch 1: tensor([1793, 1062, 3853,  645, 4149, 3765,   32,  691,  933, 3582, 3680, 3159,
        1899, 2255, 4125,  279])
Epoch: 531, Training Loss: 0.96, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 532 - Batch 1 ########################
IDs in batch 1: tensor([2342,  520,  501, 3282, 3954, 2827, 4134,  219,  261,  491, 3701, 2161,
        2788, 2729, 1852, 1289])
Epoch: 532, Training Loss: 0.66, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 533 - Batch 1 ########################
IDs in batch 1: tensor([2117, 1891, 3582,  133, 2230,  953,  710, 2002, 1913, 1597, 2191, 2387,
        3219, 1007, 4044, 2063])
Epoch: 533, Training Loss: 0.66, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 534 - Batch 1 ########################
IDs in batch 1: tensor([2025, 2508, 3176,    7, 2659, 2730, 3222, 4055, 2402, 1031,  981,   68,
         417, 3949, 1948, 2597])
Epoch: 534, Training Loss: 0.46, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 535 - Batch 1 ########################
IDs in batch 1: tensor([3547,   43,   81,  607, 3782, 2300, 2999, 1059, 2148, 1469, 2365,  148,
         733, 3726, 3423, 1107])
Epoch: 535, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 536 - Batch 1 ########################
IDs in batch 1: tensor([ 513,  530, 2552, 4138, 1543,  462, 3942,  993, 2450, 3589,  244, 1655,
        1206, 2908, 3139, 2553])
Epoch: 536, Training Loss: 0.68, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 537 - Batch 1 ########################
IDs in batch 1: tensor([ 103, 1174, 2825, 2605, 1324, 3534,  256, 2638, 3388, 2120, 3836, 2829,
        3272,  274, 3156, 2114])
Epoch: 537, Training Loss: 0.59, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 538 - Batch 1 ########################
IDs in batch 1: tensor([4085, 1432, 1574, 2730, 3494, 1751, 3803, 1726, 1945, 2212, 2506,  862,
        1472, 4057,  516, 1617])
Epoch: 538, Training Loss: 0.51, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 539 - Batch 1 ########################
IDs in batch 1: tensor([ 612, 4223,  539,  481, 2978, 1408, 2926, 3996, 2195, 2469,  378, 2124,
         512, 2111, 1094, 2044])
Epoch: 539, Training Loss: 0.64, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 540 - Batch 1 ########################
IDs in batch 1: tensor([2444, 1320, 1980, 3936, 1325, 3468, 2973,  899,  300,  753, 1663, 1216,
         435, 2795, 2066, 3745])
Epoch: 540, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 541 - Batch 1 ########################
IDs in batch 1: tensor([2295, 1569, 1730,  989, 2298, 3060, 1193,  290, 1220, 3883, 2804, 2867,
        3298, 1273, 2964, 2640])
Epoch: 541, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 542 - Batch 1 ########################
IDs in batch 1: tensor([1087,  547, 4122, 2947, 1485, 1883, 2418, 2674, 1197,  483, 2250, 2287,
        2890, 1355, 4198, 2591])
Epoch: 542, Training Loss: 0.58, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 543 - Batch 1 ########################
IDs in batch 1: tensor([2098,  583,  635, 1276, 3432, 1673, 1923, 1844, 4009,  308, 2223,  923,
        3004,  878, 4073, 3404])
Epoch: 543, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 544 - Batch 1 ########################
IDs in batch 1: tensor([3459, 2246, 2799, 1748, 3268, 2853, 4003, 1605,  393, 2961, 4172, 1414,
         104,   72, 2869, 2190])
Epoch: 544, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 545 - Batch 1 ########################
IDs in batch 1: tensor([3850, 2561, 1630, 1104, 2983, 3492,  557, 1397, 3217, 3492, 3358, 2561,
        3557, 2466,  478, 3395])
Epoch: 545, Training Loss: 0.85, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 546 - Batch 1 ########################
IDs in batch 1: tensor([  42, 2085, 2418, 4146, 2999, 4053, 1274,  180, 1351, 1612, 4033, 4056,
         858, 3532, 3038, 1028])
Epoch: 546, Training Loss: 0.62, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 547 - Batch 1 ########################
IDs in batch 1: tensor([ 699, 1872, 2844, 3523, 2806, 2286,  981, 3540, 2734, 3919, 3997, 3624,
        1163, 2959, 1437, 1390])
Epoch: 547, Training Loss: 0.45, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 548 - Batch 1 ########################
IDs in batch 1: tensor([2280,  190,  981, 2120,  830,  628, 3498, 3762,   78, 2125, 2035, 1914,
        3466, 3541,  251, 3537])
Epoch: 548, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 549 - Batch 1 ########################
IDs in batch 1: tensor([1819, 2341, 1351, 3021,  920, 2394, 3133, 4172,  776,  848, 3069, 1809,
         110, 1568, 3707, 3435])
Epoch: 549, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 550 - Batch 1 ########################
IDs in batch 1: tensor([1273, 1965,  701, 2784, 1866, 2376, 1574, 1200, 4125, 3035, 1591, 1985,
        2402, 2433, 1256,  631])
Epoch: 550, Training Loss: 0.50, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 551 - Batch 1 ########################
IDs in batch 1: tensor([1290, 1895,  441,  908, 4186, 3336, 3727, 1751, 2584, 2262, 3139, 3440,
        2899,  723,  959, 3875])
Epoch: 551, Training Loss: 0.58, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 552 - Batch 1 ########################
IDs in batch 1: tensor([ 529, 3222, 2661, 2250, 1947, 1121, 1141, 1536, 3614,  673,  401, 1038,
         895, 2780, 1089, 4038])
Epoch: 552, Training Loss: 0.68, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 553 - Batch 1 ########################
IDs in batch 1: tensor([1474, 4122, 2642, 4149, 3098, 2815,  387, 2213, 1942,  825, 4087, 3240,
         221, 1007, 3410, 2146])
Epoch: 553, Training Loss: 0.46, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 554 - Batch 1 ########################
IDs in batch 1: tensor([1610, 2598, 4017, 2968, 2538, 2264, 1080, 2063, 2031, 3935, 3200, 3268,
        1097, 2408, 3427, 4215])
Epoch: 554, Training Loss: 0.75, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 555 - Batch 1 ########################
IDs in batch 1: tensor([1784, 1712, 2382, 2375, 1258,  605, 1955, 2133, 4235,  876, 3381, 3490,
        2504,   31,  278, 4198])
Epoch: 555, Training Loss: 0.76, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 556 - Batch 1 ########################
IDs in batch 1: tensor([2883, 1326, 3356, 3883,  773, 1260, 1006, 1879, 3896, 1745, 3354, 2655,
        1682, 1285, 2431, 1818])
Epoch: 556, Training Loss: 0.75, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 557 - Batch 1 ########################
IDs in batch 1: tensor([3369, 2688,  593, 2838, 3876, 3912, 2244, 3148,   81, 1834, 1045, 1041,
        3363, 1182,  323, 2587])
Epoch: 557, Training Loss: 0.47, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 558 - Batch 1 ########################
IDs in batch 1: tensor([3337,  181, 2408,  321,  413, 2113,  213, 3141, 2991, 2418, 1122, 3732,
        2730, 1665, 2950, 1678])
Epoch: 558, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 559 - Batch 1 ########################
IDs in batch 1: tensor([  44, 3124, 1345, 3154, 1330, 3486, 3314, 1360, 2577, 2014,  820, 2290,
         357, 1665,  670,  435])
Epoch: 559, Training Loss: 0.50, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 560 - Batch 1 ########################
IDs in batch 1: tensor([3785, 1836, 3871, 3718, 1028,  975, 1871,  658, 3842, 2284,  874,  818,
        1972, 2740, 4261, 3936])
Epoch: 560, Training Loss: 0.84, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 561 - Batch 1 ########################
IDs in batch 1: tensor([2121, 3444, 4194, 2678,  950,  652, 3956, 1104, 2773, 2537, 3655, 3083,
         550, 1396,   63,  626])
Epoch: 561, Training Loss: 0.56, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 562 - Batch 1 ########################
IDs in batch 1: tensor([1968, 4194,  533, 3592,  425, 2056, 1845,  884,   28, 2366, 3831, 2880,
        1093, 3362,  596, 3308])
Epoch: 562, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 563 - Batch 1 ########################
IDs in batch 1: tensor([1271,   10, 1232, 1452, 3272, 1496, 3366,  630,  206, 1947, 4224, 1927,
        2493, 2563, 3044,  532])
Epoch: 563, Training Loss: 0.53, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 564 - Batch 1 ########################
IDs in batch 1: tensor([3259,  878, 4161,  661, 1853,  841, 2847, 3558, 2151, 2806, 3852, 2858,
        2870, 3459, 4196, 3397])
Epoch: 564, Training Loss: 0.93, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 565 - Batch 1 ########################
IDs in batch 1: tensor([4057, 1351,  332,  388, 1374, 1053, 2680, 4135,  532, 2041, 2483,  887,
         676,  776,  714, 3866])
Epoch: 565, Training Loss: 0.75, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 566 - Batch 1 ########################
IDs in batch 1: tensor([2146,  442, 2349, 1752,  432, 3552,  306,  409, 1999, 3300,  279, 1499,
        2894, 1198, 3363, 3468])
Epoch: 566, Training Loss: 0.49, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 567 - Batch 1 ########################
IDs in batch 1: tensor([3424,  507,  211, 4024, 3802, 2794, 1956, 2563, 1093, 3271, 2356, 3326,
        2252, 1921, 3503,   32])
Epoch: 567, Training Loss: 0.60, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 568 - Batch 1 ########################
IDs in batch 1: tensor([4203, 3870, 3683, 1088, 2739,  389, 2643, 4218, 3874, 1880,  615,  732,
         424, 3429, 4060, 2408])
Epoch: 568, Training Loss: 0.69, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 569 - Batch 1 ########################
IDs in batch 1: tensor([1235, 2127, 3539,  718,  691,  266,  335, 3300, 3693, 2827,  992, 3121,
        3992, 1830, 1595,  425])
Epoch: 569, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 570 - Batch 1 ########################
IDs in batch 1: tensor([ 566, 2040, 1634, 3208, 3699, 2835,  841, 2907, 1601, 2452, 3513, 4140,
        3084,  994, 1147, 1956])
Epoch: 570, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 571 - Batch 1 ########################
IDs in batch 1: tensor([2982,  604, 2452, 2320, 3993, 1214, 1836, 2030, 1389,  786, 3078, 2394,
        1463, 3863,  660, 3117])
Epoch: 571, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 572 - Batch 1 ########################
IDs in batch 1: tensor([2669, 1118, 3055, 3610, 3176, 2426, 2098, 1682, 3326, 1271, 3200, 3762,
        1605, 1312, 4163, 4067])
Epoch: 572, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 573 - Batch 1 ########################
IDs in batch 1: tensor([2092,  476, 2667, 3506,  408, 1171, 4036,  603, 3406, 3635,  399,   28,
        3123,  755, 1810, 2466])
Epoch: 573, Training Loss: 0.65, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 574 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 2797, 2059, 2375, 1276,  820, 1044, 2383, 3558,  833, 1418, 2092,
        3632, 1122, 1625, 3675])
Epoch: 574, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 575 - Batch 1 ########################
IDs in batch 1: tensor([  20, 2655, 1352,  170,   25, 1658, 2505, 4124, 2275, 1506,  475, 3199,
        3569, 1680, 1049, 3306])
Epoch: 575, Training Loss: 0.62, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 576 - Batch 1 ########################
IDs in batch 1: tensor([1665,  224, 1984, 2073, 4234,  833, 2376, 3223, 4166, 1497,  393, 1186,
         631, 1282, 1826, 2733])
Epoch: 576, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 577 - Batch 1 ########################
IDs in batch 1: tensor([3242, 4175, 1931,  881, 3199, 2689, 1680, 2892, 2921, 1123, 2226, 2942,
         790, 1556,  190,  316])
Epoch: 577, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 578 - Batch 1 ########################
IDs in batch 1: tensor([1144, 4068, 1994, 1393,  145, 3284,  646, 2217, 3377, 4077, 1282, 3762,
        3977, 4094,  645, 3119])
Epoch: 578, Training Loss: 0.65, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 579 - Batch 1 ########################
IDs in batch 1: tensor([2377, 2097, 1834,  244, 2078, 4230, 3934,  645, 4152, 3552, 2360, 1126,
        2692, 1974, 1543, 2733])
Epoch: 579, Training Loss: 0.66, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 580 - Batch 1 ########################
IDs in batch 1: tensor([3370, 2565, 1760,  136, 3807, 2552, 1657, 2993, 3993, 2320, 1857, 2357,
        2099, 2776,  755, 3826])
Epoch: 580, Training Loss: 0.68, Validation Loss: 0.69, accuracy = 0.71
Save best Model_1 @ epoch 580 acc: 0.7139507620164126
Email sent!
######################## Epoch 581 - Batch 1 ########################
IDs in batch 1: tensor([1084, 2754, 4179, 1275,  569,  983, 1306, 3804, 1023, 1123,  247,  955,
         196, 2235,  873, 3160])
Epoch: 581, Training Loss: 0.62, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 582 - Batch 1 ########################
IDs in batch 1: tensor([2561, 3896, 2285,   20, 3764,  426, 2314,  851,  812, 3969, 3478, 3030,
        1986, 4027, 3130, 3846])
Epoch: 582, Training Loss: 0.70, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 583 - Batch 1 ########################
IDs in batch 1: tensor([2371,  440,  251, 2498, 3573, 4069,  125, 2517, 3211, 3700, 4048, 1524,
        1630, 3000, 1224, 1545])
Epoch: 583, Training Loss: 0.64, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 584 - Batch 1 ########################
IDs in batch 1: tensor([2777, 1556, 1804, 3458, 1056, 1178, 1011, 3547, 3970, 4236, 1232, 2148,
        3479, 3456, 1748, 2338])
Epoch: 584, Training Loss: 0.49, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 585 - Batch 1 ########################
IDs in batch 1: tensor([2331, 2224, 2099, 3948,  238, 1962, 3797, 3088, 1057, 1355, 1043,  659,
        1613, 1179,  194, 1320])
Epoch: 585, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 586 - Batch 1 ########################
IDs in batch 1: tensor([ 841, 2505, 2402, 1043, 2859, 2616, 1845, 2810,   82, 1474,  459, 1417,
        4035, 1650, 2280, 3524])
Epoch: 586, Training Loss: 0.50, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 587 - Batch 1 ########################
IDs in batch 1: tensor([2060, 3585, 3928, 1686, 4057, 1417,  854, 3271, 2170,  413, 3227, 4131,
         553, 3594, 1328,  138])
Epoch: 587, Training Loss: 0.91, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 588 - Batch 1 ########################
IDs in batch 1: tensor([3308, 4174, 2456, 2405, 2441,  803,  992, 2738, 4158, 3858, 1374, 2924,
         687, 1766, 4163, 1575])
Epoch: 588, Training Loss: 0.58, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 589 - Batch 1 ########################
IDs in batch 1: tensor([1478, 3492, 1324, 3541, 4136,  967, 3812, 1487, 1062, 2118, 1968,  520,
        3879,  505, 2544, 3283])
Epoch: 589, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 590 - Batch 1 ########################
IDs in batch 1: tensor([1510, 2245, 3037,  219, 1700,  896, 3495, 3705, 1322, 1386, 2529, 3193,
        3075, 2002, 2845, 3601])
Epoch: 590, Training Loss: 0.63, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 591 - Batch 1 ########################
IDs in batch 1: tensor([3792, 2538, 2131, 4075, 1601, 3222, 2891, 3608,  456,  244, 3489, 2296,
        3607, 2137, 3372,   25])
Epoch: 591, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 592 - Batch 1 ########################
IDs in batch 1: tensor([ 425, 1096,  484, 3507, 4213, 1082,  357, 1751,  221,  138, 1933, 2124,
        3367, 1779, 1286, 3942])
Epoch: 592, Training Loss: 0.58, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 593 - Batch 1 ########################
IDs in batch 1: tensor([3888, 1872, 1410,  996, 4057, 1620, 3303,  863, 2577, 4188,   98, 2390,
        3704, 3710, 4141, 3243])
Epoch: 593, Training Loss: 0.77, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 594 - Batch 1 ########################
IDs in batch 1: tensor([ 888,  151,  276, 3056, 2999, 2518, 3851, 2354,  632, 1066,  821, 2034,
         290, 3506, 3644, 3524])
Epoch: 594, Training Loss: 0.49, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 595 - Batch 1 ########################
IDs in batch 1: tensor([1224, 4088, 1942, 3077, 3466, 1122, 1117, 3299, 3044, 2098, 3222, 2643,
         417, 1081,   14, 3217])
Epoch: 595, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.70
######################## Epoch 596 - Batch 1 ########################
IDs in batch 1: tensor([2382,  556, 3843, 1335,  516, 3484, 2035,  135, 1673, 4003, 1536, 1953,
         773, 3697, 3977,  839])
Epoch: 596, Training Loss: 0.72, Validation Loss: 0.68, accuracy = 0.70
######################## Epoch 597 - Batch 1 ########################
IDs in batch 1: tensor([2117, 3526, 3161, 1630, 3911,    4, 3203, 1181,  346, 2696, 2926,   46,
        3831, 3912, 2232, 4096])
Epoch: 597, Training Loss: 0.67, Validation Loss: 0.68, accuracy = 0.70
######################## Epoch 598 - Batch 1 ########################
IDs in batch 1: tensor([1699, 1402, 2600, 3127,  539, 3856, 2632,  897, 2775, 2437, 3208,  357,
         274, 1183,  693,  816])
Epoch: 598, Training Loss: 0.67, Validation Loss: 0.68, accuracy = 0.70
######################## Epoch 599 - Batch 1 ########################
IDs in batch 1: tensor([3241,  325, 4055, 1671, 1357,  526, 4180,   73, 3409, 3240, 4018, 3651,
        2601,  535, 2111, 4236])
Epoch: 599, Training Loss: 0.72, Validation Loss: 0.68, accuracy = 0.70
######################## Epoch 600 - Batch 1 ########################
IDs in batch 1: tensor([ 250,  996,  587, 2959,   96, 3214, 3659, 2119, 1020, 2022, 3235, 3461,
        1782, 2763, 2204, 2767])
Epoch: 600, Training Loss: 0.77, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 601 - Batch 1 ########################
IDs in batch 1: tensor([2161, 2010, 3763, 1232, 2771, 2410, 3406,  873, 3700, 2710, 3952, 2290,
        2825, 1868,  557, 3841])
Epoch: 601, Training Loss: 0.65, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 602 - Batch 1 ########################
IDs in batch 1: tensor([ 323, 1472, 3436, 2358, 3879, 2729, 2807, 2678, 2088, 2751, 3783, 3833,
         913, 1128,  546, 1932])
Epoch: 602, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.72
Save best Model_1 @ epoch 602 acc: 0.7151230949589683
Email sent!
######################## Epoch 603 - Batch 1 ########################
IDs in batch 1: tensor([3907, 1885, 1299, 2869,  508,  933, 3616, 1657, 2767, 2591, 3996, 1644,
        2870, 2466, 3803,  415])
Epoch: 603, Training Loss: 0.67, Validation Loss: 0.68, accuracy = 0.72
Save best Model_1 @ epoch 603 acc: 0.7174677608440797
Email sent!
######################## Epoch 604 - Batch 1 ########################
IDs in batch 1: tensor([1504,  607, 1123,  863, 3767, 3083, 1852,  884, 1434, 2873, 3486, 2582,
        3028, 1651, 3017,  663])
Epoch: 604, Training Loss: 0.42, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 605 - Batch 1 ########################
IDs in batch 1: tensor([4018, 2833,  312, 2103,   73, 4257, 3905,  440,  994, 1409, 2718,  646,
         503,  965, 1635, 2141])
Epoch: 605, Training Loss: 0.49, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 606 - Batch 1 ########################
IDs in batch 1: tensor([1360,  206,   51, 2292,  662, 2406, 3859, 2467, 1122,   47, 2075, 2207,
        2248, 3385, 3939, 2582])
Epoch: 606, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 607 - Batch 1 ########################
IDs in batch 1: tensor([2179, 1295, 2887, 3731, 2286, 3087, 3765, 4138, 3183, 3632, 2782, 1956,
        2942, 2764, 2763, 3538])
Epoch: 607, Training Loss: 0.82, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 608 - Batch 1 ########################
IDs in batch 1: tensor([1453,  119, 4097, 3529, 2328,  534, 3016, 3014, 3407, 2688, 3474, 4051,
         723, 2526, 2251, 3531])
Epoch: 608, Training Loss: 0.81, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 609 - Batch 1 ########################
IDs in batch 1: tensor([1176,  974,  787,  612, 3789, 2656, 1374, 3701, 1442, 1384, 2417, 2826,
          81,  908, 1290, 3807])
Epoch: 609, Training Loss: 0.74, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 610 - Batch 1 ########################
IDs in batch 1: tensor([1432, 3701, 2023,  159, 2418, 4135, 3487, 4181, 2085, 3859,  306, 3313,
        1193, 3830, 1136, 1504])
Epoch: 610, Training Loss: 0.66, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 611 - Batch 1 ########################
IDs in batch 1: tensor([1942, 3133, 1734,  819,  822, 3367, 4025, 1920, 3524, 2253, 4033,  965,
        1676, 2743,  432,  657])
Epoch: 611, Training Loss: 0.39, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 612 - Batch 1 ########################
IDs in batch 1: tensor([1870,  348, 2280, 2892, 2391, 1177, 1077,  870, 3161, 2600, 1361,  994,
         827,  274,  245, 3956])
Epoch: 612, Training Loss: 0.40, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 613 - Batch 1 ########################
IDs in batch 1: tensor([3640, 1107, 4057,  838, 3052, 1869, 1532,  829, 1670, 2193,  129, 3105,
          39, 4114, 1878,  454])
Epoch: 613, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 614 - Batch 1 ########################
IDs in batch 1: tensor([1413, 2185, 1069, 3443, 1826, 1360, 3351,  699, 1660,  155,  393, 2408,
         100, 3471,  119,  523])
Epoch: 614, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 615 - Batch 1 ########################
IDs in batch 1: tensor([2050, 3961, 1665, 1730, 2767,  492, 4195, 2257, 1130,  660,  672, 3126,
        2298, 1144, 1039, 2170])
Epoch: 615, Training Loss: 0.79, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 616 - Batch 1 ########################
IDs in batch 1: tensor([4154, 3912, 1162, 1950, 1022, 1948, 2179, 2235, 2359, 1022, 3829, 3977,
         132,  276,  672, 1612])
Epoch: 616, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 617 - Batch 1 ########################
IDs in batch 1: tensor([3188, 3862, 3436, 1015, 2439, 2578,  274, 2026,   22,  718,  207, 3440,
         660, 2298, 1102, 2682])
Epoch: 617, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 618 - Batch 1 ########################
IDs in batch 1: tensor([3744, 3532,  583, 3022, 4161, 1720, 2350, 3958, 2516, 1518, 2885,  394,
        3236, 2514, 3130, 3990])
Epoch: 618, Training Loss: 0.59, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 619 - Batch 1 ########################
IDs in batch 1: tensor([4095, 3190, 1589, 3836, 1655, 1826, 1140,   13,  119, 3615, 3534,  741,
        3435, 1357, 4093,  790])
Epoch: 619, Training Loss: 0.71, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 620 - Batch 1 ########################
IDs in batch 1: tensor([ 841,  682, 3961,  640, 1570,  934, 3567,  804, 1160, 1774, 4168, 1044,
        3507, 1834, 2231,   28])
Epoch: 620, Training Loss: 0.76, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 621 - Batch 1 ########################
IDs in batch 1: tensor([3963,  110, 1219, 1445, 2539,  584, 1317, 1594, 1646, 4025, 3436, 3108,
        2693, 3278,  863, 4186])
Epoch: 621, Training Loss: 0.75, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 622 - Batch 1 ########################
IDs in batch 1: tensor([2316, 1181, 3647, 3604, 4148, 3379, 1076, 3836, 2688,  391, 2075, 1567,
        3044, 2817, 3961,  828])
Epoch: 622, Training Loss: 0.80, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 623 - Batch 1 ########################
IDs in batch 1: tensor([ 658, 2349, 2305,  143, 3764, 4101,   32, 3875, 3110, 2552,   61, 4195,
        1143,  816,  874,  145])
Epoch: 623, Training Loss: 0.67, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 624 - Batch 1 ########################
IDs in batch 1: tensor([1337, 1730, 2540, 2517,   84,  582,  837, 2036,  822, 4204, 3168,  316,
        2473, 1297, 4175, 3479])
Epoch: 624, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.73
Save best Model_1 @ epoch 624 acc: 0.7256740914419695
Email sent!
######################## Epoch 625 - Batch 1 ########################
IDs in batch 1: tensor([2551,    7, 2980,  402, 4249, 1832, 4094, 2028, 2990, 3917,  382, 2848,
         826, 1463,   26, 2036])
Epoch: 625, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.73
Save best Model_1 @ epoch 625 acc: 0.7338804220398594
Email sent!
######################## Epoch 626 - Batch 1 ########################
IDs in batch 1: tensor([2224, 3673, 2110, 1627, 3428, 2469, 1341, 2583, 3461,   15, 3632, 1588,
        3298, 3234,  211, 2871])
Epoch: 626, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 627 - Batch 1 ########################
IDs in batch 1: tensor([ 203, 1914, 1413, 1639, 2652, 3597,  767, 3969, 3988, 1660, 1428,  736,
         405, 1530, 2241, 2248])
Epoch: 627, Training Loss: 0.87, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 628 - Batch 1 ########################
IDs in batch 1: tensor([1377, 3753,  942,  499, 1861,  363, 1083, 3334, 2334, 1277,  606, 2551,
         367,  342, 1580, 2819])
Epoch: 628, Training Loss: 0.63, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 629 - Batch 1 ########################
IDs in batch 1: tensor([4187, 2709,  699, 3643, 1053, 2449, 1882, 3417, 3372, 1895,  568,  646,
         103, 3364, 2388,  356])
Epoch: 629, Training Loss: 0.49, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 630 - Batch 1 ########################
IDs in batch 1: tensor([3969, 1005, 2002, 1044, 2173, 2244, 3060, 4004, 1457, 3246, 4097, 3926,
         330,  119, 1404,  613])
Epoch: 630, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 631 - Batch 1 ########################
IDs in batch 1: tensor([4053,  995, 1680, 2433, 2339, 3336, 1646, 1618, 2742,  811, 1836, 2146,
         869, 2646, 3980, 3536])
Epoch: 631, Training Loss: 0.80, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 632 - Batch 1 ########################
IDs in batch 1: tensor([2642, 3745, 3531, 2398,  970, 4030, 2362,  149, 3853, 1868,  257, 1312,
        3082, 3673, 3991, 4234])
Epoch: 632, Training Loss: 0.86, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 633 - Batch 1 ########################
IDs in batch 1: tensor([2205, 4031, 2443,  245,   44,  851,  794, 3242, 1007, 3637,  617,  934,
        1250, 3689, 2019, 3707])
Epoch: 633, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 634 - Batch 1 ########################
IDs in batch 1: tensor([ 250,  617, 3151, 4115, 2127, 1263, 1568, 1043, 3328, 3897,  252, 3659,
        4204,  330, 3156, 3494])
Epoch: 634, Training Loss: 0.69, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 635 - Batch 1 ########################
IDs in batch 1: tensor([2495, 1499,   92, 1970, 2064, 3407, 2470, 2328, 3860, 3227,  960, 2781,
         151, 1594, 2940,  826])
Epoch: 635, Training Loss: 0.58, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 636 - Batch 1 ########################
IDs in batch 1: tensor([1269, 2248, 2316, 3812, 3144, 1354, 4213, 3492, 3203, 3176, 1953,  213,
        2258, 2964, 2121, 1772])
Epoch: 636, Training Loss: 0.46, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 637 - Batch 1 ########################
IDs in batch 1: tensor([1646, 4187, 2966,   73, 4126, 2949, 3354, 2489,  448, 3446, 4156, 3118,
        1179, 2207, 4267, 4005])
Epoch: 637, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 638 - Batch 1 ########################
IDs in batch 1: tensor([1845, 4119, 2074, 2119, 4256, 3960,  538, 3183, 2250, 3254, 3865, 2173,
         723,    4, 3581, 2995])
Epoch: 638, Training Loss: 0.74, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 639 - Batch 1 ########################
IDs in batch 1: tensor([3342,  672, 4085, 1882, 1007, 1851, 3932,  534, 2440, 4070, 3894, 3152,
        1426,  773,  276, 2156])
Epoch: 639, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 640 - Batch 1 ########################
IDs in batch 1: tensor([3704,  343, 4078, 1882,  266, 2444,  387, 1426, 3831, 4016,  603, 3569,
        1395, 4031, 1730, 3996])
Epoch: 640, Training Loss: 0.87, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 641 - Batch 1 ########################
IDs in batch 1: tensor([1986,  419, 3755, 1003,  262,  726, 2357, 2829, 1543, 2485, 4000, 3527,
         818, 2529, 3866, 3948])
Epoch: 641, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 642 - Batch 1 ########################
IDs in batch 1: tensor([1490, 3987, 1140, 3246, 1379, 1737, 3065, 2010, 3376, 2629, 4072, 2667,
        2377, 1017, 3905,  518])
Epoch: 642, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 643 - Batch 1 ########################
IDs in batch 1: tensor([1883, 3262, 1884,   63, 4115, 1233, 1037, 1404, 2842,  128, 2135, 4062,
        3003, 4124,  133, 1242])
Epoch: 643, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 644 - Batch 1 ########################
IDs in batch 1: tensor([1291, 3700, 1168,  659, 1024, 1678, 3339,  603, 2505,  182,  104, 2822,
        1174, 1858, 1022,  281])
Epoch: 644, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 645 - Batch 1 ########################
IDs in batch 1: tensor([1023, 3258, 3132,  389,  921,  516, 2605, 2697, 2771, 3536, 1599, 2891,
        1981, 2051, 1858, 1724])
Epoch: 645, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 646 - Batch 1 ########################
IDs in batch 1: tensor([3053,  151, 1920,  721,  944, 3751,  965, 3458, 1950, 3587, 1258, 3441,
        1951, 1297, 1870, 2459])
Epoch: 646, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 647 - Batch 1 ########################
IDs in batch 1: tensor([2025, 2872, 3336,   73, 1996, 1635,  279, 3617, 2683, 3187,  125,  236,
         915, 2119, 1082,  978])
Epoch: 647, Training Loss: 0.48, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 648 - Batch 1 ########################
IDs in batch 1: tensor([4264, 2357, 1553, 2998, 3005, 2648,  910, 2110, 3497, 3196, 3843, 2844,
        3935, 2343, 1900, 3428])
Epoch: 648, Training Loss: 0.74, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 649 - Batch 1 ########################
IDs in batch 1: tensor([3487, 2173, 1546, 3072, 3166, 2258, 2561, 4116, 1589, 2745, 3900, 1710,
        2745, 2736, 3832, 1802])
Epoch: 649, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 650 - Batch 1 ########################
IDs in batch 1: tensor([ 125, 2485, 1258, 4159,  775, 3977,  452, 1931,  553,  290, 1635, 2426,
         890,  878, 2127,  501])
Epoch: 650, Training Loss: 0.61, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 651 - Batch 1 ########################
IDs in batch 1: tensor([  70, 3738, 1397, 1855,  727, 1131, 2700, 1812,  394, 2034, 2399, 3689,
        1419, 2822, 1463, 3509])
Epoch: 651, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 652 - Batch 1 ########################
IDs in batch 1: tensor([1025,    5, 2869, 2137, 3373, 1185, 2498, 1710, 3751, 2739,  119, 2485,
        1439,   93, 3973, 3660])
Epoch: 652, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 653 - Batch 1 ########################
IDs in batch 1: tensor([2653, 2614, 1305, 3181, 1985, 1772, 3926, 2516, 1746, 3926, 2385, 3357,
        4220, 4114, 3303, 1779])
Epoch: 653, Training Loss: 0.44, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 654 - Batch 1 ########################
IDs in batch 1: tensor([2703, 1900,  590,  466,  663, 1290, 3865, 2956, 1056, 4088,  444, 1708,
         909, 3568, 4053, 2085])
Epoch: 654, Training Loss: 0.62, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 655 - Batch 1 ########################
IDs in batch 1: tensor([2493, 3044,  143,  667,  550, 1299, 3767, 1496, 4226, 2329, 3049,  923,
        2331,  808, 1684, 4195])
Epoch: 655, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 656 - Batch 1 ########################
IDs in batch 1: tensor([1932, 4103, 2116,  909, 2546,  652,   27, 2297, 1360, 1051, 2506, 3371,
        2328, 2773, 1025, 4163])
Epoch: 656, Training Loss: 0.42, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 657 - Batch 1 ########################
IDs in batch 1: tensor([ 983, 2448,  217,   34, 2642,  482, 1993, 1386, 2867,  926, 2555, 2584,
        3717, 1275, 1596, 4140])
Epoch: 657, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 658 - Batch 1 ########################
IDs in batch 1: tensor([2458, 2213,  980, 2363, 3912, 3243, 1472,  558,   18,  578, 4011, 3354,
        2388,  357, 3135, 1157])
Epoch: 658, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 659 - Batch 1 ########################
IDs in batch 1: tensor([ 238, 1974, 4217, 3858, 2898, 3069, 1273, 3792, 1120, 3815, 1305, 2996,
        1732,  534, 3542,  485])
Epoch: 659, Training Loss: 0.68, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 660 - Batch 1 ########################
IDs in batch 1: tensor([1855,  645, 1761, 1855, 4008, 1823, 2329, 4180,  586, 2982,   51,  348,
        3399, 3599, 1853,   95])
Epoch: 660, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 661 - Batch 1 ########################
IDs in batch 1: tensor([2276, 2257, 2621, 3738, 3343, 3338,  324, 3669,  206, 1286, 1289, 4181,
         516,  312,  986,  892])
Epoch: 661, Training Loss: 0.63, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 662 - Batch 1 ########################
IDs in batch 1: tensor([4224, 1341, 1213,  625, 3553, 3987, 3991, 2567, 1967,  828, 1953, 1139,
        2907, 2887, 1678, 3252])
Epoch: 662, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.74
Save best Model_1 @ epoch 662 acc: 0.738569753810082
Email sent!
######################## Epoch 663 - Batch 1 ########################
IDs in batch 1: tensor([1196, 1819, 1070, 3638,  818, 1436, 1746, 1417,   26, 3667, 1090,  363,
        2237,  627, 3098, 2836])
Epoch: 663, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 664 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 4115,  751,  199, 2070, 1463, 2631, 2978, 1826, 1125, 2337,  492,
        2729, 2327, 3329, 4114])
Epoch: 664, Training Loss: 0.74, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 665 - Batch 1 ########################
IDs in batch 1: tensor([2191, 2891, 4026, 1409, 1404, 2624, 2260, 2822, 4229, 3894, 1174, 3236,
        2492, 3217, 2912,  360])
Epoch: 665, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 666 - Batch 1 ########################
IDs in batch 1: tensor([3640,  207, 1619, 4232, 2936, 1931, 2073, 3798, 1684, 1728, 1236,  736,
        2497, 2204, 2760, 3100])
Epoch: 666, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 667 - Batch 1 ########################
IDs in batch 1: tensor([2477, 2358, 3698, 2796, 3246, 2571, 3110, 3947, 3644, 3998,    5, 3514,
        1425, 3099,  537, 1275])
Epoch: 667, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 668 - Batch 1 ########################
IDs in batch 1: tensor([1390,  689, 3438, 4125, 1521, 1650, 2529,  803, 2415, 1410, 2687, 1284,
        2772, 1073, 1521, 2484])
Epoch: 668, Training Loss: 0.51, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 669 - Batch 1 ########################
IDs in batch 1: tensor([ 704,  733, 2279, 3604, 3073, 3739,  490, 3581,  531, 3789, 1437, 1746,
        4035, 2661, 3568,   96])
Epoch: 669, Training Loss: 0.77, Validation Loss: 0.67, accuracy = 0.74
Save best Model_1 @ epoch 669 acc: 0.7397420867526378
Email sent!
######################## Epoch 670 - Batch 1 ########################
IDs in batch 1: tensor([  18, 1408, 2978,  255,  306, 2479,  384, 2317, 4075,  897,  670,  321,
        2842, 2764,  275,   35])
Epoch: 670, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 671 - Batch 1 ########################
IDs in batch 1: tensor([ 454, 2961,  942, 4012, 2466,   85, 3815, 1613, 4055, 2535, 1999, 1039,
        1984, 2313, 4017, 3830])
Epoch: 671, Training Loss: 0.58, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 672 - Batch 1 ########################
IDs in batch 1: tensor([3144, 3024, 2014, 1639, 2672, 2482, 3676,  544, 2209, 1552,  882, 1935,
         367, 3395, 3553, 1984])
Epoch: 672, Training Loss: 0.63, Validation Loss: 0.67, accuracy = 0.74
Save best Model_1 @ epoch 672 acc: 0.7432590855803048
Email sent!
######################## Epoch 673 - Batch 1 ########################
IDs in batch 1: tensor([ 953, 2198, 4261, 3139,  323, 2193, 3204, 2290, 2028,  256, 1419, 4203,
        3075, 2603, 1860, 1956])
Epoch: 673, Training Loss: 0.77, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 674 - Batch 1 ########################
IDs in batch 1: tensor([1302, 2386, 2571, 2436, 2406, 1726, 3913, 1384, 3583, 2845, 1122, 1125,
         923, 1821,  595, 1756])
Epoch: 674, Training Loss: 0.82, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 675 - Batch 1 ########################
IDs in batch 1: tensor([3713, 3065, 1321, 3394,   82, 2257,   47, 3289, 1482, 1568, 2810, 3964,
         678,  378, 3593,  236])
Epoch: 675, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 676 - Batch 1 ########################
IDs in batch 1: tensor([1639, 2761, 3119, 3055, 1526, 2284, 1846, 3933, 1819, 1559, 1171, 1772,
         575, 2823, 4175, 2489])
Epoch: 676, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 677 - Batch 1 ########################
IDs in batch 1: tensor([3958, 3714, 2991,  401, 1556, 3408,  237, 1597, 3228, 3018,  516, 4088,
         467, 2415, 1436, 4050])
Epoch: 677, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 678 - Batch 1 ########################
IDs in batch 1: tensor([ 436, 3714, 1377, 2706,  615, 3370, 2014, 1489, 3358, 3020, 2085, 1373,
        3345, 1877, 1125, 4027])
Epoch: 678, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 679 - Batch 1 ########################
IDs in batch 1: tensor([2960, 1180, 4146, 2817,  601, 1166, 2636, 1443,  252, 3742, 1665, 4170,
        1663, 2642,  875, 1877])
Epoch: 679, Training Loss: 0.74, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 680 - Batch 1 ########################
IDs in batch 1: tensor([1618, 1632, 2092, 3947,  739,  195,  555, 1080, 1471,  563, 3105, 1444,
        3254,  577, 3455, 4016])
Epoch: 680, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 681 - Batch 1 ########################
IDs in batch 1: tensor([ 308, 4017, 2546, 2701, 4215,  907, 4107, 2636, 2094,  499, 1566,  681,
        4258, 1585, 4073, 2772])
Epoch: 681, Training Loss: 0.76, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 682 - Batch 1 ########################
IDs in batch 1: tensor([3040, 1986, 2183, 2064, 1434, 3345, 4097, 2823, 1026, 1249, 2751, 2536,
         173,   10, 2926, 1316])
Epoch: 682, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 683 - Batch 1 ########################
IDs in batch 1: tensor([3744, 1595, 2558, 4008, 1077, 2429,  808, 1842, 4268, 1491, 1153, 3223,
        1949, 2377, 3372, 1636])
Epoch: 683, Training Loss: 0.56, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 684 - Batch 1 ########################
IDs in batch 1: tensor([  98,  811, 1140, 3697, 1497, 3668,  390, 1364, 2807,  234, 2290, 4120,
        2038, 3647,  826, 2190])
Epoch: 684, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 685 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 3933, 4180, 1137, 1643, 3018, 1175, 2849,  203,  444, 1927, 1310,
         966,  874, 1037, 2456])
Epoch: 685, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 686 - Batch 1 ########################
IDs in batch 1: tensor([  28,  699,  199, 1294, 3114,  489, 2183,  172, 1371, 2669,  752, 2826,
         530, 3394,  507, 4046])
Epoch: 686, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 687 - Batch 1 ########################
IDs in batch 1: tensor([2038, 3428, 2591,  135, 4062, 3616, 2348, 3141, 1124, 2680, 1039,  613,
        2332, 2106, 3277,  136])
Epoch: 687, Training Loss: 0.66, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 688 - Batch 1 ########################
IDs in batch 1: tensor([3669, 3047,  796, 1765,   88, 4218, 3159, 2574, 2023,  555,  834, 3985,
        1231, 1125, 2387, 2748])
Epoch: 688, Training Loss: 0.66, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 689 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 2901, 3972, 1231,  377, 2027, 1508, 3453, 1178,  371, 2823, 1803,
        3157, 1540, 2326, 2407])
Epoch: 689, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 690 - Batch 1 ########################
IDs in batch 1: tensor([ 205,  830, 1686, 2913, 3272,  355, 3876, 2461,  741, 2173, 3926, 3853,
        1226, 2028, 3588,  327])
Epoch: 690, Training Loss: 0.71, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 691 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 2459, 2476, 3516, 2159, 2579, 3310, 1312, 2044, 3713, 2189,  749,
        3693, 4234, 1885, 1377])
Epoch: 691, Training Loss: 0.62, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 692 - Batch 1 ########################
IDs in batch 1: tensor([2727,   19, 2506,  808, 2718, 1417, 1090,  820, 2945,  117, 1332,  846,
        2583,  177, 1665,   41])
Epoch: 692, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 693 - Batch 1 ########################
IDs in batch 1: tensor([4036, 4049,  117, 3139, 1559, 2192,  977, 2917, 3577, 3390, 3345, 4217,
        2536, 2426, 4198, 3603])
Epoch: 693, Training Loss: 0.77, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 694 - Batch 1 ########################
IDs in batch 1: tensor([3128,  557,  154, 1957, 2086, 3049, 1098, 1938,  957,  966, 1716, 1817,
        2179,   74, 3675, 3663])
Epoch: 694, Training Loss: 0.47, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 695 - Batch 1 ########################
IDs in batch 1: tensor([2544,  467, 1500, 1913, 3683, 2252,  594, 2621, 2030, 3900, 2619, 2960,
        1023,  824, 2645, 1772])
Epoch: 695, Training Loss: 0.49, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 696 - Batch 1 ########################
IDs in batch 1: tensor([ 478, 1545, 1248, 3936, 2919, 4220, 3463, 3476, 1418,  762, 1551, 2172,
        1947, 3016, 4266, 1500])
Epoch: 696, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 697 - Batch 1 ########################
IDs in batch 1: tensor([3802, 4184, 1225, 3057, 3847, 4108, 3650, 3718,  519, 3279, 1855, 2455,
        2372, 3818, 1602, 3318])
Epoch: 697, Training Loss: 1.19, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 698 - Batch 1 ########################
IDs in batch 1: tensor([2746, 4000, 1777, 1306, 4093,  405, 3487, 1026, 4050, 2357, 2298, 1005,
         317,   62, 3744,  727])
Epoch: 698, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 699 - Batch 1 ########################
IDs in batch 1: tensor([ 373, 2350, 4077,  577, 2780, 2663, 4051, 1942,  394, 3881,  154, 3098,
        3136,  262, 3870,  620])
Epoch: 699, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 700 - Batch 1 ########################
IDs in batch 1: tensor([ 511, 2278, 3610, 1498,  494, 1958, 4168, 2517,  524,  588, 3407, 1641,
        2572, 1266, 2203, 1373])
Epoch: 700, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 701 - Batch 1 ########################
IDs in batch 1: tensor([2614,  819, 1003, 2364, 2117, 2832, 1116, 2505, 3569, 2413,  693, 1499,
         390, 4195, 3118,  405])
Epoch: 701, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 702 - Batch 1 ########################
IDs in batch 1: tensor([1471, 3865, 3389, 1993, 2959,   20, 1967, 3498, 2937, 1405, 2610, 2555,
         974, 1567,  139, 2802])
Epoch: 702, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 703 - Batch 1 ########################
IDs in batch 1: tensor([3530, 3933, 2357,  388,  314, 4138, 1417,   95, 2025, 1286, 1798,  129,
         852, 1834, 2357,  112])
Epoch: 703, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 704 - Batch 1 ########################
IDs in batch 1: tensor([2323, 2137,   32, 2664, 2541, 4089, 2475, 3787, 3042, 1986, 3448, 3997,
        3257, 2223, 2656, 1397])
Epoch: 704, Training Loss: 0.61, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 705 - Batch 1 ########################
IDs in batch 1: tensor([4170,   51, 2169,  615,  796, 1387,  586, 3604, 2880,  436, 1077, 4005,
        3362,  879, 2352, 1448])
Epoch: 705, Training Loss: 0.50, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 706 - Batch 1 ########################
IDs in batch 1: tensor([1548, 1840,  185, 4093,  928, 3833, 3353, 1275, 4126, 2413, 2349, 3936,
        3597, 3039, 3421, 1212])
Epoch: 706, Training Loss: 0.63, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 707 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 2150,  402,  844, 1972,  232, 2122, 3478, 3306, 3356, 2250, 2090,
        2231,  785, 1055, 1250])
Epoch: 707, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 708 - Batch 1 ########################
IDs in batch 1: tensor([3025, 1326,  918, 2743, 3977, 1852, 2802, 3795,  910, 3793, 3484, 3438,
        3399,  710,  295, 3100])
Epoch: 708, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 709 - Batch 1 ########################
IDs in batch 1: tensor([3035, 3544, 3014,  452, 3304, 1612, 2807, 2088, 3950, 1347, 3672, 3532,
        2826, 2353, 1496,  430])
Epoch: 709, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 710 - Batch 1 ########################
IDs in batch 1: tensor([2791, 1370, 2144, 2616, 3298, 1473,  305,  237, 1942, 3087,  709,  343,
         214,  897, 4159, 3166])
Epoch: 710, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 711 - Batch 1 ########################
IDs in batch 1: tensor([  30, 3516, 3410,  427, 1137, 3533, 2099, 2455,  590, 1274, 3996, 3501,
        4198, 3886,  108,  968])
Epoch: 711, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 712 - Batch 1 ########################
IDs in batch 1: tensor([2234,  212, 3790, 2008,  348, 2692, 1213, 2924, 1476,  470, 2018,  295,
        3354, 4025, 3843, 2476])
Epoch: 712, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 713 - Batch 1 ########################
IDs in batch 1: tensor([3718, 1049, 2412, 1061, 2296, 3577, 2367, 3244,   70, 3962, 1090, 4006,
        3490,  312,   71, 2817])
Epoch: 713, Training Loss: 0.70, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 714 - Batch 1 ########################
IDs in batch 1: tensor([2603, 4051, 2121, 1144, 3039, 1111, 2407, 3121, 3511,  688,  936, 2924,
        4061,  409, 3592,   93])
Epoch: 714, Training Loss: 0.51, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 715 - Batch 1 ########################
IDs in batch 1: tensor([ 724,  976, 4187, 2776, 3830, 2357, 2604, 3253, 1045, 2064,   15, 3698,
         635, 3118, 1685, 2781])
Epoch: 715, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 716 - Batch 1 ########################
IDs in batch 1: tensor([2245, 3261, 2601, 3023,  713,  941,  217, 2031, 2301,  812, 1082, 1950,
        1244, 2524, 3536, 3803])
Epoch: 716, Training Loss: 0.48, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 717 - Batch 1 ########################
IDs in batch 1: tensor([ 740,  322, 4139, 1281,  372, 1028, 2738, 3384,  164, 3417,  382,  337,
         455, 4236, 2049,  256])
Epoch: 717, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 718 - Batch 1 ########################
IDs in batch 1: tensor([1754, 2180, 4154, 3286,  989, 3382, 2550, 1910,   44, 3997, 2065, 3481,
        1051, 3577, 1439,  717])
Epoch: 718, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 719 - Batch 1 ########################
IDs in batch 1: tensor([ 933, 3987, 2181, 2701, 3594, 2408, 1793, 1988, 2597,  848, 3223, 3148,
         232,  830,  786, 1802])
Epoch: 719, Training Loss: 0.92, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 720 - Batch 1 ########################
IDs in batch 1: tensor([ 679,  622, 2719,  127, 1591, 1613, 3426, 2869, 2708, 2745, 2552, 2726,
        1658, 3376,   26, 3152])
Epoch: 720, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 721 - Batch 1 ########################
IDs in batch 1: tensor([2845, 2038, 3942, 3385, 4230,  615,  959,  960, 2286,  220, 2887, 3447,
         977, 4236, 1506,  484])
Epoch: 721, Training Loss: 0.32, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 722 - Batch 1 ########################
IDs in batch 1: tensor([4037, 1671, 2489,  324,  628, 3453,  105, 3131,  388, 2329, 1869, 3503,
        3184,  582, 2597, 2114])
Epoch: 722, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 723 - Batch 1 ########################
IDs in batch 1: tensor([2405,  676,  501,  659, 2991, 1570, 1063, 1599, 3425, 1676, 1748, 3217,
        3430,   61, 3787, 4086])
Epoch: 723, Training Loss: 0.53, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 724 - Batch 1 ########################
IDs in batch 1: tensor([2697, 3693, 4144, 4184, 2453, 3275, 2123,  325, 1594, 3904, 3342, 2326,
        1380, 4168, 2978,  343])
Epoch: 724, Training Loss: 0.67, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 725 - Batch 1 ########################
IDs in batch 1: tensor([1761, 2178, 2800, 1341, 1690, 3406, 1428, 3888,  516,   18,  823,  625,
          73,  897,  202,  266])
Epoch: 725, Training Loss: 0.72, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 726 - Batch 1 ########################
IDs in batch 1: tensor([1391, 2855, 3014, 1260,  851, 3543, 3935,  679, 3047, 2773, 2842, 3401,
        2932, 1104, 1677, 1960])
Epoch: 726, Training Loss: 0.54, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 727 - Batch 1 ########################
IDs in batch 1: tensor([2791,  792, 3765, 1251, 2648, 2581, 2697, 1233,  894, 2524, 2402, 1948,
        3084, 1781, 2773,  952])
Epoch: 727, Training Loss: 0.53, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 728 - Batch 1 ########################
IDs in batch 1: tensor([1056,  315,  187,  308,  538, 4031, 3554, 3109,  887, 3473, 3600, 2582,
         255, 2806, 1493, 3188])
Epoch: 728, Training Loss: 0.56, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 729 - Batch 1 ########################
IDs in batch 1: tensor([2764, 2885, 2229,  432,  957, 4223, 1506, 3913, 4119, 1863, 1871, 1256,
        2141, 3474, 3830, 1395])
Epoch: 729, Training Loss: 0.40, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 730 - Batch 1 ########################
IDs in batch 1: tensor([ 983, 2892, 1102, 3421, 1458, 3363, 3333, 1618, 2541, 2362, 3461, 2116,
        3284, 1306,   73, 4166])
Epoch: 730, Training Loss: 0.48, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 731 - Batch 1 ########################
IDs in batch 1: tensor([2378, 1076, 2203, 3071, 3406, 2355, 3836, 1857, 3118, 1910, 4214, 1267,
        3509, 3214,  478, 3816])
Epoch: 731, Training Loss: 0.66, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 732 - Batch 1 ########################
IDs in batch 1: tensor([2687, 3333, 2344, 2090, 1371, 2926,  893, 3367, 3133, 1471,  900,  950,
          77, 3382, 1419, 3659])
Epoch: 732, Training Loss: 0.45, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 733 - Batch 1 ########################
IDs in batch 1: tensor([3264, 4027, 2419, 3438, 1833, 2957,  134, 1161,    5, 3568, 3756,  469,
        1295, 3970, 3793, 2444])
Epoch: 733, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 734 - Batch 1 ########################
IDs in batch 1: tensor([3808, 1124,  556, 2609,  827, 2868, 3101, 3920, 1103, 3667, 1850, 1585,
         512, 2725, 4048,  936])
Epoch: 734, Training Loss: 0.57, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 735 - Batch 1 ########################
IDs in batch 1: tensor([3275,  214,  827, 2470, 1861, 4040, 1491, 1858, 3618, 3969, 1566, 2142,
        3860, 2446, 2949, 4113])
Epoch: 735, Training Loss: 0.56, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 736 - Batch 1 ########################
IDs in batch 1: tensor([ 389, 1136,  843, 4096, 1001, 2298, 1728, 3472, 1185, 4235, 2407, 3615,
        3697,  770, 3677, 2306])
Epoch: 736, Training Loss: 0.53, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 737 - Batch 1 ########################
IDs in batch 1: tensor([3590,  538, 3313,  112, 3943, 2567, 4113, 2362, 3674, 1730, 2587, 2898,
        1153, 1723, 3919, 1767])
Epoch: 737, Training Loss: 0.68, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 738 - Batch 1 ########################
IDs in batch 1: tensor([ 206, 2751, 3378, 2555, 3700,  490, 3233, 1596, 2452, 2708, 1965, 1957,
         828,  488, 1041,  952])
Epoch: 738, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 739 - Batch 1 ########################
IDs in batch 1: tensor([3448, 3166, 2737, 1599,  341, 4180,  959, 2652, 3531, 1154, 1278, 1439,
        3467, 1802, 3744, 4061])
Epoch: 739, Training Loss: 0.53, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 740 - Batch 1 ########################
IDs in batch 1: tensor([3700,  380, 3003,  194, 1325, 1624,  120,  348, 2661, 1680, 2366, 1436,
          20, 3414, 2250, 1410])
Epoch: 740, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 741 - Batch 1 ########################
IDs in batch 1: tensor([3368, 3168, 2390, 1219, 3733, 1380, 1914,  360,  732, 1118, 1007,  538,
        3141, 2167, 4114,  322])
Epoch: 741, Training Loss: 0.83, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 742 - Batch 1 ########################
IDs in batch 1: tensor([2209, 2771,  770, 1562, 1075, 1489, 3434, 3500, 4263, 3590,  419, 2416,
        1883,  533, 3707, 2578])
Epoch: 742, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 743 - Batch 1 ########################
IDs in batch 1: tensor([3590, 1128,  977, 3668,  851,  894, 2688, 1647,   13, 1144,  757,  894,
        2116, 1294,  835, 3465])
Epoch: 743, Training Loss: 0.69, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 744 - Batch 1 ########################
IDs in batch 1: tensor([4058, 3160, 2800,  262, 3635, 3148, 3714, 1938,  665, 3408, 1760, 1965,
        1406, 3659, 4030, 3552])
Epoch: 744, Training Loss: 0.84, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 745 - Batch 1 ########################
IDs in batch 1: tensor([  32, 2907, 2245, 1892, 1570, 2278,  219, 3992, 1377, 2051, 3542,  225,
        1937, 1786,  946, 3628])
Epoch: 745, Training Loss: 0.54, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 746 - Batch 1 ########################
IDs in batch 1: tensor([2439,  194,  977, 1208,  989, 1361, 2091, 2280, 1059, 2346, 1193, 3753,
        4057, 2088, 1602, 1812])
Epoch: 746, Training Loss: 0.44, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 747 - Batch 1 ########################
IDs in batch 1: tensor([ 615, 3630, 3227, 2954, 3542,   37,  131, 3948, 2983, 1180, 1015, 2161,
         691,  398, 1054,  657])
Epoch: 747, Training Loss: 0.56, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 748 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1914, 1428, 1793, 1971,  394, 3135, 4086, 2465, 3881, 3430, 2737,
        2450, 1911, 2969,  750])
Epoch: 748, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 749 - Batch 1 ########################
IDs in batch 1: tensor([1182, 1620, 1988, 3438, 4185,  969,  167,  422,  822, 1331, 3368, 1045,
        1234,   34,  418,   21])
Epoch: 749, Training Loss: 0.68, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 750 - Batch 1 ########################
IDs in batch 1: tensor([ 701, 2851,  136, 2473, 4062,  662, 3997, 3841,  105, 1183, 2127, 1672,
        2568,  639, 1487,  578])
Epoch: 750, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 751 - Batch 1 ########################
IDs in batch 1: tensor([3073, 1178, 2536, 2869, 1001,   13, 1507, 1857, 4220, 1731, 2480, 2653,
        3074, 2584, 1031, 2074])
Epoch: 751, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 752 - Batch 1 ########################
IDs in batch 1: tensor([4117, 1803, 1578,  161, 2028, 1177, 3609, 4032, 2207,  344, 2150, 1934,
        1181, 3948, 2350,  121])
Epoch: 752, Training Loss: 0.41, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 753 - Batch 1 ########################
IDs in batch 1: tensor([2488, 3593,   73, 1393,  955, 2682, 2091, 2230, 2841, 2579,   82, 2627,
        4022, 2539,  605, 1132])
Epoch: 753, Training Loss: 0.74, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 754 - Batch 1 ########################
IDs in batch 1: tensor([2921,  401, 1405, 3545, 3267, 2433, 1493,  918, 1186, 3925, 3729, 1630,
        3053, 1367, 2674, 3535])
Epoch: 754, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 755 - Batch 1 ########################
IDs in batch 1: tensor([4114, 2804, 1828, 3699, 1120, 3852, 1638, 3563, 1953, 4240, 1723, 2564,
        1206, 3323, 1007, 3534])
Epoch: 755, Training Loss: 0.75, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 756 - Batch 1 ########################
IDs in batch 1: tensor([1602,  871,  469, 1081, 3058, 2142, 2206, 1457, 3259, 1990, 3441, 3907,
         710, 1255, 2353, 3700])
Epoch: 756, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 757 - Batch 1 ########################
IDs in batch 1: tensor([3336, 4032, 3221,  529, 1562, 1344, 1680, 2890, 2435, 3765, 1384, 2736,
         402, 2788,   39,  557])
Epoch: 757, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 758 - Batch 1 ########################
IDs in batch 1: tensor([2815,  773,  835, 4033, 1859, 2113, 1320,  787, 3588, 3744, 1642, 2179,
        1167, 3707, 2600, 2080])
Epoch: 758, Training Loss: 0.69, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 759 - Batch 1 ########################
IDs in batch 1: tensor([3911, 2199, 3447, 3222,  275, 2228, 3650, 1421, 2840, 2550, 1551, 1077,
        2060, 1299, 1294, 4108])
Epoch: 759, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 760 - Batch 1 ########################
IDs in batch 1: tensor([ 484,  323, 1833,  405, 2996, 2220, 3658, 2770,  265,  522, 2691, 2601,
        1153,  663, 1613,  941])
Epoch: 760, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 761 - Batch 1 ########################
IDs in batch 1: tensor([ 963, 1634, 3016, 3444, 4141, 2727, 3777,  601, 4158, 2619, 2035, 1506,
         762, 3523,  195, 3458])
Epoch: 761, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 762 - Batch 1 ########################
IDs in batch 1: tensor([3447, 3432, 1152,  243, 1502,  376, 3000, 1059,  670, 3806, 3712, 1660,
        3428, 3683,  377,  322])
Epoch: 762, Training Loss: 0.80, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 763 - Batch 1 ########################
IDs in batch 1: tensor([4238,  437, 4069, 1469, 1333, 3385,  862,  622, 1909,  367,  627, 2891,
          62, 2999, 2232, 3977])
Epoch: 763, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 764 - Batch 1 ########################
IDs in batch 1: tensor([ 257, 2890,   18, 1255, 2919, 1409, 3569, 2416, 2932,   35, 1938,  145,
        1751, 1073, 2770, 3731])
Epoch: 764, Training Loss: 0.32, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 765 - Batch 1 ########################
IDs in batch 1: tensor([2224, 1360, 3143, 1746,  342, 2815, 3933, 3630, 3268, 2091, 2873, 3162,
        2810,  334, 1474, 1193])
Epoch: 765, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 766 - Batch 1 ########################
IDs in batch 1: tensor([  52, 2298, 3238, 1056, 3451, 2469, 2406, 3207,  515, 1809, 4067, 1952,
         105, 4234, 1993,  949])
Epoch: 766, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 767 - Batch 1 ########################
IDs in batch 1: tensor([ 180, 2250, 2734, 3326, 3925, 3427, 3553, 1993,  167, 1762, 3150, 1956,
        2418, 1176, 4012, 2301])
Epoch: 767, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 768 - Batch 1 ########################
IDs in batch 1: tensor([3203, 2954, 2204, 3652, 2733,  284,  316, 1661,  864, 2004,   35, 1573,
        2080, 3834, 2967, 1679])
Epoch: 768, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 769 - Batch 1 ########################
IDs in batch 1: tensor([1306, 1463, 2401, 1562,  193, 1212, 3529, 2926, 1796, 1698, 1283,  160,
        1030, 3554, 2777, 3866])
Epoch: 769, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 770 - Batch 1 ########################
IDs in batch 1: tensor([1578, 3554, 1655,   70,  184, 3904,  926, 3246, 2614, 4056,  326, 1405,
         151,   71, 3146, 2986])
Epoch: 770, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 771 - Batch 1 ########################
IDs in batch 1: tensor([ 412, 2737, 3214, 3124, 1597, 3387, 1437, 1195, 1596, 1310, 1080, 3499,
        2546, 3917, 1704,  395])
Epoch: 771, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 772 - Batch 1 ########################
IDs in batch 1: tensor([1055, 1711,  794, 4267, 3188,  151,  505, 2475, 2146, 4265, 1826,  452,
        1139,  875, 1355, 1336])
Epoch: 772, Training Loss: 0.60, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 773 - Batch 1 ########################
IDs in batch 1: tensor([2122,  740, 2098, 3974,  516, 2736, 1548, 3391, 3936,  217, 1080, 1459,
         665, 4194, 1285, 2993])
Epoch: 773, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 774 - Batch 1 ########################
IDs in batch 1: tensor([2731,  354, 3507, 2238, 3962, 1558, 3451, 3124, 3433,  332, 3871, 2461,
        1370,  139, 1083,  375])
Epoch: 774, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 775 - Batch 1 ########################
IDs in batch 1: tensor([2398,  104, 1097, 3746, 1918, 3333, 1144,  602, 1675, 3407, 2251, 2482,
        1030,  201,  467, 2009])
Epoch: 775, Training Loss: 0.87, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 776 - Batch 1 ########################
IDs in batch 1: tensor([3310, 1197,  968,  399, 1223, 2097, 2783, 3051, 1047, 3160, 1174, 3592,
         472, 1648, 2810, 4226])
Epoch: 776, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 777 - Batch 1 ########################
IDs in batch 1: tensor([4067,  161,  104, 1370,  111, 4205, 2727,  832, 3310, 3196,  217,  724,
         910,  897, 3705,  943])
Epoch: 777, Training Loss: 1.02, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 778 - Batch 1 ########################
IDs in batch 1: tensor([2469, 2599, 4140, 2950, 2804,  735, 4251, 3395, 3987, 3992, 3643, 3248,
        2799,  683,  283, 2854])
Epoch: 778, Training Loss: 0.87, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 779 - Batch 1 ########################
IDs in batch 1: tensor([ 290, 1845, 1199, 4204, 2544,   77, 2045, 3437, 2781, 4181, 3044, 3654,
        1201, 3218, 4127, 4238])
Epoch: 779, Training Loss: 0.51, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 780 - Batch 1 ########################
IDs in batch 1: tensor([1429, 2668, 4046, 4096, 2315, 1442, 3382, 2562, 3648, 4082,  739,  221,
         139, 2051, 1610, 3479])
Epoch: 780, Training Loss: 0.55, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 781 - Batch 1 ########################
IDs in batch 1: tensor([ 326, 1229, 3732,  238, 3353, 3912, 1942, 3683,  345,  200, 1551, 3917,
        4261,  993, 3480,   96])
Epoch: 781, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 782 - Batch 1 ########################
IDs in batch 1: tensor([3806, 3958, 2692, 1415, 1347,  749, 1352, 1665, 2323, 2606, 2787, 4152,
         636, 1553,  317, 1548])
Epoch: 782, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 783 - Batch 1 ########################
IDs in batch 1: tensor([3100, 3911, 3219, 3248,   39, 1005, 1956, 1377, 1278, 2018,  229, 3072,
        1381,  203, 2731, 1337])
Epoch: 783, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 784 - Batch 1 ########################
IDs in batch 1: tensor([3049, 1426, 1235, 1120,  105, 3698,  835,   84, 1049, 3329, 3143, 2982,
        1704, 4199, 1016, 3244])
Epoch: 784, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 785 - Batch 1 ########################
IDs in batch 1: tensor([3471, 3154,  691,  490, 3312, 1476,  568, 2230,  360,  636,  388, 2010,
        1952, 1519, 1060, 2405])
Epoch: 785, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 786 - Batch 1 ########################
IDs in batch 1: tensor([1726, 3130, 1770, 1886,  699, 1310,  714,  451, 2170, 1892, 3340,  977,
        1134, 2917,  595,  314])
Epoch: 786, Training Loss: 0.45, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 787 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 2331, 2316,  141, 3538, 1567,  691, 2999, 1818, 3484, 1287,  943,
        1320, 1026,  507, 1613])
Epoch: 787, Training Loss: 0.63, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 788 - Batch 1 ########################
IDs in batch 1: tensor([2228, 2999, 2081,  987, 2541, 1198, 3051, 2408, 3961, 3488, 3513,  568,
        1332,  586,  989, 4133])
Epoch: 788, Training Loss: 0.83, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 789 - Batch 1 ########################
IDs in batch 1: tensor([3617, 2676, 3136, 4217,  212, 3697, 1375, 4094, 3745,  637, 1084, 1023,
        3782, 4203, 1330,  143])
Epoch: 789, Training Loss: 0.89, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 790 - Batch 1 ########################
IDs in batch 1: tensor([1996,  890, 1171, 3674, 3148, 1283, 1988, 4002,  891, 4122, 3962, 3798,
        3530, 3983, 2763, 1634])
Epoch: 790, Training Loss: 0.80, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 791 - Batch 1 ########################
IDs in batch 1: tensor([2493, 4085, 4140, 4242, 2721,  803, 2323, 2189, 1945, 1981,  455, 3127,
         574, 2837, 3203, 3740])
Epoch: 791, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 792 - Batch 1 ########################
IDs in batch 1: tensor([3674, 1377, 1933, 4006, 1948,  816, 1361, 3601, 2328, 3513, 2452, 3456,
        1558, 3991, 3037,  546])
Epoch: 792, Training Loss: 0.52, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 793 - Batch 1 ########################
IDs in batch 1: tensor([  46, 1842,  330,  362, 2306, 4061, 1380,  855, 2999, 3650,  790, 3037,
        2519, 2431, 4197, 1965])
Epoch: 793, Training Loss: 0.61, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 794 - Batch 1 ########################
IDs in batch 1: tensor([1484, 3133, 1372, 2583, 1335,  488, 3702, 2844, 1252, 3142, 4220, 2244,
         899,  828, 3425, 1425])
Epoch: 794, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 795 - Batch 1 ########################
IDs in batch 1: tensor([3769, 2598,   59,  141, 3503, 3661, 1496,  855,  348,  954, 3816, 2691,
        3656, 3664, 1103,  907])
Epoch: 795, Training Loss: 0.76, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 796 - Batch 1 ########################
IDs in batch 1: tensor([1081,  393, 1642,  627,  503, 2483, 2855, 1346, 1646, 3885, 1723,  712,
        1039, 3118, 3886, 1812])
Epoch: 796, Training Loss: 0.46, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 797 - Batch 1 ########################
IDs in batch 1: tensor([1711, 4161, 2584, 1660, 2346, 3272,  693, 4036, 3950, 3756, 1061, 4057,
        2014, 3537,  663,  977])
Epoch: 797, Training Loss: 0.59, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 798 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 1177, 3990, 2250, 3674, 1212, 2851, 3628, 1111,  829, 1730, 1773,
         152, 3182, 3427, 1458])
Epoch: 798, Training Loss: 0.45, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 799 - Batch 1 ########################
IDs in batch 1: tensor([ 832, 2400,    5, 4131, 1166, 1093, 3401, 1967,  337, 2695, 3648, 3676,
        3130, 2189, 2399, 2052])
Epoch: 799, Training Loss: 0.68, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 800 - Batch 1 ########################
IDs in batch 1: tensor([3327, 3453, 1421, 3139,  881,   35, 2700, 2982, 3667, 4070, 3479,  771,
        2725, 2887, 2135, 2671])
Epoch: 800, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 801 - Batch 1 ########################
IDs in batch 1: tensor([1860, 2365, 1454, 1286, 1324, 1588, 2653, 1869, 1448,  430,   99, 1923,
         435,  279, 4222, 3353])
Epoch: 801, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 802 - Batch 1 ########################
IDs in batch 1: tensor([2386, 1062,  357,   62,   51, 3668,  415, 2876,  332, 2947, 2016,  226,
        3004, 2493,  236, 1625])
Epoch: 802, Training Loss: 0.57, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 803 - Batch 1 ########################
IDs in batch 1: tensor([4224, 1297,  524, 1971, 4172, 1030, 2119, 1636, 3255,  342, 3493,  558,
        3939, 3617, 2782, 3027])
Epoch: 803, Training Loss: 0.67, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 804 - Batch 1 ########################
IDs in batch 1: tensor([3427, 1133, 3962, 2219, 4067, 3757, 2497,  133,  221, 3317, 2265,  747,
        3206, 2646, 1324, 2364])
Epoch: 804, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 805 - Batch 1 ########################
IDs in batch 1: tensor([  81, 3841, 2776, 2825,  224, 4121, 2052,  888, 1804, 2558, 3816,  679,
         102, 3147,  774, 3378])
Epoch: 805, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 806 - Batch 1 ########################
IDs in batch 1: tensor([1252, 4214, 2285, 2090, 3487, 1420, 2341, 2663, 3869, 4268, 1037, 1536,
        1822, 2456, 3428, 3643])
Epoch: 806, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 807 - Batch 1 ########################
IDs in batch 1: tensor([ 266,  823, 2819, 3993,  314, 1028, 3337, 1707, 1784, 1784, 3010,  721,
         756, 2125, 2373,  439])
Epoch: 807, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 808 - Batch 1 ########################
IDs in batch 1: tensor([2141,  729, 1395,  274, 2383,  735, 2195, 1693, 3334,  787, 2284, 1367,
         459, 2373,   63, 3711])
Epoch: 808, Training Loss: 0.40, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 809 - Batch 1 ########################
IDs in batch 1: tensor([ 646, 3569, 2209, 3786,  140, 3003, 2298, 2426, 2650,  490, 3036, 2839,
         582,  284, 3655, 3713])
Epoch: 809, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 810 - Batch 1 ########################
IDs in batch 1: tensor([1702,  455, 2143, 1295, 1986, 2122, 2682, 2505, 2851, 1879,  590, 2452,
        3257, 2879, 1518, 1249])
Epoch: 810, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 811 - Batch 1 ########################
IDs in batch 1: tensor([ 944, 4175, 1157, 3052, 4067, 1869, 3449, 2131, 1016, 3638, 3343,   92,
        1576, 3392, 2306, 3673])
Epoch: 811, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 812 - Batch 1 ########################
IDs in batch 1: tensor([1826, 3366, 1137,  569, 1824, 2119, 1417, 1507, 3370, 2977, 1835, 3058,
        2795, 2131, 1469, 3617])
Epoch: 812, Training Loss: 0.60, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 813 - Batch 1 ########################
IDs in batch 1: tensor([3111, 1415, 1242,  681, 3763, 3183, 3980, 2004, 2149, 2806, 1748, 3998,
        1333, 1855, 1950,  419])
Epoch: 813, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 814 - Batch 1 ########################
IDs in batch 1: tensor([3872, 2370, 2113, 1212, 1098, 1070, 3790,  680, 1999, 2934,   15, 3862,
         361, 1596,  412, 1960])
Epoch: 814, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 815 - Batch 1 ########################
IDs in batch 1: tensor([2644, 3337, 2265, 2605,  498,  876,  913,  819, 3505, 2254, 3942, 3370,
        3207, 2276, 1140, 3642])
Epoch: 815, Training Loss: 0.97, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 816 - Batch 1 ########################
IDs in batch 1: tensor([3865, 4181, 3218, 1116, 3624, 2859,  729, 2606, 2041, 3496,  354, 4172,
        2141, 2159, 2137,  593])
Epoch: 816, Training Loss: 0.64, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 817 - Batch 1 ########################
IDs in batch 1: tensor([4205, 2751, 1370, 1845, 1736, 2111, 2255, 3473, 3017, 3349, 2567, 3599,
        2519, 3478,  980,  354])
Epoch: 817, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 818 - Batch 1 ########################
IDs in batch 1: tensor([1665, 3475, 3881,   68, 3479,  351, 3376,  815, 2773,  345,   24, 2879,
        2106,  132,  305, 1003])
Epoch: 818, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.75
Save best Model_1 @ epoch 818 acc: 0.7479484173505275
Email sent!
######################## Epoch 819 - Batch 1 ########################
IDs in batch 1: tensor([3188, 1862,  140, 2545,  659, 3364, 2252, 2154, 4061,  137, 3481, 4235,
         704, 4117, 3514, 2650])
Epoch: 819, Training Loss: 0.49, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 820 - Batch 1 ########################
IDs in batch 1: tensor([ 136, 1075, 3317, 3797,  893, 3644, 3243, 1954,  450, 2521, 1665, 1310,
        1933, 1524, 3283,  930])
Epoch: 820, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 821 - Batch 1 ########################
IDs in batch 1: tensor([1798,  503, 2412, 2793,  874, 2516, 2281, 3902,  820,  830, 3100, 1591,
        1636, 1347, 1933,  430])
Epoch: 821, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 822 - Batch 1 ########################
IDs in batch 1: tensor([3461, 3852, 2740, 3905, 1643, 3111, 2182, 3154, 3017, 1305, 3723,  962,
         631, 3463, 2428, 3154])
Epoch: 822, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 823 - Batch 1 ########################
IDs in batch 1: tensor([1049, 3851, 1576, 1727,  670,  752, 1525, 1154,  159, 1136, 4161, 2812,
        3658,  607,  908, 3381])
Epoch: 823, Training Loss: 0.64, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 824 - Batch 1 ########################
IDs in batch 1: tensor([1343, 2255, 2504, 4134, 2143,  277, 3568, 2390, 2993, 2399, 2990,  120,
        1614, 2017, 1309, 3939])
Epoch: 824, Training Loss: 0.58, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 825 - Batch 1 ########################
IDs in batch 1: tensor([2023, 3047, 3872, 2448, 2257, 1704, 1425, 3863, 3712, 4203, 3272, 2649,
         252,   27, 1409, 1811])
Epoch: 825, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 826 - Batch 1 ########################
IDs in batch 1: tensor([2627, 2069,  533,  627, 2523, 1488, 3913, 3902, 1638, 3719, 2346, 2587,
        1278, 1794,  980,  120])
Epoch: 826, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 827 - Batch 1 ########################
IDs in batch 1: tensor([1361,   60,  781,  593, 1700,  514,  842, 4230, 1740, 2265,  275, 2362,
         159, 3874, 1251, 1437])
Epoch: 827, Training Loss: 0.69, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 828 - Batch 1 ########################
IDs in batch 1: tensor([3862, 1967, 2823, 4172,   81, 2036, 2011, 2838, 3214, 3908, 3272, 1279,
        3334,  411, 3321,  609])
Epoch: 828, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 829 - Batch 1 ########################
IDs in batch 1: tensor([4152, 2258, 2783,  425, 4025, 2812,  281, 2238, 4061, 1720, 2773, 3601,
        1909,  441, 1895, 2206])
Epoch: 829, Training Loss: 0.55, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 830 - Batch 1 ########################
IDs in batch 1: tensor([3092, 3551, 1041, 4214, 2477, 2835,  219, 3105, 3265, 2788, 1009,  387,
        2027,  843, 1256,  391])
Epoch: 830, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 831 - Batch 1 ########################
IDs in batch 1: tensor([2561,  439, 3710, 2204, 4040, 1566,  996, 1464, 2066, 2017, 1853, 2026,
        3654, 1881,  424, 4080])
Epoch: 831, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 832 - Batch 1 ########################
IDs in batch 1: tensor([3942, 3423, 4148, 2145, 2999, 2417, 3987, 4080, 1994,  387, 1003, 2921,
        3216, 3219, 3358, 3985])
Epoch: 832, Training Loss: 0.63, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 833 - Batch 1 ########################
IDs in batch 1: tensor([3655, 2094, 3317, 3615, 3615, 1225, 1698, 3943,  781,   20, 3074, 3564,
         879,   78, 3271,  359])
Epoch: 833, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 834 - Batch 1 ########################
IDs in batch 1: tensor([3484,  492, 1090, 1320,  665, 1954, 2477, 1975, 3780, 1136, 1605, 2132,
         262, 1956, 4122, 1722])
Epoch: 834, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 835 - Batch 1 ########################
IDs in batch 1: tensor([ 896,  887, 4084, 2947,   49, 1681, 2497, 4026, 3058,  956, 4225, 1861,
        2523,  910, 1155, 2144])
Epoch: 835, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 836 - Batch 1 ########################
IDs in batch 1: tensor([2890, 3372, 3539, 4089, 1614,  907, 2172, 3673, 1500, 4200, 1798, 2355,
        3217, 3751,  890, 3187])
Epoch: 836, Training Loss: 0.49, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 837 - Batch 1 ########################
IDs in batch 1: tensor([4196, 3446, 1224, 1863, 3891, 1740, 2238, 2423, 1234, 1287, 1502, 2974,
         820, 1959, 3756, 3905])
Epoch: 837, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 838 - Batch 1 ########################
IDs in batch 1: tensor([4222,  100, 2080,  452,  545, 1086,  832, 3516, 1957, 2993, 2146, 3306,
         610, 3130, 3673, 1756])
Epoch: 838, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 839 - Batch 1 ########################
IDs in batch 1: tensor([1397, 1140, 2546, 1117, 1373, 1826, 2260, 4254, 1508, 1775,  343, 3920,
        3617, 3661, 3044,  470])
Epoch: 839, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 840 - Batch 1 ########################
IDs in batch 1: tensor([2892,  725,  899, 1266,  154, 3467,   50,  644, 1859, 3913, 2552,  750,
        1426, 4152,  199, 4116])
Epoch: 840, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 841 - Batch 1 ########################
IDs in batch 1: tensor([1229, 2963, 2890, 1133, 4146,  200, 3692, 2708,  535,  266, 1228, 3676,
        2980,  851, 3701,  129])
Epoch: 841, Training Loss: 0.73, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 842 - Batch 1 ########################
IDs in batch 1: tensor([3257, 3903, 2234, 3227, 3021, 2313, 1751, 2617, 1784, 3834, 2839,  553,
         755,  348, 1916,  966])
Epoch: 842, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 843 - Batch 1 ########################
IDs in batch 1: tensor([1099, 2516, 1272, 2360, 3243, 1147,  394, 1070, 1996, 1213, 1672, 3983,
         134, 2005, 2217,  553])
Epoch: 843, Training Loss: 0.50, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 844 - Batch 1 ########################
IDs in batch 1: tensor([ 497, 2169, 2304, 3441, 4257, 3990, 1793, 1377,  824, 2051, 1660, 2968,
        4044, 2348, 1056, 2245])
Epoch: 844, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 845 - Batch 1 ########################
IDs in batch 1: tensor([4144, 2087, 4127, 3718, 3863, 1017, 3615, 3326, 3539,  282,  491, 1770,
        1784, 1571, 3355,   86])
Epoch: 845, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 846 - Batch 1 ########################
IDs in batch 1: tensor([2103, 2218, 2794,  966, 3958, 2217, 1573, 3728, 3961, 3471, 3135, 3053,
        3582, 2453, 1668, 4073])
Epoch: 846, Training Loss: 0.82, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 847 - Batch 1 ########################
IDs in batch 1: tensor([1832, 3166, 3037, 1318, 2674,  950, 1588, 2883, 3993, 3136, 2523, 3723,
        1439,  261, 1931, 3734])
Epoch: 847, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 848 - Batch 1 ########################
IDs in batch 1: tensor([1748,  834, 1676, 1923, 1107,  804,  276, 1878, 3287, 3900, 3516, 1006,
        2332, 2876, 1009, 2823])
Epoch: 848, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 849 - Batch 1 ########################
IDs in batch 1: tensor([2687, 4213, 1862, 1655, 4049, 2995, 1234, 2526,  805, 2127, 3177, 2907,
        2388, 3344, 4190, 3532])
Epoch: 849, Training Loss: 0.73, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 850 - Batch 1 ########################
IDs in batch 1: tensor([1920, 2546, 2749, 1108, 2770, 1968, 3813,  676, 2848, 3183, 1668,  200,
        3698, 2649,  252, 2732])
Epoch: 850, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 851 - Batch 1 ########################
IDs in batch 1: tensor([1795, 3975, 1491, 2538, 3603, 1045,  997, 2616, 1617, 3919, 3564, 2183,
        1485, 3897, 3127,  139])
Epoch: 851, Training Loss: 0.58, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 852 - Batch 1 ########################
IDs in batch 1: tensor([2832,   20,  565, 3999, 2664, 3042, 3962, 3882,  365, 2457, 2974, 3073,
        4140,  969, 2674, 2023])
Epoch: 852, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 853 - Batch 1 ########################
IDs in batch 1: tensor([3540, 2954, 4217, 1030, 3712, 2488, 1285,   72,  701,  129, 3624, 4168,
        1022, 1094, 4122, 4032])
Epoch: 853, Training Loss: 0.74, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 854 - Batch 1 ########################
IDs in batch 1: tensor([3907, 3898, 3193, 1132, 3969, 2600,  842, 1947, 3603, 1963, 1379, 1980,
        2989, 3460,   35, 1684])
Epoch: 854, Training Loss: 0.86, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 855 - Batch 1 ########################
IDs in batch 1: tensor([3704, 4120, 3904, 1670, 2372, 4222, 1077, 2674,  623, 1868, 2977, 1789,
        4080, 4044, 2550, 2748])
Epoch: 855, Training Loss: 0.81, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 856 - Batch 1 ########################
IDs in batch 1: tensor([3441, 3604, 2858, 2954, 4037, 1086, 3853, 2874, 1324, 3609, 3907, 3193,
         786, 1684,  503, 2524])
Epoch: 856, Training Loss: 0.50, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 857 - Batch 1 ########################
IDs in batch 1: tensor([3558, 1393, 1476, 2605, 1222, 2516, 1474,  400, 3731, 1016, 3310, 1247,
        4088, 1374, 2423, 3264])
Epoch: 857, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 858 - Batch 1 ########################
IDs in batch 1: tensor([2571,  103, 1508, 2402,  105,  790, 2003, 3278,  110, 3407, 1857,  541,
        4008, 3423, 1042, 1028])
Epoch: 858, Training Loss: 0.50, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 859 - Batch 1 ########################
IDs in batch 1: tensor([2203, 3465,  243, 1396, 1328, 3030, 3241, 2304,  501, 3932, 1650, 2166,
        3734, 2249,  758,  511])
Epoch: 859, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 860 - Batch 1 ########################
IDs in batch 1: tensor([1803, 1555, 2092,  281,  966, 1866, 3250, 1163,  681, 3990, 3139,  345,
         382, 1736,  963,  941])
Epoch: 860, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 861 - Batch 1 ########################
IDs in batch 1: tensor([3907, 3749, 2306, 2887, 2466,  141, 1402, 1057, 4058,  186, 2365, 1737,
        3830, 3317,  827, 2230])
Epoch: 861, Training Loss: 0.49, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 862 - Batch 1 ########################
IDs in batch 1: tensor([1134, 3376, 2943, 1391,  882, 1154, 3410, 1846, 3907, 2385,  234, 1647,
        3284, 1200, 4119, 3197])
Epoch: 862, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 863 - Batch 1 ########################
IDs in batch 1: tensor([3975, 1524,  361, 1282, 1925, 3804,  534, 1789, 3841, 1796, 3940, 1312,
        1034, 2701, 1434, 1436])
Epoch: 863, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 864 - Batch 1 ########################
IDs in batch 1: tensor([1264, 1817, 2815, 3567,   72, 2500, 1740,  960, 2435, 1502, 4165,  944,
         992, 1799, 2225,  956])
Epoch: 864, Training Loss: 0.58, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 865 - Batch 1 ########################
IDs in batch 1: tensor([2279,  148, 4036,  607, 3389, 1842, 2271, 3815,  704, 2848,  456, 3271,
         575, 1264, 1517, 3395])
Epoch: 865, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 866 - Batch 1 ########################
IDs in batch 1: tensor([  81, 3270, 2956, 2883, 2539, 1627,  921,   81,  774, 2595, 2410, 3399,
        4011, 3731, 1932, 4232])
Epoch: 866, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 867 - Batch 1 ########################
IDs in batch 1: tensor([3354, 3021, 1844, 3705, 1190, 1779, 1761, 4168, 2272, 2181, 1092,  236,
        1318, 3588, 2196, 2579])
Epoch: 867, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 868 - Batch 1 ########################
IDs in batch 1: tensor([2251, 1887, 4265, 2519, 3552, 1521, 1059,  729, 3113, 2641,  510,  263,
        3594, 1352, 2025, 2090])
Epoch: 868, Training Loss: 0.58, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 869 - Batch 1 ########################
IDs in batch 1: tensor([1214, 1376,  252, 4258,  194, 3423, 2477, 2416, 2737, 1948, 2086, 4128,
        2643,  902, 2761, 4238])
Epoch: 869, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 870 - Batch 1 ########################
IDs in batch 1: tensor([2050, 3975, 2171,  952, 1611, 2825, 3398,  617,  805,  769, 1842, 2656,
        1663, 1658, 3898, 1376])
Epoch: 870, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 871 - Batch 1 ########################
IDs in batch 1: tensor([1212,  481, 1085,  262, 3006, 2771, 3668,  809,  974, 1038, 1923, 4199,
        1685, 3818, 3135, 1008])
Epoch: 871, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 872 - Batch 1 ########################
IDs in batch 1: tensor([1124, 1333,  893, 1973, 1563, 3358, 1450, 2810,  434, 1012, 1734, 2823,
        4072, 1868, 3071,  766])
Epoch: 872, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 873 - Batch 1 ########################
IDs in batch 1: tensor([1185, 1328,  631, 1649,  803, 3925, 3308, 1027,   81, 3154, 3908, 2606,
        1126, 1181,  512,   43])
Epoch: 873, Training Loss: 0.60, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 874 - Batch 1 ########################
IDs in batch 1: tensor([2385, 2075, 2831, 4093, 3711, 1580, 1224, 3757, 1585, 1496, 2419,  183,
        4108,  356, 2592, 2369])
Epoch: 874, Training Loss: 0.36, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 875 - Batch 1 ########################
IDs in batch 1: tensor([4161, 1818, 1037, 1773, 3943, 1055,   62, 2965, 2552, 2064, 1764, 1612,
        2737, 1795, 2312, 1472])
Epoch: 875, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 876 - Batch 1 ########################
IDs in batch 1: tensor([1051,  497, 1656, 1740, 1677, 2999,  181,  986, 2009, 3856, 1855, 2056,
        2016, 2091, 2575, 3745])
Epoch: 876, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 877 - Batch 1 ########################
IDs in batch 1: tensor([1775, 2667, 2854, 3372, 1753, 1101, 3829, 3886, 2652, 3196, 1140, 1553,
        3610,  894, 3256,  645])
Epoch: 877, Training Loss: 0.55, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 878 - Batch 1 ########################
IDs in batch 1: tensor([4012, 1186, 1611, 2483, 4012, 3883, 2423, 2546, 2564, 2721, 1371, 3110,
        4040, 2419, 2447,  792])
Epoch: 878, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 879 - Batch 1 ########################
IDs in batch 1: tensor([  56,  605, 4070, 3531, 1945,   97, 3188,  557, 1879,  735, 1212, 2541,
         350, 2223, 2442, 2908])
Epoch: 879, Training Loss: 0.60, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 880 - Batch 1 ########################
IDs in batch 1: tensor([2610, 3181, 1804, 2098, 2106,  769,  578, 3939, 3497, 3221, 3401,  206,
        1224,   60, 3238, 3787])
Epoch: 880, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.75
Save best Model_1 @ epoch 880 acc: 0.7491207502930832
Email sent!
######################## Epoch 881 - Batch 1 ########################
IDs in batch 1: tensor([2485, 3358, 1972, 2125, 2306, 2827,   56, 4240, 3970,  451, 2149,  897,
         607,  512, 1698, 1868])
Epoch: 881, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 882 - Batch 1 ########################
IDs in batch 1: tensor([ 725, 3569, 2644, 3509, 1208, 2649, 1305, 3878, 2115, 3838, 3084, 1487,
        3777, 1256, 1319, 1968])
Epoch: 882, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 883 - Batch 1 ########################
IDs in batch 1: tensor([3616, 4228, 2013,  594, 3900,  258, 3478, 1948, 1604, 3695, 3667, 1402,
        1421, 3715,  607, 3993])
Epoch: 883, Training Loss: 0.71, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 884 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 1330, 3471, 1510, 3782, 1108, 1886, 3400, 2203, 2710, 2157, 2431,
        4133,  498, 2407, 1731])
Epoch: 884, Training Loss: 0.39, Validation Loss: 0.65, accuracy = 0.75
Save best Model_1 @ epoch 884 acc: 0.7502930832356389
Email sent!
######################## Epoch 885 - Batch 1 ########################
IDs in batch 1: tensor([4031, 1731,  555,  205, 2287,  397, 2173, 1295, 1972, 1421,  519,  915,
         499,  786, 1737,  605])
Epoch: 885, Training Loss: 0.66, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 886 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 3669, 1892, 1054, 3610, 2238, 4139, 1276, 1061, 3554,  682, 3484,
         924, 3313,  182,  450])
Epoch: 886, Training Loss: 0.67, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 887 - Batch 1 ########################
IDs in batch 1: tensor([ 809, 2823,  766, 2044, 1419, 1179, 3895,  228, 1569, 2497, 3126, 1136,
        1065, 1439, 2405, 1406])
Epoch: 887, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 888 - Batch 1 ########################
IDs in batch 1: tensor([1331,  855, 3072, 3938, 2577, 2652,  484,  194, 1844, 1305,  317, 1157,
        2412, 3268, 4117, 3925])
Epoch: 888, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 889 - Batch 1 ########################
IDs in batch 1: tensor([3935, 4095, 1144, 2723, 2833, 1851, 2315, 1512, 3218,  320,  360, 1418,
        2005, 3003, 3275, 2292])
Epoch: 889, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 890 - Batch 1 ########################
IDs in batch 1: tensor([3656,  520, 2371, 3985, 3069, 3472, 1878, 3115, 1107,  277, 3842,  399,
         666, 1391,  904, 2056])
Epoch: 890, Training Loss: 0.51, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 891 - Batch 1 ########################
IDs in batch 1: tensor([4220,  659,  226,  534, 2996, 3739, 3409, 2595, 1080, 2002, 1863, 3456,
          44, 4077, 1375,  883])
Epoch: 891, Training Loss: 0.49, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 892 - Batch 1 ########################
IDs in batch 1: tensor([2683, 3222, 2978, 1953, 1620,   51, 3647, 3572, 1690, 2659,  186, 2653,
        2337, 2849, 1175, 3558])
Epoch: 892, Training Loss: 0.47, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 893 - Batch 1 ########################
IDs in batch 1: tensor([1663, 1076, 1573, 1851, 2465, 2281, 2362,  263,  869, 2313, 3936, 2355,
        2069, 2035, 1559, 3177])
Epoch: 893, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 894 - Batch 1 ########################
IDs in batch 1: tensor([ 993, 2812, 1162, 2132, 1406, 3699,  779, 1617,  250, 1122, 3700, 3363,
        3528,  250, 2951, 1159])
Epoch: 894, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 895 - Batch 1 ########################
IDs in batch 1: tensor([3017, 1512, 4067, 2511, 2551,  418, 3870,  106, 2773, 1507,  741,  612,
        1233, 2765, 3336, 2912])
Epoch: 895, Training Loss: 0.24, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 896 - Batch 1 ########################
IDs in batch 1: tensor([3588, 2107, 1183, 3693, 4236, 2433, 3506, 2495, 1429, 3438,  820, 3458,
         488,  344,  483, 2069])
Epoch: 896, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 897 - Batch 1 ########################
IDs in batch 1: tensor([ 471, 1284,  755,   44,  573, 2412,  636, 1647, 3451,  613,  615, 2869,
        2956, 3473,  832, 1287])
Epoch: 897, Training Loss: 0.57, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 898 - Batch 1 ########################
IDs in batch 1: tensor([3615, 3192, 3136,   28, 1134, 2535, 3538,   57, 2806, 2334,  154, 1041,
         503, 1863, 3388, 1602])
Epoch: 898, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 899 - Batch 1 ########################
IDs in batch 1: tensor([2191, 3832, 2060, 2671,  871, 1093,  873, 2511, 3676, 3345, 3338, 2812,
        1417, 2682, 1778, 1861])
Epoch: 899, Training Loss: 0.33, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 900 - Batch 1 ########################
IDs in batch 1: tensor([2940, 3364, 2041, 1134,  681, 1277,  122, 3476, 3903, 1402, 3127, 1655,
          25, 2435, 2559,  795])
Epoch: 900, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 901 - Batch 1 ########################
IDs in batch 1: tensor([ 497, 3968, 4255,  842, 3700, 1935, 3675, 2399, 2664,  961,   25, 3545,
         167, 3886, 1488,  519])
Epoch: 901, Training Loss: 0.64, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 902 - Batch 1 ########################
IDs in batch 1: tensor([2947,   97, 2863,  550, 3327,  699, 1916, 2885, 1332, 4172, 4189, 3287,
        2973, 1448, 3220, 3355])
Epoch: 902, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 903 - Batch 1 ########################
IDs in batch 1: tensor([3963,  375, 3859,  568,   28, 3494,  419, 3699, 2151, 2695,  302,  527,
         627,  871, 2802, 3781])
Epoch: 903, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 904 - Batch 1 ########################
IDs in batch 1: tensor([1644, 1472, 1199, 1024, 3074, 2752, 2246,  322, 3525, 3537, 1185, 3879,
        1571, 1111, 2752, 1030])
Epoch: 904, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 905 - Batch 1 ########################
IDs in batch 1: tensor([1988, 3379, 1673, 1765, 3607, 1592,  129, 2529, 1543, 1862, 2802,   51,
        3783, 1391, 1698, 1311])
Epoch: 905, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 906 - Batch 1 ########################
IDs in batch 1: tensor([2376, 3478,  440, 1174, 1267, 2146, 4057,  451, 2414,  101, 1923, 3254,
        3921, 2281, 3654,  900])
Epoch: 906, Training Loss: 0.79, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 907 - Batch 1 ########################
IDs in batch 1: tensor([ 657,  219,  813, 3783, 2024,  644,  327,  441, 2247,  987, 1383, 3813,
          13,  148, 2452, 3424])
Epoch: 907, Training Loss: 0.54, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 908 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 2914,  994, 2157, 4158,  910, 2509, 1887,  367, 3147, 2564,  596,
         617, 1131, 2575, 1781])
Epoch: 908, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 909 - Batch 1 ########################
IDs in batch 1: tensor([2810, 2914, 1795,  944, 3827, 2295, 2180,  676, 2382, 2394, 1396, 2106,
        2166, 1341,  106, 1060])
Epoch: 909, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 910 - Batch 1 ########################
IDs in batch 1: tensor([1160,  333, 1185, 1767,  492, 2561, 1097, 2257, 3597, 1682, 3121, 1732,
         449,  379, 1221, 3408])
Epoch: 910, Training Loss: 0.61, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 911 - Batch 1 ########################
IDs in batch 1: tensor([1578,  915,  891,  232, 3480,  685, 3425,  382, 2688, 1780, 4159, 3031,
        1472,  574, 1476, 2183])
Epoch: 911, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 912 - Batch 1 ########################
IDs in batch 1: tensor([2316, 3084, 2366,  147,  281, 1198, 1833, 4189,  348, 2312,  785, 3082,
          31, 3092,   77, 3714])
Epoch: 912, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 913 - Batch 1 ########################
IDs in batch 1: tensor([3733, 1918, 3479, 2538, 3888, 1803,  755, 3002, 3852, 2522, 3511, 2122,
        2636, 3262, 1072, 2225])
Epoch: 913, Training Loss: 0.71, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 914 - Batch 1 ########################
IDs in batch 1: tensor([3428,  515, 2212, 3366,  164,  874, 3221, 3200, 1566, 2847, 2446, 4022,
         484, 1166,  247, 2040])
Epoch: 914, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 915 - Batch 1 ########################
IDs in batch 1: tensor([1722, 3782,   13,  524, 1242, 3806, 3601, 3476, 1015,  587, 2122, 4026,
         584, 2963, 4257, 4011])
Epoch: 915, Training Loss: 0.63, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 916 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 1975, 3806, 2285, 1356,  714, 2282, 3745, 4097, 3406, 1415,  917,
         295, 1154, 1423,  665])
Epoch: 916, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 917 - Batch 1 ########################
IDs in batch 1: tensor([ 574, 1668, 2511, 2167, 4076,   46, 1885, 1275, 2688, 3551,  842, 2740,
        3795,  693, 2687, 1213])
Epoch: 917, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 918 - Batch 1 ########################
IDs in batch 1: tensor([ 815, 2462, 2467, 1255,  955, 3127, 2451, 1003, 3047,   51,  955, 2873,
        2809, 1751, 3202, 3114])
Epoch: 918, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 919 - Batch 1 ########################
IDs in batch 1: tensor([3845,   11, 2841, 2046,   25,  553,  755, 1510,  874, 3451, 4095, 2731,
        2232, 3156, 1973, 1562])
Epoch: 919, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 920 - Batch 1 ########################
IDs in batch 1: tensor([ 880, 2203, 4084,  274, 1458, 1117, 2367, 2963, 4139, 3592, 1570, 2387,
        3711, 2509, 3336, 3753])
Epoch: 920, Training Loss: 0.43, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 921 - Batch 1 ########################
IDs in batch 1: tensor([ 244, 2407, 3010, 3635, 3601, 3018,  292, 1543,  688, 1781, 2978,  776,
        2094, 3016, 1869, 3676])
Epoch: 921, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 922 - Batch 1 ########################
IDs in batch 1: tensor([3182,  251, 1022,  961, 2257,  129, 3642, 3317,  899, 1369, 4101, 3705,
        4013, 1489,  539, 1574])
Epoch: 922, Training Loss: 0.80, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 923 - Batch 1 ########################
IDs in batch 1: tensor([3250,   20, 4056,  260,  615, 4008, 1008,   11, 2354, 3435, 1283,  180,
        1414, 1053, 1553, 1166])
Epoch: 923, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 924 - Batch 1 ########################
IDs in batch 1: tensor([3458, 2638, 1959, 2354, 4046, 1124, 4014,  636,  545, 2189, 1193, 1266,
        4061, 1176,  250, 3991])
Epoch: 924, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 925 - Batch 1 ########################
IDs in batch 1: tensor([2649, 2210, 3751,   27, 1168, 4265, 3549, 1007, 2949, 1420, 2116, 3495,
        3834,   73,  904,  914])
Epoch: 925, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 926 - Batch 1 ########################
IDs in batch 1: tensor([2111, 1343,  875, 4084, 2056, 2406, 1157, 2745,  207, 3136, 1171, 3028,
         274, 1331,  182,  485])
Epoch: 926, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 927 - Batch 1 ########################
IDs in batch 1: tensor([2775,  953, 4107, 1081, 1092,  595, 3253, 1748, 1540, 2287, 4044,  537,
        2195, 4176,  472, 3903])
Epoch: 927, Training Loss: 0.76, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 928 - Batch 1 ########################
IDs in batch 1: tensor([1655,  465, 1632, 2589, 2098, 1633, 4100, 3136, 4087, 4133,   73, 1131,
         239, 2853,  368, 1066])
Epoch: 928, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 929 - Batch 1 ########################
IDs in batch 1: tensor([1322,  418, 1174, 3214,  603,  828,  769,  593, 3081, 3850, 1754, 1263,
         871,  788,  191, 2645])
Epoch: 929, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 930 - Batch 1 ########################
IDs in batch 1: tensor([1182, 2246, 3398, 3492, 4148, 1977,  284, 3837,  680, 3484, 2150, 3541,
        2341, 2656, 1186,  850])
Epoch: 930, Training Loss: 0.54, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 931 - Batch 1 ########################
IDs in batch 1: tensor([  96, 2563, 2887, 3501, 3466, 1104, 4245, 2869,  121,  848, 2064,  432,
        4117, 3894, 3823, 3321])
Epoch: 931, Training Loss: 0.62, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 932 - Batch 1 ########################
IDs in batch 1: tensor([ 245,  418, 3862,  577, 2123, 1610, 2708, 3709, 4198, 2777, 3984, 2544,
        2734, 1490, 2088, 3499])
Epoch: 932, Training Loss: 0.58, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 933 - Batch 1 ########################
IDs in batch 1: tensor([2121, 1098, 1852,  897,  188, 2708, 2104, 2382, 1958, 2947, 2974, 3739,
         533, 3394, 3755, 1578])
Epoch: 933, Training Loss: 0.47, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 934 - Batch 1 ########################
IDs in batch 1: tensor([3635, 3692,  811,  326, 2204,  390, 2669,   62, 2614,  467, 1704,  819,
        3936, 3627, 1882, 3896])
Epoch: 934, Training Loss: 0.45, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 935 - Batch 1 ########################
IDs in batch 1: tensor([2090, 1556, 3710,  491, 1153, 2945, 4168,  822,  778, 4238, 2616, 2041,
        3127, 3287, 2284, 1611])
Epoch: 935, Training Loss: 0.31, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 936 - Batch 1 ########################
IDs in batch 1: tensor([3733, 3276,  529, 2252,  199, 2960, 4007, 3300, 3822,  631, 2217,  354,
         201, 4005, 1047, 3044])
Epoch: 936, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 937 - Batch 1 ########################
IDs in batch 1: tensor([1086, 3836, 4204,  726, 3771, 2234,   93, 2086, 1432, 1153, 3669,  763,
        3990,  991, 2292, 3031])
Epoch: 937, Training Loss: 0.48, Validation Loss: 0.64, accuracy = 0.75
Save best Model_1 @ epoch 937 acc: 0.7526377491207503
Email sent!
######################## Epoch 938 - Batch 1 ########################
IDs in batch 1: tensor([3856,  390, 4069, 4188, 3092,  653,  750, 2014, 1499,  187, 2587, 1113,
        2328, 1273, 3926,  522])
Epoch: 938, Training Loss: 0.36, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 939 - Batch 1 ########################
IDs in batch 1: tensor([3251, 4197, 1055, 3342, 3779, 3306, 2141, 2448,  255, 1316, 1931, 1242,
        1711, 2127, 3185, 1617])
Epoch: 939, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 940 - Batch 1 ########################
IDs in batch 1: tensor([1325, 3826, 2053, 4082, 1962,  224, 2110, 3329,  264, 4224, 3010, 3139,
        4204, 3022, 2049, 2690])
Epoch: 940, Training Loss: 0.71, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 941 - Batch 1 ########################
IDs in batch 1: tensor([3022,  828, 1495, 1737, 3056, 2279, 2038, 2134,  279,   70, 1139, 1633,
        2641,  688, 3218, 2652])
Epoch: 941, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 942 - Batch 1 ########################
IDs in batch 1: tensor([ 128, 2399, 1393, 3410,  380, 2202,  839, 3430, 3651, 1772, 1601, 3696,
        1521,  607,  220, 4135])
Epoch: 942, Training Loss: 0.59, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 943 - Batch 1 ########################
IDs in batch 1: tensor([2448, 3255, 2553, 4030, 2520,  637, 2873, 2119, 1716,  533, 4204, 2108,
        3142,  807, 3554, 2976])
Epoch: 943, Training Loss: 0.45, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 944 - Batch 1 ########################
IDs in batch 1: tensor([3177, 2039, 1858, 2242, 2172, 2866,  512, 2231, 2285, 2448, 3299, 3382,
        3994,  909, 3531, 2794])
Epoch: 944, Training Loss: 0.98, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 945 - Batch 1 ########################
IDs in batch 1: tensor([ 434,  527, 2432, 3327, 4008, 2390, 2736, 2005, 3161,  552, 3289, 1371,
        3870, 2752, 2220, 2328])
Epoch: 945, Training Loss: 0.50, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 946 - Batch 1 ########################
IDs in batch 1: tensor([   4,  269,  438, 1566, 1363, 2945,  749, 3487, 3087, 2386,  350, 1122,
        1638, 3025, 1171,  482])
Epoch: 946, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 947 - Batch 1 ########################
IDs in batch 1: tensor([3468, 1955, 2017, 2868,  777,   82, 1605, 1349,  956, 2887, 2371,  112,
         202, 3027,  821, 1764])
Epoch: 947, Training Loss: 0.48, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 948 - Batch 1 ########################
IDs in batch 1: tensor([3397,  494, 1980, 1909,  872, 3311,  842, 2198, 1122,   95, 3471,   77,
        3862, 2346,  837,  232])
Epoch: 948, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 949 - Batch 1 ########################
IDs in batch 1: tensor([3928,  693, 4149,  225, 3609, 3407,  346, 2040, 3928, 4179, 1988,  578,
        2354, 2737, 3105,  522])
Epoch: 949, Training Loss: 0.45, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 950 - Batch 1 ########################
IDs in batch 1: tensor([1488,  211, 2836, 2417, 2991, 3882, 2733, 1087, 1452,   15, 2016, 2978,
         635, 1222, 3344, 2537])
Epoch: 950, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 951 - Batch 1 ########################
IDs in batch 1: tensor([2375, 2606, 1524, 3818, 3084, 3227,  229,  942, 3836, 4179, 1049, 1732,
        4166, 1167, 3655,  130])
Epoch: 951, Training Loss: 0.64, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 952 - Batch 1 ########################
IDs in batch 1: tensor([2085, 1760, 1073, 3475, 1899,  441,  944, 3632, 1604, 4073,  602, 1963,
         667,  155, 2153, 1271])
Epoch: 952, Training Loss: 0.47, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 953 - Batch 1 ########################
IDs in batch 1: tensor([4015, 1967,  140, 2516, 2642, 3672,  900, 2487, 2999, 4089, 2352, 2956,
         858,  352, 1857,  262])
Epoch: 953, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 954 - Batch 1 ########################
IDs in batch 1: tensor([3488, 1152, 2207, 3029, 1835,  463, 3499, 2312, 4125,  225, 4224, 2232,
        1718,   38,  214, 3087])
Epoch: 954, Training Loss: 0.82, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 955 - Batch 1 ########################
IDs in batch 1: tensor([2059, 1162,  850, 2483, 3601, 4180, 3135, 2414, 2011, 3661, 4197, 1972,
        1536, 3456, 1009, 4238])
Epoch: 955, Training Loss: 0.56, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 956 - Batch 1 ########################
IDs in batch 1: tensor([ 778,  408, 2257,  220, 1426, 3538, 1562, 3091,  327, 3838, 4156,  456,
         141,  436, 2624, 1632])
Epoch: 956, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 957 - Batch 1 ########################
IDs in batch 1: tensor([3490,  680, 1796, 3869, 3866,  170, 3009, 1113, 3523, 2193,  218,  283,
         191, 2701, 3177, 3535])
Epoch: 957, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 958 - Batch 1 ########################
IDs in batch 1: tensor([1722, 3009, 2442,  387,  693, 3469, 3746,  682, 2727, 2755,  586, 1663,
        2398, 2470, 3746,  878])
Epoch: 958, Training Loss: 0.85, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 959 - Batch 1 ########################
IDs in batch 1: tensor([4033,  223, 3780, 3526,  125, 1877,  645,   31, 1636, 1257,  741,  262,
        3139,  335, 2455, 3592])
Epoch: 959, Training Loss: 0.60, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 960 - Batch 1 ########################
IDs in batch 1: tensor([3757, 2024, 1123, 2256, 2520,  992, 2375, 3930, 3409, 3410, 2119, 3211,
        2605, 4115, 3506,  203])
Epoch: 960, Training Loss: 0.53, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 961 - Batch 1 ########################
IDs in batch 1: tensor([ 875, 1990, 2142, 3162, 2789,  902, 2887, 1731,  139, 1379, 2106, 2343,
        1299, 2799, 1273,  769])
Epoch: 961, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 962 - Batch 1 ########################
IDs in batch 1: tensor([4110,  704, 1408,  882, 2949, 3235, 4065, 2019, 4119, 4172, 2683, 3119,
        3308,  322, 3658, 2451])
Epoch: 962, Training Loss: 0.56, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 963 - Batch 1 ########################
IDs in batch 1: tensor([2258, 3032, 3388, 4118, 4159, 3075, 3826,  884, 2364, 3886,  530, 2708,
        3267, 1426, 2492, 3030])
Epoch: 963, Training Loss: 0.43, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 964 - Batch 1 ########################
IDs in batch 1: tensor([4069,  259, 2986, 1663, 2143, 2674, 1711, 1193, 1345, 2718, 2121, 3109,
        1474,  679, 3807, 1979])
Epoch: 964, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 965 - Batch 1 ########################
IDs in batch 1: tensor([ 320,  864,  966, 2274, 2443, 4146, 3238, 4108, 1819, 2599, 1559, 2859,
        2173,  992, 3437, 2015])
Epoch: 965, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 966 - Batch 1 ########################
IDs in batch 1: tensor([3077, 4084, 3882, 3079, 2964, 3856,  314, 3823, 1647, 2148, 1892, 1126,
        1707, 1556, 3905,  501])
Epoch: 966, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 967 - Batch 1 ########################
IDs in batch 1: tensor([3214,  628, 3706,  625,  348, 1039, 4127, 2582, 1879, 4152, 1635, 3710,
        1745,  218, 3314, 3628])
Epoch: 967, Training Loss: 0.43, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 968 - Batch 1 ########################
IDs in batch 1: tensor([2629, 2876, 1675, 1032,  866, 1003, 1284,  212, 2014, 3152, 2614, 2180,
        1595, 1860,  846, 1755])
Epoch: 968, Training Loss: 0.51, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 969 - Batch 1 ########################
IDs in batch 1: tensor([1704, 4058, 3704,  747,  317, 1415,  358, 2863, 3742, 2817, 1506, 3143,
        1451,   20, 1840, 2874])
Epoch: 969, Training Loss: 0.58, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 970 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2641, 3188,  961,  101, 2247, 3540, 1041, 1596, 1073, 1193,  738,
         260, 1961, 1853, 2921])
Epoch: 970, Training Loss: 0.36, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 971 - Batch 1 ########################
IDs in batch 1: tensor([2442, 1426, 3920, 1334,   84, 3513, 2373, 2737, 1799, 3581, 1292, 2835,
        2317, 2433, 1016, 4017])
Epoch: 971, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 972 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2218, 1299, 2887,  430, 2499, 2537, 3745,  544, 3022, 3564, 2342,
         388, 2721, 2796, 1658])
Epoch: 972, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 973 - Batch 1 ########################
IDs in batch 1: tensor([2854, 3074, 2456, 2485, 2359, 2039, 2467, 3071, 3707,  960,  402, 2942,
         827, 1237,  232, 1306])
Epoch: 973, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 974 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 2754, 3221, 2344, 1182, 2666,  108, 3696, 1438,  243, 4107, 4161,
        1023, 3426, 3436, 3181])
Epoch: 974, Training Loss: 0.43, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 975 - Batch 1 ########################
IDs in batch 1: tensor([2091, 2847, 4136, 1747,  574,  994, 1223, 2742,  727, 3379, 1733, 2712,
         603, 1546, 1604, 2674])
Epoch: 975, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 976 - Batch 1 ########################
IDs in batch 1: tensor([1289, 1267,  956, 1222,   98, 3345,  202,   13, 3492, 2947, 3710, 2305,
        3349, 2783, 1734, 2859])
Epoch: 976, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 977 - Batch 1 ########################
IDs in batch 1: tensor([3498, 3168, 3704, 2835,  265, 3810, 1891,  957, 3815, 3147, 1840, 3777,
         652, 3219, 1780, 2706])
Epoch: 977, Training Loss: 0.60, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 978 - Batch 1 ########################
IDs in batch 1: tensor([4146, 2119, 1680, 1506, 2435, 1189, 2377, 3792, 3418, 1124, 4113, 1812,
        3651, 1003,  465, 1056])
Epoch: 978, Training Loss: 0.50, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 979 - Batch 1 ########################
IDs in batch 1: tensor([ 674,  422, 2863, 2586, 1414, 2659, 2917, 2109, 1698, 1960, 2098, 1573,
        1121, 3850, 1871, 2470])
Epoch: 979, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 980 - Batch 1 ########################
IDs in batch 1: tensor([ 180, 4185, 2281, 1457, 3806,  538,  445, 1318, 1860, 2763, 2044,  376,
        3143, 3058, 2538,   24])
Epoch: 980, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 981 - Batch 1 ########################
IDs in batch 1: tensor([3300, 2645, 3756, 2230, 3425, 3415,  609, 1158, 2902, 2553, 2066, 2085,
        2876, 2121,  605, 1260])
Epoch: 981, Training Loss: 0.74, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 982 - Batch 1 ########################
IDs in batch 1: tensor([2695,  667, 3530, 2817, 2473, 3388, 1646, 2018, 2680, 1014, 1384, 2537,
        1914,  823, 3183, 2132])
Epoch: 982, Training Loss: 0.63, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 983 - Batch 1 ########################
IDs in batch 1: tensor([2156, 3751, 2646,  900, 2550, 1833, 3256, 3480, 2494, 3496,  807, 1060,
        3740, 1518, 2181,  395])
Epoch: 983, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 984 - Batch 1 ########################
IDs in batch 1: tensor([ 352, 3803,   62, 3947, 4157, 3740, 3974,  462, 2039, 1918, 3088,  613,
        3509, 3344, 1949, 2246])
Epoch: 984, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 985 - Batch 1 ########################
IDs in batch 1: tensor([2461, 3400, 3257, 2426,   84, 4125, 2855, 1716, 2742, 4032, 1024, 3117,
        3904,  438, 1932, 4003])
Epoch: 985, Training Loss: 0.42, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 986 - Batch 1 ########################
IDs in batch 1: tensor([1434, 4222, 2489, 1198, 2051,  387, 1355,  747, 1724, 1251, 2368, 4257,
        4005, 3543, 3448, 2831])
Epoch: 986, Training Loss: 0.65, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 987 - Batch 1 ########################
IDs in batch 1: tensor([2995, 3756, 1484, 1177, 2075, 3496, 2412,  846, 1283,  660, 1126, 2986,
        1761,   11, 1589, 3180])
Epoch: 987, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 988 - Batch 1 ########################
IDs in batch 1: tensor([1137,  488, 2817, 3498,  409, 4110, 1754, 2632, 2500,  390, 1677, 4157,
        2408, 3194, 1008, 3000])
Epoch: 988, Training Loss: 0.32, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 989 - Batch 1 ########################
IDs in batch 1: tensor([ 137, 3408, 2443, 3399, 3099, 2912, 4133, 3683, 3635, 1921,  667, 4203,
         405,  777, 3681, 2715])
Epoch: 989, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 990 - Batch 1 ########################
IDs in batch 1: tensor([ 448, 3047, 1498,  626, 3136, 2236,  787, 3111,  393, 3017, 2418,  129,
        3117,  558,  149, 2236])
Epoch: 990, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 991 - Batch 1 ########################
IDs in batch 1: tensor([3765, 3693,  741, 4234, 3922, 4256, 3866, 2627,  229, 4200, 1900,  947,
         515, 2837, 2342, 1638])
Epoch: 991, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 992 - Batch 1 ########################
IDs in batch 1: tensor([1414, 3101,  743,  136, 1258, 1803, 2970,  395, 3841, 2111, 3939, 1030,
        1834,  936, 1163,  609])
Epoch: 992, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 993 - Batch 1 ########################
IDs in batch 1: tensor([2195,  455, 3060, 1808, 1011, 3105, 1371,  234, 3822,  355,  919, 1730,
        1060,  350, 3435, 1096])
Epoch: 993, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 994 - Batch 1 ########################
IDs in batch 1: tensor([1850,  510,   37, 1309,  221, 3183, 4058,  261,  815, 2882, 2680, 3303,
        1825, 3298, 3214, 2661])
Epoch: 994, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 995 - Batch 1 ########################
IDs in batch 1: tensor([ 427, 3680, 3637, 3731,  844, 2005, 3272,   47, 3663, 2410,  489, 4049,
        3223,  851, 3240,   22])
Epoch: 995, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 996 - Batch 1 ########################
IDs in batch 1: tensor([2354, 3286, 1628, 2845, 4249, 3751, 1510, 2432, 1617, 3503, 1069, 1945,
        1134, 1285, 3000, 2010])
Epoch: 996, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 997 - Batch 1 ########################
IDs in batch 1: tensor([ 323, 1067, 3487, 3084, 3111,  790, 3902,  766, 1686, 2575, 1357,  879,
        3767,  203, 4135,  941])
Epoch: 997, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 998 - Batch 1 ########################
IDs in batch 1: tensor([2109, 3934, 3743, 1698, 1014, 3157, 2544,  949, 2167, 2223,  325,  456,
        4000, 1965,  975, 1753])
Epoch: 998, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 999 - Batch 1 ########################
IDs in batch 1: tensor([1882, 3233, 3688, 1894,  251, 2519, 2740, 1052, 3614, 1231, 4173, 2781,
        2976, 3922, 1364,  348])
Epoch: 999, Training Loss: 0.64, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1000 - Batch 1 ########################
IDs in batch 1: tensor([1084,  362, 1432, 2298, 1222, 3778, 2837,  556, 2461, 2235,   47, 1173,
         945, 3927,  143, 1334])
Epoch: 1000, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1001 - Batch 1 ########################
IDs in batch 1: tensor([3692,  472, 2723, 2631, 3228, 4076, 4213, 2080, 4165, 3547, 2134, 3976,
        1060,  582,  662, 2444])
Epoch: 1001, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1002 - Batch 1 ########################
IDs in batch 1: tensor([1711, 3896, 3222,  919, 1755, 2040,  613, 2173, 1693, 2171, 2417, 2107,
         915,  306, 2541, 1968])
Epoch: 1002, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1003 - Batch 1 ########################
IDs in batch 1: tensor([4240, 2028, 3897,  547, 3500, 2499,  161, 2328, 2692,  828,  841, 1439,
        1371, 2292, 1798,  956])
Epoch: 1003, Training Loss: 0.51, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1004 - Batch 1 ########################
IDs in batch 1: tensor([2199,  450, 2315, 2828, 4234,  445, 3496,  725, 2980, 3496, 3303,  674,
        2228,  738,  640, 2711])
Epoch: 1004, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1005 - Batch 1 ########################
IDs in batch 1: tensor([ 656, 3118, 2822,  438, 1872, 2732, 2469, 2053,  565, 2157,  514, 2568,
         507, 3409, 3088, 3374])
Epoch: 1005, Training Loss: 0.52, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1006 - Batch 1 ########################
IDs in batch 1: tensor([3671, 2382,  196, 3127, 1346, 3310, 1131,  277,  282, 1676,  776, 2870,
        2019, 2749, 2536, 2810])
Epoch: 1006, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1007 - Batch 1 ########################
IDs in batch 1: tensor([1804, 1647, 4018,  143, 2983, 2251, 2348, 4245,  620,  775,  963, 1647,
        4076, 2936, 1836,  953])
Epoch: 1007, Training Loss: 0.49, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1008 - Batch 1 ########################
IDs in batch 1: tensor([ 105, 2738, 3981, 3581, 2377, 1589, 3427, 1573, 2489, 2775,  750, 2961,
        4006, 1082,  943, 1543])
Epoch: 1008, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1009 - Batch 1 ########################
IDs in batch 1: tensor([1478, 2908, 1836, 3417, 1803, 2341, 1760, 2667, 2812, 3337, 3497, 2636,
        3127, 1414, 4200,  544])
Epoch: 1009, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1010 - Batch 1 ########################
IDs in batch 1: tensor([3115, 2600, 1255, 1923, 3536, 1159, 1773,  982, 1255, 4115, 2617,  893,
        2949, 3181,  755, 1927])
Epoch: 1010, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1011 - Batch 1 ########################
IDs in batch 1: tensor([3563, 1639,  256, 2631, 2067, 2399,  976, 2995, 4008, 1285, 2798,  260,
        1532, 2595,  960, 2103])
Epoch: 1011, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1012 - Batch 1 ########################
IDs in batch 1: tensor([2123,   61,  238,  518, 3373, 3723, 4000, 3516,  565, 1722, 2891, 2348,
        3338, 2693, 2620, 2664])
Epoch: 1012, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1013 - Batch 1 ########################
IDs in batch 1: tensor([1450, 1537, 3648,  917, 3364, 3745, 4238, 3970, 3869, 3481, 4218, 1425,
        2770, 3839,  394,  361])
Epoch: 1013, Training Loss: 0.62, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1014 - Batch 1 ########################
IDs in batch 1: tensor([1024, 4094, 1316, 3806,  924, 2749,  182, 1947,  591, 2206, 2024, 1291,
        1958, 3243, 2565, 1051])
Epoch: 1014, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1015 - Batch 1 ########################
IDs in batch 1: tensor([ 424, 1409, 1897, 3832, 2938,  129,  855,  821, 1212,  165, 4148, 1984,
        1585, 2080, 2760, 3526])
Epoch: 1015, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1016 - Batch 1 ########################
IDs in batch 1: tensor([1690, 1849, 1028, 3558,  572,  444, 2870, 3999, 3336, 2687, 2604, 4118,
        3792, 3126, 2780, 1678])
Epoch: 1016, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1017 - Batch 1 ########################
IDs in batch 1: tensor([3862, 2390, 2155, 3492, 1595, 3143, 2617, 1885, 2463, 3372,  642, 2442,
        3002, 1082, 2362,  657])
Epoch: 1017, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1018 - Batch 1 ########################
IDs in batch 1: tensor([3255, 1707, 4189, 2592,  368, 2134, 1054, 1799, 4199, 2403, 1947,  482,
        2618, 2599, 2210, 3057])
Epoch: 1018, Training Loss: 0.45, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1019 - Batch 1 ########################
IDs in batch 1: tensor([1545, 2292, 2860, 4039, 3958, 1125,  214, 1646, 3262, 1775,  245, 3270,
        3187, 1335, 1952, 1370])
Epoch: 1019, Training Loss: 0.29, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1020 - Batch 1 ########################
IDs in batch 1: tensor([4212, 2213, 3126, 4264,  753, 2150, 3037,  488, 3999, 3601, 3111, 2892,
        4118, 1200, 2751, 1825])
Epoch: 1020, Training Loss: 0.50, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1021 - Batch 1 ########################
IDs in batch 1: tensor([2863, 2040, 1724,  685, 3789, 1808, 2332, 3529, 2582,  834, 2360, 1292,
        2282, 2921, 1316, 3469])
Epoch: 1021, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1022 - Batch 1 ########################
IDs in batch 1: tensor([2080, 3308, 2247, 2638, 3058, 2986, 4070, 2891, 2023,  653, 3600, 2373,
         417,  320, 1443, 2670])
Epoch: 1022, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1023 - Batch 1 ########################
IDs in batch 1: tensor([3839, 4035, 1057, 2518, 2579, 1649, 2123, 1049, 2669,  252, 1415, 2182,
        2167, 3842,  330,   96])
Epoch: 1023, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1024 - Batch 1 ########################
IDs in batch 1: tensor([4246, 1340, 2950, 3485, 2121, 3000, 2331, 2472, 3704, 1247, 3963, 1914,
         442, 1923,  430, 3495])
Epoch: 1024, Training Loss: 0.53, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1025 - Batch 1 ########################
IDs in batch 1: tensor([3659,  317, 3199,  953,   70, 1198, 1283, 1011, 2356,  627,  258, 3433,
        3139, 4267, 3697, 2217])
Epoch: 1025, Training Loss: 0.49, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1026 - Batch 1 ########################
IDs in batch 1: tensor([3051, 2264, 3451,  335, 3300,  424, 2521,  833, 3551, 1672,  511,  753,
         846,  442, 1993, 1287])
Epoch: 1026, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1027 - Batch 1 ########################
IDs in batch 1: tensor([4232,  964,   78, 1186, 1270, 4133, 2245, 1285, 2150, 2463, 2265, 4136,
        3036, 4257,  205, 1823])
Epoch: 1027, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1028 - Batch 1 ########################
IDs in batch 1: tensor([ 369, 3351,  926, 1845, 3466,  982, 2870, 3364, 4018, 3197,  738, 1346,
        3738, 2575, 2087, 3246])
Epoch: 1028, Training Loss: 0.39, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1029 - Batch 1 ########################
IDs in batch 1: tensor([2442, 2346, 3257,  279,  595, 3056, 2143, 1630, 2980, 4110,  953, 2287,
        1798,  637, 2646,  245])
Epoch: 1029, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1030 - Batch 1 ########################
IDs in batch 1: tensor([ 330, 3002, 4253, 2072, 1517, 2711, 2206, 4184,   39, 1067, 2444, 3552,
        3258, 1067, 3808, 2122])
Epoch: 1030, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1031 - Batch 1 ########################
IDs in batch 1: tensor([2420, 3363, 1810,   97, 3985,  991,  920, 3627, 4075, 2370, 4002, 1025,
        2383, 1130,  729,  824])
Epoch: 1031, Training Loss: 0.83, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1032 - Batch 1 ########################
IDs in batch 1: tensor([2644, 2693, 1076,  758, 4176,  340, 1168,  786, 1144, 1490, 1108, 1011,
          14, 3727, 1357, 3764])
Epoch: 1032, Training Loss: 1.08, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1033 - Batch 1 ########################
IDs in batch 1: tensor([3583, 2322, 2523, 1455, 1276, 2919,  815, 1510, 2804,  838, 3378, 3806,
        1200, 3790, 1178, 3866])
Epoch: 1033, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1034 - Batch 1 ########################
IDs in batch 1: tensor([ 991, 3866,  830, 4048, 3379,  377, 2511, 2546, 1536, 3531, 4015, 3074,
        2733, 2228, 2011,  609])
Epoch: 1034, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1035 - Batch 1 ########################
IDs in batch 1: tensor([2829, 2011,  785,  852, 2697, 3733,  727,  539,  679, 3141, 1439, 2069,
        3659, 3245, 1352, 2369])
Epoch: 1035, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1036 - Batch 1 ########################
IDs in batch 1: tensor([2535, 3476, 2666, 2572,  787, 2286, 3018, 4141, 1740, 2989, 1756,  653,
        1958, 2115, 4120, 2413])
Epoch: 1036, Training Loss: 0.77, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1037 - Batch 1 ########################
IDs in batch 1: tensor([1684, 3382,  937,   13, 1747,   93,  679,  857, 3548, 3133, 4186, 2610,
        3204, 2046, 3475, 1973])
Epoch: 1037, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1038 - Batch 1 ########################
IDs in batch 1: tensor([1996, 3589,  590, 2650, 1405, 2841, 3193, 2005, 2011,  991,  519, 1626,
        2545, 4030, 2666, 2806])
Epoch: 1038, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1039 - Batch 1 ########################
IDs in batch 1: tensor([ 378,  417, 2207, 3397,  957, 2299, 2309,  890,  148, 2206,  390, 1157,
        3676, 1728, 2161, 3240])
Epoch: 1039, Training Loss: 0.18, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1040 - Batch 1 ########################
IDs in batch 1: tensor([ 727,  352, 3207, 3921, 3895, 2004, 3734, 2548, 3135, 2447, 2787,  376,
         417, 3856,  282, 3200])
Epoch: 1040, Training Loss: 0.63, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1041 - Batch 1 ########################
IDs in batch 1: tensor([1186, 1372, 3661, 3177, 1428, 1244, 1973, 2275, 2383, 3160, 2749, 2678,
        2280, 1481, 1463,  306])
Epoch: 1041, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1042 - Batch 1 ########################
IDs in batch 1: tensor([1775, 4005,  219, 1931, 2467, 1918, 2915,  797, 2015, 3270,  378, 2478,
        3476, 1223, 3228,  430])
Epoch: 1042, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1043 - Batch 1 ########################
IDs in batch 1: tensor([3699, 4114, 2406,  508, 2112, 3303, 2284, 4067, 1458, 1312, 2787, 2022,
        2666, 3947, 2627, 1558])
Epoch: 1043, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1044 - Batch 1 ########################
IDs in batch 1: tensor([2408, 2553, 2472, 1375, 2099, 3451, 3082, 3199, 3289, 3821, 3369,  393,
        4005, 1980, 4188, 2206])
Epoch: 1044, Training Loss: 0.58, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1045 - Batch 1 ########################
IDs in batch 1: tensor([4258, 3353, 1900, 3654, 1770, 3338, 3660, 2002, 3541, 1649, 1208,  640,
        2423, 3031, 2749, 1015])
Epoch: 1045, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1046 - Batch 1 ########################
IDs in batch 1: tensor([3647, 3056,  882,  160,  256, 1208, 3200, 4199, 1222, 1670, 1732, 2755,
         541,  920, 3973,  108])
Epoch: 1046, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1047 - Batch 1 ########################
IDs in batch 1: tensor([3636, 3738,   64, 1418,  590, 3127, 1808, 2600, 2295, 3847,  470, 1962,
         125, 2829, 2663, 2131])
Epoch: 1047, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1048 - Batch 1 ########################
IDs in batch 1: tensor([1176, 3355, 2856, 4050,   74, 1859, 1117, 1143, 2148,  590, 3533, 1120,
         538,  926, 4013,  330])
Epoch: 1048, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1049 - Batch 1 ########################
IDs in batch 1: tensor([2615,  936, 3532,  356,  622, 1707, 2453, 1556, 2959, 3871, 3963,  244,
        4196, 3492, 3168, 1925])
Epoch: 1049, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1050 - Batch 1 ########################
IDs in batch 1: tensor([2362, 3354,  588, 2868, 3471, 1945, 3329, 3875, 3727, 3911, 2452,  470,
         886, 2703, 3767, 3245])
Epoch: 1050, Training Loss: 0.48, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1051 - Batch 1 ########################
IDs in batch 1: tensor([3161,  441, 2917, 2650, 1409, 1595, 3564, 2631, 3278, 1167, 1961, 3087,
        1947, 1970, 3829, 1953])
Epoch: 1051, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1052 - Batch 1 ########################
IDs in batch 1: tensor([2660, 3598, 1317,   98, 3701, 4085, 3264, 2614, 1927, 1361, 1617,  236,
        3604, 2498, 3465,  265])
Epoch: 1052, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1053 - Batch 1 ########################
IDs in batch 1: tensor([1493, 2261, 3154, 4181, 1226, 2393, 3265,  819,  417, 2045, 2974, 1384,
        4107, 2982, 4133, 1385])
Epoch: 1053, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1054 - Batch 1 ########################
IDs in batch 1: tensor([3842, 2544, 3303, 1882, 4073, 2238, 3120,  239,  809, 4018, 3277, 3506,
        2902, 1879,  565, 4037])
Epoch: 1054, Training Loss: 0.60, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1055 - Batch 1 ########################
IDs in batch 1: tensor([ 266,  826, 2004, 3782, 3810, 1038,  804,  346, 3242, 1391,   52, 2135,
        3190, 2712,  149, 1760])
Epoch: 1055, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1056 - Batch 1 ########################
IDs in batch 1: tensor([1690, 4056, 3528, 2925, 2894,   61, 2856, 3846, 4078, 3179, 4187,   74,
          92, 2313, 2986, 4222])
Epoch: 1056, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1057 - Batch 1 ########################
IDs in batch 1: tensor([3042, 2526, 2802, 2667,  456, 3352, 1379, 3459, 4049, 3982, 1823, 3789,
        4011,  122, 1076, 1110])
Epoch: 1057, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1058 - Batch 1 ########################
IDs in batch 1: tensor([2764, 3587, 1385, 1934,  816, 2010, 2853, 2648,  147, 2104, 2207, 4067,
         816, 2272, 1054, 3949])
Epoch: 1058, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1059 - Batch 1 ########################
IDs in batch 1: tensor([ 498,  907,  503, 3311, 4238, 3594, 1299, 4037, 1236, 1812, 2378, 3945,
        2368, 2815, 3762, 1082])
Epoch: 1059, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1060 - Batch 1 ########################
IDs in batch 1: tensor([2485, 2261, 3055,  681,  583,  415, 2731,  350, 3902, 1576, 3697, 2118,
         275, 1595,  988, 2932])
Epoch: 1060, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1061 - Batch 1 ########################
IDs in batch 1: tensor([ 503, 2217, 2841,  651, 3369, 1458,  117, 1380,  569, 3330,  881, 3023,
        4253,   25, 4185, 3872])
Epoch: 1061, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1062 - Batch 1 ########################
IDs in batch 1: tensor([1552, 1041, 3340, 1007, 3314,   37, 1221, 1242, 1241,  323, 4265, 2145,
        1707, 3136, 1722, 2509])
Epoch: 1062, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1063 - Batch 1 ########################
IDs in batch 1: tensor([3701, 2132,  287, 4124, 2099, 1571, 3467, 2328,   30, 2015, 1840, 1117,
        1067, 1632, 1404,  884])
Epoch: 1063, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1064 - Batch 1 ########################
IDs in batch 1: tensor([ 981, 2976, 1233, 3701, 3717, 1011, 3859, 3035, 3072, 1009, 2683, 3875,
        2046, 1330,  363,  615])
Epoch: 1064, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1065 - Batch 1 ########################
IDs in batch 1: tensor([3204, 3927, 2190, 3394,   72, 2461, 2817, 2831, 2666, 3236, 1043, 3060,
        4189, 2264, 1753, 1489])
Epoch: 1065, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1066 - Batch 1 ########################
IDs in batch 1: tensor([ 237, 1076, 1879, 2969, 3060, 2133, 3652, 1910, 2831,  537, 3357, 3969,
        1060, 2582, 2482, 2536])
Epoch: 1066, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1067 - Batch 1 ########################
IDs in batch 1: tensor([1651, 2719, 3570, 1252, 3069,  346, 2412, 3652, 2242, 2521, 2965, 3035,
        1277, 2418, 4203, 3139])
Epoch: 1067, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1068 - Batch 1 ########################
IDs in batch 1: tensor([2963, 1726, 1335, 3114, 3782, 2070, 1793, 3366, 2245,  955, 2134, 1180,
        4249,   93, 3194, 1056])
Epoch: 1068, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1069 - Batch 1 ########################
IDs in batch 1: tensor([1671, 2743, 3207, 3497, 2117, 1272,  818, 1056, 2695,  110, 3449, 4044,
        3337, 2010, 3501, 3300])
Epoch: 1069, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1070 - Batch 1 ########################
IDs in batch 1: tensor([3604, 1140, 3732, 2542,  355, 2169, 1950,  524, 1895, 4228, 3797, 3540,
        1249,  120, 3810,  632])
Epoch: 1070, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1071 - Batch 1 ########################
IDs in batch 1: tensor([3410,  314, 2085, 3391, 1225,  601, 4198, 4199, 1286, 1438, 2484, 2524,
        1001, 1161, 1824, 1154])
Epoch: 1071, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1072 - Batch 1 ########################
IDs in batch 1: tensor([1826, 2324, 3389, 3219, 2629, 3617,  373, 4232, 1825,  413, 2412, 1395,
        3083, 2385, 1419,  131])
Epoch: 1072, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1073 - Batch 1 ########################
IDs in batch 1: tensor([  86, 1425, 3507,  962,  274, 2849, 1328, 3493, 1626,  274,  604, 1168,
        4100, 2111,  466, 2598])
Epoch: 1073, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1074 - Batch 1 ########################
IDs in batch 1: tensor([1248, 1024, 2295, 1977, 1641, 1471,  541, 1899, 2405,  251, 2097, 1113,
        1680,  628, 1347, 2961])
Epoch: 1074, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1075 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 3647,  316, 1408, 3621,  816, 1862, 3309, 2469, 2880, 4196, 3060,
        4138,  324,  713, 3702])
Epoch: 1075, Training Loss: 0.83, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1076 - Batch 1 ########################
IDs in batch 1: tensor([3006,  736, 4009, 3009,  524,   78, 1585, 1152, 3661, 1270, 1770, 3591,
        2828, 2812, 1882, 1076])
Epoch: 1076, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1077 - Batch 1 ########################
IDs in batch 1: tensor([ 637,  946,  914, 1821, 4036, 3998, 3290, 3040, 1517, 2112, 3120, 3999,
        1804, 3239, 2470,   57])
Epoch: 1077, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1078 - Batch 1 ########################
IDs in batch 1: tensor([1067, 3398, 3557, 1558,  417, 1500, 4220, 1356,  752, 1711, 4220, 1548,
        2953, 3643,  325, 2957])
Epoch: 1078, Training Loss: 0.82, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1079 - Batch 1 ########################
IDs in batch 1: tensor([1360, 2024, 3975, 1157, 1887,  394, 3333, 1481, 2036, 1951, 3680, 3905,
        2314, 1804, 2110, 1651])
Epoch: 1079, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1080 - Batch 1 ########################
IDs in batch 1: tensor([3599, 3035,  879, 1851, 1962, 4084,  485, 2052, 2482, 4154, 4266, 2219,
         824, 1891,  637,  422])
Epoch: 1080, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1081 - Batch 1 ########################
IDs in batch 1: tensor([ 842,  568, 2938, 3246, 2749, 3360, 1041, 2391, 3074, 2212, 3378, 1225,
        4037, 4077, 3203, 4053])
Epoch: 1081, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1082 - Batch 1 ########################
IDs in batch 1: tensor([4159,  408,  850, 3479,  256, 3693, 3883, 2217,  181, 2435, 2836, 3742,
         771, 3287, 2440, 4146])
Epoch: 1082, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1083 - Batch 1 ########################
IDs in batch 1: tensor([3674,  105, 1030, 1173,  427, 2204, 1765, 4107, 1568,  194, 1498, 3912,
        2088, 1661,  290,   82])
Epoch: 1083, Training Loss: 0.91, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1084 - Batch 1 ########################
IDs in batch 1: tensor([4110,  218, 1545, 2615, 2614, 1672, 3568, 1663,  256,  990, 3541, 3223,
        3570, 2370,  666, 1605])
Epoch: 1084, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1085 - Batch 1 ########################
IDs in batch 1: tensor([3671, 1083, 1747, 2921,  683, 4190,  516, 2791,  986, 2847, 1311, 3705,
        1423, 3807, 3304,  494])
Epoch: 1085, Training Loss: 0.71, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1086 - Batch 1 ########################
IDs in batch 1: tensor([3204, 1955, 3197,  212, 3334, 4036, 3326, 1426, 2516, 4255, 2632, 3060,
        4236, 1321, 1204, 4256])
Epoch: 1086, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1087 - Batch 1 ########################
IDs in batch 1: tensor([ 405,  337, 2879,  491, 3010, 2207,  950, 1177, 2242, 2370, 2796, 3330,
        2401,  758, 1346, 3207])
Epoch: 1087, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1088 - Batch 1 ########################
IDs in batch 1: tensor([2847, 3511, 3873, 2653, 3552, 3772, 1076, 2727,  256, 4036, 2498,  928,
        2496, 3032, 3521, 1999])
Epoch: 1088, Training Loss: 0.46, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1089 - Batch 1 ########################
IDs in batch 1: tensor([3553, 1176,  135, 1337, 2691, 1070, 1317,  112, 3985, 2995, 1011, 1673,
         456, 1704,  803,  591])
Epoch: 1089, Training Loss: 0.73, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1090 - Batch 1 ########################
IDs in batch 1: tensor([3188,  324, 3621, 2880, 2476,  438, 2086, 3563, 1139,  206,  317, 2469,
         511, 1281, 1552, 3692])
Epoch: 1090, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1091 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 1044, 2749,  212,  914,   88,  596, 2995, 1124, 3826, 2669, 1397,
        2121, 1656,  976, 3661])
Epoch: 1091, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1092 - Batch 1 ########################
IDs in batch 1: tensor([3251, 2848, 3151, 4265, 1618, 1444,  763,  425,  412, 2366, 1370,  191,
         279,  812, 3729,  476])
Epoch: 1092, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1093 - Batch 1 ########################
IDs in batch 1: tensor([3970, 3023, 1648, 3945, 3807, 2632, 1174,  518, 3717, 1894,  732,  688,
        1685, 3299,  976, 1234])
Epoch: 1093, Training Loss: 0.59, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1094 - Batch 1 ########################
IDs in batch 1: tensor([1457,  821, 1954, 2131,  566, 4258,  234, 2621, 2102,  491, 2049, 2616,
        3390, 1748, 3712, 2034])
Epoch: 1094, Training Loss: 0.50, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1095 - Batch 1 ########################
IDs in batch 1: tensor([  64, 3998,  738, 3945, 4126, 2277, 3142, 1028, 1022, 4176,  991, 3267,
        1819, 3671, 3267, 3094])
Epoch: 1095, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1096 - Batch 1 ########################
IDs in batch 1: tensor([2109, 1324,  757, 3110,  150, 1495, 2758, 1349, 2437, 2030, 3878, 4197,
        2265, 3216,  379, 2453])
Epoch: 1096, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1097 - Batch 1 ########################
IDs in batch 1: tensor([2643, 2664,   41,  256, 3988, 3960, 2678, 2305, 2643, 1097, 2236, 3927,
         450, 3404, 1153, 1872])
Epoch: 1097, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1098 - Batch 1 ########################
IDs in batch 1: tensor([3747, 1892, 3974, 1183, 2346, 3831,  794, 2241, 2306,  239, 4044, 3073,
        2737, 2156, 1913,  393])
Epoch: 1098, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1099 - Batch 1 ########################
IDs in batch 1: tensor([2110, 2477,  869,   51, 2420, 2046, 2134, 2231, 3614,  212,  279, 3327,
        2382, 3542, 1320,  137])
Epoch: 1099, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1100 - Batch 1 ########################
IDs in batch 1: tensor([2036, 2004,  306, 1985,  789, 3604, 1173, 4195, 3385,  463, 3558, 1231,
        2960, 1258,  450, 3031])
Epoch: 1100, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1101 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 1244, 3421, 3056,  129, 1880, 1620, 1438, 1248, 2399, 2350, 2412,
        2457,  568, 3852,  893])
Epoch: 1101, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1102 - Batch 1 ########################
IDs in batch 1: tensor([1909, 4197, 1057, 4139,  199, 2406, 2383,  687, 2040, 2261, 3410, 1419,
         442, 1796, 1638, 1958])
Epoch: 1102, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1103 - Batch 1 ########################
IDs in batch 1: tensor([3440, 1474, 2040, 2645, 3981,  552, 1954, 1101, 1553, 4002, 4078, 3829,
         340, 3627, 3218, 3607])
Epoch: 1103, Training Loss: 0.71, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1104 - Batch 1 ########################
IDs in batch 1: tensor([2085, 1975, 3337, 2448, 2113,  196, 1308, 3437, 1336, 3384, 2883, 2248,
        2721,  749, 4076, 1626])
Epoch: 1104, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1105 - Batch 1 ########################
IDs in batch 1: tensor([2743, 2674, 3659, 3552, 2574,  709, 2456, 4253, 3706, 2782, 2376, 2315,
        3042, 3497, 1478,  635])
Epoch: 1105, Training Loss: 0.48, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1106 - Batch 1 ########################
IDs in batch 1: tensor([1488, 4058, 1690,  949, 3236, 2237, 3144, 3821, 1756, 2019, 1386, 2298,
        2469,  391, 2178, 1333])
Epoch: 1106, Training Loss: 0.50, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1107 - Batch 1 ########################
IDs in batch 1: tensor([3998, 3992, 2120, 3961, 1566, 3525, 3729, 2412, 3778, 1387, 2046, 2581,
         375, 3474, 3433, 1354])
Epoch: 1107, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1108 - Batch 1 ########################
IDs in batch 1: tensor([2748, 1037, 2479, 4253, 3701, 2465, 3111, 2887, 2732, 2951, 3638,  375,
        1844,  841,  900, 3707])
Epoch: 1108, Training Loss: 0.50, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1109 - Batch 1 ########################
IDs in batch 1: tensor([3942, 1761, 3569,   41, 3499, 2449, 1916,  408, 4026, 2810, 3897, 3397,
        3667, 3317,  670, 2280])
Epoch: 1109, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1110 - Batch 1 ########################
IDs in batch 1: tensor([3712, 3681, 1428, 2282, 4143, 4055, 3990, 3363,  653, 4055, 1434,  808,
        2669,  177, 1530, 2026])
Epoch: 1110, Training Loss: 0.58, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1111 - Batch 1 ########################
IDs in batch 1: tensor([3970, 3255, 1015, 4113, 1724, 3135,  842, 1623, 3345, 3282, 3236,  880,
        3121,  755,  126, 3366])
Epoch: 1111, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1112 - Batch 1 ########################
IDs in batch 1: tensor([2360, 4173, 2226, 3211, 2231,   64,  289,  928, 2126, 3023, 1642, 3976,
        1991,  308, 1016, 3568])
Epoch: 1112, Training Loss: 0.51, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1113 - Batch 1 ########################
IDs in batch 1: tensor([3567,  975, 2046, 3603, 2578, 3615, 3843, 1511, 1647,  809, 4265, 1365,
        2278, 2067, 1828,  280])
Epoch: 1113, Training Loss: 0.47, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1114 - Batch 1 ########################
IDs in batch 1: tensor([1221, 1955, 2094, 3447, 2841, 2254,  661, 3453,  281, 2198, 2171,  555,
        4093, 1963,  516, 1044])
Epoch: 1114, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1115 - Batch 1 ########################
IDs in batch 1: tensor([ 971, 2393,  440, 1877, 1979, 2819,   37, 3600, 1496, 4256,  966, 4078,
        2758, 1614,   82, 3627])
Epoch: 1115, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1116 - Batch 1 ########################
IDs in batch 1: tensor([4077, 2847, 3021,  359, 2126, 3480, 4006, 2315, 4232, 3830, 2526,  119,
        3452, 2844,  738, 3676])
Epoch: 1116, Training Loss: 0.37, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1117 - Batch 1 ########################
IDs in batch 1: tensor([2290, 1779,  733, 2726, 1723, 1453,  454, 1081, 1558,  407, 3481, 2390,
         188, 3570, 1107, 1720])
Epoch: 1117, Training Loss: 0.55, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1118 - Batch 1 ########################
IDs in batch 1: tensor([ 666, 3802, 1808, 3829, 2897, 3451, 2614,  858,  726, 3609, 2253, 1370,
        1773, 4264, 2819, 3726])
Epoch: 1118, Training Loss: 0.51, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1119 - Batch 1 ########################
IDs in batch 1: tensor([1345, 3275, 1249, 1840, 1518, 4197, 2648, 2545, 3989, 2849, 1828, 1216,
         295, 4037, 2683, 3674])
Epoch: 1119, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1120 - Batch 1 ########################
IDs in batch 1: tensor([ 964, 3968, 2126,  533, 3401, 2902, 3500,  100, 1668, 3652,  251,  994,
        3604, 2116, 1746, 2703])
Epoch: 1120, Training Loss: 0.29, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1121 - Batch 1 ########################
IDs in batch 1: tensor([2595,  639,  184, 3860,  376,   95, 2234,  602,   26, 2137, 1734, 3552,
         846,  874, 2059, 2234])
Epoch: 1121, Training Loss: 0.52, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1122 - Batch 1 ########################
IDs in batch 1: tensor([2784, 3529, 3207,  604, 2149, 1381, 1336,  739, 1641, 1707, 3471,  823,
        2726, 1506,  875, 3851])
Epoch: 1122, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1123 - Batch 1 ########################
IDs in batch 1: tensor([ 119, 3243, 1495, 1641, 1959,  367, 3492, 2895, 2652, 1186, 1634, 1170,
        1175, 2976, 1372, 3812])
Epoch: 1123, Training Loss: 0.53, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1124 - Batch 1 ########################
IDs in batch 1: tensor([2807,  110, 2418, 3898, 1868, 1944, 3014, 1977, 2564, 1476, 3465, 2462,
        1397, 2436, 3982, 3637])
Epoch: 1124, Training Loss: 0.59, Validation Loss: 0.64, accuracy = 0.76
Save best Model_1 @ epoch 1124 acc: 0.7584994138335287
Email sent!
######################## Epoch 1125 - Batch 1 ########################
IDs in batch 1: tensor([3472,  324,  892, 3990, 1284, 2028, 1712, 4215,  749, 3726, 4190, 1373,
        2794, 1734, 3521, 1796])
Epoch: 1125, Training Loss: 0.45, Validation Loss: 0.64, accuracy = 0.76
Save best Model_1 @ epoch 1125 acc: 0.7608440797186401
Email sent!
######################## Epoch 1126 - Batch 1 ########################
IDs in batch 1: tensor([1619, 1383, 2242, 1189, 4067, 2015, 2726, 1951, 1961, 2940, 3669,  323,
        1991, 3327, 2511, 1892])
Epoch: 1126, Training Loss: 0.38, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1127 - Batch 1 ########################
IDs in batch 1: tensor([3718, 2590, 2730, 2485, 1521, 3542,  556, 3866,  462,  202,  456, 2514,
        2017, 1860, 1974, 3886])
Epoch: 1127, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1128 - Batch 1 ########################
IDs in batch 1: tensor([2795, 3105, 1322, 2386,  970, 1601, 2587, 4226, 2178, 3353, 1418, 3334,
          92, 1356, 2563,  225])
Epoch: 1128, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1129 - Batch 1 ########################
IDs in batch 1: tensor([1802, 3757, 2610, 1256, 3871, 2153, 3371, 2842, 1226, 1174, 1344,  501,
        2915, 1605, 2664, 4242])
Epoch: 1129, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1130 - Batch 1 ########################
IDs in batch 1: tensor([2832, 2777, 1355,  809, 1900,  335, 2980,  419, 2493, 4185, 2370,  467,
         145, 3558, 1863, 3015])
Epoch: 1130, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1131 - Batch 1 ########################
IDs in batch 1: tensor([2836,  869, 2487, 3467, 3246,  687, 2444, 3673, 1525,  147, 4030,  365,
         518, 2391, 2366, 2940])
Epoch: 1131, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1132 - Batch 1 ########################
IDs in batch 1: tensor([ 670, 1241, 1830,  518, 1383,  190, 3130, 3585, 1190, 3261, 1131,   85,
        3637, 2791, 4055,  660])
Epoch: 1132, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1133 - Batch 1 ########################
IDs in batch 1: tensor([ 455, 3764,  857,  300,  350,  490, 4077, 3624,   88,  612,  797, 2447,
         673, 4234, 2213, 3476])
Epoch: 1133, Training Loss: 0.70, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1134 - Batch 1 ########################
IDs in batch 1: tensor([1596, 2157, 1973, 4037, 2521, 2248, 2398, 2432,  149, 2976, 4264, 2504,
        3903, 1471, 2616,  245])
Epoch: 1134, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1135 - Batch 1 ########################
IDs in batch 1: tensor([2176, 1374, 1397, 2324, 3778, 3677, 2839, 1879, 3238, 1060, 2841,   30,
        3974, 1661,  377,  807])
Epoch: 1135, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1136 - Batch 1 ########################
IDs in batch 1: tensor([ 676, 2359,  514, 3968,  185, 2010, 2203, 3489,  292,  167, 1015, 2066,
        3767, 2937, 1119,  615])
Epoch: 1136, Training Loss: 0.36, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1137 - Batch 1 ########################
IDs in batch 1: tensor([1154,  823, 2075,   15, 3787, 2118, 1484, 2884, 3654, 2961, 2414,  739,
         750, 2235, 3630, 3985])
Epoch: 1137, Training Loss: 0.28, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1138 - Batch 1 ########################
IDs in batch 1: tensor([1049, 3252, 1399, 1086, 4138, 1817,  106, 3640, 3673, 2667, 3433, 2708,
        2646, 3499, 4039,  751])
Epoch: 1138, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1139 - Batch 1 ########################
IDs in batch 1: tensor([ 554,  316, 2772,  557, 1137, 2091, 2947, 1833, 2399, 1945,  656,  545,
         887,   56, 2151, 2133])
Epoch: 1139, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1140 - Batch 1 ########################
IDs in batch 1: tensor([3501, 2375, 2317,  238,  656,  391,  915, 1478, 2065, 3181, 1377,  588,
        4226, 2447, 3883, 4140])
Epoch: 1140, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1141 - Batch 1 ########################
IDs in batch 1: tensor([  64, 3079, 1836,  785, 2869, 3671,  577,  147, 3455, 2810, 1872, 3540,
        3742, 2582, 3092,  640])
Epoch: 1141, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1142 - Batch 1 ########################
IDs in batch 1: tensor([3127, 2804, 1913, 4158,  496, 3671,    5, 1386, 1722, 2833, 3771,  740,
        3077, 2905, 1333,  904])
Epoch: 1142, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1143 - Batch 1 ########################
IDs in batch 1: tensor([ 538, 1390,  218, 3101, 3543, 1913,  483, 1803, 3056, 1017, 3540, 1981,
        1734,  914,  275, 1962])
Epoch: 1143, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1144 - Batch 1 ########################
IDs in batch 1: tensor([ 195, 3632,  642, 2265, 1015,  839,  969, 2829, 1803, 2794,  247,  277,
        3092, 2241, 1357,  900])
Epoch: 1144, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1145 - Batch 1 ########################
IDs in batch 1: tensor([  97, 1614,  442,  300, 3473,  427, 3317, 3233, 2461, 3162, 4186, 2697,
        1970, 2648, 1387, 1567])
Epoch: 1145, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1146 - Batch 1 ########################
IDs in batch 1: tensor([3194, 3005, 3039, 1311, 3065, 1877, 3418, 1726, 3126, 3642, 2182, 2039,
        1574,  622, 4115,  526])
Epoch: 1146, Training Loss: 0.45, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1147 - Batch 1 ########################
IDs in batch 1: tensor([ 864, 2733, 1651, 3298, 2869, 3333, 3797, 4095,  252,  981, 3299, 1229,
        2488, 3524, 1818, 1611])
Epoch: 1147, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1148 - Batch 1 ########################
IDs in batch 1: tensor([2729, 4190, 1180, 1990, 3156,  511, 1065, 4120, 1176,  516, 2586, 1821,
          13, 2420, 1270,  371])
Epoch: 1148, Training Loss: 0.23, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1149 - Batch 1 ########################
IDs in batch 1: tensor([3470,  914, 4048, 1830,   77,   18, 2521, 1111,  379, 3078, 3793,  471,
        2581,  494, 2110,  278])
Epoch: 1149, Training Loss: 0.51, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1150 - Batch 1 ########################
IDs in batch 1: tensor([3003, 3392, 1404,  850,  757, 1113, 3990, 1763, 1007, 1591,  776,  102,
         432, 1015, 3386, 1089])
Epoch: 1150, Training Loss: 0.72, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1151 - Batch 1 ########################
IDs in batch 1: tensor([3069, 2589,  122,  359, 3384,  444, 2461,   74, 1379, 2603, 1899, 2529,
        1292, 2398, 2458,  135])
Epoch: 1151, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1152 - Batch 1 ########################
IDs in batch 1: tensor([2459, 3460, 2248,  456, 3238, 1914,  656, 1347, 3399, 2306,  225, 2586,
         587, 2690,  714,  807])
Epoch: 1152, Training Loss: 0.52, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1153 - Batch 1 ########################
IDs in batch 1: tensor([ 516, 3313, 2371, 2969, 3928,  967, 4004,  514, 1986, 4258, 2649, 1895,
        3660, 3655, 3429, 2458])
Epoch: 1153, Training Loss: 0.56, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1154 - Batch 1 ########################
IDs in batch 1: tensor([3642, 3065, 3072, 3253,   49, 3969,  691, 4099,  365, 2886, 3651,   51,
        1222,  863, 2894, 1389])
Epoch: 1154, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1155 - Batch 1 ########################
IDs in batch 1: tensor([3709, 1716,  533, 1835, 3588, 4228, 1110, 3962, 1485,   41, 2751, 3572,
        3363,  946, 3203, 3732])
Epoch: 1155, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1156 - Batch 1 ########################
IDs in batch 1: tensor([1084,  318, 2572, 2886, 2853,  909, 4200, 1685, 3018, 4265, 3245, 1189,
        2500,  789, 2733, 4213])
Epoch: 1156, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1157 - Batch 1 ########################
IDs in batch 1: tensor([  26, 2986, 1147, 3480, 4033, 1921, 4175, 1643, 3052, 1540, 3644, 3729,
        1702, 3218,  121,   78])
Epoch: 1157, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1158 - Batch 1 ########################
IDs in batch 1: tensor([1038,  701, 2271, 1341, 1590, 3728, 1588,   44,  481, 2667, 2492, 3904,
        2870, 4156,  448,  626])
Epoch: 1158, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1159 - Batch 1 ########################
IDs in batch 1: tensor([2016, 2074, 1031, 1437, 2872, 2359,  869, 1159,  196,  976, 2577, 1299,
        3942, 3015, 1556, 3712])
Epoch: 1159, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1160 - Batch 1 ########################
IDs in batch 1: tensor([1356, 2995,  997, 4212, 3078, 2480, 2597, 2056, 1559, 2292, 1182,  228,
        1733,  441, 3506,  359])
Epoch: 1160, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1161 - Batch 1 ########################
IDs in batch 1: tensor([3859, 1852, 1506, 1502, 1419, 1442,  833, 1451, 2726, 2447, 3874, 1072,
        3308, 3594,  743,  496])
Epoch: 1161, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1162 - Batch 1 ########################
IDs in batch 1: tensor([4168, 2367, 2363, 1133, 3184, 2004,  471, 3044, 2983, 2237, 2867,  993,
        2901, 3444, 2775,   62])
Epoch: 1162, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1163 - Batch 1 ########################
IDs in batch 1: tensor([3765, 1716, 1499, 2520, 1754, 4038, 1734, 3083,  223, 2817,  762, 3942,
        3808, 1798,  804,  547])
Epoch: 1163, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1164 - Batch 1 ########################
IDs in batch 1: tensor([3102, 1302,  365,  855, 3661,  821, 2354, 3683, 3087, 3617, 3251, 2367,
        2883, 2526, 1016, 1374])
Epoch: 1164, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1165 - Batch 1 ########################
IDs in batch 1: tensor([2578,  930, 1026, 1432,  401, 1459, 3100, 3895,  478, 3014, 2765, 1923,
        2284, 3928,  803, 3536])
Epoch: 1165, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1166 - Batch 1 ########################
IDs in batch 1: tensor([  92, 2379, 2459, 1751, 1962, 2643, 1579, 1480, 3895, 1680, 1024,  117,
        1084, 3676, 3415, 2359])
Epoch: 1166, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1167 - Batch 1 ########################
IDs in batch 1: tensor([3714, 1225, 2151, 1257,  257, 3968, 1740, 2305,  894, 1630, 1409, 1118,
        1933,  266,  682, 1436])
Epoch: 1167, Training Loss: 0.78, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1168 - Batch 1 ########################
IDs in batch 1: tensor([2349,  520, 4133, 1510,  523, 2276, 1260, 3099,  110, 2388, 1623, 2009,
        1218, 2567,  758, 1249])
Epoch: 1168, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1169 - Batch 1 ########################
IDs in batch 1: tensor([2470, 3688, 3377, 1260, 3298,   24, 3876,  223,  139,  971, 4046, 2824,
        2442, 3983, 1574, 3052])
Epoch: 1169, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1170 - Batch 1 ########################
IDs in batch 1: tensor([3446, 2204,  407,  534, 3873,  501, 3379, 3673, 2099,  316, 2650, 4099,
        3370, 3740, 3389,   63])
Epoch: 1170, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1171 - Batch 1 ########################
IDs in batch 1: tensor([1675,  670, 1870, 1578, 4100, 3367,  477, 1734, 2883, 4166, 2441,  858,
        3692, 1975,  729, 2536])
Epoch: 1171, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1172 - Batch 1 ########################
IDs in batch 1: tensor([3673,  985, 3599, 1747, 4159, 1751,  514, 1117, 4025, 1604, 3136, 2254,
         603, 2484,  318, 2485])
Epoch: 1172, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1173 - Batch 1 ########################
IDs in batch 1: tensor([1281, 3081, 2480, 1647,  837, 3480, 1138, 1159, 2080, 4077,  813, 3953,
        1501, 1597,   28,  538])
Epoch: 1173, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1174 - Batch 1 ########################
IDs in batch 1: tensor([2254, 2849, 2724,  862, 3907, 1070,  775, 3252,  752, 2892, 2065, 2726,
         305, 2312,  407, 2938])
Epoch: 1174, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1175 - Batch 1 ########################
IDs in batch 1: tensor([ 251, 3417, 3161,  855, 1740, 1375, 3178, 1740, 1850, 2298, 1166, 1578,
        1993, 4144, 1080, 2508])
Epoch: 1175, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1176 - Batch 1 ########################
IDs in batch 1: tensor([2072, 3938, 1879, 1883, 2159, 3988, 2706,  482, 2313, 4189, 2116, 4073,
        3826, 1334, 3895, 3193])
Epoch: 1176, Training Loss: 0.69, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1177 - Batch 1 ########################
IDs in batch 1: tensor([ 687, 2282, 2419,  949, 3715, 3317,  190,  125,  976, 3995, 1372,  279,
        1081, 2405, 3875,  607])
Epoch: 1177, Training Loss: 0.29, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1178 - Batch 1 ########################
IDs in batch 1: tensor([1996,  515, 1204, 3021,  221,  969, 3614, 1174,  225, 2452, 3700, 3693,
        1985,  164, 2459,  777])
Epoch: 1178, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1179 - Batch 1 ########################
IDs in batch 1: tensor([2577, 1296, 1799, 3740, 1521, 1321,  180, 3656, 4049,  194, 2745, 1660,
         653, 3228, 1737, 1219])
Epoch: 1179, Training Loss: 0.33, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1180 - Batch 1 ########################
IDs in batch 1: tensor([1824, 1916,  295, 1426, 2546, 1894, 2469, 3141, 3894,  529,   52, 4068,
        2300, 1641, 2587, 2959])
Epoch: 1180, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1181 - Batch 1 ########################
IDs in batch 1: tensor([2418, 3598, 4082, 3160,  401, 3841, 3469, 3847,  405, 1626, 3614, 4238,
        3810, 3718, 2821, 3386])
Epoch: 1181, Training Loss: 0.62, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1182 - Batch 1 ########################
IDs in batch 1: tensor([3152, 1376, 4018, 4088, 4096, 4228,  786, 1310, 4007, 3838,  862, 1746,
        4258, 1086,  879, 3437])
Epoch: 1182, Training Loss: 0.86, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1183 - Batch 1 ########################
IDs in batch 1: tensor([4094, 2524, 2986,  127,  345, 2874, 2574,  821,  887, 2086, 1026, 3523,
        4166, 4141, 4036, 1271])
Epoch: 1183, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1184 - Batch 1 ########################
IDs in batch 1: tensor([1244, 2870, 2845, 1663,  893, 2271, 4011, 1143, 3713, 1418, 3014, 3822,
        3040, 1896,  915, 1887])
Epoch: 1184, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1185 - Batch 1 ########################
IDs in batch 1: tensor([2872, 3851, 1459, 2181,  941, 1027, 2050, 2312, 1613,    5, 1376, 1099,
        3779, 2732, 2703, 3534])
Epoch: 1185, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1186 - Batch 1 ########################
IDs in batch 1: tensor([ 164, 2697, 3812, 4141,  926, 1678, 4254, 3467, 2465, 2475, 4065, 2279,
        1949, 2524,  467, 2837])
Epoch: 1186, Training Loss: 0.44, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1187 - Batch 1 ########################
IDs in batch 1: tensor([2558,  539, 2826, 2603, 1599, 3021, 3357, 3029,  858,  738, 3326, 2836,
         526, 1784, 4158,  875])
Epoch: 1187, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1188 - Batch 1 ########################
IDs in batch 1: tensor([3898, 3016,  876, 1824, 2328, 1177, 4101, 4089, 2075, 3888, 3655, 3526,
        1118, 3992,  630, 1324])
Epoch: 1188, Training Loss: 0.69, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1189 - Batch 1 ########################
IDs in batch 1: tensor([ 971, 1973,  884, 2857, 1310, 4113,  921, 2886,  630, 1256,  390, 2729,
        2455, 4067, 3504,  371])
Epoch: 1189, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1190 - Batch 1 ########################
IDs in batch 1: tensor([ 239, 4027, 1066, 3334, 2461, 2835, 2097, 1886, 1258, 2977, 1156, 4139,
        1988, 3727, 3532, 3467])
Epoch: 1190, Training Loss: 0.54, Validation Loss: 0.72, accuracy = 0.68
######################## Epoch 1191 - Batch 1 ########################
IDs in batch 1: tensor([2180, 3567, 3202, 3962,  997,  602, 3604, 2537,  367,  725,  520, 1775,
        3656, 2742, 3317,  805])
Epoch: 1191, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 1192 - Batch 1 ########################
IDs in batch 1: tensor([2974,  143, 3804, 2386, 3873, 2825,  408, 1962, 2479,  261, 1604, 2044,
        4266, 2363, 2898, 1967])
Epoch: 1192, Training Loss: 0.63, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 1193 - Batch 1 ########################
IDs in batch 1: tensor([ 524, 2390, 3250, 2121, 1886, 3035, 3177,  636,  365, 1077, 4166,  455,
          60, 1927, 1558,  280])
Epoch: 1193, Training Loss: 0.44, Validation Loss: 0.74, accuracy = 0.67
######################## Epoch 1194 - Batch 1 ########################
IDs in batch 1: tensor([1317,  785, 2035, 1935, 2641, 2796,   51, 2726, 2590, 1754,  952,  182,
         596,   98, 1103, 3072])
Epoch: 1194, Training Loss: 0.33, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 1195 - Batch 1 ########################
IDs in batch 1: tensor([4086, 1111,  532, 4238,  380,  726,  627, 3053,  258, 2619, 2833, 2045,
        3105, 4116,  346, 2018])
Epoch: 1195, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 1196 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 3604, 1369, 3874,  476, 3047,  812, 3815, 1960, 3553, 3101,   34,
        2480, 3765, 2148, 1619])
Epoch: 1196, Training Loss: 0.35, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 1197 - Batch 1 ########################
IDs in batch 1: tensor([3672, 3400, 3777,  363,  672, 1673,  615, 1266, 1273,  150,  512, 3467,
        4173,  465, 2066, 4251])
Epoch: 1197, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1198 - Batch 1 ########################
IDs in batch 1: tensor([1680, 1826, 1139, 2226, 1369, 3528, 3374, 1548, 2782, 2332, 2653,  511,
        4022, 3636, 2742, 3437])
Epoch: 1198, Training Loss: 0.62, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1199 - Batch 1 ########################
IDs in batch 1: tensor([1196, 2432,  503, 4200, 3981, 2114, 1429,  348, 3920, 1517, 3831, 1224,
        3110, 2275,  884,  751])
Epoch: 1199, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1200 - Batch 1 ########################
IDs in batch 1: tensor([1971, 3272, 2578, 2791, 1193, 3797,  595, 3607, 1567, 1167,  928, 1440,
        3902, 3071, 3018,  944])
Epoch: 1200, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1201 - Batch 1 ########################
IDs in batch 1: tensor([3459,  683,  751,  710, 3398, 2103, 3539,  787,  316, 1555, 3118,   19,
        1364, 1027, 1426,  685])
Epoch: 1201, Training Loss: 0.46, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1202 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 3344, 2466, 2413, 3729,  440, 1294,  694,  441, 3487, 3727, 1857,
        3717,  530, 1851,  977])
Epoch: 1202, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1203 - Batch 1 ########################
IDs in batch 1: tensor([3077,  756,  814, 4268, 3040, 1231, 1993, 1121, 2098,  942, 3757, 2003,
        2521, 2372,  552, 3920])
Epoch: 1203, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1204 - Batch 1 ########################
IDs in batch 1: tensor([2504, 2492, 3344,  300,  519, 1545, 4120, 2621, 4220, 2002, 2183, 1242,
        2141,  569, 1512,  961])
Epoch: 1204, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1205 - Batch 1 ########################
IDs in batch 1: tensor([ 368, 1321, 1931,  259, 3408, 2030, 1556, 3105, 3914, 3600, 1270,  550,
         491, 3998, 4108, 2885])
Epoch: 1205, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1206 - Batch 1 ########################
IDs in batch 1: tensor([1793, 2669, 3531, 3354, 2393, 2372, 3099, 2687, 3112, 3370, 1704, 2386,
        4180, 2600,  472, 4263])
Epoch: 1206, Training Loss: 0.49, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1207 - Batch 1 ########################
IDs in batch 1: tensor([ 470,  505,  348,  536,  470,  397,  412,   62, 2065, 3911, 2198, 1279,
        2578,  644, 3466,   41])
Epoch: 1207, Training Loss: 0.47, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1208 - Batch 1 ########################
IDs in batch 1: tensor([3217, 3429,  198, 3726, 1146, 2640, 1022,  566, 1578, 3950, 2260, 1131,
          85, 2189, 1381,  569])
Epoch: 1208, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1209 - Batch 1 ########################
IDs in batch 1: tensor([ 804, 3839, 1032, 1507, 2094, 2748, 2872, 2315, 4263, 2558, 1677,  167,
        1381, 2749, 3533, 1507])
Epoch: 1209, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1210 - Batch 1 ########################
IDs in batch 1: tensor([ 181, 3786, 2655,  113, 2353, 2957, 3480, 3511, 4138, 2574, 2407,   41,
        2550, 1385, 3421, 3087])
Epoch: 1210, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1211 - Batch 1 ########################
IDs in batch 1: tensor([1646, 3110, 2309, 3044, 1128,  448,  395, 1250, 4148, 3194, 1782, 2387,
           7, 2688,   37, 3166])
Epoch: 1211, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1212 - Batch 1 ########################
IDs in batch 1: tensor([ 721, 1600,  575, 2627, 1881,  472, 3936, 1646, 3656, 2415, 1464, 1778,
         910, 2796, 2869, 2417])
Epoch: 1212, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1213 - Batch 1 ########################
IDs in batch 1: tensor([4146, 3793,  977, 3020, 3628,  195, 2682, 3697, 1025, 2154, 1833, 3221,
         435, 2262, 3150,  960])
Epoch: 1213, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1214 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 1279, 1764, 3496,  959, 4004,  318, 1453, 1459, 1556, 1532,  482,
        3650, 3168, 4135, 2413])
Epoch: 1214, Training Loss: 0.59, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1215 - Batch 1 ########################
IDs in batch 1: tensor([2182, 2788, 2739,  963, 3065, 1025, 1810, 3810, 2364, 2620, 3689, 2521,
        1073,   62, 4226, 2050])
Epoch: 1215, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1216 - Batch 1 ########################
IDs in batch 1: tensor([2155,  139, 3711, 3279, 3634, 4015,  851,  869, 1041, 1031, 3599, 4172,
         767, 2690, 1434,  442])
Epoch: 1216, Training Loss: 0.42, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1217 - Batch 1 ########################
IDs in batch 1: tensor([3837,  639, 2431,   92,  485, 1434, 4245, 1614,  821,  184, 2876, 1418,
        4232,  134, 3689,  844])
Epoch: 1217, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1218 - Batch 1 ########################
IDs in batch 1: tensor([4199, 1332, 1851, 1914, 3841, 1166, 4076, 1711,  676, 2871, 3258, 3850,
         295, 4146, 3108, 2051])
Epoch: 1218, Training Loss: 0.38, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1219 - Batch 1 ########################
IDs in batch 1: tensor([1706, 3257, 1454, 1626, 1321, 2131, 3949, 4036, 2210, 3827, 2413,  323,
         574, 1614, 2316, 3386])
Epoch: 1219, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1220 - Batch 1 ########################
IDs in batch 1: tensor([2695,  256, 4010, 4189, 3483, 2202, 2281, 3994, 2010, 2332, 1686, 1032,
        3547, 3094, 3123, 1620])
Epoch: 1220, Training Loss: 0.57, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1221 - Batch 1 ########################
IDs in batch 1: tensor([1244, 3387,  884, 3751, 1628,  134, 3655, 3374, 2835, 3964, 3594, 2681,
        1163, 2476, 2278, 1116])
Epoch: 1221, Training Loss: 0.61, Validation Loss: 0.79, accuracy = 0.68
######################## Epoch 1222 - Batch 1 ########################
IDs in batch 1: tensor([ 334, 3715, 3463, 2298, 2081, 2469, 3728, 2942,  809, 2876, 1065, 3668,
        4097, 3700,  375,  596])
Epoch: 1222, Training Loss: 0.30, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1223 - Batch 1 ########################
IDs in batch 1: tensor([3749, 3110, 1678,  967, 3547, 2295, 3656, 3896, 1275,  426, 2572, 2202,
        2945, 1730, 3133, 1295])
Epoch: 1223, Training Loss: 0.34, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1224 - Batch 1 ########################
IDs in batch 1: tensor([2489,  109, 3418,  520, 2170, 2876, 1055, 2262, 3459, 4115, 1170, 3974,
        3157,  398, 3437, 1975])
Epoch: 1224, Training Loss: 0.47, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 1225 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 4099,  797, 1049, 2297, 1708, 3375, 2724,  300,   71, 1125, 3313,
        2693,  730, 4228,    4])
Epoch: 1225, Training Loss: 0.52, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1226 - Batch 1 ########################
IDs in batch 1: tensor([2856,  519, 3426,  312, 1470, 4139, 2883, 4002,  161, 2996, 2448, 2706,
        1454, 4229,   62, 1672])
Epoch: 1226, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1227 - Batch 1 ########################
IDs in batch 1: tensor([3188, 3483, 2472, 4035, 4108, 1122, 3695, 2457,  949,  444, 1871,  983,
        3900, 3159, 2586, 1028])
Epoch: 1227, Training Loss: 0.31, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1228 - Batch 1 ########################
IDs in batch 1: tensor([3913,  302,  105, 3253, 3973, 2537, 4240,  880, 4198, 2943,  139,  575,
        2912, 4002, 4227, 1054])
Epoch: 1228, Training Loss: 0.43, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1229 - Batch 1 ########################
IDs in batch 1: tensor([1892, 2600, 2385,  159, 3601, 1600, 1225,  628,  372, 2977, 4238, 4011,
        3933, 2462, 1345, 1551])
Epoch: 1229, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1230 - Batch 1 ########################
IDs in batch 1: tensor([ 587, 4097, 3160, 1720, 1957, 1107,  630, 1469, 3754, 2176, 2619, 3265,
        3543,  363, 1517, 3926])
Epoch: 1230, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1231 - Batch 1 ########################
IDs in batch 1: tensor([4108, 1618, 1299, 2511,  111, 1817, 2257,  358,  962, 3030, 3105,  884,
         893, 3718, 3336, 3980])
Epoch: 1231, Training Loss: 0.48, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1232 - Batch 1 ########################
IDs in batch 1: tensor([1258, 2348, 3772, 1234,  266,  400, 2097,  438, 2116,  101, 3740, 3853,
        3942, 2905, 2953, 1179])
Epoch: 1232, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1233 - Batch 1 ########################
IDs in batch 1: tensor([2074, 2126, 1426, 3658, 2977, 1823, 1154, 1775, 2838,  221, 1763, 2448,
         262,  203, 1974, 1157])
Epoch: 1233, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1234 - Batch 1 ########################
IDs in batch 1: tensor([1445, 3680, 1498, 1459,  547, 3839,  944, 2244, 2277, 3702, 2250, 1793,
          15, 1364, 3528, 2578])
Epoch: 1234, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1235 - Batch 1 ########################
IDs in batch 1: tensor([ 661,  986, 3821, 1225, 1384,  565,  709, 2836, 2956, 4190, 3427, 3220,
        2146, 2609,  417,   63])
Epoch: 1235, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1236 - Batch 1 ########################
IDs in batch 1: tensor([1372, 1141, 1953, 2018,  985, 3248, 3483,  306, 3381,  529,  380, 2455,
        1762, 3117, 3355, 1097])
Epoch: 1236, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1237 - Batch 1 ########################
IDs in batch 1: tensor([ 630, 3029, 3127, 2324, 3308, 2500, 3991, 3888,  342,  372, 3108, 1237,
        2539, 3523, 1961, 1361])
Epoch: 1237, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1238 - Batch 1 ########################
IDs in batch 1: tensor([1795,  586,  968, 3974, 4224, 1360, 2582,  893, 1882, 3259,  427, 3087,
        1965,  736, 3006, 2478])
Epoch: 1238, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1239 - Batch 1 ########################
IDs in batch 1: tensor([3917, 1008, 3757, 2292,  134, 3527, 3718, 2232, 1061, 3706, 2202, 2316,
        2544, 3244,  942,  541])
Epoch: 1239, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1240 - Batch 1 ########################
IDs in batch 1: tensor([3859, 3616, 1429,  407, 3655, 3878, 2760,  351, 2442, 2420,  743, 4031,
        2767, 2235,  892, 2536])
Epoch: 1240, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1241 - Batch 1 ########################
IDs in batch 1: tensor([ 568,  612,   60, 2961, 1840, 1728, 2828, 1811, 3244,  835, 3182, 3617,
        3558,  132, 3459, 2355])
Epoch: 1241, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1242 - Batch 1 ########################
IDs in batch 1: tensor([ 986,  171, 1526, 1395, 1900, 3637, 3523,  483, 2141, 2141, 1126, 1977,
        1826, 1817, 1423,  874])
Epoch: 1242, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1243 - Batch 1 ########################
IDs in batch 1: tensor([ 839, 1644, 3234, 3563, 3022, 1731,  726, 1596, 3287, 3964, 3746, 3852,
          78, 3485, 3105, 1580])
Epoch: 1243, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1244 - Batch 1 ########################
IDs in batch 1: tensor([1094,  408, 2016, 2681, 2249, 1686,  477,   10, 2372, 1649,  950, 3779,
        1950, 1641, 1167, 1147])
Epoch: 1244, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1245 - Batch 1 ########################
IDs in batch 1: tensor([3057, 2945, 2601, 3479, 2737, 1198, 3100,  282,  263,  753, 3286, 1845,
        3754, 1625, 1438, 1949])
Epoch: 1245, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1246 - Batch 1 ########################
IDs in batch 1: tensor([4073, 1159, 1556, 3850, 3521, 1027,  337, 1576, 1960,  181, 2046, 1918,
        2045,  264, 4179,  578])
Epoch: 1246, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1247 - Batch 1 ########################
IDs in batch 1: tensor([1225, 3715, 1779, 2807, 2176, 2828,  413,  513, 4232, 2125, 2805, 2451,
        1035, 1799,  626, 1228])
Epoch: 1247, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1248 - Batch 1 ########################
IDs in batch 1: tensor([3640, 1279, 3157, 2754, 1410,  312, 2924,  398, 2275, 4026,  803,  150,
        3218, 1937,  688, 1789])
Epoch: 1248, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1249 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 3635, 1099, 3832, 1436, 2518, 1596, 3010, 2247, 2091,   43, 3616,
        1081, 3668, 3497, 2915])
Epoch: 1249, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1250 - Batch 1 ########################
IDs in batch 1: tensor([3963, 3468,  545, 1208,  915,  874, 2717, 4117,  382, 3545, 3021, 2387,
        2111,  955, 1490, 3354])
Epoch: 1250, Training Loss: 0.34, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1251 - Batch 1 ########################
IDs in batch 1: tensor([2477, 1842, 3130, 3286,  351, 3042, 3268, 3544, 2797, 3087, 2584, 2915,
        2548,  427,  335, 3114])
Epoch: 1251, Training Loss: 0.65, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1252 - Batch 1 ########################
IDs in batch 1: tensor([3590, 1242, 3117, 3473, 1333,  148, 2284, 4119, 3878,  316, 3553, 2189,
        3994,  112,  818, 3787])
Epoch: 1252, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1253 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 1916, 2498,   68,  729, 3533, 2150, 3648, 1502, 3896, 2116, 2860,
        3891, 1375, 1845,  583])
Epoch: 1253, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1254 - Batch 1 ########################
IDs in batch 1: tensor([3990, 1804, 3818,  201, 2506, 1690, 1321, 1767, 2070, 1084,  357, 3552,
         150,  419, 4085, 2844])
Epoch: 1254, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1255 - Batch 1 ########################
IDs in batch 1: tensor([1956,   85,  496,  128, 3537, 2092,  914, 1458, 4238, 1225, 2463, 3772,
         184,  956, 3911, 1367])
Epoch: 1255, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1256 - Batch 1 ########################
IDs in batch 1: tensor([1101, 3154, 2591, 1231, 1578, 3185, 1081,   35, 1657,  477, 3744, 3723,
         278, 3713, 3930,  135])
Epoch: 1256, Training Loss: 0.52, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1257 - Batch 1 ########################
IDs in batch 1: tensor([ 539, 2917, 1599, 4238, 2226, 4000,  574, 1605, 1406, 1488,  796, 3142,
        3306,  718, 3398, 1428])
Epoch: 1257, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1258 - Batch 1 ########################
IDs in batch 1: tensor([ 306, 3286,  965, 1421,   24,  673, 2479, 1292,  736,  516,  186, 2617,
        3998, 3118,  128, 1221])
Epoch: 1258, Training Loss: 0.45, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1259 - Batch 1 ########################
IDs in batch 1: tensor([1204, 2143, 3597, 1612, 2784, 1178, 3020, 4133, 3371,  139, 3635, 3593,
        1146, 1950, 1942, 1209])
Epoch: 1259, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1260 - Batch 1 ########################
IDs in batch 1: tensor([ 237, 3783, 4080, 2842, 4222, 2497, 4139, 3345, 3592, 4134, 1731,  749,
        4088, 3668, 1256, 3114])
Epoch: 1260, Training Loss: 0.53, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1261 - Batch 1 ########################
IDs in batch 1: tensor([1272, 1442, 4114, 1012,  601,  444, 2364, 4116, 4076, 1306,  527, 3895,
        3258, 2565, 1016, 3147])
Epoch: 1261, Training Loss: 0.49, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1262 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 2121, 1880, 1136, 3638, 2868, 3990, 2629, 1884, 2199, 3344, 2666,
        3323, 1371, 1555, 2109])
Epoch: 1262, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1263 - Batch 1 ########################
IDs in batch 1: tensor([2155, 3083, 3183, 1376,  557, 1489,  636, 1578, 3798,  773, 3999, 3364,
        4114,  315, 2420, 2452])
Epoch: 1263, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1264 - Batch 1 ########################
IDs in batch 1: tensor([3434,  411, 2561, 2111, 2368, 3328, 3400, 2437, 1575, 3014,  941,  563,
        1638,  113, 1154,   32])
Epoch: 1264, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1265 - Batch 1 ########################
IDs in batch 1: tensor([3389,  625, 2782, 3862,  975, 2206,  185, 3812, 3208, 1937, 1710, 1766,
        1158, 4038, 1283, 3886])
Epoch: 1265, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1266 - Batch 1 ########################
IDs in batch 1: tensor([3977,  646,  100, 3245,  505, 1485, 2202, 3628, 1014, 2230, 3226,  469,
        1321, 1005,  352, 1152])
Epoch: 1266, Training Loss: 0.27, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1267 - Batch 1 ########################
IDs in batch 1: tensor([1840, 4007, 1680,  928, 1834, 1693,  152,  896,  918, 3974, 1958,   98,
         971, 2578, 2912, 2737])
Epoch: 1267, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1268 - Batch 1 ########################
IDs in batch 1: tensor([1733, 2741, 1123, 3806,  314,  120, 1133, 2113,  177, 2343, 3999,  232,
        2849, 2646, 2118,  583])
Epoch: 1268, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1269 - Batch 1 ########################
IDs in batch 1: tensor([2014, 3282,  605,  740,   70, 1093, 1425,  620, 1060, 2465,  145, 1845,
        3112, 2405, 2304,  102])
Epoch: 1269, Training Loss: 0.39, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1270 - Batch 1 ########################
IDs in batch 1: tensor([ 430,  133, 1845,  191, 2996, 1143, 2700, 2066, 1740, 3474, 3146, 1833,
        3025, 1001, 1332, 2868])
Epoch: 1270, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1271 - Batch 1 ########################
IDs in batch 1: tensor([ 539,  376,  891,  196, 2535, 1085, 1852,  946, 3078,   34, 2213, 1634,
        2113, 2005, 1027, 2497])
Epoch: 1271, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1272 - Batch 1 ########################
IDs in batch 1: tensor([ 617,  138,  195,  591,  141, 1123, 2529,  981, 1855, 1731, 1155, 2555,
         289, 2173,   18,  751])
Epoch: 1272, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1273 - Batch 1 ########################
IDs in batch 1: tensor([4003,  389,  363, 1093, 3644, 3624, 1384, 2559,  432, 1793, 3718,  982,
        2752,  419, 3667, 4256])
Epoch: 1273, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1274 - Batch 1 ########################
IDs in batch 1: tensor([ 205, 1540, 2373,  201, 3740, 2142,  568, 2420, 1395,  732, 1057, 1052,
         778, 2435, 1096, 3991])
Epoch: 1274, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1275 - Batch 1 ########################
IDs in batch 1: tensor([1286, 1011,  441,  342,  503, 3287, 1730, 1481, 2324, 2183, 1274, 1920,
         465, 1730, 1005, 1804])
Epoch: 1275, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1276 - Batch 1 ########################
IDs in batch 1: tensor([1281,  963, 2718,  478,  139, 3204, 3181,  260,  941,  727, 1931, 3272,
        1037, 3146,  833, 2428])
Epoch: 1276, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1277 - Batch 1 ########################
IDs in batch 1: tensor([ 247, 1007, 2241, 2609, 2913, 1872, 3336,  547, 2229, 2919, 2520, 1478,
         735, 1474, 3746,  863])
Epoch: 1277, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1278 - Batch 1 ########################
IDs in batch 1: tensor([3681, 2166, 2320, 1273, 4251,  305, 2523,  196, 1345, 4131, 1855, 3227,
        1841, 2394,  437,  658])
Epoch: 1278, Training Loss: 0.56, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1279 - Batch 1 ########################
IDs in batch 1: tensor([3271, 2644, 3570, 1305, 4255, 3954, 1321, 3193, 2450,  257,   50, 1619,
        4163, 3518, 2080, 2030])
Epoch: 1279, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1280 - Batch 1 ########################
IDs in batch 1: tensor([1093, 2118, 3992,  950, 2912, 2945, 2018, 3647, 3672, 1282, 1346, 1087,
        3227,  843, 1195, 3627])
Epoch: 1280, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1281 - Batch 1 ########################
IDs in batch 1: tensor([3497, 2312, 3532, 1835,  739, 2126, 4010, 2272, 2206, 3357, 3166, 1910,
        1001, 3150, 1605, 3932])
Epoch: 1281, Training Loss: 0.57, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1282 - Batch 1 ########################
IDs in batch 1: tensor([ 357, 1901, 2767, 1075,  725, 3424, 1645, 1495, 2899, 2370, 1770,  811,
        4149, 1051, 4124, 3002])
Epoch: 1282, Training Loss: 0.52, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1283 - Batch 1 ########################
IDs in batch 1: tensor([ 752,  704,  496, 3389, 2826, 2137, 3726,  167,  876, 3282, 2412, 1932,
        3020, 2853, 2178, 2206])
Epoch: 1283, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1284 - Batch 1 ########################
IDs in batch 1: tensor([1913, 3756, 1065,  555, 3950, 4133, 2327, 1984, 2845, 4087, 1755, 3399,
        3883, 3950, 2416, 3846])
Epoch: 1284, Training Loss: 0.77, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1285 - Batch 1 ########################
IDs in batch 1: tensor([3712,  332, 2798, 3441, 1316, 1281,  849,  496, 1333, 3182, 3187, 1668,
        1146, 3374,  498, 1953])
Epoch: 1285, Training Loss: 0.74, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1286 - Batch 1 ########################
IDs in batch 1: tensor([1198,   81, 2995, 2416, 1120,  538, 1088, 3394, 1370, 2306,  968, 3718,
        3585, 3787,  225, 4197])
Epoch: 1286, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1287 - Batch 1 ########################
IDs in batch 1: tensor([ 101, 2887,  212,  919, 1891, 2371, 2770, 3353, 1521, 4126,  766,  691,
        4253, 3286, 1007, 1511])
Epoch: 1287, Training Loss: 0.12, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1288 - Batch 1 ########################
IDs in batch 1: tensor([1726, 1789, 1450, 1524, 1453, 1853, 2051, 2764,  687, 2789,   15, 3525,
        1140, 3218, 3972,  851])
Epoch: 1288, Training Loss: 0.18, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1289 - Batch 1 ########################
IDs in batch 1: tensor([2821, 1372, 1225, 3306, 2809, 3760, 1504, 2209, 4189, 1249,  617, 1734,
        1450, 1077, 3479, 1553])
Epoch: 1289, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1290 - Batch 1 ########################
IDs in batch 1: tensor([1452, 3793, 2695,  771, 4143, 1418,  132, 2272, 1665, 4234,  214, 2661,
        2264, 2433, 1649, 1793])
Epoch: 1290, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1291 - Batch 1 ########################
IDs in batch 1: tensor([ 623,  974,   31, 2643, 2295, 2483, 3664, 1297, 2715, 3729, 2209, 4099,
        1062,  620,  713, 2885])
Epoch: 1291, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1292 - Batch 1 ########################
IDs in batch 1: tensor([1056, 4139,  263,  649,  401, 3082, 4186, 1526, 3610,  217,   85, 2727,
        1955, 2510, 3528, 3197])
Epoch: 1292, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1293 - Batch 1 ########################
IDs in batch 1: tensor([1754, 3980,  824, 3536,  303, 2347,  750, 2997, 3628, 4263, 3677, 1871,
         539,  673, 1761,  373])
Epoch: 1293, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1294 - Batch 1 ########################
IDs in batch 1: tensor([1760, 3785, 3119,  667, 3473, 1877, 2485, 4068,  111, 2357, 2097,  710,
        3118, 1388, 1439, 2764])
Epoch: 1294, Training Loss: 0.29, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1295 - Batch 1 ########################
IDs in batch 1: tensor([3632, 2579, 4238,  820, 4088, 1784, 3078, 3238,  588,  418, 1325, 2343,
        1548,  704, 1478, 1317])
Epoch: 1295, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1296 - Batch 1 ########################
IDs in batch 1: tensor([3368, 2285, 2504, 3290, 1383,   18, 3842,  316,  452, 3057, 3689, 3094,
        1869, 2660, 1833,  803])
Epoch: 1296, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1297 - Batch 1 ########################
IDs in batch 1: tensor([3654,  219, 2207,  934, 1496, 2997,  980, 3136, 2696,  132, 3713,  393,
        3084,  721, 4152, 3993])
Epoch: 1297, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1298 - Batch 1 ########################
IDs in batch 1: tensor([3815,  441,  483,    7, 2478,  803, 1932, 2332,  556, 4213,  982, 2567,
         467, 1658, 3960,   28])
Epoch: 1298, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1299 - Batch 1 ########################
IDs in batch 1: tensor([ 736, 3928, 3661, 1251,  902, 4082, 3022, 2027, 1745, 1830, 3408, 3534,
        2950, 2081, 2821, 3616])
Epoch: 1299, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1300 - Batch 1 ########################
IDs in batch 1: tensor([ 259, 3352, 1113, 3414,  688, 3188, 1643, 1755, 3357, 2587, 1421, 1157,
         184, 4033, 2456, 2535])
Epoch: 1300, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1301 - Batch 1 ########################
IDs in batch 1: tensor([1062, 1209, 3299, 2370,  956, 4223, 2365, 3834, 3004, 3077, 3981, 1130,
        1014,  858,  797, 2905])
Epoch: 1301, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1302 - Batch 1 ########################
IDs in batch 1: tensor([1576, 1438,  407, 3251, 1668, 2784, 2425, 1160,  758, 2027, 2150, 3367,
         335, 4082, 3279, 2405])
Epoch: 1302, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1303 - Batch 1 ########################
IDs in batch 1: tensor([3969, 1802, 4255, 3912, 2133, 4222, 2599, 1096,  415,   71, 1892, 1070,
        2177, 3569,  522, 3674])
Epoch: 1303, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1304 - Batch 1 ########################
IDs in batch 1: tensor([3922, 3972, 3030, 3363, 2729, 2723, 1863,  379, 1731, 1208, 1828, 1410,
        3569, 4195, 2967, 3832])
Epoch: 1304, Training Loss: 0.42, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1305 - Batch 1 ########################
IDs in batch 1: tensor([ 403, 1778, 2695,  807, 1730, 4128, 2784,   64, 1197, 3494, 2367, 3511,
        3384, 1140, 2052, 2385])
Epoch: 1305, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1306 - Batch 1 ########################
IDs in batch 1: tensor([2209, 3265, 3949, 2932,  137, 1809, 1476, 2627, 3437, 3228, 3311,  954,
        2849, 2907,  607, 1579])
Epoch: 1306, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1307 - Batch 1 ########################
IDs in batch 1: tensor([3020, 2015, 2931, 1124,  415,  943, 4008, 3087, 1676, 1110, 2847, 2464,
        1231,  846, 1747, 1706])
Epoch: 1307, Training Loss: 0.36, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1308 - Batch 1 ########################
IDs in batch 1: tensor([3672, 3282, 4220, 4026, 2921, 1258,  435, 2780, 4136, 2629,  554, 2853,
        3506, 1121, 1308, 4203])
Epoch: 1308, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1309 - Batch 1 ########################
IDs in batch 1: tensor([1775,  441, 2206, 2998,  110,   38,  990, 2902, 4018, 2745,  738, 2822,
        2115,  269, 3598, 1798])
Epoch: 1309, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1310 - Batch 1 ########################
IDs in batch 1: tensor([1960, 1984, 2887, 1619,  212, 3385, 2040, 2825,  120, 1357, 1311, 1473,
        3669, 1408,  888, 3632])
Epoch: 1310, Training Loss: 0.12, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1311 - Batch 1 ########################
IDs in batch 1: tensor([2807, 3098, 3340, 3075, 2755, 1069, 1931,   20,  917, 2506,  678, 4033,
         914, 1755, 2841, 3395])
Epoch: 1311, Training Loss: 0.16, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1312 - Batch 1 ########################
IDs in batch 1: tensor([ 615,  203, 1600,  217,    5,  533, 3072,  127, 3693, 3547, 3481,  351,
         749, 3042, 2717, 3907])
Epoch: 1312, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1313 - Batch 1 ########################
IDs in batch 1: tensor([ 140, 1352, 2913, 1186,  120, 1635,  914, 3588, 1388, 2510,  826, 4246,
          97,  795, 3807, 2191])
Epoch: 1313, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1314 - Batch 1 ########################
IDs in batch 1: tensor([3298, 3822, 4086, 2177, 3300,  908, 1869, 1283, 3999, 1343,  387, 3180,
        4062, 4199, 1556, 1859])
Epoch: 1314, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1315 - Batch 1 ########################
IDs in batch 1: tensor([2170, 1641,  961, 3756, 3268, 1388,  607, 1173, 2353,  369,  804,  136,
         565, 4229, 1195, 1938])
Epoch: 1315, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1316 - Batch 1 ########################
IDs in batch 1: tensor([1611, 1726, 3392, 2897,  530, 1761, 1134,  278, 4053, 1592,   99, 2770,
        1458, 1968, 1132, 1832])
Epoch: 1316, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1317 - Batch 1 ########################
IDs in batch 1: tensor([3002, 2736, 3627, 3540,  219, 2488, 3343, 2154, 1562,  971, 1131, 2368,
         811, 1050, 3902, 3099])
Epoch: 1317, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1318 - Batch 1 ########################
IDs in batch 1: tensor([2729, 4190, 1680, 1208, 1493, 3282, 3963, 1980, 1278,  255, 3627, 1437,
        3728, 1861,  612, 1655])
Epoch: 1318, Training Loss: 0.45, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1319 - Batch 1 ########################
IDs in batch 1: tensor([ 721,  976, 1767, 2473, 3608, 2729, 2370, 1708, 4253,  496, 1858,  484,
        1774,  324, 3190, 1836])
Epoch: 1319, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1320 - Batch 1 ########################
IDs in batch 1: tensor([ 987,  284, 2401, 1794, 1343, 2205, 1157, 1201, 2180,  269,  232, 3970,
         402,  338, 1241, 3283])
Epoch: 1320, Training Loss: 0.52, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1321 - Batch 1 ########################
IDs in batch 1: tensor([2961, 3627, 2406, 1490, 3469, 1822, 2615, 1736, 3022, 1297, 1425,  946,
        2787, 1335, 2353, 1866])
Epoch: 1321, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1322 - Batch 1 ########################
IDs in batch 1: tensor([2758, 2375, 2252, 2798,  855,  320, 1878, 1624, 1933, 2123, 1982,  963,
        2551, 4032, 2150, 2887])
Epoch: 1322, Training Loss: 0.68, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1323 - Batch 1 ########################
IDs in batch 1: tensor([2519, 2809, 1158, 2711,  645, 1173,  487,  368, 1591, 1122, 3564, 3991,
        1406, 2248,  820, 2869])
Epoch: 1323, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1324 - Batch 1 ########################
IDs in batch 1: tensor([3002,  411,  361, 1970, 4010, 1038, 2347,  850, 1886,  282,  586, 1167,
        1333, 1126, 3781, 3695])
Epoch: 1324, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1325 - Batch 1 ########################
IDs in batch 1: tensor([ 539,   32, 3349, 3500,  828,   19,  959, 1812,  609,  394, 4225, 1025,
        1799, 1774, 2116, 4006])
Epoch: 1325, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1326 - Batch 1 ########################
IDs in batch 1: tensor([ 438, 3863, 1904,  757, 1389, 3190, 4078, 3289, 1455, 3459, 1487, 1559,
        1320, 3017, 2582, 1410])
Epoch: 1326, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1327 - Batch 1 ########################
IDs in batch 1: tensor([1023, 2668,  733, 3536, 2099, 1834, 3913, 3394, 4118, 1355, 1098, 1957,
          71, 1322, 1602, 1158])
Epoch: 1327, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1328 - Batch 1 ########################
IDs in batch 1: tensor([1569, 2851, 1530,  182,  126, 2041, 2241, 3027,  825, 1556,  344, 1601,
        2697, 3327, 3284, 1051])
Epoch: 1328, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1329 - Batch 1 ########################
IDs in batch 1: tensor([1420, 3204, 1281, 3344, 1949, 4107, 1537, 2951, 3514,   19, 2326, 3921,
        3841, 1596, 3991, 1793])
Epoch: 1329, Training Loss: 0.49, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1330 - Batch 1 ########################
IDs in batch 1: tensor([ 185,  136, 1345,  454, 3339, 1623, 4222, 3858, 2986,  755, 2827, 1537,
        3244, 2347, 2711,  487])
Epoch: 1330, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1331 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 2781, 3044,  221, 2482,  424, 4011, 3433,  380,  572, 1072, 3196,
        2858, 2127,  942, 4168])
Epoch: 1331, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1332 - Batch 1 ########################
IDs in batch 1: tensor([2540, 2690, 3088, 1017,  278, 3119, 1444,  740,  919, 3697, 3704, 1224,
        3821, 1883, 2840, 3483])
Epoch: 1332, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1333 - Batch 1 ########################
IDs in batch 1: tensor([1819, 2824, 3379, 3056, 3152, 4094, 2858, 2847, 2966, 4161, 1147, 3429,
        3427, 2837,  395, 1884])
Epoch: 1333, Training Loss: 0.84, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1334 - Batch 1 ########################
IDs in batch 1: tensor([4076, 2783, 1633, 1306,  475, 2642, 2237,  631, 1125,    7, 3875,  864,
         636, 2934,  538, 2254])
Epoch: 1334, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1335 - Batch 1 ########################
IDs in batch 1: tensor([1438, 3098, 2348, 2070, 1971, 2387,  102,  986, 3589, 1376,  182, 1624,
         849, 3533, 2807, 3680])
Epoch: 1335, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1336 - Batch 1 ########################
IDs in batch 1: tensor([3762, 2831, 1472, 2743,  960,  203,  983, 1970, 2642,  832, 3268, 1273,
         807, 2787, 4194, 3426])
Epoch: 1336, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1337 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 2724, 2025, 2369, 3139, 3712, 1673, 2956, 2870, 2472,  367, 2034,
        2137, 4258,  908, 1334])
Epoch: 1337, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1338 - Batch 1 ########################
IDs in batch 1: tensor([1869, 4266, 2398, 2736, 4062, 2467, 1057, 1283, 1016,   70, 2844, 2718,
        2367, 1311, 1052, 2883])
Epoch: 1338, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1339 - Batch 1 ########################
IDs in batch 1: tensor([ 475, 4036, 4230, 1086, 1208,  494, 1877,  263, 1110, 3996, 1195,  119,
        2251,  360, 2122, 2731])
Epoch: 1339, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1340 - Batch 1 ########################
IDs in batch 1: tensor([1895, 1812, 1478, 3860, 3723, 1812, 1685,  897, 2541, 2116,  918, 4143,
        1879, 3278,  471, 1249])
Epoch: 1340, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1341 - Batch 1 ########################
IDs in batch 1: tensor([ 965,  586, 2476, 3940, 3718,  165, 2932, 3276, 2056, 2246, 2377, 3339,
        3139,  440, 1971, 4190])
Epoch: 1341, Training Loss: 0.59, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1342 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 3985, 1034,  713,  371, 1428, 1737,  963, 2760, 1825, 2121, 3675,
        3885, 3114,  959, 3952])
Epoch: 1342, Training Loss: 0.36, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1343 - Batch 1 ########################
IDs in batch 1: tensor([2885,  239, 2328, 2597,  762, 3862,  676,  725, 2332, 2667, 2247, 2701,
        2812, 3827, 3841, 1896])
Epoch: 1343, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1344 - Batch 1 ########################
IDs in batch 1: tensor([2996, 1628, 2065,  807, 1745, 1026, 3878,  586, 2356, 2161,  496, 2210,
        4025, 1802, 3415, 2251])
Epoch: 1344, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1345 - Batch 1 ########################
IDs in batch 1: tensor([1480, 2832, 2017,  833, 1291, 1471, 1287, 1482, 1707, 1693, 4235, 2860,
         615, 2541,  926, 3047])
Epoch: 1345, Training Loss: 0.51, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1346 - Batch 1 ########################
IDs in batch 1: tensor([ 106, 4056, 4253, 1182,  283, 2177, 2134, 3289,  382, 1292, 3638, 2074,
        3787, 2508,  721, 3831])
Epoch: 1346, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1347 - Batch 1 ########################
IDs in batch 1: tensor([3983, 1286,  994, 1059, 3114, 3655, 3549, 2406, 2536, 4114, 1918,  184,
        3397,  389, 3845, 3693])
Epoch: 1347, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1348 - Batch 1 ########################
IDs in batch 1: tensor([3842, 2223,  469, 3075,  238, 1067, 1590,  879, 4073, 1375,  790, 3567,
        3547, 1090, 1774,   22])
Epoch: 1348, Training Loss: 0.61, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1349 - Batch 1 ########################
IDs in batch 1: tensor([2619, 2295, 1655, 3005, 4005, 3289, 1438, 4031, 3764,  333, 2695, 3136,
        1134, 3832, 3823, 2688])
Epoch: 1349, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1350 - Batch 1 ########################
IDs in batch 1: tensor([2286, 4097, 4176, 3102, 2272, 4232, 1869, 4255,  341, 3432, 1087, 2118,
        1985, 1932, 1324, 2205])
Epoch: 1350, Training Loss: 0.74, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1351 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 1355, 3943,  120, 3604,  897, 2081, 1487, 4175,  251,  565, 3518,
        2541, 1152, 2045, 2693])
Epoch: 1351, Training Loss: 0.16, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1352 - Batch 1 ########################
IDs in batch 1: tensor([2255,  841, 4122, 2049, 3709, 3839, 1970, 3052, 2652, 2416, 3755, 3925,
         138, 3907, 2003, 1909])
Epoch: 1352, Training Loss: 0.81, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1353 - Batch 1 ########################
IDs in batch 1: tensor([ 183,  371, 3947, 3160,  899, 1932, 1591, 2337,  864,  481, 3459, 2094,
        2636,  122, 1708, 3709])
Epoch: 1353, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1354 - Batch 1 ########################
IDs in batch 1: tensor([3261, 4058, 1085, 3527, 1767,  323, 1625,  130, 4115, 2220,   15, 1901,
        2317, 4060, 3304, 4197])
Epoch: 1354, Training Loss: 0.39, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1355 - Batch 1 ########################
IDs in batch 1: tensor([1518,  401, 3234, 4195, 2466, 1537, 4235, 2526, 2884, 3949,  631, 1849,
        1779, 2038, 2098, 2995])
Epoch: 1355, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1356 - Batch 1 ########################
IDs in batch 1: tensor([ 857,  316, 3318, 3831, 2443, 4246, 2574, 1711, 2253, 3108,  262,  280,
        1525, 3607, 4135, 2081])
Epoch: 1356, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1357 - Batch 1 ########################
IDs in batch 1: tensor([3810,  141, 4200, 2199, 1052, 2008, 2542, 4026,  512,  234,  881, 1670,
        3047, 3696, 2648, 4131])
Epoch: 1357, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1358 - Batch 1 ########################
IDs in batch 1: tensor([ 815, 1493, 3503, 1322, 3328, 3440, 2393, 2192, 1620, 2250, 1962, 1119,
        2431, 2745, 1611, 2709])
Epoch: 1358, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1359 - Batch 1 ########################
IDs in batch 1: tensor([3949,  469, 3426,  119, 1047,  263, 3040, 4235, 1558, 2290,  807, 2098,
        1751,  182,  465, 1455])
Epoch: 1359, Training Loss: 0.35, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1360 - Batch 1 ########################
IDs in batch 1: tensor([1324, 3015, 3601,  971, 2874, 3862,  554, 2758,  966, 2010,  203, 2729,
        4087, 1017, 2655, 3185])
Epoch: 1360, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1361 - Batch 1 ########################
IDs in batch 1: tensor([1770, 2024,  517, 3961,  261, 3426, 2306, 1948, 2178,  143, 3989, 2123,
        2890, 2817, 2687, 2447])
Epoch: 1361, Training Loss: 0.81, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1362 - Batch 1 ########################
IDs in batch 1: tensor([3558, 2822, 1007, 2719, 3121, 2908,  432, 2719, 4246, 1361, 1024, 4136,
        2355, 4267, 1891,  320])
Epoch: 1362, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1363 - Batch 1 ########################
IDs in batch 1: tensor([2810, 1321, 4149, 3461, 1500, 2691, 3552,  790, 3333, 4138, 4197, 3272,
        1562,  661, 3123, 1117])
Epoch: 1363, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1364 - Batch 1 ########################
IDs in batch 1: tensor([3410, 4230,  676, 2309,  300, 4229, 2301, 1663, 1222, 1585,  590, 3333,
        3676, 3460,  771,   64])
Epoch: 1364, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1365 - Batch 1 ########################
IDs in batch 1: tensor([2368, 2851, 1657,  876, 3536, 4124, 3074,   42,  890,  407, 1711,  879,
        3777, 2344, 2124, 2309])
Epoch: 1365, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1366 - Batch 1 ########################
IDs in batch 1: tensor([  35, 4011,  212, 2075, 4203, 2262, 1570, 3430,  613, 3621, 1872, 1408,
        1556, 4027,  405, 3480])
Epoch: 1366, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1367 - Batch 1 ########################
IDs in batch 1: tensor([  49, 2251, 1448,  530,  812,  776,  379, 1326, 2672, 1636, 3734,  792,
         120, 2999, 2224, 2804])
Epoch: 1367, Training Loss: 0.68, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1368 - Batch 1 ########################
IDs in batch 1: tensor([1234,  688,  545,   56,  717,  512, 2621, 3278,  828, 3132, 3991, 1080,
        1887,  583, 1842,  515])
Epoch: 1368, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1369 - Batch 1 ########################
IDs in batch 1: tensor([ 399, 2825,  452, 3110, 3373, 2967,  653, 3781,  919, 4116, 3895,  928,
        3241, 1655, 1518, 2040])
Epoch: 1369, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1370 - Batch 1 ########################
IDs in batch 1: tensor([2873, 3207, 3351, 2548,  387, 3663, 3917, 4096,  474, 3833, 4139,  640,
        1993, 2394, 2795,  739])
Epoch: 1370, Training Loss: 0.54, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1371 - Batch 1 ########################
IDs in batch 1: tensor([1562, 2468, 1569,  522, 3353, 2965,  910, 2731, 3183, 2606, 1295, 2721,
        3272, 1624, 2595, 3030])
Epoch: 1371, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1372 - Batch 1 ########################
IDs in batch 1: tensor([1507, 3810, 4128, 1131, 3532, 3713, 3181,  399, 1093, 2238, 3905, 2978,
         822, 3530,  282, 1525])
Epoch: 1372, Training Loss: 0.29, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1373 - Batch 1 ########################
IDs in batch 1: tensor([ 623, 4027, 1161, 3987, 2180, 1125, 2696, 4002, 3299, 2832, 2578, 1144,
        1379, 2172, 1232, 1574])
Epoch: 1373, Training Loss: 0.45, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1374 - Batch 1 ########################
IDs in batch 1: tensor([3303, 3985,  180,  917, 2314, 2441, 2967, 3228,  322, 1107, 2463, 4168,
         545,  821, 1360, 1842])
Epoch: 1374, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1375 - Batch 1 ########################
IDs in batch 1: tensor([4263, 2574,  200, 3087, 1260, 1700, 2938, 1099, 1110, 1060, 2847, 3833,
        2821, 4073, 3465, 3767])
Epoch: 1375, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1376 - Batch 1 ########################
IDs in batch 1: tensor([ 425, 4078, 1642, 3932, 3496, 2672, 3531, 3974, 3423,   95, 1001, 1370,
        2127, 2859, 3220,  106])
Epoch: 1376, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1377 - Batch 1 ########################
IDs in batch 1: tensor([ 440, 4197, 3672, 1645, 3816,  361, 2348, 1063,  462, 3652, 4103, 3925,
        2493, 3882, 3790, 2582])
Epoch: 1377, Training Loss: 0.92, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1378 - Batch 1 ########################
IDs in batch 1: tensor([1506, 3308, 2691,  103, 2026, 2682, 3572,  838,  340, 1937,  738,  733,
        3604, 3223, 3962, 2280])
Epoch: 1378, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1379 - Batch 1 ########################
IDs in batch 1: tensor([2041,  161, 3728, 3767,  101, 3991,  154, 3272,   44,  649, 1399, 2810,
        2414,  636, 2400,  736])
Epoch: 1379, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1380 - Batch 1 ########################
IDs in batch 1: tensor([4012,  594, 2880, 2393,  691,  974, 3920, 3168,  184, 1118, 3842, 1290,
        3025, 2718, 1526, 3795])
Epoch: 1380, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1381 - Batch 1 ########################
IDs in batch 1: tensor([1122, 2931, 2410, 3194, 1131, 1124, 1101, 3898, 3894, 2228, 2153, 1702,
        1512, 1920,  527, 3371])
Epoch: 1381, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1382 - Batch 1 ########################
IDs in batch 1: tensor([1682, 2967, 2544, 1186, 3197, 3518, 4159, 1500,   74, 1736, 2583,  260,
        2784, 2189,  625, 2680])
Epoch: 1382, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1383 - Batch 1 ########################
IDs in batch 1: tensor([ 803, 1504, 2600, 2376,   18, 3227, 3696, 1263, 1627, 3052, 1103, 3637,
        2506, 2274, 2050, 2484])
Epoch: 1383, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1384 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 3763, 1977, 2967, 3618, 1487,  212, 2179,  684, 1826, 2275, 2023,
        2414, 1685, 1895, 3780])
Epoch: 1384, Training Loss: 0.52, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1385 - Batch 1 ########################
IDs in batch 1: tensor([3587, 2583, 3939,  360, 2109, 2262, 1570, 1454, 1234, 2973,  490, 1745,
        4141,  139, 3816,  863])
Epoch: 1385, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1386 - Batch 1 ########################
IDs in batch 1: tensor([3414, 1886, 3436, 3240, 3993, 1859,  316, 2173, 3161, 3399, 1613, 1526,
        2462, 2353,  522, 1495])
Epoch: 1386, Training Loss: 0.47, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1387 - Batch 1 ########################
IDs in batch 1: tensor([  30, 3513,  352, 1086, 3663,  207, 1803, 4240,  355, 1836, 3073, 3570,
        2125, 1377,  851, 3388])
Epoch: 1387, Training Loss: 0.16, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1388 - Batch 1 ########################
IDs in batch 1: tensor([4176,  787, 2177,  881,  397, 3252, 3977, 1295,  469,  617, 1832, 4076,
        2099, 1044, 3960, 2659])
Epoch: 1388, Training Loss: 0.24, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1389 - Batch 1 ########################
IDs in batch 1: tensor([4117, 2871, 1657, 2026, 2236, 3608, 3428,  876,  256, 1043, 2198,  269,
        1226, 3469, 2358, 1650])
Epoch: 1389, Training Loss: 0.15, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1390 - Batch 1 ########################
IDs in batch 1: tensor([ 637, 4002, 3160, 3523, 1754, 1663, 1291,  914, 2682, 2506,  884, 2368,
        3644, 3342, 3717, 1932])
Epoch: 1390, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1391 - Batch 1 ########################
IDs in batch 1: tensor([1728, 2195, 4077, 4027, 1949,  256, 1869,  605, 4214, 1628, 2880, 3199,
         659, 1504, 1024,  121])
Epoch: 1391, Training Loss: 0.25, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1392 - Batch 1 ########################
IDs in batch 1: tensor([ 584,  105,  539,  520,  595,  512,  550,  154, 1980,  106,  928,  928,
        2597,  997, 1962, 1448])
Epoch: 1392, Training Loss: 0.70, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1393 - Batch 1 ########################
IDs in batch 1: tensor([3765, 2338, 1311, 3659, 1356, 1454, 2681,  155,  565, 2767, 4000, 2856,
          81,  217, 3047,  403])
Epoch: 1393, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1394 - Batch 1 ########################
IDs in batch 1: tensor([ 184, 4159, 3589,  863, 4172, 3943,  986, 3133, 2734, 1723, 1464, 1780,
         795, 3496, 2466,  396])
Epoch: 1394, Training Loss: 0.43, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1395 - Batch 1 ########################
IDs in batch 1: tensor([2587, 1642, 2464, 4225, 3540, 3727, 1897, 2399,  226, 4251, 1161, 3481,
        1270, 1072, 3366,  628])
Epoch: 1395, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1396 - Batch 1 ########################
IDs in batch 1: tensor([ 372,  503, 1508, 4195, 2616, 3304,  330,   86, 1355, 3885, 1501, 2290,
         786, 2432, 1179, 2924])
Epoch: 1396, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1397 - Batch 1 ########################
IDs in batch 1: tensor([ 684, 2327, 2908, 3069, 2938, 2091,  393, 2697, 2819,  941,  886, 2192,
         726, 3094, 2844, 4230])
Epoch: 1397, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1398 - Batch 1 ########################
IDs in batch 1: tensor([1131,  660, 2749, 2232, 3732, 1297, 2822,  893, 1421, 1336, 4224,  407,
        1774, 2718,  583, 2212])
Epoch: 1398, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1399 - Batch 1 ########################
IDs in batch 1: tensor([3798, 3886, 3539, 1913,  732,  537,  496, 1324, 3876, 3290, 2461, 1045,
        1965, 3246, 1369,  628])
Epoch: 1399, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1400 - Batch 1 ########################
IDs in batch 1: tensor([1580, 3131,  557, 2523, 2044, 3131,  819, 1949, 4118, 2826, 3603, 3876,
        3900, 4010, 2500,  229])
Epoch: 1400, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1401 - Batch 1 ########################
IDs in batch 1: tensor([4087, 1474, 1640, 3344,  652, 1196, 1956, 2276, 2616, 3427, 3147, 2064,
        4061, 1224, 2789, 4124])
Epoch: 1401, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1402 - Batch 1 ########################
IDs in batch 1: tensor([3989, 2468,  766, 1755, 1870,  262,  232, 1104,   59,  997, 3479, 2754,
        1710, 1733, 2723, 2539])
Epoch: 1402, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1403 - Batch 1 ########################
IDs in batch 1: tensor([3384,  653, 1380, 2645,  825,   14, 2595, 1133,  733,  565, 3507, 3879,
        2228, 2857, 4004, 2835])
Epoch: 1403, Training Loss: 0.16, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1404 - Batch 1 ########################
IDs in batch 1: tensor([2836,  566,  492, 4122, 1015, 4048, 2357, 1579,  825, 1748,  478,  322,
          25,   43, 2632, 2924])
Epoch: 1404, Training Loss: 0.35, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1405 - Batch 1 ########################
IDs in batch 1: tensor([2652, 1952, 1286, 2353, 3309, 1661,  526,  324, 2736, 2196, 3839, 3834,
        2450,  617, 3435, 1267])
Epoch: 1405, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1406 - Batch 1 ########################
IDs in batch 1: tensor([2465, 2065, 1189, 2150, 1247, 3083, 3345,  870,  243, 1567, 2472, 3053,
        1977, 3203, 2509, 3227])
Epoch: 1406, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1407 - Batch 1 ########################
IDs in batch 1: tensor([1665, 3428,  150, 1558, 3130, 2088,  515, 1817, 1004, 3536, 1532,  314,
        2656,  219, 2914, 3604])
Epoch: 1407, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1408 - Batch 1 ########################
IDs in batch 1: tensor([1506, 2056, 3943, 2926, 1138, 3647, 2563, 2314, 1818, 3077, 3003,  371,
        2010, 4253, 3648, 2444])
Epoch: 1408, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1409 - Batch 1 ########################
IDs in batch 1: tensor([3710,  412,  755, 2561,  282, 3938, 1235, 1183,  351, 2983, 1779, 2359,
        4035, 2104, 2775, 1545])
Epoch: 1409, Training Loss: 0.28, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1410 - Batch 1 ########################
IDs in batch 1: tensor([  30,  790, 1326, 1294,  980,   77, 1271, 1229, 2763, 4100, 2002, 1428,
        2180, 1173,  892, 1775])
Epoch: 1410, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1411 - Batch 1 ########################
IDs in batch 1: tensor([3535, 1170, 2905, 1364,  452, 3194, 3632, 2653, 4062, 3306,  487, 1891,
        1101, 4121,  966,  963])
Epoch: 1411, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1412 - Batch 1 ########################
IDs in batch 1: tensor([3345, 3640, 3871, 1891,  891, 1180, 1986, 1443,   62, 3763, 1761, 2854,
        3248, 1354,  985, 2822])
Epoch: 1412, Training Loss: 0.12, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1413 - Batch 1 ########################
IDs in batch 1: tensor([3699,  834, 2188, 4116, 2142, 1283, 4254, 1311,  211, 3789,  334, 3642,
        3727,  774,  573, 1525])
Epoch: 1413, Training Loss: 0.63, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1414 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 3208, 1702, 1157,  324, 1578,  926, 2879, 2540, 2895, 3179, 1947,
        1612, 1066, 1277, 1337])
Epoch: 1414, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1415 - Batch 1 ########################
IDs in batch 1: tensor([2775, 2905, 2989, 1810, 2167, 2908, 3202, 2181, 1871,  451,  394,   73,
        1493, 2629,  290, 1351])
Epoch: 1415, Training Loss: 0.66, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1416 - Batch 1 ########################
IDs in batch 1: tensor([1056, 1390, 1945, 2149, 1015, 3485, 2687, 1471, 3185, 3831, 4212,  459,
        2761, 3951, 1208, 2258])
Epoch: 1416, Training Loss: 0.54, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1417 - Batch 1 ########################
IDs in batch 1: tensor([3582, 4119, 3401,  910,  190, 4100, 1641, 2456, 3357, 3211, 3693, 3808,
        2452, 4107,  678, 3701])
Epoch: 1417, Training Loss: 0.67, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1418 - Batch 1 ########################
IDs in batch 1: tensor([2902, 1673,  735, 1072, 4080, 3843, 2281, 2945,  436, 2358, 2656,  194,
        2334, 2836,  387, 2660])
Epoch: 1418, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1419 - Batch 1 ########################
IDs in batch 1: tensor([2855, 2119, 2116, 1409, 2224, 4242, 3842, 1840,  130,  666, 1676, 3891,
        1077,   95, 2153, 1540])
Epoch: 1419, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1420 - Batch 1 ########################
IDs in batch 1: tensor([ 642, 1977,  583, 2817, 2907, 1032,  870, 3634, 3414, 3208,  749, 1371,
        2640, 1740, 3146,  797])
Epoch: 1420, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1421 - Batch 1 ########################
IDs in batch 1: tensor([2344, 3850, 3531, 2597,  756, 1315, 3585,  656, 2844, 1097, 2252, 3204,
         575, 3847, 3336, 1420])
Epoch: 1421, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1422 - Batch 1 ########################
IDs in batch 1: tensor([2822, 2146, 4032,  402, 2060, 1579, 3518, 1123, 4078, 2796, 3203,   95,
        2765, 2914,  191,  259])
Epoch: 1422, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1423 - Batch 1 ########################
IDs in batch 1: tensor([1770, 3267, 1237, 2791, 1583,   60, 3692,  908, 3221, 2030, 3248,  607,
         451, 1880,  264, 2090])
Epoch: 1423, Training Loss: 0.16, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1424 - Batch 1 ########################
IDs in batch 1: tensor([2344, 1599,  333, 1216,  733, 1974, 1020,  477, 1311,  148, 4238, 1229,
          34, 2312,  967, 2091])
Epoch: 1424, Training Loss: 0.33, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1425 - Batch 1 ########################
IDs in batch 1: tensor([4127, 1027,  184, 2247, 3321, 2090,  127,  646, 1979, 2126, 2541, 1379,
        3976, 3842, 1841, 1128])
Epoch: 1425, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1426 - Batch 1 ########################
IDs in batch 1: tensor([1600, 1111, 4010,  226, 2313, 2144, 1886,  340, 1576, 4165, 2087,  976,
        1833,   30, 3485,  234])
Epoch: 1426, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1427 - Batch 1 ########################
IDs in batch 1: tensor([ 575, 2752, 3970,  220,  950, 1863, 1536, 3087, 3710, 1835, 1599, 2388,
        3124, 3132,  340, 2977])
Epoch: 1427, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1428 - Batch 1 ########################
IDs in batch 1: tensor([ 823, 3729, 3928,  217,  384, 2731, 1471, 1409, 3897,  667, 1883, 2095,
        2202, 4203, 3387, 2242])
Epoch: 1428, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1429 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 4267, 2360, 1047, 2327,  491, 1264, 3521, 2934,  550, 2339, 3885,
        3588, 3509,  151,  538])
Epoch: 1429, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1430 - Batch 1 ########################
IDs in batch 1: tensor([2799, 2641,  773, 3113,  872, 1141, 1418, 3913, 1968, 2873, 3131, 3833,
        4120, 2915, 3461, 1279])
Epoch: 1430, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1431 - Batch 1 ########################
IDs in batch 1: tensor([2806, 3551,  130,  395,  394, 2382, 3942, 3808, 3473,  565, 2514, 1155,
        4056, 2342, 4127, 1333])
Epoch: 1431, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1432 - Batch 1 ########################
IDs in batch 1: tensor([2869, 1502, 4157,  257, 3345, 1087,   96, 2191, 4120,  212,  886,  574,
        2045,  573, 3147, 2064])
Epoch: 1432, Training Loss: 0.14, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1433 - Batch 1 ########################
IDs in batch 1: tensor([ 259,   93, 1121, 2169, 2738, 2452, 2725, 2655, 3284, 1209, 2672,  950,
        2616, 1140, 2204, 1345])
Epoch: 1433, Training Loss: 0.20, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1434 - Batch 1 ########################
IDs in batch 1: tensor([2090, 1035, 1810, 3005, 1764,  229, 1803,  693, 3831, 2828, 2765, 2279,
        4004, 3233, 2010, 3603])
Epoch: 1434, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1435 - Batch 1 ########################
IDs in batch 1: tensor([ 900, 2751, 3079, 1413,  694, 2039, 3818, 3993,  206, 3455, 1319, 3755,
        1511, 2734, 3005, 2309])
Epoch: 1435, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1436 - Batch 1 ########################
IDs in batch 1: tensor([2191, 2545,  482, 3655, 1490,   57, 1306, 1155, 1999, 2855, 2752, 3845,
         934, 1428, 4089, 2157])
Epoch: 1436, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1437 - Batch 1 ########################
IDs in batch 1: tensor([ 842,   13, 1011,  487, 1555,  305, 4212, 1511, 1973, 3516, 1228, 1474,
         369, 2016, 4144, 2788])
Epoch: 1437, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1438 - Batch 1 ########################
IDs in batch 1: tensor([1821, 3449,  672, 3935, 2210, 3568,  709,  819, 4080, 1780, 1345, 3105,
        3031, 1388, 1193, 3157])
Epoch: 1438, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1439 - Batch 1 ########################
IDs in batch 1: tensor([1471, 2085, 3418,  882,  809, 2664,  519,  851, 3286, 1895, 3734, 3777,
         345, 3558,  963, 3902])
Epoch: 1439, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1440 - Batch 1 ########################
IDs in batch 1: tensor([2234, 1836,  601,  483, 3329, 3490, 1819, 1123, 1676, 3303, 2059, 2420,
        4051,  292, 3604, 1551])
Epoch: 1440, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1441 - Batch 1 ########################
IDs in batch 1: tensor([1596, 2232, 1137,  238,  914, 1512,  449,  732, 2853,  681, 3091, 1626,
        2827, 1626, 1686, 3432])
Epoch: 1441, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1442 - Batch 1 ########################
IDs in batch 1: tensor([3549, 1647,  290, 2619, 2817, 2383, 2418, 2791,  857, 3181, 1119, 2132,
        1493,  639, 2551, 3823])
Epoch: 1442, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1443 - Batch 1 ########################
IDs in batch 1: tensor([1089, 3994,  244, 4046, 2316, 3786, 1498, 2833, 3765,  149, 1110, 3203,
        2279, 1918,   13, 1682])
Epoch: 1443, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1444 - Batch 1 ########################
IDs in batch 1: tensor([3870, 2098,  892, 3593, 3783, 1859,  387,  274, 2966,  785, 1287, 1656,
        3568,  959, 1536, 3494])
Epoch: 1444, Training Loss: 0.83, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1445 - Batch 1 ########################
IDs in batch 1: tensor([  14, 1904,  127, 1684, 3160, 3743, 1082,  218, 3267, 3006, 2120,  814,
         872, 3763, 1611,   95])
Epoch: 1445, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1446 - Batch 1 ########################
IDs in batch 1: tensor([2154, 1519, 1157, 3179, 2591, 2706, 2155, 3718,  471,    7,  325, 3073,
        3099, 1914,  203, 2642])
Epoch: 1446, Training Loss: 0.16, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1447 - Batch 1 ########################
IDs in batch 1: tensor([2046, 3663,  762,  555,  919,  491, 1156, 3367, 1485, 1883, 3252, 2815,
        4094, 3790, 2444, 3100])
Epoch: 1447, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1448 - Batch 1 ########################
IDs in batch 1: tensor([1795, 1179,  578, 3726,  327, 3721, 1434, 3360, 1963, 1104, 1575, 1935,
        4117, 1182, 3988, 1610])
Epoch: 1448, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1449 - Batch 1 ########################
IDs in batch 1: tensor([1625,  332, 2980, 3367, 3615, 3079, 2011, 2765,  127, 3353, 1883, 2017,
        1509, 2819, 4255, 1213])
Epoch: 1449, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1450 - Batch 1 ########################
IDs in batch 1: tensor([2385, 2937,  964, 3481, 2606, 2066, 4222, 3421, 1796, 4113, 1536,  413,
        2795,  316,  494,   77])
Epoch: 1450, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1451 - Batch 1 ########################
IDs in batch 1: tensor([2959,  683,  121,  726, 2652, 3244, 3101,  583, 3114, 1450, 1363, 1073,
         151, 2973, 2394, 3917])
Epoch: 1451, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1452 - Batch 1 ########################
IDs in batch 1: tensor([2099, 1249,  182,  417, 2359, 3753, 1627, 1413, 1286, 2109,  710,  363,
        3585,  128, 2030, 3821])
Epoch: 1452, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1453 - Batch 1 ########################
IDs in batch 1: tensor([3028, 1748,  218, 3886, 3695, 3885, 1294, 4176, 3829,  966,  399,  220,
        2125, 1264, 4222,  587])
Epoch: 1453, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1454 - Batch 1 ########################
IDs in batch 1: tensor([ 126, 3028, 1428,  992, 2369, 2011,  635,  275, 2262, 2537, 3499,  516,
         148,  470, 1639, 2737])
Epoch: 1454, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1455 - Batch 1 ########################
IDs in batch 1: tensor([3541, 1143,   86, 3961, 1835, 1661, 1755, 3177, 2724, 1540,  202,   49,
         541,  537, 2632, 2400])
Epoch: 1455, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1456 - Batch 1 ########################
IDs in batch 1: tensor([2529, 2104, 1242, 3757,  345,  434,  918,  821, 3503, 1291, 1793,   32,
        4235, 2856, 2363,  969])
Epoch: 1456, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1457 - Batch 1 ########################
IDs in batch 1: tensor([ 553,  818, 1125, 2419, 3309,  606, 3243,  154, 1062, 1032, 1706, 1360,
        3020,  190, 2800, 2641])
Epoch: 1457, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1458 - Batch 1 ########################
IDs in batch 1: tensor([1228,  256, 2863, 3027, 3115, 1956, 1421, 2306, 1232, 3474,  873, 4128,
        2942,  683, 2417, 2913])
Epoch: 1458, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1459 - Batch 1 ########################
IDs in batch 1: tensor([ 316, 3488, 1699,  609, 1897,  295, 1107, 2360,  733, 3023, 2398, 3581,
        3792, 1965, 1438, 3010])
Epoch: 1459, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1460 - Batch 1 ########################
IDs in batch 1: tensor([3395, 3233, 2902, 3367, 1063, 3564, 3005,  111, 4144, 2949, 1177, 2858,
        2932,  583, 3919, 1870])
Epoch: 1460, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1461 - Batch 1 ########################
IDs in batch 1: tensor([1444,  527, 1154, 2394, 3426, 2210, 3610, 2973,  841,  250,  359, 4258,
        1418, 1180, 2176, 3389])
Epoch: 1461, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1462 - Batch 1 ########################
IDs in batch 1: tensor([ 456, 3474, 1646, 2040, 2024,  365, 1643,  437, 1237, 1049, 3942, 1370,
        1573, 2015, 1066, 1961])
Epoch: 1462, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1463 - Batch 1 ########################
IDs in batch 1: tensor([1365, 1122, 3999, 1320,  821, 2352, 2431, 1132, 2172, 2065,  918, 1881,
        3810, 1932, 3252, 4166])
Epoch: 1463, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1464 - Batch 1 ########################
IDs in batch 1: tensor([1644, 1439,  644,  344,  679, 1588, 1107, 2087, 2995, 2217, 2314, 2624,
          34, 2642, 1562, 2823])
Epoch: 1464, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1465 - Batch 1 ########################
IDs in batch 1: tensor([4103, 1372, 1346, 2362, 1220, 2648, 3264, 1973, 4035, 2111, 3318, 1168,
        1011, 2641, 2858, 2829])
Epoch: 1465, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1466 - Batch 1 ########################
IDs in batch 1: tensor([2733, 3202, 2124, 3017, 3996, 1239, 2727, 2473, 2752, 4105, 1952, 4222,
        1153, 1123, 2429, 1285])
Epoch: 1466, Training Loss: 0.28, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1467 - Batch 1 ########################
IDs in batch 1: tensor([3366,  333, 2324, 3956, 4030, 2517, 2921,  568, 1548, 1782,  827, 3437,
        2681, 1684, 3030, 2090])
Epoch: 1467, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1468 - Batch 1 ########################
IDs in batch 1: tensor([ 778, 3821,  904, 3642,  342, 1841, 3271, 3826, 3699, 2644, 1617, 2019,
        2297, 3358, 3858, 1289])
Epoch: 1468, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1469 - Batch 1 ########################
IDs in batch 1: tensor([2110,  672,  602, 3459,  125, 1122, 1158, 3110,  863,  926, 3732, 1257,
         185, 1982,  518, 2849])
Epoch: 1469, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1470 - Batch 1 ########################
IDs in batch 1: tensor([1601, 2305, 1330,  607, 4188, 2876,  326,  681, 2110, 2405, 3028, 1344,
        1226,  943, 2183, 1746])
Epoch: 1470, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1471 - Batch 1 ########################
IDs in batch 1: tensor([1030,  136, 1451, 1051, 2599, 3216, 3487, 2355, 3472,  348, 2354, 3366,
        3996, 2008, 3092, 2898])
Epoch: 1471, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1472 - Batch 1 ########################
IDs in batch 1: tensor([4222, 1251, 3928, 2369, 1635, 1803,  130,  279,  287, 1635,  684, 3853,
         884, 3745, 2986, 2003])
Epoch: 1472, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1473 - Batch 1 ########################
IDs in batch 1: tensor([3543,  193, 1113, 3763, 3749, 1042,  538,   28,  693,  981, 2661, 2465,
        2436, 2582, 2802, 4235])
Epoch: 1473, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1474 - Batch 1 ########################
IDs in batch 1: tensor([3248, 1189,  995, 3985, 4097, 2113, 3022, 1793, 1204, 2586, 3220,  312,
        3235, 1752, 3886, 1156])
Epoch: 1474, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1475 - Batch 1 ########################
IDs in batch 1: tensor([1590,  714, 1605,  981, 1840, 1052, 2373, 2976, 3338, 1909,  994, 1558,
        3151,  391, 1826,  807])
Epoch: 1475, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1476 - Batch 1 ########################
IDs in batch 1: tensor([1107,  171,  358,   11, 2615, 2372, 3032,  295,  103, 4012, 3726, 3704,
        2035, 1555, 4039,  432])
Epoch: 1476, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1477 - Batch 1 ########################
IDs in batch 1: tensor([1229, 1391, 1044, 2301,  388, 2324, 3132, 3081,  471,  462,  555, 3609,
        3532, 1732, 3782,  986])
Epoch: 1477, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1478 - Batch 1 ########################
IDs in batch 1: tensor([1583, 1862,  870, 3997, 3930, 2002,  237, 1540,  391, 1670, 1984, 2614,
        3982, 3714, 4228, 3437])
Epoch: 1478, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1479 - Batch 1 ########################
IDs in batch 1: tensor([ 833, 3742, 1580,  533,  408, 4203,  315, 3763,  534, 1935,  378, 1004,
        4006, 2070, 2070,  488])
Epoch: 1479, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1480 - Batch 1 ########################
IDs in batch 1: tensor([ 487, 1221,  874, 3609,  245, 3836, 2103, 4039, 1038, 2584,  403, 1904,
        3501, 4138,  435, 4050])
Epoch: 1480, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1481 - Batch 1 ########################
IDs in batch 1: tensor([3608, 3065, 2403,  113,  463, 4124,   95, 2693, 3637, 3608, 3077, 3480,
        3838, 3692,  365, 2426])
Epoch: 1481, Training Loss: 0.49, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1482 - Batch 1 ########################
IDs in batch 1: tensor([3618, 1553,  212,  996,   43, 2912, 1543,  289, 3417,  921,  701,  689,
        3449, 2518, 4072, 2998])
Epoch: 1482, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1483 - Batch 1 ########################
IDs in batch 1: tensor([3452,  907,  572, 2278,  159, 1330,   62, 2355, 2629, 3932, 2746, 1185,
        1883, 1025, 1517,  202])
Epoch: 1483, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1484 - Batch 1 ########################
IDs in batch 1: tensor([1532, 1345, 2807, 2572, 4006, 1988, 1146, 1871, 3401, 2179,  444, 3183,
        3342, 3077,  419, 2031])
Epoch: 1484, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1485 - Batch 1 ########################
IDs in batch 1: tensor([ 149, 1413, 2363, 1346, 4205,  470, 4046, 2040, 4108, 2529, 2854, 3511,
        1086, 2568, 1214, 1308])
Epoch: 1485, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1486 - Batch 1 ########################
IDs in batch 1: tensor([ 693, 3467, 3345, 2064, 4086, 1754,  997,   81, 1001, 3344, 3962, 2976,
         552,   88, 3754, 3600])
Epoch: 1486, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1487 - Batch 1 ########################
IDs in batch 1: tensor([2582, 3410, 3077, 3604, 3176,  469, 1025,  228, 2553, 3542, 1059,    4,
        1120,  260, 3500, 4065])
Epoch: 1487, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1488 - Batch 1 ########################
IDs in batch 1: tensor([3692, 3997, 2274, 2489,  337, 2802,  377,  910, 4121, 4235,  813, 3656,
        3151, 2730, 2777,  794])
Epoch: 1488, Training Loss: 0.19, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1489 - Batch 1 ########################
IDs in batch 1: tensor([4234,  823, 3523, 2583, 2655,   15, 2072, 1736,  875, 2344, 2120,  825,
         573, 1841,  574,  368])
Epoch: 1489, Training Loss: 0.14, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1490 - Batch 1 ########################
IDs in batch 1: tensor([ 683, 4152, 3113, 2423, 2882,  574, 1161, 1869, 1511,  398, 2574, 1821,
         281, 4246, 3357,  982])
Epoch: 1490, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1491 - Batch 1 ########################
IDs in batch 1: tensor([3022, 3747, 3974, 3886,  403, 2764, 2119, 2874, 2154,  758,  657,  917,
        3002, 2196, 1649,  503])
Epoch: 1491, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1492 - Batch 1 ########################
IDs in batch 1: tensor([4077, 1063,  403,   39, 1857, 3514, 3558, 4195, 2540, 2385, 2689, 1562,
        3133, 2090, 1014, 3845])
Epoch: 1492, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1493 - Batch 1 ########################
IDs in batch 1: tensor([3501, 3014, 3797, 1274,  673, 4084,   18, 3368, 2053, 1684, 3404,  980,
        3717,  673,  871, 3115])
Epoch: 1493, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1494 - Batch 1 ########################
IDs in batch 1: tensor([3227, 2360, 2349, 2629, 2347, 3933, 3680,  552,  137, 3473, 3634,    5,
        3029,  532,  351, 1128])
Epoch: 1494, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1495 - Batch 1 ########################
IDs in batch 1: tensor([4099, 3415, 1027, 2141,  225,  280, 3598, 3652,   22, 1680,  913, 2558,
        3476, 4027, 3290,  874])
Epoch: 1495, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1496 - Batch 1 ########################
IDs in batch 1: tensor([2423, 4017, 1891, 1845, 2190, 2887, 2780, 2019,  902, 2196, 3435, 3219,
        2104, 2590, 4226, 2218])
Epoch: 1496, Training Loss: 1.15, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1497 - Batch 1 ########################
IDs in batch 1: tensor([  88, 4205, 2207, 1762, 2819, 3334, 1117, 2176, 2206, 1655, 1835, 2017,
        1326, 2539,  739,  505])
Epoch: 1497, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1498 - Batch 1 ########################
IDs in batch 1: tensor([ 775,  515,  997, 3698,  292, 1819,  290, 3283, 1665, 2932, 3749, 1004,
        1938, 3837, 4140, 3499])
Epoch: 1498, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1499 - Batch 1 ########################
IDs in batch 1: tensor([3366, 3078, 4267, 4057, 3897, 2835, 2980,  219,  283, 3069, 3956,  519,
        2535, 2574, 3757, 1645])
Epoch: 1499, Training Loss: 0.23, Validation Loss: 0.65, accuracy = 0.77
Save best Model_1 @ epoch 1499 acc: 0.7655334114888629
Email sent!
######################## Epoch 1500 - Batch 1 ########################
IDs in batch 1: tensor([1508,  412, 1174, 1020, 2010, 4084, 3554, 1161,  811, 2131,  866, 2025,
        1221, 1884,  572, 2763])
Epoch: 1500, Training Loss: 0.54, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1501 - Batch 1 ########################
IDs in batch 1: tensor([1118, 1143, 1882, 2480, 3105, 1257, 3925, 1878, 1786,  135, 1380, 1765,
        2687, 1239,  945,  878])
Epoch: 1501, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1502 - Batch 1 ########################
IDs in batch 1: tensor([3553, 3349, 2204, 2990, 3425,  602, 2127, 3928, 4180, 4158, 1174, 2290,
        3663,  432,  408, 3803])
Epoch: 1502, Training Loss: 0.36, Validation Loss: 0.66, accuracy = 0.77
Save best Model_1 @ epoch 1502 acc: 0.7667057444314185
Email sent!
######################## Epoch 1503 - Batch 1 ########################
IDs in batch 1: tensor([3102, 2171, 1397, 3286,  882, 3328, 2546, 2689, 3530, 3802,  977, 3554,
         661, 2209, 1613, 2867])
Epoch: 1503, Training Loss: 0.42, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1504 - Batch 1 ########################
IDs in batch 1: tensor([ 434, 2219, 3463, 2610, 2659, 4006, 3035, 2783, 3120, 2467, 3496, 3702,
        1548, 4101,  947, 3739])
Epoch: 1504, Training Loss: 0.60, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1505 - Batch 1 ########################
IDs in batch 1: tensor([1648, 1699,   88, 3417, 4025, 3226, 1183,  442, 4225, 1154, 3254,  833,
        2863, 3053, 3248, 3381])
Epoch: 1505, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1506 - Batch 1 ########################
IDs in batch 1: tensor([3813, 2977,  356,  558, 1189, 3314, 1900, 2120, 3235, 3188, 1469,  190,
        3597,  356,  203, 2372])
Epoch: 1506, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1507 - Batch 1 ########################
IDs in batch 1: tensor([2189, 3343,  170, 3367,  869,  547, 1225, 2462, 3381, 3443,  529, 1117,
        2119, 3746, 2782, 3326])
Epoch: 1507, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1508 - Batch 1 ########################
IDs in batch 1: tensor([1591,  172,  625, 3837, 3700, 3254, 1049, 3239, 1794, 3990,  710,  129,
        3948, 2038, 1361, 4065])
Epoch: 1508, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1509 - Batch 1 ########################
IDs in batch 1: tensor([3881,   22, 1193,  723, 1746,  516, 2947,  991, 3634, 3671, 1084, 2857,
        3384, 1266, 2860, 4026])
Epoch: 1509, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1510 - Batch 1 ########################
IDs in batch 1: tensor([ 395, 3503, 2688, 2606, 3888, 3037, 3253, 3544,  350, 2367, 2193, 4016,
         467, 2619, 4146,  100])
Epoch: 1510, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1511 - Batch 1 ########################
IDs in batch 1: tensor([2765, 1318, 3428,  778, 3434, 2559,  829, 2966, 1647,  843,   39, 2212,
        1635,  644, 2943,  214])
Epoch: 1511, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1512 - Batch 1 ########################
IDs in batch 1: tensor([1028, 1799, 1022, 2114,  211,  628, 3398, 2276, 2420, 1220,  462,  382,
        1556, 3983,  529,   64])
Epoch: 1512, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1513 - Batch 1 ########################
IDs in batch 1: tensor([3749, 2358, 2191,  964,  417,  183, 1945, 1787,   97, 1570, 1423, 2010,
           5, 3235, 2228,  846])
Epoch: 1513, Training Loss: 0.35, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1514 - Batch 1 ########################
IDs in batch 1: tensor([2362, 2546, 1313, 3418, 2624, 2954,  172, 3038, 1656,  333, 1896, 1349,
         475, 2977, 2304, 1136])
Epoch: 1514, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1515 - Batch 1 ########################
IDs in batch 1: tensor([2800,  880, 4126, 3688,  672, 1132, 1869, 2065, 1612, 1255, 2018, 3564,
        3244, 1459, 3704, 3194])
Epoch: 1515, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1516 - Batch 1 ########################
IDs in batch 1: tensor([2582,  989, 2116, 2358,  926, 2504,  684, 2696,  883, 3971,   38,  660,
        1223,  442, 3234, 1859])
Epoch: 1516, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1517 - Batch 1 ########################
IDs in batch 1: tensor([2538,  591, 2124,  266, 2070, 2572, 2046,  921, 3474, 1360, 1216, 1057,
         250,  435, 1161, 1975])
Epoch: 1517, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1518 - Batch 1 ########################
IDs in batch 1: tensor([ 426,  627,  667, 2284, 3314,  827, 2719, 3827, 3627, 2998, 1836, 2902,
        2899, 1745,  674, 2676])
Epoch: 1518, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1519 - Batch 1 ########################
IDs in batch 1: tensor([3932,   56, 2369, 1312, 3496, 4095, 1343, 1248,  356, 3017,  361, 2179,
         609,  691, 2605, 2804])
Epoch: 1519, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1520 - Batch 1 ########################
IDs in batch 1: tensor([ 563, 1075, 2064, 2913,  432,  263, 3142, 2571, 3222, 2419, 3160, 2224,
        3790, 3925,  164,  376])
Epoch: 1520, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1521 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 4195, 1485,  128, 3176, 3920, 2109,  627, 3226,  120,  462, 3983,
        3444,  834, 1591, 1499])
Epoch: 1521, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1522 - Batch 1 ########################
IDs in batch 1: tensor([1174,  779, 2314, 1751, 1284, 1724,  148, 3111, 1436, 3771,  229, 2841,
        3326,  281, 2298,  503])
Epoch: 1522, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1523 - Batch 1 ########################
IDs in batch 1: tensor([2638, 1795, 3321, 2287,  842, 3015,  701, 4024, 2890, 2615, 3636, 2003,
        1499, 3452, 1315, 2120])
Epoch: 1523, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1524 - Batch 1 ########################
IDs in batch 1: tensor([1390,  356,   14,  808, 3537, 1020, 1681, 1117, 3709, 1031, 3481, 3707,
        2382, 3378,  575, 1591])
Epoch: 1524, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1525 - Batch 1 ########################
IDs in batch 1: tensor([ 376, 2365, 4235, 3151, 3808, 1469, 3610,  129, 3956, 1937,  887, 2226,
        1236, 1532, 4205, 3087])
Epoch: 1525, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1526 - Batch 1 ########################
IDs in batch 1: tensor([4005, 3216,  683, 2342,  573, 2914, 2643, 2103, 1787,  337,  258, 2466,
        2831, 2883, 2258, 2212])
Epoch: 1526, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1527 - Batch 1 ########################
IDs in batch 1: tensor([2245, 3501,  842, 3423, 1273, 2577, 1745, 4154,  595, 1914, 1234, 1306,
        1566,  422, 1600, 2546])
Epoch: 1527, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1528 - Batch 1 ########################
IDs in batch 1: tensor([ 120, 3081, 3992, 4022, 4008, 1204, 4058, 2954, 2166,  604, 3179,   28,
         767, 2614,  444, 2398])
Epoch: 1528, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1529 - Batch 1 ########################
IDs in batch 1: tensor([4035, 3693, 3545, 1896,  356, 3533,  251,  541, 2807, 3947, 1624, 3836,
        1056, 4127, 2832,  278])
Epoch: 1529, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1530 - Batch 1 ########################
IDs in batch 1: tensor([1956, 3378, 1292, 2725, 1186, 1302, 3168,  866, 3875, 2236, 1526, 2004,
        3435, 1107, 3900,  874])
Epoch: 1530, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1531 - Batch 1 ########################
IDs in batch 1: tensor([1841, 4046, 2838, 1004, 2231,  547, 2390, 1286, 3751, 1026,  846, 2116,
        2371, 1443, 1648, 1102])
Epoch: 1531, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1532 - Batch 1 ########################
IDs in batch 1: tensor([ 550,  135,  487,  858, 2324, 3587, 2405, 4114,  303, 2905, 2190, 3549,
        2837, 4143,  434, 2891])
Epoch: 1532, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1533 - Batch 1 ########################
IDs in batch 1: tensor([1316, 1624, 1763, 2332, 4186, 3299, 3539, 3964, 1373, 1990, 3504, 3318,
         642,   52, 2254, 2925])
Epoch: 1533, Training Loss: 0.54, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1534 - Batch 1 ########################
IDs in batch 1: tensor([2970, 3121, 1393, 2487,  803, 2408, 1968, 2387,  355,  713, 1195, 2494,
        2025, 3437,  682,  134])
Epoch: 1534, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1535 - Batch 1 ########################
IDs in batch 1: tensor([2180, 1380,  403, 2379, 1344,  771, 2142, 1902, 1901,  670, 2322, 2282,
        2394, 3702, 3843, 1267])
Epoch: 1535, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1536 - Batch 1 ########################
IDs in batch 1: tensor([2041, 1976,   61, 2137, 2144,   50,  340, 1463,  586, 1128, 1754, 1482,
        2372, 3860,  966, 3995])
Epoch: 1536, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1537 - Batch 1 ########################
IDs in batch 1: tensor([ 914,  255, 1448, 2743, 1844, 2737, 2377,  417,  203, 1247, 1171, 3977,
        3886, 1681, 3245,  450])
Epoch: 1537, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1538 - Batch 1 ########################
IDs in batch 1: tensor([2413,  628,  356, 1892, 1279, 3223, 3035, 1628, 1765, 4213,  996, 3982,
        2798,  527, 1425, 2840])
Epoch: 1538, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1539 - Batch 1 ########################
IDs in batch 1: tensor([1660, 3333, 4195,  909, 3771,   59, 4055,  195, 1563, 3298, 4088, 3783,
        3399,  516, 3259, 1548])
Epoch: 1539, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1540 - Batch 1 ########################
IDs in batch 1: tensor([2391, 3803, 3945,  395, 4015, 4022, 3377,  265,  854, 2891, 4120, 1419,
        2509,  672, 1093,  391])
Epoch: 1540, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1541 - Batch 1 ########################
IDs in batch 1: tensor([ 147,  352, 1892, 3458, 1886, 2476, 1116, 2146, 2945, 2523, 2143, 1035,
        1141,  738, 4100, 2986])
Epoch: 1541, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1542 - Batch 1 ########################
IDs in batch 1: tensor([ 603,  823,  909, 1570, 1070, 2125, 2730, 3000, 2832,  515, 1760, 3330,
        3227, 1923, 3334, 3656])
Epoch: 1542, Training Loss: 0.18, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1543 - Batch 1 ########################
IDs in batch 1: tensor([2016, 3114, 3458,  926,  474, 3339, 1156, 3102, 3245, 3765, 3121, 3177,
        2045,  729, 1799,  239])
Epoch: 1543, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1544 - Batch 1 ########################
IDs in batch 1: tensor([ 342,  858,  132,  604, 2897, 3408,  129, 2555, 2172, 1808,  807, 3190,
        1365,  112,  518, 3466])
Epoch: 1544, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1545 - Batch 1 ########################
IDs in batch 1: tensor([1309, 2423, 3392, 4134, 1642, 2908, 1953, 3389, 2357, 1568, 1349, 3563,
        1485, 3688, 1331, 1962])
Epoch: 1545, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1546 - Batch 1 ########################
IDs in batch 1: tensor([1445, 3023, 3429,  786,  478,  451, 3330,  217, 1081, 1136, 1642, 3536,
        3514, 3142, 1083, 3706])
Epoch: 1546, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1547 - Batch 1 ########################
IDs in batch 1: tensor([2590, 2317, 4196, 1453, 3699, 3238, 2317, 3185, 3671, 1470, 2088, 1755,
         852, 2510, 4084, 4188])
Epoch: 1547, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1548 - Batch 1 ########################
IDs in batch 1: tensor([2236, 3035, 3144, 3545, 1661, 3501, 2074, 3961, 1752, 3549, 2539, 3808,
         284, 2998, 3557, 2425])
Epoch: 1548, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1549 - Batch 1 ########################
IDs in batch 1: tensor([ 217,  878, 3389, 1592, 2561, 2382,  494, 3408,  277, 1223, 2645,  689,
        1945, 1102, 4172,   30])
Epoch: 1549, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1550 - Batch 1 ########################
IDs in batch 1: tensor([2666, 1808, 4134, 3513, 1137,  244,  513, 2028,  159, 1526,  956, 2145,
        1035, 2457, 1958,  858])
Epoch: 1550, Training Loss: 0.16, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1551 - Batch 1 ########################
IDs in batch 1: tensor([3177, 3919, 2262, 2316, 4035,   59, 1957, 3712, 2127, 2776, 2116,  136,
        1784,   81, 1558, 1498])
Epoch: 1551, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1552 - Batch 1 ########################
IDs in batch 1: tensor([1670, 3276, 3503,  454, 3381, 2337,  448,  436,  829,  482, 2572, 2498,
        3317, 3110, 4240, 2604])
Epoch: 1552, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1553 - Batch 1 ########################
IDs in batch 1: tensor([1140, 3935, 1445,  679, 3355, 3833, 3452,  405, 3693,  736, 3128, 2718,
        2682, 1050, 1784, 3441])
Epoch: 1553, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1554 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 3251, 2689,  930, 1050, 2052, 3083, 1493,  259, 3878, 3949, 2356,
        1122,  154, 1963, 1794])
Epoch: 1554, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1555 - Batch 1 ########################
IDs in batch 1: tensor([   5,  689,  150, 1699, 3183, 2825,  438, 2198,   13, 1089, 1736, 1976,
        1740, 3712,  882, 2738])
Epoch: 1555, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1556 - Batch 1 ########################
IDs in batch 1: tensor([ 282, 1795, 3336,  832,  247, 2238, 4012,  595, 2314, 2453, 1311, 1793,
        2024, 2213,  289, 1678])
Epoch: 1556, Training Loss: 0.19, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1557 - Batch 1 ########################
IDs in batch 1: tensor([2871, 1648, 1459, 2487, 3199,  809,  952, 1540,  498, 3401, 1292, 2789,
         941,  852, 2642, 3337])
Epoch: 1557, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1558 - Batch 1 ########################
IDs in batch 1: tensor([2435, 4003, 2073, 4097, 2980, 1478, 3842,  689, 2521, 2403, 2587, 3425,
        3948, 4110, 1160,  928])
Epoch: 1558, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1559 - Batch 1 ########################
IDs in batch 1: tensor([3357, 2217,  312, 3489, 3407, 2751, 2039, 3241, 3493, 4044, 3040, 1067,
        2322, 1733,  808, 1698])
Epoch: 1559, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1560 - Batch 1 ########################
IDs in batch 1: tensor([3642, 1123, 2692, 3913, 3469,  741,  678, 2559, 3132, 3094,  375, 1737,
        2119, 3330, 3334, 1370])
Epoch: 1560, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1561 - Batch 1 ########################
IDs in batch 1: tensor([2821, 3439, 1448, 1811, 4119, 1673, 2425, 2660, 3234, 3154, 3553, 3980,
         572,  825, 1026, 2563])
Epoch: 1561, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1562 - Batch 1 ########################
IDs in batch 1: tensor([4072,  723, 2469,  277, 1443, 1842, 2938, 2739, 3928, 2974,  670, 1131,
        1736,  201,  751, 1057])
Epoch: 1562, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1563 - Batch 1 ########################
IDs in batch 1: tensor([  47, 3410,  284, 2376, 2606, 3127, 2500, 3513, 3228, 1315, 3042, 2575,
        3594, 1459, 1918, 2276])
Epoch: 1563, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1564 - Batch 1 ########################
IDs in batch 1: tensor([1803, 4133, 3023, 3624, 4107,  997, 3615, 3472, 3570, 2265, 1173, 3065,
        1752, 1213, 3845, 3757])
Epoch: 1564, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1565 - Batch 1 ########################
IDs in batch 1: tensor([3151, 1832, 1090,  122,  964, 1897,  899,  684,  811, 3436, 1020, 2897,
        3343, 2428, 3738, 3378])
Epoch: 1565, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1566 - Batch 1 ########################
IDs in batch 1: tensor([ 833, 2771, 1638, 2516, 2203, 2292, 3466, 1882, 3695, 3042,   96, 2327,
         522, 3947, 1163, 1651])
Epoch: 1566, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1567 - Batch 1 ########################
IDs in batch 1: tensor([2529, 1213,  103,  155, 2419, 1740, 1575, 2181, 3372,  811, 1956,  909,
         850, 1313,  465, 1770])
Epoch: 1567, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1568 - Batch 1 ########################
IDs in batch 1: tensor([2873, 1891,  881, 2600, 1760,  944,   72, 3244, 3707, 3449,  132, 3813,
        1103, 1365, 3680, 2772])
Epoch: 1568, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1569 - Batch 1 ########################
IDs in batch 1: tensor([1704, 3503,  450, 2172, 1325, 2031, 3873,  325, 2225, 4222, 1639,  531,
        3060, 2431, 4212, 2565])
Epoch: 1569, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1570 - Batch 1 ########################
IDs in batch 1: tensor([1042, 3853, 3671, 3267, 2142, 1796, 4163, 3728, 1777, 2824, 3607, 1334,
        3894, 3075, 1044, 3939])
Epoch: 1570, Training Loss: 0.46, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1571 - Batch 1 ########################
IDs in batch 1: tensor([1092, 4134,  465, 1005, 2146, 1853, 3146, 4179, 3309, 2529, 3386,   34,
         986, 4214, 3738, 3139])
Epoch: 1571, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1572 - Batch 1 ########################
IDs in batch 1: tensor([3418, 2202, 2521, 1437, 1537, 3677, 2286, 3693, 4128, 3717, 3032, 1162,
         824, 3439, 1026, 3746])
Epoch: 1572, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1573 - Batch 1 ########################
IDs in batch 1: tensor([4174, 3369, 2949, 3529, 2497,  541, 1469, 3914,  303, 3217, 4105, 3911,
        3455,  964, 2870, 2127])
Epoch: 1573, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1574 - Batch 1 ########################
IDs in batch 1: tensor([3985, 2690, 1826, 3940, 2697, 3803, 1409,  484, 1051, 3911,    5, 1779,
        3591, 3802,  774,  862])
Epoch: 1574, Training Loss: 0.60, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1575 - Batch 1 ########################
IDs in batch 1: tensor([3448, 1746, 1085, 2372, 1270, 4222, 1024,  937, 1390, 3734, 2517, 2655,
        2565, 3962, 1096, 3769])
Epoch: 1575, Training Loss: 0.39, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1576 - Batch 1 ########################
IDs in batch 1: tensor([ 532, 1081, 4057, 2419, 3370,  465, 3248, 2945,   64, 4017, 2577, 1869,
        1900, 1439,  843, 2925])
Epoch: 1576, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1577 - Batch 1 ########################
IDs in batch 1: tensor([3509, 2292, 4242, 3053, 1222, 1897, 1751,  937, 1868,  287,  472, 1954,
        2610,   57,   71, 1402])
Epoch: 1577, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1578 - Batch 1 ########################
IDs in batch 1: tensor([3733, 2437, 1965, 4117, 3798, 2706, 2431, 2734,  970, 3373, 1789,  334,
        1811, 3494, 2805, 1620])
Epoch: 1578, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1579 - Batch 1 ########################
IDs in batch 1: tensor([1901, 2244, 3333, 2795, 2793, 3738,  450, 2425, 4017, 4053, 3009, 2996,
          13, 3105,   71,   50])
Epoch: 1579, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1580 - Batch 1 ########################
IDs in batch 1: tensor([3455, 2649, 1051, 1732,  533, 1028, 1055, 1206, 2638, 2721,  373, 1328,
        1047, 4225, 2748, 2050])
Epoch: 1580, Training Loss: 0.33, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1581 - Batch 1 ########################
IDs in batch 1: tensor([ 978, 4204, 2855, 3843,  895, 2991,  812, 3925,  193,  376, 2521, 1764,
        2855, 1878, 3349, 3374])
Epoch: 1581, Training Loss: 0.44, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1582 - Batch 1 ########################
IDs in batch 1: tensor([ 377,  770, 3099,  356, 4005, 3257,  870,  437, 2711, 1130, 2712,  234,
        1264, 3496, 1624, 3829])
Epoch: 1582, Training Loss: 0.53, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1583 - Batch 1 ########################
IDs in batch 1: tensor([3954, 1634,  850,  812, 1746, 2290, 2149, 3980,  517, 3534, 3446, 3187,
        2823, 2015, 2810,  753])
Epoch: 1583, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1584 - Batch 1 ########################
IDs in batch 1: tensor([3592, 3827, 3124, 3271,  303, 3181, 1277, 3769,  736, 1651,  519, 1006,
        3650, 3841, 3956, 3470])
Epoch: 1584, Training Loss: 0.57, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1585 - Batch 1 ########################
IDs in batch 1: tensor([1443, 2271, 2470, 3755, 1871, 2739, 2410, 1161, 3740, 3660,  947, 3647,
        3783, 1228, 2065,  796])
Epoch: 1585, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1586 - Batch 1 ########################
IDs in batch 1: tensor([2155, 1270, 1434, 4261, 1035, 1381,  472, 3940, 1624, 1031, 1579,  113,
         427, 3384,  982, 3470])
Epoch: 1586, Training Loss: 0.59, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1587 - Batch 1 ########################
IDs in batch 1: tensor([ 983, 1120, 1896, 3427, 2080, 2189, 2839, 3374, 2581, 2306, 1512, 1266,
        1849, 1474,  870, 3357])
Epoch: 1587, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1588 - Batch 1 ########################
IDs in batch 1: tensor([ 871, 1276, 3654, 3299, 1390, 3489, 1708,  870, 3588, 3440, 4044, 1532,
        4118, 2601, 2441,  496])
Epoch: 1588, Training Loss: 0.31, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1589 - Batch 1 ########################
IDs in batch 1: tensor([3511, 3250, 2802, 3124, 4099, 1592, 2845, 1360, 3968,  165, 2719, 4097,
         627, 3983, 2317, 1322])
Epoch: 1589, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1590 - Batch 1 ########################
IDs in batch 1: tensor([1450, 1027, 1346,  797, 1918, 4062, 2548, 3816, 1693, 3073,  323, 2403,
        3790, 3728, 2278, 2476])
Epoch: 1590, Training Loss: 0.62, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1591 - Batch 1 ########################
IDs in batch 1: tensor([4049,  993, 1511, 1104, 2470, 2212, 3876,  437, 3935,  767, 4046, 1882,
        3764, 3558,  532, 3318])
Epoch: 1591, Training Loss: 0.45, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1592 - Batch 1 ########################
IDs in batch 1: tensor([4080,  333, 3549, 3317, 2754, 3991, 2028, 1932, 2993, 1123, 1818, 4222,
        1218, 1495,  852,  393])
Epoch: 1592, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1593 - Batch 1 ########################
IDs in batch 1: tensor([3894, 4056, 1315, 3424, 1168, 1189, 2856, 2176, 1825,  544, 3139, 2680,
         292,  615, 1746, 3793])
Epoch: 1593, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1594 - Batch 1 ########################
IDs in batch 1: tensor([ 390,  177, 3286, 2943,  676, 2375, 1084, 3102, 1887, 4038, 3991, 2448,
        1448, 4075, 3891,  278])
Epoch: 1594, Training Loss: 0.58, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1595 - Batch 1 ########################
IDs in batch 1: tensor([ 257,   99, 3896, 4136, 1840,  436, 2341, 1397, 1933, 1497, 1216, 3071,
         835, 3443, 2670, 2431])
Epoch: 1595, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 1596 - Batch 1 ########################
IDs in batch 1: tensor([3317, 2745,  578,  274, 4003, 2931,  322, 2324,  359, 3751, 1356,   99,
        2423, 3715, 3460,  691])
Epoch: 1596, Training Loss: 0.41, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1597 - Batch 1 ########################
IDs in batch 1: tensor([2028,  807, 3604, 1545, 4156, 1319, 4263, 1332, 2579, 2464, 4266,  994,
        1823, 3695, 4152, 4005])
Epoch: 1597, Training Loss: 0.73, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1598 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 2402, 2009, 1668, 4014,  657, 3757,  964, 2748, 3176, 1605, 3214,
        3284, 3509, 3738, 3531])
Epoch: 1598, Training Loss: 0.44, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1599 - Batch 1 ########################
IDs in batch 1: tensor([3655, 3913, 3459,  841, 3865, 2040, 3947, 1779, 1295, 1310, 1161, 2473,
        4006, 3452, 1360, 2682])
Epoch: 1599, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1600 - Batch 1 ########################
IDs in batch 1: tensor([2882,   34, 1141, 2514,  893, 1733, 2255,  232, 1406,  340,  926, 1961,
         494, 1011, 3738,  202])
Epoch: 1600, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1601 - Batch 1 ########################
IDs in batch 1: tensor([1336, 1294, 1808, 1190,  497, 1418, 1051, 2484, 1677, 3681, 1414, 3669,
        1643,  255,  160, 3494])
Epoch: 1601, Training Loss: 0.59, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1602 - Batch 1 ########################
IDs in batch 1: tensor([3982, 1952, 2539, 1937, 1292,  632, 3871, 3381, 2236, 1685, 2359, 3836,
        2664,  991, 4212, 3698])
Epoch: 1602, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1603 - Batch 1 ########################
IDs in batch 1: tensor([2237, 2329,  122, 4018,  488, 1828, 1384, 3896,  194,  983, 3756, 3695,
        3808, 2278,  418,  965])
Epoch: 1603, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1604 - Batch 1 ########################
IDs in batch 1: tensor([1933, 4214, 2477, 4168, 1920, 1555,  636,  834, 3084, 3250, 2271, 3484,
        3370, 1965,  263, 1183])
Epoch: 1604, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1605 - Batch 1 ########################
IDs in batch 1: tensor([ 280,  756, 3040,  673, 1011, 1835, 2155, 1772, 1710,   68,  173, 1182,
         103, 3016, 2220, 2995])
Epoch: 1605, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1606 - Batch 1 ########################
IDs in batch 1: tensor([3786, 1084, 2086, 1810, 1944, 3996, 3558, 1113,  220, 2224, 1938, 2724,
        1410,  316, 1555, 1624])
Epoch: 1606, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1607 - Batch 1 ########################
IDs in batch 1: tensor([ 352, 3644, 2947, 2897, 1285, 1707,  482, 1841, 3726, 2926, 2841, 3326,
        4156,  397, 3342, 3592])
Epoch: 1607, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1608 - Batch 1 ########################
IDs in batch 1: tensor([ 424, 3124, 2291, 2618,  821, 2244,  890, 3177, 1364, 1266,  152,  956,
         781, 1320, 3847, 1255])
Epoch: 1608, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1609 - Batch 1 ########################
IDs in batch 1: tensor([ 884,  678,  788,  848, 2458, 1988, 4075, 2080,  147, 2934,  992, 4131,
        2019, 1274, 3588, 2257])
Epoch: 1609, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1610 - Batch 1 ########################
IDs in batch 1: tensor([2546, 4060, 2228, 3953, 1853, 1736, 3521, 3313, 1491, 1754, 4005, 1881,
        2328, 1278,  507,   28])
Epoch: 1610, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1611 - Batch 1 ########################
IDs in batch 1: tensor([1059, 1381,  516, 1196, 4037,  595, 3291, 2378, 1488, 3531,  341, 1698,
        1216,  102, 1555,  316])
Epoch: 1611, Training Loss: 0.45, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1612 - Batch 1 ########################
IDs in batch 1: tensor([ 391,  226,  508,  964, 2731,  181, 1840, 2767, 3604, 3472,  729, 3532,
        3087, 2281, 2245, 2342])
Epoch: 1612, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1613 - Batch 1 ########################
IDs in batch 1: tensor([3772, 1643, 1252, 2587, 1030,   96, 1625, 2144, 3934, 2030, 3516, 3734,
         841, 1375,  398, 1508])
Epoch: 1613, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1614 - Batch 1 ########################
IDs in batch 1: tensor([3836, 1481, 3982, 3245, 3637, 1223,   64, 3709, 1351, 1649,  454, 4110,
        2919,  894, 1025, 2120])
Epoch: 1614, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1615 - Batch 1 ########################
IDs in batch 1: tensor([3897, 3216, 2879, 1016,  314,  527, 2169, 1860,  138, 2182,  324, 1077,
         591, 1160, 3597, 2013])
Epoch: 1615, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1616 - Batch 1 ########################
IDs in batch 1: tensor([3658, 2885, 2143, 2360,   26, 3340, 4097, 1450, 1611, 2841, 3996, 3072,
        2018, 1975,    4,  266])
Epoch: 1616, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1617 - Batch 1 ########################
IDs in batch 1: tensor([ 269, 3309, 1242,  259, 3373, 2102, 3118, 2697, 1035,  125, 3113, 1985,
        2672, 3597, 3300,  100])
Epoch: 1617, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1618 - Batch 1 ########################
IDs in batch 1: tensor([1291, 2844,  832,  779,  553, 2391, 1478, 1417, 3278,  593, 1257, 3469,
         730, 1613, 2469, 1942])
Epoch: 1618, Training Loss: 0.36, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1619 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 2202,  902, 2876, 1097, 3974,   61, 1228, 3222, 3441,  134, 1107,
        3740, 2085, 3486, 3594])
Epoch: 1619, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1620 - Batch 1 ########################
IDs in batch 1: tensor([1204, 1311, 3509,  251, 1072, 3485, 1879, 4068,  991, 1812,  578,  945,
        2535, 1822,  595, 4127])
Epoch: 1620, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1621 - Batch 1 ########################
IDs in batch 1: tensor([4203, 2344, 2329, 3547,  239, 1085, 1086, 1365, 2624, 2069, 3098,   72,
          88, 3395,  550, 4046])
Epoch: 1621, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1622 - Batch 1 ########################
IDs in batch 1: tensor([  97, 2464, 3507, 1956, 4013, 1258, 1356, 1767,  667, 3384, 1698, 1937,
        2459, 3176, 3204, 3182])
Epoch: 1622, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1623 - Batch 1 ########################
IDs in batch 1: tensor([1084,  553,  941, 3244, 3417, 2180, 3757,  881, 2839, 1069, 2824,  520,
        3538, 4110, 2942, 2964])
Epoch: 1623, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1624 - Batch 1 ########################
IDs in batch 1: tensor([2847, 4240, 3589, 1294, 3384, 2760, 3220, 2312, 3401, 1405,  117, 3583,
        3860, 3851, 2286,  832])
Epoch: 1624, Training Loss: 0.58, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1625 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 2223,  181, 4030, 4039, 1896, 3524, 1650,  425, 1405, 2431, 1678,
        1110, 4080, 2953, 2518])
Epoch: 1625, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 1626 - Batch 1 ########################
IDs in batch 1: tensor([ 218, 2304, 2478, 1976, 1093, 2784, 1767, 1170, 1011, 3972,  718,  277,
        2171,  397, 2075, 4046])
Epoch: 1626, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1627 - Batch 1 ########################
IDs in batch 1: tensor([1937, 3597,  194,   72, 2285, 2874, 1345,  620, 3972, 2733, 2073,  870,
        2670,  881, 3303, 2640])
Epoch: 1627, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1628 - Batch 1 ########################
IDs in batch 1: tensor([3366,  779, 3591, 2940, 3032, 2075, 2250, 1340,  281, 4224, 1330, 2299,
         739,  138, 3227, 4242])
Epoch: 1628, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1629 - Batch 1 ########################
IDs in batch 1: tensor([3526, 3036,   81,  346,  180, 3499,  893,  838,  820, 1781, 2249, 3524,
        1796, 2117,  466, 1600])
Epoch: 1629, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1630 - Batch 1 ########################
IDs in batch 1: tensor([2314,  685, 2518,  789, 3650, 3447, 2237,  284, 2905,  396,   10,  437,
        2238, 2010, 1290, 1219])
Epoch: 1630, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1631 - Batch 1 ########################
IDs in batch 1: tensor([1537, 3975, 3705, 3960, 1498, 2271, 3553, 3010, 2090, 3882, 1082, 1817,
        3132, 1812, 1668, 3582])
Epoch: 1631, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1632 - Batch 1 ########################
IDs in batch 1: tensor([ 471, 1977,  631,   85,   78,  225, 4126, 2444,  653, 2212, 3998,  816,
        1751, 2568, 2506, 4187])
Epoch: 1632, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1633 - Batch 1 ########################
IDs in batch 1: tensor([2008, 3648, 3057, 2526, 2564,  403,  378, 1450, 3693, 1685,  583, 1949,
        1937, 3841,  238, 2035])
Epoch: 1633, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1634 - Batch 1 ########################
IDs in batch 1: tensor([2274,  193, 1676,  852, 4026, 2552, 3428,  910, 1292,  797, 3024, 3875,
        1049, 2457, 1834, 2106])
Epoch: 1634, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1635 - Batch 1 ########################
IDs in batch 1: tensor([2610, 2837, 2982, 1485, 1001, 2806, 1241,  477, 3154, 2106, 3745, 2109,
        3949,  492, 1369, 1712])
Epoch: 1635, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1636 - Batch 1 ########################
IDs in batch 1: tensor([3010,  796, 2356, 4040,  522,  848, 2170,  120,  827,  738, 2974, 1361,
        4220,  833, 2254, 2343])
Epoch: 1636, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1637 - Batch 1 ########################
IDs in batch 1: tensor([ 306,  544, 2754, 1189, 3563, 2927, 1798, 1308, 1055,  977, 1592, 3217,
        3404, 3055, 3783, 1770])
Epoch: 1637, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1638 - Batch 1 ########################
IDs in batch 1: tensor([2051, 2261, 3815, 1540, 4258, 3115, 2339, 4010,  212, 1224, 4095,  201,
        1050, 3499, 3547,   13])
Epoch: 1638, Training Loss: 0.31, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1639 - Batch 1 ########################
IDs in batch 1: tensor([2275, 1404, 2354, 1086, 2627, 2692, 2925,  541, 3581, 2572, 3603, 3743,
        1099,  520, 2413, 3372])
Epoch: 1639, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 1640 - Batch 1 ########################
IDs in batch 1: tensor([4254, 1656,   72, 1012, 3115, 2650,   85, 1562, 1599, 2342, 1895,  173,
        3785, 3304, 2159,   20])
Epoch: 1640, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 1641 - Batch 1 ########################
IDs in batch 1: tensor([1052,  279, 3318,  670,  277, 1125, 1250,  893, 4024, 2479, 3591,  676,
         646,  371, 2821, 2416])
Epoch: 1641, Training Loss: 0.44, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 1642 - Batch 1 ########################
IDs in batch 1: tensor([3211, 3326,  733, 1956, 2452, 1290, 3310,  957, 3675, 3501, 3425,  918,
        3421, 3783,  523, 2824])
Epoch: 1642, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1643 - Batch 1 ########################
IDs in batch 1: tensor([3489, 1597, 2030, 1566, 3255,  306,  965, 1802, 2049,  236,  985, 2123,
         874, 3029, 1614, 3256])
Epoch: 1643, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1644 - Batch 1 ########################
IDs in batch 1: tensor([4126, 1954, 2095, 3194, 4069, 1297,  658, 1287, 1054,  913, 2245, 3521,
        4007, 1055,  138, 2249])
Epoch: 1644, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1645 - Batch 1 ########################
IDs in batch 1: tensor([4159, 2894,  880, 3409,  983, 3659, 1782, 1389, 3958,  365, 3355, 1190,
        3132,  572, 1489, 1967])
Epoch: 1645, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1646 - Batch 1 ########################
IDs in batch 1: tensor([2009, 2680, 2584, 3698,  828, 1325, 3527, 1007, 2135, 3394, 4235, 2578,
        2224, 1497, 1437, 3797])
Epoch: 1646, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1647 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 3534, 1178, 1895, 1678,  234, 2394, 1332,  131, 3850,  797,  237,
        2561, 1328, 1088, 1318])
Epoch: 1647, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1648 - Batch 1 ########################
IDs in batch 1: tensor([3549, 2701, 1222, 1039,  996, 3065, 1826,  804, 3505, 1003, 3511,  396,
         936, 2579,  327, 1716])
Epoch: 1648, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1649 - Batch 1 ########################
IDs in batch 1: tensor([4168, 2854, 1428,  825, 3387, 4058, 2936, 2616, 1209, 3373,  767,  121,
        1632, 2708,   26, 1270])
Epoch: 1649, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1650 - Batch 1 ########################
IDs in batch 1: tensor([2423, 2670, 1612, 4236, 2135,  207, 1574, 1877, 3392, 4127, 1290, 1195,
        1668,  751, 3513,    5])
Epoch: 1650, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1651 - Batch 1 ########################
IDs in batch 1: tensor([2708,  405, 3017, 1562, 2447, 1297, 2914,  789, 3290, 2545, 2890, 1556,
        3514, 3467, 2444, 4156])
Epoch: 1651, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1652 - Batch 1 ########################
IDs in batch 1: tensor([1389, 1526,  172, 2497,  148, 2908, 3943, 3006, 1087, 3693,  250, 3314,
        2235, 2743,  411, 3428])
Epoch: 1652, Training Loss: 0.12, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1653 - Batch 1 ########################
IDs in batch 1: tensor([ 678, 3467, 2976, 1343, 2367, 4049,  794, 3541,  411, 1004, 1290, 2883,
        2159, 1882, 2795, 1076])
Epoch: 1653, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1654 - Batch 1 ########################
IDs in batch 1: tensor([  51, 1484, 1802, 1799, 1367, 1877, 1900,  283, 4220, 1155,  125, 2209,
        1967, 3534, 3717,   51])
Epoch: 1654, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1655 - Batch 1 ########################
IDs in batch 1: tensor([ 184, 1201,  211, 1316, 2322,  575, 3139,  693, 2479, 1500,  490, 1396,
        1315, 3731,  193, 2075])
Epoch: 1655, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1656 - Batch 1 ########################
IDs in batch 1: tensor([1822, 1233, 3582, 2477, 3488, 2234,  305, 3886, 4135, 3356, 3573, 2102,
        1480, 2899, 1231, 2450])
Epoch: 1656, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1657 - Batch 1 ########################
IDs in batch 1: tensor([3953, 2758, 1960,  183,  653, 2185, 3823,  255, 3192,  103, 1670, 2577,
          31, 4139, 2995, 4077])
Epoch: 1657, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1658 - Batch 1 ########################
IDs in batch 1: tensor([3352,  346, 2696, 3495,  659, 1236, 1239, 2989, 3025, 3481,  275, 3035,
         661, 3330, 3830, 3503])
Epoch: 1658, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1659 - Batch 1 ########################
IDs in batch 1: tensor([4119, 1355,  391,  724,  778, 1901, 2616, 3151,  382, 2414, 1141,  676,
        4031, 2695, 1116, 1766])
Epoch: 1659, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1660 - Batch 1 ########################
IDs in batch 1: tensor([ 844, 4005, 2039, 1256, 2210, 3644,  180, 1495, 2075,  195, 3327, 1782,
        3028, 3717, 1950, 2789])
Epoch: 1660, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1661 - Batch 1 ########################
IDs in batch 1: tensor([3415, 3000, 2476, 1901, 1197, 3781,  236, 2615, 2450,  283,  407, 2938,
         864, 3711, 1879, 2659])
Epoch: 1661, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1662 - Batch 1 ########################
IDs in batch 1: tensor([2815, 1910, 3943, 2373, 3427,  632, 1258, 2439,  674, 3328, 3490, 2516,
        1724,  503, 2649,  775])
Epoch: 1662, Training Loss: 0.16, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1663 - Batch 1 ########################
IDs in batch 1: tensor([ 687, 2476, 1493, 3251, 1414, 3421, 2264, 3757, 2693, 1276, 3668, 1090,
         498,  872, 2984, 2882])
Epoch: 1663, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1664 - Batch 1 ########################
IDs in batch 1: tensor([2086, 2320, 2799, 4245, 2681,  661,  833, 3345, 2026, 1421,  682, 3399,
        2113,  888,   44, 1973])
Epoch: 1664, Training Loss: 0.18, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1665 - Batch 1 ########################
IDs in batch 1: tensor([1733, 1022, 2574, 3742,  970, 1548, 3394, 2825, 3841, 2228, 2349, 3357,
         895, 2365, 1870, 1677])
Epoch: 1665, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1666 - Batch 1 ########################
IDs in batch 1: tensor([3440, 2599, 1604,  160, 1273, 3933, 1894, 3927, 2134, 3394,  910, 2674,
         439, 3270, 2763, 4062])
Epoch: 1666, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1667 - Batch 1 ########################
IDs in batch 1: tensor([2356,  934,  750, 3905, 3911, 2414,  425, 1748, 1055, 3321, 2172,   99,
        3747, 2448,  334, 1291])
Epoch: 1667, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1668 - Batch 1 ########################
IDs in batch 1: tensor([1454,  709,  855, 3300, 1592, 4198, 1794, 1233, 3992, 1761,  819, 1183,
         632, 1611, 3368, 3029])
Epoch: 1668, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1669 - Batch 1 ########################
IDs in batch 1: tensor([2108, 3975, 2960, 1502,  957, 3963, 2207,  252, 2945, 4068, 3713,  471,
        3489,  773, 1153, 2245])
Epoch: 1669, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1670 - Batch 1 ########################
IDs in batch 1: tensor([ 652,  203, 3009, 1617, 3188, 3570, 2066, 2038, 4136, 2355, 4094, 3693,
        2668,   57, 3352, 2480])
Epoch: 1670, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1671 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 2011, 3196, 1958, 2477, 1655,  757, 2205, 1994, 1248, 1028, 3505,
        3196, 2494,  844, 2967])
Epoch: 1671, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1672 - Batch 1 ########################
IDs in batch 1: tensor([  10, 3433, 1012, 1830, 2320, 1537, 2151,  378, 2127, 1103, 3216, 1638,
        3415, 1309,  426, 2008])
Epoch: 1672, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1673 - Batch 1 ########################
IDs in batch 1: tensor([3079, 1076, 1641, 3248, 1896, 2659,  816, 2228, 1585,  417,  577, 1556,
        4255, 3680, 2436,  143])
Epoch: 1673, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1674 - Batch 1 ########################
IDs in batch 1: tensor([2092, 2872, 2873, 3298, 3991, 4067, 2297,  186, 2706, 2770, 2954, 3142,
        3786,  718, 3905,  444])
Epoch: 1674, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1675 - Batch 1 ########################
IDs in batch 1: tensor([3719,   86, 1073, 2072, 1684, 3676, 2522, 1208, 3188, 3505,  646,  835,
           5, 1225,  591, 1425])
Epoch: 1675, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1676 - Batch 1 ########################
IDs in batch 1: tensor([2378,  256, 1181, 3958,  314,  994, 3540, 3585, 4087, 4195, 3963, 2212,
        3499, 1174, 1963, 2708])
Epoch: 1676, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1677 - Batch 1 ########################
IDs in batch 1: tensor([3075, 3182,  993,  718, 3911, 2672, 2296, 1602, 2899, 1076,  907, 2282,
        3577, 3148, 2733,  683])
Epoch: 1677, Training Loss: 0.40, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1678 - Batch 1 ########################
IDs in batch 1: tensor([   7, 1896, 3367,   95,  572, 2874, 2452, 4217, 3430, 3144, 1012, 1255,
        1484, 2772,  649, 2847])
Epoch: 1678, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1679 - Batch 1 ########################
IDs in batch 1: tensor([1826, 1971, 2508,  636, 1086, 2891,  941,  295, 2467, 2842,  881, 1141,
        3876,  574, 4036, 2151])
Epoch: 1679, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1680 - Batch 1 ########################
IDs in batch 1: tensor([3418, 2537, 2855, 1373, 3240, 3524, 1751,  372, 4004, 2142, 1754, 1822,
        2365, 2742, 1171,  691])
Epoch: 1680, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1681 - Batch 1 ########################
IDs in batch 1: tensor([2838,  507, 2603, 2132,  484, 4011, 3982,  345, 3537, 1927, 3390, 2065,
        1420, 1096, 2907,  412])
Epoch: 1681, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1682 - Batch 1 ########################
IDs in batch 1: tensor([ 876,  568, 3894, 3614,  397, 2358,  277,  838, 4149, 1094, 1239,  363,
        2090,  436, 1986, 2078])
Epoch: 1682, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1683 - Batch 1 ########################
IDs in batch 1: tensor([ 826, 3705,  790, 2927, 1824, 1951, 3339, 1448,  284, 1720, 1798, 1910,
        1218,  767, 3493, 1469])
Epoch: 1683, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1684 - Batch 1 ########################
IDs in batch 1: tensor([2204, 3500, 3871, 1077,  375, 3118, 3692, 3587, 2030, 4124, 2883, 1032,
        1182, 3399, 2070, 1010])
Epoch: 1684, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1685 - Batch 1 ########################
IDs in batch 1: tensor([4122, 4141,  147, 2798, 4148, 1218,  610, 2489, 1467, 2638, 1942,  952,
        3271, 2853, 3917, 2732])
Epoch: 1685, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1686 - Batch 1 ########################
IDs in batch 1: tensor([ 212, 3818, 3128, 2897, 2443, 3644,  332, 1236, 3317,  471, 3982, 2407,
        1024, 2521,  526, 2710])
Epoch: 1686, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1687 - Batch 1 ########################
IDs in batch 1: tensor([2178, 3597, 4136,  257, 3029,  557, 3674,  533, 2088, 4175, 2855, 1484,
        1885, 1649, 1125, 3832])
Epoch: 1687, Training Loss: 0.26, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1688 - Batch 1 ########################
IDs in batch 1: tensor([2700, 3675, 3984,  513, 1269, 2144, 4215,   20, 4187, 1752, 3366,  439,
        2489, 1751,  804, 3392])
Epoch: 1688, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1689 - Batch 1 ########################
IDs in batch 1: tensor([1096, 1017, 1680, 1789, 1419, 2546, 2998, 4218, 3871,  398,  970,  591,
        1774, 3935, 2810,  770])
Epoch: 1689, Training Loss: 0.49, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1690 - Batch 1 ########################
IDs in batch 1: tensor([3328, 3385, 4146, 2249, 2034, 3876, 1849, 2341, 4220,  787, 3453,  365,
        2078, 3136,   41, 3410])
Epoch: 1690, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1691 - Batch 1 ########################
IDs in batch 1: tensor([2250,  651,  287, 2683,  660, 4226, 4026,  505, 4125,  639, 3443,  119,
         886,  969,  757, 2621])
Epoch: 1691, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1692 - Batch 1 ########################
IDs in batch 1: tensor([ 987, 4038, 3659, 1931, 1414,  357, 3110, 3528,  266, 2295, 1661, 4188,
         234, 3308, 1247,  684])
Epoch: 1692, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1693 - Batch 1 ########################
IDs in batch 1: tensor([ 430, 3878, 2717,   10, 2081, 2004,  274,  459, 3147, 1711,  345,  787,
        2517, 2924,  834, 3006])
Epoch: 1693, Training Loss: 0.36, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1694 - Batch 1 ########################
IDs in batch 1: tensor([ 955, 2107, 3227, 1740,  538, 3911,  185,  387, 3132, 3268, 2529, 4053,
        3120,  259, 3891, 2036])
Epoch: 1694, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1695 - Batch 1 ########################
IDs in batch 1: tensor([3896,  685,  302,  372, 3284, 2346,  255, 2784, 2907, 4205, 1220, 4108,
         890, 3956, 2999,  238])
Epoch: 1695, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1696 - Batch 1 ########################
IDs in batch 1: tensor([  57, 1899, 3837,  818, 2417, 1676,  796, 1436, 3069,  534, 1444,  952,
        1356, 3251, 2806, 2541])
Epoch: 1696, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1697 - Batch 1 ########################
IDs in batch 1: tensor([2013, 1356, 3533,  914, 2236, 3474, 2510, 2290, 2703, 1921, 2013, 2860,
        3490, 4198, 1639, 1849])
Epoch: 1697, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1698 - Batch 1 ########################
IDs in batch 1: tensor([3549, 2231, 1039, 1881, 2883, 2794,   74,  515, 2927, 3456, 2102, 3329,
        1626, 3157, 3487, 2891])
Epoch: 1698, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1699 - Batch 1 ########################
IDs in batch 1: tensor([ 811, 3826, 1455, 3661, 2739,  736, 1982, 3651, 2126, 2653, 2924, 1008,
        2217, 4267, 3831, 3489])
Epoch: 1699, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1700 - Batch 1 ########################
IDs in batch 1: tensor([  39, 3206, 3765, 3545, 2938, 3038,  573, 2538, 4133, 3049, 2500, 2154,
        2983, 1363, 3706, 2495])
Epoch: 1700, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1701 - Batch 1 ########################
IDs in batch 1: tensor([4254, 3243, 1050, 3932, 2461,   22, 2299, 3461, 2338,  753, 3039,  661,
         413, 2687,  520, 2739])
Epoch: 1701, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1702 - Batch 1 ########################
IDs in batch 1: tensor([4055, 1267, 3217, 2886, 2892, 3878, 1083,  150, 2412, 2398, 4212, 2725,
        3025, 3245, 2915, 1084])
Epoch: 1702, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1703 - Batch 1 ########################
IDs in batch 1: tensor([1841,  815, 1809, 1010, 3969, 2060,  950, 3521, 3693, 3114,  356, 3740,
        4050,  713, 3262,  438])
Epoch: 1703, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1704 - Batch 1 ########################
IDs in batch 1: tensor([2387, 3866, 4076, 1279, 1031, 3458, 1361, 2169, 1345,  950, 3194, 2198,
        1274, 4072, 3468, 2044])
Epoch: 1704, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1705 - Batch 1 ########################
IDs in batch 1: tensor([4108,  471, 1003, 2247,   88, 3883, 1509,  936,  538, 1484, 3954, 2767,
        3541,  207, 2772, 2008])
Epoch: 1705, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1706 - Batch 1 ########################
IDs in batch 1: tensor([2553, 1014, 2382, 1934,  652, 1195,  942,  858, 4133, 2034, 1413, 2638,
         117, 4212,  228,  733])
Epoch: 1706, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1707 - Batch 1 ########################
IDs in batch 1: tensor([1775, 3869, 4261, 1740, 4136, 2484,  177, 4012, 1474, 2755, 2691,  389,
        2035, 3204,  630, 3994])
Epoch: 1707, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1708 - Batch 1 ########################
IDs in batch 1: tensor([3032, 3318, 2235, 3783,  496, 2957, 4184, 4161, 3258,  290, 3082, 1979,
         679, 2437, 2589, 3193])
Epoch: 1708, Training Loss: 0.40, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1709 - Batch 1 ########################
IDs in batch 1: tensor([1828, 1809, 2652,  401, 2190,  252, 3572, 2097, 3418,  920, 3056, 2977,
        1782, 4110, 3032, 3124])
Epoch: 1709, Training Loss: 0.33, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1710 - Batch 1 ########################
IDs in batch 1: tensor([4134, 3438, 3238, 2041, 1420, 2038, 2703,  239, 1415, 2511,   19, 2352,
        3216, 3956, 2908,  730])
Epoch: 1710, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1711 - Batch 1 ########################
IDs in batch 1: tensor([3806, 1133, 2182, 1308, 2088,  190, 3136, 3616, 2425, 1007, 3954,  651,
        2320, 2013, 2198, 3236])
Epoch: 1711, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1712 - Batch 1 ########################
IDs in batch 1: tensor([ 881,  520, 2761, 3077, 3179, 2300, 2009,   46, 1340, 3618, 2366, 3530,
         660, 3486, 2498, 2620])
Epoch: 1712, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1713 - Batch 1 ########################
IDs in batch 1: tensor([1161, 3112, 1324, 1267,  394,  448, 2154, 1793, 3015, 2046, 1213,   86,
        2678, 2619,  397, 1731])
Epoch: 1713, Training Loss: 0.41, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1714 - Batch 1 ########################
IDs in batch 1: tensor([3384, 1766, 1495, 3960, 4101,  148, 1369, 3949, 3617, 2292, 2159,  632,
        3426, 2496,  933,  185])
Epoch: 1714, Training Loss: 0.73, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1715 - Batch 1 ########################
IDs in batch 1: tensor([2636,  995, 1349,  183, 4172, 3469, 1993, 1821, 1256, 1153,  738,  287,
        4179, 2323,  552, 1672])
Epoch: 1715, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1716 - Batch 1 ########################
IDs in batch 1: tensor([1614,  829, 1467, 1299, 2956,  970, 3962,  993, 1835, 3351, 2109, 2195,
        1225, 3471,  388, 3711])
Epoch: 1716, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1717 - Batch 1 ########################
IDs in batch 1: tensor([2719, 3435, 2075, 4072, 3434, 1861, 1716, 2431, 1766, 1015, 4075, 3150,
        1618, 2595, 3193, 2290])
Epoch: 1717, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1718 - Batch 1 ########################
IDs in batch 1: tensor([2791, 1762, 2887, 1509, 2027, 2996,  913, 2837,  896,  590, 1698,  630,
          14, 3676, 2146, 4152])
Epoch: 1718, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1719 - Batch 1 ########################
IDs in batch 1: tensor([1473,  892, 3785, 2157, 3729, 1635,   42, 3453,  880, 4062, 1956, 4267,
         926,  604, 1881,  358])
Epoch: 1719, Training Loss: 0.32, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1720 - Batch 1 ########################
IDs in batch 1: tensor([2966, 3669,  251, 3088, 2650, 2692, 3255,  835,  173, 2386,   84,  318,
        3544, 4006, 1147, 4256])
Epoch: 1720, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1721 - Batch 1 ########################
IDs in batch 1: tensor([4003, 1951,  405, 3922, 1085, 1471, 3755, 2863, 3581, 3644,  832,  104,
        4050, 1979, 4264, 3713])
Epoch: 1721, Training Loss: 0.71, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1722 - Batch 1 ########################
IDs in batch 1: tensor([1676, 2943, 3707, 2465, 2901,  348,  181, 2921,  106, 3484,  484, 4005,
        2783, 2383,  432, 3136])
Epoch: 1722, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1723 - Batch 1 ########################
IDs in batch 1: tensor([4100, 1690, 2572,  188, 1583, 3951, 1472, 1108, 2475,  545, 2314, 2797,
         704, 2703, 2102,  816])
Epoch: 1723, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1724 - Batch 1 ########################
IDs in batch 1: tensor([2604, 3638, 2838, 1945, 2085, 1426,  766, 1133,  964, 1012, 2086, 1648,
        4135, 3672, 1445, 1139])
Epoch: 1724, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1725 - Batch 1 ########################
IDs in batch 1: tensor([ 526, 1747, 4184, 1597, 3017, 1223, 1727, 2682, 3404,  827,  503,   51,
        2026, 3427, 3535,   10])
Epoch: 1725, Training Loss: 0.32, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1726 - Batch 1 ########################
IDs in batch 1: tensor([  47,  399, 2440, 3363, 1096,   88, 3185, 2883, 2991, 4157, 2659, 2995,
        1273, 1201, 3767, 2254])
Epoch: 1726, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1727 - Batch 1 ########################
IDs in batch 1: tensor([2540, 1923, 1592, 2851,  750, 1931, 3121,   60, 3368, 2210,  894, 1536,
        1887, 4228, 2586, 1763])
Epoch: 1727, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1728 - Batch 1 ########################
IDs in batch 1: tensor([3755,  396, 3558, 2976, 3934, 2721, 3257,  712, 2563, 1414,  323,  314,
        4062, 3837,  194, 2510])
Epoch: 1728, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1729 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 3047, 3581, 1734,  481,  964,  224,   82, 4128, 1726,  359, 1845,
        1491,  904, 2656,  516])
Epoch: 1729, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1730 - Batch 1 ########################
IDs in batch 1: tensor([1965,  693,  781, 1921, 4220, 1047,  679, 4222, 1555, 1313, 1817, 2418,
        2691, 2087, 1195, 1224])
Epoch: 1730, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1731 - Batch 1 ########################
IDs in batch 1: tensor([3159, 2013, 2131, 4080,  244,  990, 3492,  946, 4040, 1080, 3524,  161,
        2886,  612, 1901,  351])
Epoch: 1731, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1732 - Batch 1 ########################
IDs in batch 1: tensor([2687, 3453, 3073, 1702, 3185, 3208, 1363,  988, 1045, 4073,  201, 3743,
        3124,  463, 1108,  766])
Epoch: 1732, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1733 - Batch 1 ########################
IDs in batch 1: tensor([2382, 1981, 3526, 1041, 3031,  378, 3740, 1199, 4261, 3499, 4016,  568,
        3317, 3250, 2577, 2118])
Epoch: 1733, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1734 - Batch 1 ########################
IDs in batch 1: tensor([3677, 4251, 3223,  833,  967, 2235, 1014,  750, 2161, 2640, 2315, 1556,
          81,  747,  371, 3831])
Epoch: 1734, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1735 - Batch 1 ########################
IDs in batch 1: tensor([3609,   74, 1108, 3782,  260, 3806,  380, 2773, 1934, 1970, 2255, 2578,
        3756,  537, 2248,   46])
Epoch: 1735, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1736 - Batch 1 ########################
IDs in batch 1: tensor([3193,  930, 2959, 2277, 2690, 1034, 1810, 1740, 4138, 2619, 2821, 1671,
        2650, 1179, 3743,  400])
Epoch: 1736, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1737 - Batch 1 ########################
IDs in batch 1: tensor([3075, 2116, 2348,  851, 2453,   13, 1568,  930, 2809, 2914, 1916,  228,
        3271, 4236, 3779, 3404])
Epoch: 1737, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1738 - Batch 1 ########################
IDs in batch 1: tensor([1377,  415, 2285, 2169, 1393,  530,  143, 4024, 3267,  762, 2034, 2770,
        1474,   85, 1982, 4228])
Epoch: 1738, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1739 - Batch 1 ########################
IDs in batch 1: tensor([ 986,  182,  289,  627, 2563, 2181, 1628, 3190, 1039, 2950, 3058, 2993,
         259, 3252, 2060, 2323])
Epoch: 1739, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1740 - Batch 1 ########################
IDs in batch 1: tensor([4022, 3572, 3275, 3822, 1381,  990, 3630, 3490, 2497, 4068, 4254, 3291,
        1481,  252,  131, 1270])
Epoch: 1740, Training Loss: 0.51, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1741 - Batch 1 ########################
IDs in batch 1: tensor([ 630, 3701, 1999, 2456, 4253, 2578, 2575, 1480, 4188,   70, 2284, 1156,
         670, 1886, 3617,   11])
Epoch: 1741, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1742 - Batch 1 ########################
IDs in batch 1: tensor([1830,  851, 1530, 1990, 1387, 3351, 4238, 2727, 3760, 2244, 3600, 4127,
        1809,  207,  794,  846])
Epoch: 1742, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1743 - Batch 1 ########################
IDs in batch 1: tensor([4078,  617, 2358, 1208, 1778, 1375, 3726,  412, 1716, 3573, 3490, 2265,
         283, 2346, 1796, 2550])
Epoch: 1743, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1744 - Batch 1 ########################
IDs in batch 1: tensor([ 160, 1726, 2094, 3771, 2907, 2809, 4069, 4060, 3904, 3476, 3368, 2322,
        3367,  753, 3220, 2461])
Epoch: 1744, Training Loss: 0.37, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1745 - Batch 1 ########################
IDs in batch 1: tensor([3731, 1493, 3762, 2932, 1225, 3371,  325,  857,  913,  670, 3523,  997,
         956, 2807, 2954, 3831])
Epoch: 1745, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1746 - Batch 1 ########################
IDs in batch 1: tensor([2851, 1693, 3628,  945,  340, 2539, 2855,  987, 3676, 3196,  501, 1595,
          26, 2198,  198,  343])
Epoch: 1746, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1747 - Batch 1 ########################
IDs in batch 1: tensor([3927, 2765, 3003, 1286,  159, 3406, 2432,  202, 2412, 3329, 3874, 1718,
         910, 2070,  234, 1793])
Epoch: 1747, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1748 - Batch 1 ########################
IDs in batch 1: tensor([ 105,  269, 1295, 4033, 2426, 1600,  494, 1887, 2003,  435, 2017, 1682,
        1220, 3501, 3136, 1341])
Epoch: 1748, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1749 - Batch 1 ########################
IDs in batch 1: tensor([2487, 1578, 3207, 1383, 3839, 3942, 3704, 3004, 3822, 3932, 2451,  879,
         766, 2462,  981, 2883])
Epoch: 1749, Training Loss: 0.25, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1750 - Batch 1 ########################
IDs in batch 1: tensor([1110, 1156, 3272, 3954,  117,  790, 1900, 3531, 3345, 2365,   81, 1754,
        4139,   10, 3246,  350])
Epoch: 1750, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1751 - Batch 1 ########################
IDs in batch 1: tensor([  62, 4173, 2960,   14, 1918,  612, 4222, 2073, 4181,  568,  749, 1325,
        1887, 3833, 1508,  565])
Epoch: 1751, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1752 - Batch 1 ########################
IDs in batch 1: tensor([1312, 3593, 3117,  941,  888,  257, 2327, 3903, 1761,  496, 1999,  879,
        1880, 1234,  312, 1657])
Epoch: 1752, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1753 - Batch 1 ########################
IDs in batch 1: tensor([ 584, 1137, 3671, 3234, 1602, 2621, 2432,  355, 4172,  432, 2458, 1014,
         501, 1125, 1737, 3710])
Epoch: 1753, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1754 - Batch 1 ########################
IDs in batch 1: tensor([ 812,  804, 3592, 3603, 4229, 2190, 1811, 1161,  516, 2604, 2426, 4254,
        2775, 4228, 3352, 3516])
Epoch: 1754, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1755 - Batch 1 ########################
IDs in batch 1: tensor([3426, 2663,  281,  900, 1102, 2842,   77, 2098, 1676, 2284,  236, 3314,
         733, 3485, 1641, 2884])
Epoch: 1755, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1756 - Batch 1 ########################
IDs in batch 1: tensor([ 993, 1108, 4070, 1957, 2034, 2367, 1954, 3496, 2997, 1154, 3888, 2429,
        1162,  474, 2110, 3390])
Epoch: 1756, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1757 - Batch 1 ########################
IDs in batch 1: tensor([2251, 3806, 3436,  915, 3995, 2107, 3313, 3233, 2484, 3337, 3314, 1260,
        1469, 2516, 1257, 2176])
Epoch: 1757, Training Loss: 0.50, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1758 - Batch 1 ########################
IDs in batch 1: tensor([ 106, 2959, 1256, 1458, 3856, 2767, 2416, 2809, 1552, 3533, 1878, 1408,
        2036, 2452, 1319, 3398])
Epoch: 1758, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1759 - Batch 1 ########################
IDs in batch 1: tensor([1020, 2855, 1311, 1473,  159,  962,   15,  491,   49, 2312, 1583, 2524,
        1777,  787, 1920, 1354])
Epoch: 1759, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1760 - Batch 1 ########################
IDs in batch 1: tensor([1657, 3635,  459, 4170, 2420, 1044, 3449, 3732,  444, 3176, 1850, 3016,
        2640,  583, 3569, 3036])
Epoch: 1760, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1761 - Batch 1 ########################
IDs in batch 1: tensor([3664,  656, 3207, 4133, 1258, 4152, 4205, 3075, 3259,  430, 1247, 3603,
        2967, 3256, 1578, 4189])
Epoch: 1761, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1762 - Batch 1 ########################
IDs in batch 1: tensor([2332, 1393,  808, 2440,  380, 3547, 3798, 4212, 1810,  225, 1123, 3831,
        3926,  850,  993,  986])
Epoch: 1762, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1763 - Batch 1 ########################
IDs in batch 1: tensor([ 838,  496, 1571, 3792,  974, 2106, 1082, 2477, 2723, 2506, 2496, 2538,
        1051, 1063,  171, 3216])
Epoch: 1763, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1764 - Batch 1 ########################
IDs in batch 1: tensor([2934, 3014, 4253, 3311, 3569, 2841,  126,    5, 3123, 1810, 1364, 3362,
        4127, 3526, 2149, 2338])
Epoch: 1764, Training Loss: 0.42, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1765 - Batch 1 ########################
IDs in batch 1: tensor([2010, 1498,  590, 4039, 2822,  596, 2998,  390, 2838, 1704, 3993, 1126,
         835,  462, 3160,  841])
Epoch: 1765, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1766 - Batch 1 ########################
IDs in batch 1: tensor([3340, 2641, 3882,  476, 3349, 2280,  269,  482, 1670, 2516, 3994, 1775,
        2546, 1012, 4105, 2885])
Epoch: 1766, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1767 - Batch 1 ########################
IDs in batch 1: tensor([2926, 2540, 3852, 1367, 4154,  615, 3252,  136, 1724, 2692, 1511, 2524,
        4266,  812, 2891, 4266])
Epoch: 1767, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1768 - Batch 1 ########################
IDs in batch 1: tensor([3900, 2462,  582, 3009, 1279, 2224,  300, 3529, 2121, 1795,  971,  844,
        2072,  360,  684,   64])
Epoch: 1768, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1769 - Batch 1 ########################
IDs in batch 1: tensor([4114, 3051, 1443, 3157, 3441, 4125, 3192,  326, 3582, 3881,  909, 3408,
        2734,  563, 3701, 3128])
Epoch: 1769, Training Loss: 0.34, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1770 - Batch 1 ########################
IDs in batch 1: tensor([3082,  183, 1702, 3982, 1832,  788,  983,  833, 4238, 1504, 3869,  275,
        4138, 2450, 3803, 2034])
Epoch: 1770, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1771 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 1678, 2667, 2025,  924, 4094,  264,  891, 1186, 3197,  470,  368,
        2090, 4030, 3624, 1035])
Epoch: 1771, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1772 - Batch 1 ########################
IDs in batch 1: tensor([1387, 3441,  312, 3002, 1229, 2299, 1498, 2185, 3981, 1034,  882,  305,
        3197, 3351,  659, 1583])
Epoch: 1772, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1773 - Batch 1 ########################
IDs in batch 1: tensor([3984,  930, 3136,  652, 1027,  969, 3317, 3891, 4015,  910,  606, 2359,
        2749, 2426, 2428, 3000])
Epoch: 1773, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1774 - Batch 1 ########################
IDs in batch 1: tensor([3500, 2192, 3765,  365,   44, 1990, 3407, 1062, 3130, 3742, 1326, 2459,
        1901,  255, 1627, 1793])
Epoch: 1774, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1775 - Batch 1 ########################
IDs in batch 1: tensor([1858, 3166, 1069, 2236, 2552, 1341, 2036,  284, 1295, 2693, 1952,  430,
        2663, 1406, 4125,  279])
Epoch: 1775, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1776 - Batch 1 ########################
IDs in batch 1: tensor([ 591, 3875,  492, 1200, 3497, 2621, 2650, 2724, 1264,  505,  946, 2179,
        3498,  345, 1665, 2829])
Epoch: 1776, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1777 - Batch 1 ########################
IDs in batch 1: tensor([2921, 1059, 1478, 2450, 2568, 3345, 1945, 2367, 1872, 1869, 1869, 3356,
        2522, 2550, 1062, 2520])
Epoch: 1777, Training Loss: 0.62, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1778 - Batch 1 ########################
IDs in batch 1: tensor([1796, 3053, 3304, 2050, 1784, 2905, 4015,  578,  510, 1851, 3888, 1591,
         735,  673, 2326, 1708])
Epoch: 1778, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1779 - Batch 1 ########################
IDs in batch 1: tensor([2349, 3485,   61,  476, 3220, 1160,  752, 3947,  488, 3999, 2842, 4110,
        1214, 2648, 2849,  172])
Epoch: 1779, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1780 - Batch 1 ########################
IDs in batch 1: tensor([1312,  201, 3810, 1878, 3866, 2355, 1080, 2998, 4180, 2492, 3599, 1316,
        2375, 3664, 1097,  554])
Epoch: 1780, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1781 - Batch 1 ########################
IDs in batch 1: tensor([ 882, 3091,  924, 4257,  918, 2897, 3636, 1066, 2517,  394, 3701, 3961,
        3939, 3980, 3463, 1546])
Epoch: 1781, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1782 - Batch 1 ########################
IDs in batch 1: tensor([3092, 3253, 2229,  255,  110, 2156,  547, 2787,  326, 1387, 3585, 1942,
        3603, 1628, 1445,  519])
Epoch: 1782, Training Loss: 0.27, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1783 - Batch 1 ########################
IDs in batch 1: tensor([1942, 3673, 2171,  523, 1645, 4179,  649, 2710, 3950, 4146, 1500, 2169,
        1116, 1777, 1042, 2452])
Epoch: 1783, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1784 - Batch 1 ########################
IDs in batch 1: tensor([1032, 3879, 4141, 3333, 1101, 1672,  819, 3368, 2932, 3807,  727,   30,
        2217, 2615, 1051, 1231])
Epoch: 1784, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1785 - Batch 1 ########################
IDs in batch 1: tensor([2435, 2052, 1754, 1933, 1247, 2462, 4121, 3554,  247,   13, 1981, 3031,
        3888, 3526,  378,  753])
Epoch: 1785, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1786 - Batch 1 ########################
IDs in batch 1: tensor([3185, 3385, 3950, 3474, 2807, 4240,  217, 3321, 2943,  786,  609, 1474,
         456, 1341,  261, 2745])
Epoch: 1786, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1787 - Batch 1 ########################
IDs in batch 1: tensor([1699, 1337, 3696, 3949, 3257, 2518, 2388, 3891,  257, 1665, 2402,  510,
         417, 1500, 2224, 2733])
Epoch: 1787, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1788 - Batch 1 ########################
IDs in batch 1: tensor([1540, 3235, 4051,  967, 3865,  990, 1495, 1645, 1010, 3091, 4075, 4118,
        3806, 3349, 1299, 3894])
Epoch: 1788, Training Loss: 0.60, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1789 - Batch 1 ########################
IDs in batch 1: tensor([2023, 2798, 2403, 3390, 3109,  496, 3747, 3177, 1452, 3777,  812, 1102,
        3458, 2632, 2908,  632])
Epoch: 1789, Training Loss: 0.34, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1790 - Batch 1 ########################
IDs in batch 1: tensor([2940, 1010, 2456, 3983,  128,  226, 2898, 3673,  660, 2510, 2238,  396,
        2812, 1921, 1920, 3475])
Epoch: 1790, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1791 - Batch 1 ########################
IDs in batch 1: tensor([ 930, 4115, 3795, 3498,  565, 1686, 3487, 1911, 1931,  792, 3925, 1255,
        1726, 2275, 1530, 3199])
Epoch: 1791, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1792 - Batch 1 ########################
IDs in batch 1: tensor([2894, 1277, 4255, 3299, 2870,  417, 2018,  538, 1160, 2742,   35, 3469,
        2743, 2892, 2366, 4257])
Epoch: 1792, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1793 - Batch 1 ########################
IDs in batch 1: tensor([ 451,  172,  803, 3650, 3908, 3894, 1712, 2095, 4227, 2144, 3363,  838,
        1076, 3719, 2914, 2767])
Epoch: 1793, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1794 - Batch 1 ########################
IDs in batch 1: tensor([1853, 1845, 2252,  804,  604, 2959, 2155,  968,  497,  568, 4240, 3675,
        1275, 3610, 2436, 4026])
Epoch: 1794, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1795 - Batch 1 ########################
IDs in batch 1: tensor([2536, 3745, 3542, 3753,  538,  656, 4245, 3920, 3384,  811, 1137, 1235,
        1010,   35, 3166, 2844])
Epoch: 1795, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1796 - Batch 1 ########################
IDs in batch 1: tensor([2986,  402,  368, 1623,  367, 3836, 3455, 1374,  472, 2045,  202, 4173,
        1177, 3065, 1060, 2721])
Epoch: 1796, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1797 - Batch 1 ########################
IDs in batch 1: tensor([3638, 3907, 1239, 2876, 3934, 1308,  596, 3749, 2725, 3714, 3318, 1617,
        3593, 1452, 2990, 4095])
Epoch: 1797, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1798 - Batch 1 ########################
IDs in batch 1: tensor([1157, 3963, 1641, 1306, 1321, 2796, 4265, 1137,  788, 1770, 3275,  522,
        3119,   81, 1063, 2024])
Epoch: 1798, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1799 - Batch 1 ########################
IDs in batch 1: tensor([2715,  121, 2489, 2432, 3427,  225, 3162, 2653, 2993, 2934, 3663, 3755,
        1305, 1017, 3984, 2008])
Epoch: 1799, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1800 - Batch 1 ########################
IDs in batch 1: tensor([ 558,  601,  779, 1160, 2188,  827, 1518, 1777, 3286, 2464, 1347, 3615,
        3913, 4095, 1361, 3756])
Epoch: 1800, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1801 - Batch 1 ########################
IDs in batch 1: tensor([2660, 2624, 2046, 3272, 1765, 1846, 1770, 3150, 3119, 4012, 3589, 2094,
        1380,   74, 2238,  874])
Epoch: 1801, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1802 - Batch 1 ########################
IDs in batch 1: tensor([1850, 1530,  250, 2736, 2641, 2832, 3642,  913, 4200, 3015,   30, 3242,
        3472, 1732, 3983, 1228])
Epoch: 1802, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1803 - Batch 1 ########################
IDs in batch 1: tensor([2204, 3995, 2733, 4044, 3746,   63,  462, 3786, 1991,  256,  427, 1510,
         904,  517,  637,   92])
Epoch: 1803, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1804 - Batch 1 ########################
IDs in batch 1: tensor([2867, 1485, 3150, 2425, 1426, 3552, 1951, 3787, 2723, 3268,  546, 1087,
         907,  850,  300, 1297])
Epoch: 1804, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1805 - Batch 1 ########################
IDs in batch 1: tensor([3798, 1318, 4080, 4179,  642, 3808, 1661, 3101,  320, 3178,  834, 3461,
         805, 3672, 2915, 3601])
Epoch: 1805, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1806 - Batch 1 ########################
IDs in batch 1: tensor([2053,  338, 2250, 2898, 3379, 1526, 3065, 1767, 2835,  226, 2521, 2828,
        2589, 2272, 2278, 4018])
Epoch: 1806, Training Loss: 0.42, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1807 - Batch 1 ########################
IDs in batch 1: tensor([1381,  449, 3920, 1023, 1954, 2518, 1884, 3180,  138,  496, 2855, 1367,
        1316, 1960,  437,  681])
Epoch: 1807, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1808 - Batch 1 ########################
IDs in batch 1: tensor([4121, 2742, 3010, 3207, 3712, 2009, 3356, 2479, 1799,   26,   25, 3500,
        3581, 1075, 1039, 1935])
Epoch: 1808, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1809 - Batch 1 ########################
IDs in batch 1: tensor([1647, 1796, 1457, 3932,  341, 3018,  274, 2821, 2508, 3821, 2467, 1850,
        2217, 2669, 2780, 2936])
Epoch: 1809, Training Loss: 0.33, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1810 - Batch 1 ########################
IDs in batch 1: tensor([4114, 1321,  774, 2819,  635, 2234, 3321, 2500, 4184, 1326, 1083,  302,
        2419, 3740, 1673,  593])
Epoch: 1810, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1811 - Batch 1 ########################
IDs in batch 1: tensor([4061, 3314, 2990, 2439, 3360,  660, 2386, 3760, 3472, 2925, 2357, 3489,
        2697, 3976, 3220, 2097])
Epoch: 1811, Training Loss: 1.00, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 1812 - Batch 1 ########################
IDs in batch 1: tensor([  70, 1438,   81, 2561, 1649,  975, 1979, 2207,  133, 1057, 1005, 2426,
        1044, 3726, 3330, 2098])
Epoch: 1812, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1813 - Batch 1 ########################
IDs in batch 1: tensor([ 983,  694,    4, 1242, 1177, 1809, 3872, 3991, 2552, 1746, 2031,  177,
        1124, 1918, 3434, 3621])
Epoch: 1813, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1814 - Batch 1 ########################
IDs in batch 1: tensor([3856, 4094, 2465, 2853, 3392, 3833, 1032, 2272,  451, 3498, 3921, 4213,
        1636, 1437, 1484, 4072])
Epoch: 1814, Training Loss: 0.37, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1815 - Batch 1 ########################
IDs in batch 1: tensor([1101, 2598,   24, 1283, 1698, 1887, 3377, 1673, 2672, 2103, 2002, 1088,
        3777,  206, 3650, 2246])
Epoch: 1815, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1816 - Batch 1 ########################
IDs in batch 1: tensor([ 763, 3056,  275,  947, 1728, 1803, 1489, 1326, 3982,  152, 1753, 2446,
        1798, 3036, 2131, 2884])
Epoch: 1816, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1817 - Batch 1 ########################
IDs in batch 1: tensor([1369, 3078, 3428, 1470, 1502, 1896, 1958,  955, 4037, 2241,  335, 3932,
        4084,  262, 3608, 2726])
Epoch: 1817, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1818 - Batch 1 ########################
IDs in batch 1: tensor([4138, 3492, 2518,   52, 1782, 1276, 3176, 2280, 3810, 3152,  684, 2301,
        1249,  534, 2097, 1937])
Epoch: 1818, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1819 - Batch 1 ########################
IDs in batch 1: tensor([3075, 3397, 1879, 2940, 4002, 3460, 1285, 1054, 1891, 3590, 1093, 3591,
        2195,  558, 1822, 2712])
Epoch: 1819, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1820 - Batch 1 ########################
IDs in batch 1: tensor([1072, 4172,  957, 3564, 1117, 2440, 3246, 3905,  740, 3701, 1256, 1218,
        1660, 2869, 1038, 2172])
Epoch: 1820, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1821 - Batch 1 ########################
IDs in batch 1: tensor([1107,  127, 3648, 2097, 4093,  952,  465, 2951, 2173, 1822,  399,  833,
        2442, 2667, 2505, 3039])
Epoch: 1821, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1822 - Batch 1 ########################
IDs in batch 1: tensor([ 130, 4185, 2496, 1385,  338, 1504, 3636, 3119,  613, 3886, 3958, 1883,
        1897,  411, 2760, 2516])
Epoch: 1822, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 1823 - Batch 1 ########################
IDs in batch 1: tensor([ 315, 2449,  196, 1498,  590, 3123, 2477,  883,  553, 4120, 3604,  387,
        3400, 2403, 2309, 2828])
Epoch: 1823, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1824 - Batch 1 ########################
IDs in batch 1: tensor([1770, 2826,   50, 1853, 3591,  881, 3900, 3278, 2405, 3355, 4200,  342,
        1055, 1900, 2003, 1698])
Epoch: 1824, Training Loss: 0.10, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1825 - Batch 1 ########################
IDs in batch 1: tensor([ 870, 1060, 2370,  278, 3490, 3981, 2571,  219, 1977, 1343, 2989, 3368,
         455, 1206, 2942, 2539])
Epoch: 1825, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1826 - Batch 1 ########################
IDs in batch 1: tensor([1611, 3777, 1316, 1337,  907, 3891, 3936, 3349, 1668,  225, 2440, 1481,
        1050,  159, 2648, 3036])
Epoch: 1826, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 1827 - Batch 1 ########################
IDs in batch 1: tensor([ 924, 4238, 1372, 1334, 2005, 3876,  119,  127, 1396, 1454, 1146, 1351,
        1251, 1022, 3100,  432])
Epoch: 1827, Training Loss: 0.65, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1828 - Batch 1 ########################
IDs in batch 1: tensor([3592, 2446, 3217,   24, 2484, 2656, 2536,  952, 3793, 2217, 4005, 1090,
        1131, 1118, 1450,  854])
Epoch: 1828, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1829 - Batch 1 ########################
IDs in batch 1: tensor([3624, 1047, 1180, 1882, 2642, 2322, 3111, 3655, 3739,  527,  454, 2151,
        1179,  280, 2075, 3246])
Epoch: 1829, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1830 - Batch 1 ########################
IDs in batch 1: tensor([1960,   86, 2709,  774, 1336, 4115, 3135,  980, 1990, 2640,  681, 1817,
         318, 1190, 1291, 1718])
Epoch: 1830, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1831 - Batch 1 ########################
IDs in batch 1: tensor([4097, 1341, 1913, 1798, 4100, 2299, 3235, 2193,  601, 3248, 1496,  682,
        2902,  405, 1299,  743])
Epoch: 1831, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1832 - Batch 1 ########################
IDs in batch 1: tensor([1947, 3608, 2745, 2362, 1414, 3917, 3166,  587, 2049, 1361, 3190, 3371,
        1878,  915, 1438,  257])
Epoch: 1832, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1833 - Batch 1 ########################
IDs in batch 1: tensor([ 211, 1836, 1558, 2198, 1035, 1219,  807, 3398,   62, 1328,  391,  284,
        1747, 3996, 3489,  277])
Epoch: 1833, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1834 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 2475, 3214, 3780, 1189, 3328, 1501, 1130, 2382, 2905,  409,  879,
        1982,  601,  781,  274])
Epoch: 1834, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1835 - Batch 1 ########################
IDs in batch 1: tensor([ 757, 1580, 2464, 1880, 2788, 3392, 1162, 1811, 3545, 3378,  787, 1918,
        3027, 1391, 3119, 1826])
Epoch: 1835, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1836 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 1585, 2251, 2700, 3996, 3456, 3673,  538, 1134,  743, 4146,  321,
        2418, 2346, 1229, 2348])
Epoch: 1836, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1837 - Batch 1 ########################
IDs in batch 1: tensor([1425, 3588, 1081, 2629,  846,  779, 1677,  822, 2804, 4251, 2505,   57,
         631,  512, 1795, 2624])
Epoch: 1837, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1838 - Batch 1 ########################
IDs in batch 1: tensor([1052, 2040, 1421, 3917, 2733, 3409,  365,  239, 1471, 3742, 1341, 2367,
        3480, 1363, 2008,  964])
Epoch: 1838, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1839 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 3783,  785, 1787, 2287,  378, 2640, 3387,  830, 3303, 1613, 2298,
         145, 2579, 4126, 2977])
Epoch: 1839, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1840 - Batch 1 ########################
IDs in batch 1: tensor([3731, 2831, 2964, 3540, 3228,  550, 4004, 2450, 1650,  678,  203, 1178,
        1162, 4245, 4223, 3981])
Epoch: 1840, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1841 - Batch 1 ########################
IDs in batch 1: tensor([2405, 3989, 1650, 4196,  217, 2124,  955, 3516, 1020, 2721, 1574, 3599,
        3161, 3700,  188, 1214])
Epoch: 1841, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1842 - Batch 1 ########################
IDs in batch 1: tensor([3859, 1571, 4096, 3428, 2212,   38, 2842, 3514, 3374,  844, 1745, 2323,
        3933, 1506, 3760, 2644])
Epoch: 1842, Training Loss: 0.64, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1843 - Batch 1 ########################
IDs in batch 1: tensor([1818, 2591, 2178, 1076, 1052,  909, 2925, 1518, 4026,  960, 4101, 2656,
        1143, 1540,  219, 2644])
Epoch: 1843, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1844 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 3964, 3782,  171, 2281, 2945,  505,  890, 2446, 1532, 1706,  887,
        1252, 1845,  194, 2331])
Epoch: 1844, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1845 - Batch 1 ########################
IDs in batch 1: tensor([2015,  149, 2582, 3912,  378, 2355,  820, 2784, 4010, 1313,  102,  463,
        1272, 3180, 2739, 3732])
Epoch: 1845, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1846 - Batch 1 ########################
IDs in batch 1: tensor([1563, 3216, 1660,  445, 1569, 3538, 2387, 1495, 1199, 2572,  520,  891,
         255, 4158, 1704,  989])
Epoch: 1846, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1847 - Batch 1 ########################
IDs in batch 1: tensor([  96,  411, 3865, 1385, 3182,  900, 1710, 2122, 2701,  924, 3525, 4185,
        3490, 3110,  145, 4135])
Epoch: 1847, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1848 - Batch 1 ########################
IDs in batch 1: tensor([1395, 1935, 1480, 1012,  743, 1173, 3443, 3461,  496, 1798, 4232,  625,
        4082, 3604,  471, 1063])
Epoch: 1848, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1849 - Batch 1 ########################
IDs in batch 1: tensor([1950,  474, 1732,  444, 2873, 4008, 1548, 1006,  602, 2824, 2879, 2352,
        2468, 3460, 4016, 2375])
Epoch: 1849, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1850 - Batch 1 ########################
IDs in batch 1: tensor([ 895, 3879, 1630, 1777, 1010,  989, 3311, 2173, 2385, 2193, 3202,  774,
        1031, 2417, 2098, 2320])
Epoch: 1850, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1851 - Batch 1 ########################
IDs in batch 1: tensor([1330, 1241, 2688, 4203, 2497, 3073, 3287, 2924,   39, 3058, 2204, 3352,
        3823,  541, 3995, 1518])
Epoch: 1851, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1852 - Batch 1 ########################
IDs in batch 1: tensor([3663, 3099, 2902, 2146, 4122,  360, 4143, 1658,  852, 2178,  612, 2245,
        2546, 1892, 3219, 1973])
Epoch: 1852, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1853 - Batch 1 ########################
IDs in batch 1: tensor([ 693,  924,  531,  661, 2092, 2469, 4255, 2508,  961, 1311, 3802,  766,
        3842, 1612,  437, 3914])
Epoch: 1853, Training Loss: 0.57, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1854 - Batch 1 ########################
IDs in batch 1: tensor([3081,   28, 1429, 3833, 2320,  694,  781, 3286, 2990,   96,  854, 3208,
        3738,  322,  976,  807])
Epoch: 1854, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1855 - Batch 1 ########################
IDs in batch 1: tensor([1167, 1450, 4037, 2674, 1073, 1835, 1645, 1331, 3101, 4014, 1920, 2137,
         148, 3362, 1710, 1588])
Epoch: 1855, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1856 - Batch 1 ########################
IDs in batch 1: tensor([1648, 2081, 3668, 4134, 1214, 1080,  220, 3241, 2879, 1604, 2315,  236,
         212, 1977,  456, 3888])
Epoch: 1856, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1857 - Batch 1 ########################
IDs in batch 1: tensor([1619, 1147,   60, 1678, 1478, 3408, 3203, 1139, 3754, 2010, 4002, 3604,
        2181, 2529,  532, 2091])
Epoch: 1857, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1858 - Batch 1 ########################
IDs in batch 1: tensor([  74, 4103, 2202, 1375, 2065, 2097, 1098, 2328, 2837, 3812, 3514,  258,
        1364,  125, 1595, 3022])
Epoch: 1858, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1859 - Batch 1 ########################
IDs in batch 1: tensor([3920,  439, 4180, 1434, 1395,  899,  536,  201, 1761, 2199, 1065, 1073,
        3498, 2514, 3660, 2412])
Epoch: 1859, Training Loss: 0.31, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1860 - Batch 1 ########################
IDs in batch 1: tensor([1775,  622, 1555, 3058,  774,  615,  779, 3973, 3342, 1751, 4027, 2362,
        1236, 4062, 3003,  824])
Epoch: 1860, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1861 - Batch 1 ########################
IDs in batch 1: tensor([3192,  595,  568, 2721, 1895, 4205, 3217, 2028, 1784, 1746,  683, 2153,
        2589, 1380,  173, 4157])
Epoch: 1861, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1862 - Batch 1 ########################
IDs in batch 1: tensor([2085, 2469,  119, 3762, 2520, 2306, 4185, 1451, 1767, 3587, 1991, 4037,
         988,  577, 4086, 3818])
Epoch: 1862, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1863 - Batch 1 ########################
IDs in batch 1: tensor([3039,   77, 2327, 1846, 2120, 3643, 4212,  594, 2847,  628, 3789, 1900,
         167, 3372, 3856,  953])
Epoch: 1863, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1864 - Batch 1 ########################
IDs in batch 1: tensor([3540, 3410, 3268, 3251, 3017, 1643, 1072,  627, 3749, 4086,  467, 2212,
        3728,   74, 1777,  360])
Epoch: 1864, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1865 - Batch 1 ########################
IDs in batch 1: tensor([1183, 3239, 2636, 2091, 3851, 1860, 1444,  851, 2463,  133, 3453, 4114,
        2072, 3721, 1030, 2432])
Epoch: 1865, Training Loss: 0.57, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1866 - Batch 1 ########################
IDs in batch 1: tensor([1251, 2145, 1773, 2726, 2049,   47, 3415, 3673, 1455, 4057, 1405, 2712,
        3356, 4249, 2848, 3366])
Epoch: 1866, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1867 - Batch 1 ########################
IDs in batch 1: tensor([ 535, 3859, 3494, 1965, 3994, 3118, 1420, 1945, 3182, 1282, 1476, 3932,
         693, 1617,  448,  631])
Epoch: 1867, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1868 - Batch 1 ########################
IDs in batch 1: tensor([3187, 1545, 2144, 1297, 1733, 3667, 2280, 3998,  577, 3917, 2432, 3593,
        1042, 4161, 3333, 1507])
Epoch: 1868, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1869 - Batch 1 ########################
IDs in batch 1: tensor([3827,  738, 1440, 1472, 2087, 1297,  857, 4159, 1519, 2326,  781,  620,
        1682,  436, 3216,  455])
Epoch: 1869, Training Loss: 0.41, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1870 - Batch 1 ########################
IDs in batch 1: tensor([3188, 3523,  341, 3573, 4027, 3973,  735, 4245, 4161, 2131, 2271, 2892,
        3000, 1563,  352,  332])
Epoch: 1870, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1871 - Batch 1 ########################
IDs in batch 1: tensor([3152, 2145,  365, 1092, 1536,  234, 2072, 2383, 1369, 2477, 2761, 2383,
        4070, 3614, 3338,  740])
Epoch: 1871, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1872 - Batch 1 ########################
IDs in batch 1: tensor([1437, 3856,  575, 2070, 3498, 3702, 1870,   50, 1747, 3614, 3461, 1206,
        2388,  769, 1802,  274])
Epoch: 1872, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1873 - Batch 1 ########################
IDs in batch 1: tensor([4136,  635, 2839,  946, 1352, 1370, 3025,  665,  679, 1761, 1316, 1212,
        1532,  280,  491, 2993])
Epoch: 1873, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1874 - Batch 1 ########################
IDs in batch 1: tensor([3448, 2251, 3282, 3823, 3178, 3594,  652, 2485, 3507,  218, 3643, 3765,
        3523, 3793, 1779,  850])
Epoch: 1874, Training Loss: 0.54, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1875 - Batch 1 ########################
IDs in batch 1: tensor([ 717, 3681,  333, 3192, 2347,  989, 3661, 3127, 3126, 1850,  485,  226,
        1408, 3473, 1967, 3313])
Epoch: 1875, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1876 - Batch 1 ########################
IDs in batch 1: tensor([2945, 3647,  223, 2205, 1670, 1984, 3976, 1710,  824, 2196, 3399, 1372,
        3702, 2548,  739, 3701])
Epoch: 1876, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1877 - Batch 1 ########################
IDs in batch 1: tensor([4185, 2514, 1778, 2274, 3410, 1450, 4113, 3534,   41, 1619,  679, 4138,
        4235, 3108, 3743, 3051])
Epoch: 1877, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1878 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 3088, 2019, 3940, 3879, 1286, 3603, 3192, 2924, 1388,  511, 3021,
        3823, 3949, 1156, 4235])
Epoch: 1878, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1879 - Batch 1 ########################
IDs in batch 1: tensor([2618, 2279, 1777, 2324, 1986, 1386, 1493, 4031, 2751, 2382, 1334,  729,
        2166, 4121,  284, 4024])
Epoch: 1879, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1880 - Batch 1 ########################
IDs in batch 1: tensor([2364, 2370, 3975,  636, 1545, 2798, 1087, 3009, 3826, 3287, 2039, 3265,
        2052, 2505, 3291, 1885])
Epoch: 1880, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1881 - Batch 1 ########################
IDs in batch 1: tensor([2247, 1639, 1027, 2204, 4194, 2631, 2880, 2212, 1945, 2346, 3935,  372,
        2998,  751,  725, 2584])
Epoch: 1881, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1882 - Batch 1 ########################
IDs in batch 1: tensor([3370, 4084, 2219, 2092, 1961, 2591, 3283, 1312, 2300, 1310, 4039, 4002,
        1823,  292, 1955, 1754])
Epoch: 1882, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1883 - Batch 1 ########################
IDs in batch 1: tensor([2193, 3222, 3958, 2951, 1752,  466, 3593, 4065, 2950, 3999, 1020,  833,
         735, 2794,  517, 3798])
Epoch: 1883, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1884 - Batch 1 ########################
IDs in batch 1: tensor([2890,  823,  177, 1352, 1935, 2320,  276, 1170, 1602, 2882, 2791, 3652,
        2466, 3999, 1892, 3233])
Epoch: 1884, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1885 - Batch 1 ########################
IDs in batch 1: tensor([2742,  159, 1282, 2504, 2320, 3211, 1720,  676, 3888, 4088, 2170, 3881,
        2619,   74, 1034, 4232])
Epoch: 1885, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1886 - Batch 1 ########################
IDs in batch 1: tensor([2725,  503, 3568, 3507, 1088, 3088, 1760, 3627,  594, 1853, 4085, 1213,
        4089, 1371, 1375, 1951])
Epoch: 1886, Training Loss: 0.42, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1887 - Batch 1 ########################
IDs in batch 1: tensor([1670, 3505, 3337, 4200, 1291,  727, 2870, 3831,  413,   84, 4062, 4062,
        1170, 1770, 3421,  132])
Epoch: 1887, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 1888 - Batch 1 ########################
IDs in batch 1: tensor([1098, 4082, 1661,  344, 1292, 1679, 2355, 3932,  785, 3354, 1752, 3100,
        1384, 2378,  891,  388])
Epoch: 1888, Training Loss: 0.44, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1889 - Batch 1 ########################
IDs in batch 1: tensor([4094, 1287, 3154,  184, 4205, 1682, 1450,  663,  674, 4268,   43, 1367,
        1305, 3533, 1405, 3343])
Epoch: 1889, Training Loss: 0.54, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1890 - Batch 1 ########################
IDs in batch 1: tensor([ 223,  681,  302, 3992, 1894,  135, 1592, 2080, 3474, 1530, 3956,  358,
        1682,  983, 4264, 3313])
Epoch: 1890, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1891 - Batch 1 ########################
IDs in batch 1: tensor([4152, 3478, 3190, 3353, 3501, 3417, 1274, 2367,  736, 2429, 2873, 3912,
         795, 4256, 2689,  352])
Epoch: 1891, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1892 - Batch 1 ########################
IDs in batch 1: tensor([1485, 3920, 2710, 1214,  131, 3330, 2984, 1762, 2193, 1821,  348, 1336,
        1960, 1601, 1212,  439])
Epoch: 1892, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1893 - Batch 1 ########################
IDs in batch 1: tensor([ 250, 3094, 3038, 4122, 1780, 2465, 3029, 3771, 2024, 1832, 1482, 1467,
        3705, 2371,  921, 3908])
Epoch: 1893, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1894 - Batch 1 ########################
IDs in batch 1: tensor([ 607, 3075,  985, 2765,  956, 2563, 1028, 3246, 3999, 2819, 3099, 3873,
        3658, 1804,   30, 4228])
Epoch: 1894, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1895 - Batch 1 ########################
IDs in batch 1: tensor([3617, 2973,  941, 2947, 2444, 4138, 3514, 2882, 1116, 3961, 4152,  886,
        1910, 1818,  444, 4229])
Epoch: 1895, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1896 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 3920, 1076, 2334,  438, 3638, 2978, 2879,  645, 4197, 1610, 4108,
        1774, 1473, 1574,  613])
Epoch: 1896, Training Loss: 0.37, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1897 - Batch 1 ########################
IDs in batch 1: tensor([1166,  781,  683,  852, 3051,  769,  985, 2773, 2937, 2120, 3485, 1355,
        3101, 3317, 1120, 1802])
Epoch: 1897, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1898 - Batch 1 ########################
IDs in batch 1: tensor([1263, 2541, 4204, 2581,  255, 2399, 2796, 4070, 2789, 1278, 3044, 1117,
        4011, 2511, 3024, 3352])
Epoch: 1898, Training Loss: 0.49, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1899 - Batch 1 ########################
IDs in batch 1: tensor([1325, 1357, 3563, 4225, 3732,  523, 2180,  947,  740, 1257, 4199, 2459,
        1630, 4256, 1993, 2304])
Epoch: 1899, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1900 - Batch 1 ########################
IDs in batch 1: tensor([3264, 1015,  848, 3188,  401, 2863, 1650, 1389,  969, 1677,  943, 1139,
        3382, 2320, 1034, 1698])
Epoch: 1900, Training Loss: 0.53, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1901 - Batch 1 ########################
IDs in batch 1: tensor([3192, 1722,  590,  725, 3826, 1334,  337, 2559, 3468,  342, 4077,  846,
        1954, 2462, 2492,  818])
Epoch: 1901, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1902 - Batch 1 ########################
IDs in batch 1: tensor([2405, 2030, 3449, 2278, 1438, 3451, 3614, 1895,  257,  149,  665, 2469,
        2393,  943, 1305, 2339])
Epoch: 1902, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1903 - Batch 1 ########################
IDs in batch 1: tensor([3270, 2299,  982,  384,  264, 1476, 3044, 1895, 2498, 3146, 3317, 1648,
          43, 1159, 3072, 2711])
Epoch: 1903, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1904 - Batch 1 ########################
IDs in batch 1: tensor([2559, 2687, 3772, 4215,  375, 2748,  632, 4046, 1162,  326, 1081, 1180,
          38, 3608,  195, 2090])
Epoch: 1904, Training Loss: 0.41, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1905 - Batch 1 ########################
IDs in batch 1: tensor([ 470, 1094, 2745, 3688, 2587, 3942, 4199, 1139, 2324, 1836,  389, 3630,
        3408, 4236, 3217,  842])
Epoch: 1905, Training Loss: 0.49, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1906 - Batch 1 ########################
IDs in batch 1: tensor([ 962,  351, 3702, 3119, 1178, 3196, 4038, 3790, 3111, 3267, 1099, 3278,
        1772, 2659, 2450, 1363])
Epoch: 1906, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1907 - Batch 1 ########################
IDs in batch 1: tensor([ 693,  352, 1909, 4227,  952,  141, 1410, 1574,  363, 1649, 1024, 1319,
        4007,  205, 2145,  320])
Epoch: 1907, Training Loss: 0.51, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1908 - Batch 1 ########################
IDs in batch 1: tensor([1437, 2044, 2433, 1755,  390, 1317,  658, 4149, 3557, 3181, 1643, 2794,
        1767,  534, 1745, 2752])
Epoch: 1908, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1909 - Batch 1 ########################
IDs in batch 1: tensor([ 811, 2116, 1648, 1849,   57, 3421, 1956, 2669, 1624,  261, 3177, 3852,
        2301, 1278, 3284,  194])
Epoch: 1909, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1910 - Batch 1 ########################
IDs in batch 1: tensor([3115,  825, 3144, 2109, 1680, 1467, 3262,  605, 1201, 1796, 1421,  757,
        3728,  628, 2295, 1232])
Epoch: 1910, Training Loss: 0.35, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1911 - Batch 1 ########################
IDs in batch 1: tensor([ 397,  670, 2355, 2462, 4185,  820, 1092,  550,  863,  252, 1779,  778,
        1975, 2298, 2246, 3829])
Epoch: 1911, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1912 - Batch 1 ########################
IDs in batch 1: tensor([3904, 1579, 3827, 2553, 1526, 1365,  637, 3830, 3755, 1054,   37,  205,
        4055, 3117,  971, 2078])
Epoch: 1912, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1913 - Batch 1 ########################
IDs in batch 1: tensor([3664, 3832, 2655, 1197, 2346, 1569, 1636,  196,  721, 2924,  961,  256,
        1312, 3738, 2732,  111])
Epoch: 1913, Training Loss: 0.26, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1914 - Batch 1 ########################
IDs in batch 1: tensor([ 481, 2094,  944, 1955,   77, 3121, 2277,  454,  717, 3311, 3185, 3949,
         814, 2447,  497, 2041])
Epoch: 1914, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1915 - Batch 1 ########################
IDs in batch 1: tensor([1096, 2907, 2568, 2869,  552, 2832, 3267, 2440, 3958, 2467, 4181, 3404,
        1884, 1501, 3449, 3037])
Epoch: 1915, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1916 - Batch 1 ########################
IDs in batch 1: tensor([2936, 1231,  308,  117, 1720, 2423,  926, 3278, 1179, 4087, 2815, 3091,
        2912, 3366, 2277,  786])
Epoch: 1916, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1917 - Batch 1 ########################
IDs in batch 1: tensor([3005, 2385,  395, 1287,  430,  992, 1720, 2827, 2901,  895, 1463, 1455,
         403, 2700, 3524, 2280])
Epoch: 1917, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1918 - Batch 1 ########################
IDs in batch 1: tensor([2582, 3778, 1302, 3057, 1084,  762,  256, 2521, 1823, 3601, 3635, 3203,
        1802, 4004,   15, 2668])
Epoch: 1918, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1919 - Batch 1 ########################
IDs in batch 1: tensor([1027, 4040, 1879,  942,  119, 4087, 1751, 1028,  659, 3032, 1299, 3526,
        4188, 1751, 2558, 1408])
Epoch: 1919, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1920 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 2323,  554,  434, 3549, 1197, 1502, 2469, 2051,  726, 3949, 1823,
        3369,  325,  829, 3886])
Epoch: 1920, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1921 - Batch 1 ########################
IDs in batch 1: tensor([4004,  970, 3065, 1333, 1072, 1137, 2385, 1418, 1313, 1414, 1863, 2974,
        1498, 1352, 1199, 2291])
Epoch: 1921, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1922 - Batch 1 ########################
IDs in batch 1: tensor([ 604, 2663,  846,  225,  755, 3197,  535,  412, 3053, 3371, 3836,  440,
        4100, 2402, 4238,  827])
Epoch: 1922, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1923 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 2857, 3874, 2627, 2398, 2022, 2804, 1711, 4229, 2072,   25, 2280,
        2253, 2144, 3371, 2827])
Epoch: 1923, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1924 - Batch 1 ########################
IDs in batch 1: tensor([2938, 2143,  680,  516, 2621, 2919, 4134, 3027, 3497,  335,  373, 2272,
        1567,    7, 3532, 1185])
Epoch: 1924, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1925 - Batch 1 ########################
IDs in batch 1: tensor([3111, 2202, 3938,  959, 2799, 3837,  407, 2484, 3908,   47,  462,  874,
        2926, 1264, 1324, 2242])
Epoch: 1925, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1926 - Batch 1 ########################
IDs in batch 1: tensor([2856, 3876,   50,  588, 1347, 2561, 2870,  245,  363, 3379, 3133, 1067,
         139,  391, 3786, 1385])
Epoch: 1926, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 1927 - Batch 1 ########################
IDs in batch 1: tensor([4256, 2919,  805, 4117, 4085, 2680, 2013, 2781,  467, 1872,  306, 2819,
        1498, 2173,   97,  442])
Epoch: 1927, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1928 - Batch 1 ########################
IDs in batch 1: tensor([2040, 3904, 4055, 1432, 1044, 3616, 2523, 3139, 2257, 3765, 1436, 1376,
        3494,  354, 3101, 4223])
Epoch: 1928, Training Loss: 0.35, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1929 - Batch 1 ########################
IDs in batch 1: tensor([1003, 3615,  378, 3914, 1178, 3227, 3806, 3030, 1600,  139, 2103, 2028,
        2292, 3949, 1773, 2844])
Epoch: 1929, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1930 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 2261,  469, 3312,  497,  379, 1665,  907, 1963, 2767, 3073, 1795,
         516, 3818, 1369, 2678])
Epoch: 1930, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1931 - Batch 1 ########################
IDs in batch 1: tensor([3446, 1736, 1868, 1384, 1895,  132,  345,  617,  622, 1343,  417, 1951,
        3038,  957,  206, 3503])
Epoch: 1931, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1932 - Batch 1 ########################
IDs in batch 1: tensor([4085, 1179, 4227, 3071,  444, 4141, 4096, 4122, 2092, 1733, 3525, 2819,
         852, 2884, 3701,  766])
Epoch: 1932, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1933 - Batch 1 ########################
IDs in batch 1: tensor([2477, 2235, 3378, 3594, 1402, 3647,  930, 1642, 1141,  923, 2932, 1570,
        2518, 2086,  518, 1367])
Epoch: 1933, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1934 - Batch 1 ########################
IDs in batch 1: tensor([1406, 1762, 1219, 1022, 1661, 1568, 3975, 4110, 3182, 1016, 2907,  444,
        1885, 2925, 2286, 2509])
Epoch: 1934, Training Loss: 0.08, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1935 - Batch 1 ########################
IDs in batch 1: tensor([1031, 3921,   73, 2871, 2915, 3600, 1499,  758, 1620, 1456, 4131, 4048,
        2278, 3203, 3219, 1726])
Epoch: 1935, Training Loss: 0.67, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1936 - Batch 1 ########################
IDs in batch 1: tensor([1955, 1045, 1802,  265, 2209,  269,  541, 3233, 1193, 1186, 1173, 2700,
         344, 3217, 2683, 1849])
Epoch: 1936, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1937 - Batch 1 ########################
IDs in batch 1: tensor([1239, 1796,  408, 1963, 2701, 3471, 1176, 2410, 2733, 2060, 3581,  881,
        3568, 2067,  824,  617])
Epoch: 1937, Training Loss: 0.44, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1938 - Batch 1 ########################
IDs in batch 1: tensor([2522, 3789, 4163, 3271,  219, 3499, 2998, 2597, 2545, 3833, 3404, 2436,
         367, 3930, 2322, 1031])
Epoch: 1938, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1939 - Batch 1 ########################
IDs in batch 1: tensor([2872, 3178, 3262, 2544, 3368, 3990, 1642, 2044, 4234,  257, 1367,   18,
        2974, 1967, 2225, 1389])
Epoch: 1939, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1940 - Batch 1 ########################
IDs in batch 1: tensor([3075, 1003,  897, 2296, 1910, 2950, 2362,  372, 3088, 2742, 1583, 1387,
         125, 1003, 3698, 3856])
Epoch: 1940, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1941 - Batch 1 ########################
IDs in batch 1: tensor([  15, 2745, 4184, 2758, 3009, 2110, 2127,  320, 2446,  359, 3528,  303,
         101, 1075, 2112, 1122])
Epoch: 1941, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1942 - Batch 1 ########################
IDs in batch 1: tensor([3329, 2751, 2887, 2983, 1027,  610, 3743,  944,  217, 3357,   47, 3863,
        1740,  518, 2373,  190])
Epoch: 1942, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1943 - Batch 1 ########################
IDs in batch 1: tensor([2346,  566, 1670, 1457, 1379,  804, 3998,  483,  975, 3151, 4005, 3439,
        3654, 2828, 3002, 2443])
Epoch: 1943, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1944 - Batch 1 ########################
IDs in batch 1: tensor([3243,  217, 1810, 1384, 2264,  322,   11, 2787, 1614, 3503, 1592, 1570,
        2334, 3276, 2522, 2036])
Epoch: 1944, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1945 - Batch 1 ########################
IDs in batch 1: tensor([2010, 1592, 2659,  582, 2146,  492,  552, 3330, 2568, 3850, 2999,  229,
         108, 1458, 2798, 1448])
Epoch: 1945, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1946 - Batch 1 ########################
IDs in batch 1: tensor([ 858, 1197, 3486, 1630, 3379, 4223, 1455,  469, 1266, 2799, 1804, 3693,
        2060, 3456, 3394,  490])
Epoch: 1946, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1947 - Batch 1 ########################
IDs in batch 1: tensor([2655, 1794, 2169, 4133, 2342, 3598, 3118, 2423, 1545, 1161, 4176, 3031,
        4222, 2063, 4097, 3144])
Epoch: 1947, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1948 - Batch 1 ########################
IDs in batch 1: tensor([4165, 3435, 2070, 1223, 2456, 1007,  393, 1921, 1524, 3964,  182,  827,
        2373,   51, 1453, 2725])
Epoch: 1948, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 1949 - Batch 1 ########################
IDs in batch 1: tensor([3883, 1891, 4095, 3573, 3414, 2448, 3069, 1724, 1289,  996, 2315, 2442,
        2884, 2002, 2149, 2300])
Epoch: 1949, Training Loss: 0.32, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1950 - Batch 1 ########################
IDs in batch 1: tensor([4240, 2049,  565, 2016,  274,  741, 1545, 1833, 2359, 2597, 3536, 1138,
         871, 2869, 1189, 3896])
Epoch: 1950, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1951 - Batch 1 ########################
IDs in batch 1: tensor([1965, 3180, 1082,  148, 3475, 1399, 3874,  841, 3421,  147, 1763, 4037,
        3624, 3494,  835, 3590])
Epoch: 1951, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1952 - Batch 1 ########################
IDs in batch 1: tensor([ 475, 2558, 1655, 1909, 2723, 3072, 1923,  466, 4025, 4018, 1255,  640,
         538, 1895, 3447, 3190])
Epoch: 1952, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1953 - Batch 1 ########################
IDs in batch 1: tensor([1147, 2604, 1782, 3459, 4022, 1083, 1512, 1668, 3451,  405, 3248, 4010,
        2226, 3016, 2466, 2064])
Epoch: 1953, Training Loss: 0.29, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1954 - Batch 1 ########################
IDs in batch 1: tensor([1457,  226, 2708,  786,  330,  812,   11, 2204, 1190, 3025, 3587, 1665,
         637,  196,  135, 2671])
Epoch: 1954, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 1955 - Batch 1 ########################
IDs in batch 1: tensor([1819, 1869,  872, 2777, 1896, 1833,  767, 1213, 3223, 3643, 3021, 1098,
        4152, 1846, 3842, 1562])
Epoch: 1955, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 1956 - Batch 1 ########################
IDs in batch 1: tensor([3504, 2065, 2819, 3065,  809,  895,  352, 3379, 1913, 3874, 2804, 2980,
        1103,  735, 2483, 4124])
Epoch: 1956, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1957 - Batch 1 ########################
IDs in batch 1: tensor([1931, 2565, 1060, 3245, 1736, 2736,  907,  969, 2840, 3312, 2511, 1189,
        3253, 3664, 3360,  936])
Epoch: 1957, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1958 - Batch 1 ########################
IDs in batch 1: tensor([3865, 1195,  100, 3660, 2880,  229, 1730, 1489, 2402, 4126, 2039,  438,
        3183, 1287, 4016, 2066])
Epoch: 1958, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1959 - Batch 1 ########################
IDs in batch 1: tensor([1354, 1708,  586, 1780, 1977, 3448, 3951, 2824, 4027, 1931,  890, 1740,
        3498, 3963, 2574,   44])
Epoch: 1959, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1960 - Batch 1 ########################
IDs in batch 1: tensor([3658, 2317, 2386, 2251, 3474, 1927, 3616,  494, 4232, 2947, 2579, 3101,
        1354, 1024, 1779, 1501])
Epoch: 1960, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1961 - Batch 1 ########################
IDs in batch 1: tensor([ 937,  203,  673, 4027, 2847, 1668, 2500, 3913, 1356, 2974, 1084,  515,
        1962, 1344, 1099, 2552])
Epoch: 1961, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1962 - Batch 1 ########################
IDs in batch 1: tensor([4185, 3932, 2276, 2191, 1736,  989, 3863,  942,  434, 1887, 2587,  680,
        3255,  524, 2322,   43])
Epoch: 1962, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1963 - Batch 1 ########################
IDs in batch 1: tensor([ 498,  558,  167, 2827,  438, 3317, 2821, 2150, 2379, 1619, 3675, 1481,
        4053, 4204, 1892, 3351])
Epoch: 1963, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 1964 - Batch 1 ########################
IDs in batch 1: tensor([3789, 2265,  803,  568,  975, 3912, 3112, 1594, 1408, 1894,  535, 2277,
         986,  489, 3928, 3538])
Epoch: 1964, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1965 - Batch 1 ########################
IDs in batch 1: tensor([2857, 2978, 2760, 3538, 2688, 1648, 3496, 3466,  524, 1365,  605, 1590,
        1241, 1097, 1089, 2824])
Epoch: 1965, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1966 - Batch 1 ########################
IDs in batch 1: tensor([1543,  609, 2510, 3607, 1487, 2589, 1395, 3963, 1670,  100, 1389, 1120,
         689,  709, 2170, 3382])
Epoch: 1966, Training Loss: 0.26, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1967 - Batch 1 ########################
IDs in batch 1: tensor([2514, 4073, 1988, 2357, 2050, 1099, 4024, 1201, 4073, 3386, 1199,  781,
        2870, 3460, 2313,  857])
Epoch: 1967, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1968 - Batch 1 ########################
IDs in batch 1: tensor([4245, 1272, 1373,  520,   44, 1718, 2505, 1594, 3711, 2185, 3427,  485,
        2854, 3261, 1620, 3751])
Epoch: 1968, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1969 - Batch 1 ########################
IDs in batch 1: tensor([3537, 1345, 1022, 3253, 3487,  594, 3310,   71, 1509, 1982, 1981, 2387,
         786, 1066,  773, 1328])
Epoch: 1969, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1970 - Batch 1 ########################
IDs in batch 1: tensor([4037, 2132, 2509, 1218, 2144, 3151, 3379, 1049, 3851, 2632, 4234, 1349,
        2892, 1120, 3734, 3434])
Epoch: 1970, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 1971 - Batch 1 ########################
IDs in batch 1: tensor([3206, 1445, 3711, 2026, 4242, 2804, 3429, 2272, 3632, 1977, 3003,  578,
        1882, 3651,  490,  441])
Epoch: 1971, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1972 - Batch 1 ########################
IDs in batch 1: tensor([ 908,  377,  138, 3604,  102, 2229, 2212,  159, 3065, 1258, 2185, 1931,
        3354, 3100, 4096, 1611])
Epoch: 1972, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1973 - Batch 1 ########################
IDs in batch 1: tensor([2166,  439, 4135, 1602, 3673,  133, 2322, 2098, 1087, 1067, 1081, 2819,
        2871, 2518,  636,   86])
Epoch: 1973, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1974 - Batch 1 ########################
IDs in batch 1: tensor([3114,    7,   30, 2342, 2498, 1810, 3480, 2368, 4156, 1455,  584, 1182,
        2804, 1949,  936, 2798])
Epoch: 1974, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1975 - Batch 1 ########################
IDs in batch 1: tensor([ 308, 3087,  852, 1525, 2286, 2385, 1167, 3081, 4256, 3426,  287, 1880,
        2350,  689,  327, 1632])
Epoch: 1975, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1976 - Batch 1 ########################
IDs in batch 1: tensor([3409, 3958, 2798, 1346, 3624, 1297, 2942,  994, 3228, 3549, 2966, 1914,
        2419,  190, 4027, 2086])
Epoch: 1976, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1977 - Batch 1 ########################
IDs in batch 1: tensor([3543, 2874, 3310, 1239, 3812, 2106, 2618, 3530,  956, 1913, 2066, 1647,
        2751,  569, 2521, 4257])
Epoch: 1977, Training Loss: 0.33, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1978 - Batch 1 ########################
IDs in batch 1: tensor([ 565, 1504,  388, 3568, 3088,  355, 3000,  519,  469, 1933, 1747, 4240,
        2314,  873, 2518, 2367])
Epoch: 1978, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1979 - Batch 1 ########################
IDs in batch 1: tensor([3950,  884, 1266,  134, 3934, 3018,  920, 3908,  402, 1555, 1604, 1134,
        2552, 3976, 1819, 1299])
Epoch: 1979, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1980 - Batch 1 ########################
IDs in batch 1: tensor([2487, 1349, 3669,  888, 2443, 2653, 3698, 1761,  314, 2226, 1518, 4138,
        1740,  205,  207,  252])
Epoch: 1980, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1981 - Batch 1 ########################
IDs in batch 1: tensor([1325, 3025, 1835, 3751,  961,  821, 1125, 3474, 2963, 3499, 4110, 3807,
        3592, 2826,  962,  407])
Epoch: 1981, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1982 - Batch 1 ########################
IDs in batch 1: tensor([3616, 1376,  837, 1438,  665, 3490, 2332, 1336, 3593, 1740, 1787, 1509,
        3051,  341, 2641, 4061])
Epoch: 1982, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1983 - Batch 1 ########################
IDs in batch 1: tensor([3964, 1237, 2149, 1911, 1399, 2388, 2755, 3839, 1517, 1377, 2131,  221,
        1236, 1284, 2369, 1851])
Epoch: 1983, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1984 - Batch 1 ########################
IDs in batch 1: tensor([2348, 3874, 2169, 1065, 3609, 1822, 2738,  775,   30, 2401, 1762, 3698,
        2326, 1895, 1811,  714])
Epoch: 1984, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1985 - Batch 1 ########################
IDs in batch 1: tensor([2435, 2966, 1077,  823, 3875, 2721, 2060, 2590, 3539,  425, 3371,  617,
        2636, 3532, 1332, 2025])
Epoch: 1985, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1986 - Batch 1 ########################
IDs in batch 1: tensor([3570, 1680, 1594, 1632,   95, 1185, 1639,  152, 1504, 1870, 2109, 4133,
         252,   98, 2111, 1373])
Epoch: 1986, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1987 - Batch 1 ########################
IDs in batch 1: tensor([3772,  785,  393,  913, 3634, 3964, 1035, 1540, 2436, 3551, 1668,  967,
        1578, 2870,   27, 3202])
Epoch: 1987, Training Loss: 0.34, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1988 - Batch 1 ########################
IDs in batch 1: tensor([1236, 1555,  590, 1885, 2317, 2153, 1722, 1510, 2700, 2188,  568,  499,
        2475, 4088, 1718, 3745])
Epoch: 1988, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 1989 - Batch 1 ########################
IDs in batch 1: tensor([ 942,  656, 3279,  117, 1782, 3912, 2008, 3643, 1231, 1174, 1901, 2314,
        3912, 1234, 4157, 1921])
Epoch: 1989, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1990 - Batch 1 ########################
IDs in batch 1: tensor([3668, 1859,  134, 2867, 2347,  150, 2124, 2858, 3723, 1459, 2537, 2598,
        3523,  818, 2469, 2300])
Epoch: 1990, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 1991 - Batch 1 ########################
IDs in batch 1: tensor([3698, 3448, 2826, 2145, 2196, 1884, 1469, 3781, 2287, 2710, 3652, 3146,
        3340, 2189, 2752,  785])
Epoch: 1991, Training Loss: 0.76, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 1992 - Batch 1 ########################
IDs in batch 1: tensor([3668, 1780, 3764, 2680, 4226, 4253, 1296, 4205, 1421, 4089, 2176, 1044,
        2011,  887, 3581, 1512])
Epoch: 1992, Training Loss: 0.42, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1993 - Batch 1 ########################
IDs in batch 1: tensor([2506, 3755,  842, 1828,  987,  315, 1852,  184, 1266,  324, 1858, 1379,
        3342, 4115, 1469,   38])
Epoch: 1993, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1994 - Batch 1 ########################
IDs in batch 1: tensor([1567, 1821,  762, 1487,  862,   56,  419,  217, 2760, 3902, 3235, 1294,
        2443,  862, 2290, 2748])
Epoch: 1994, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1995 - Batch 1 ########################
IDs in batch 1: tensor([2483, 3430,  122,  280, 4118, 3078, 3523, 4198,  390, 1269, 2986,  971,
        4245,  327, 2758, 2523])
Epoch: 1995, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1996 - Batch 1 ########################
IDs in batch 1: tensor([1418, 1870, 1559, 2153, 3002, 2682,   41, 3669, 2998, 1233, 3300, 2144,
        3786, 3717,   88, 3338])
Epoch: 1996, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1997 - Batch 1 ########################
IDs in batch 1: tensor([1548,  284, 1921,  855, 2729, 3688, 3558,  203,  264, 3409, 2509, 2805,
        3150, 1010, 2642, 1984])
Epoch: 1997, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1998 - Batch 1 ########################
IDs in batch 1: tensor([2730, 3488,  550, 2458, 3919, 2859, 2590, 3895, 3659,   52, 2426,  550,
        1256, 3354, 2932, 2034])
Epoch: 1998, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 1999 - Batch 1 ########################
IDs in batch 1: tensor([3124, 3643, 2408, 3074, 2466, 3958, 2313, 1967, 3919, 2832, 2275, 2425,
        2470, 2860, 1641, 2552])
Epoch: 1999, Training Loss: 0.97, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2000 - Batch 1 ########################
IDs in batch 1: tensor([2571, 3898, 1764,  803, 2727, 3912, 2192, 2151, 3985, 2014, 3328,  909,
        2328, 2052, 4267, 1718])
Epoch: 2000, Training Loss: 0.38, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2001 - Batch 1 ########################
IDs in batch 1: tensor([3721, 2963,  649, 2603,  572,  995, 1206, 2451, 1748,  963, 3905,  555,
        3640,  348, 2740, 3738])
Epoch: 2001, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2002 - Batch 1 ########################
IDs in batch 1: tensor([3044, 1636, 1502, 1945, 2385,  134, 1478, 2731, 1636, 2853, 1957, 2282,
        4146, 2226, 2508, 2423])
Epoch: 2002, Training Loss: 0.31, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2003 - Batch 1 ########################
IDs in batch 1: tensor([3897,  380, 1088,  497, 2884, 3904, 3838, 2660, 4100, 1330, 3962, 3015,
        3290,  678,  986, 1420])
Epoch: 2003, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2004 - Batch 1 ########################
IDs in batch 1: tensor([3395, 2166,  841, 2265, 2249, 1334, 3199,  518, 2963, 2828, 3311, 1309,
        2732, 2015, 1167, 1858])
Epoch: 2004, Training Loss: 0.41, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2005 - Batch 1 ########################
IDs in batch 1: tensor([1761,  921, 1189, 1665, 2542, 1402, 4156, 2892,  727,  977, 3822, 4100,
         620, 2025, 3715, 3822])
Epoch: 2005, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2006 - Batch 1 ########################
IDs in batch 1: tensor([3529,  757,  656, 2996,  792, 2640, 2030, 1546, 1972,  160,  378, 1498,
        3658, 1624,  128, 2652])
Epoch: 2006, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2007 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2143, 3940, 2734, 2387,  928,  100, 3804, 2459, 1088, 3707, 3123,
          77,  882, 2022, 2253])
Epoch: 2007, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2008 - Batch 1 ########################
IDs in batch 1: tensor([1063, 3015, 2575, 3615, 2183, 1555, 4011, 3436, 3875, 4255,   43, 2030,
        2599, 4110, 4143, 2394])
Epoch: 2008, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2009 - Batch 1 ########################
IDs in batch 1: tensor([2016, 3548, 1568, 1869, 2131,  899,  944, 3451, 3036, 4007,   78, 4268,
        2853, 3497, 1083, 2433])
Epoch: 2009, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2010 - Batch 1 ########################
IDs in batch 1: tensor([2578, 2092,  445, 2253, 3222, 2264,  636, 2640,  808, 1233,  869,  352,
        3783,  425, 1481,  279])
Epoch: 2010, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2011 - Batch 1 ########################
IDs in batch 1: tensor([3352, 2352,  982,  119,  563, 2456,  612, 1700,  436,  983, 1221, 2854,
         785,  200, 4051, 4152])
Epoch: 2011, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2012 - Batch 1 ########################
IDs in batch 1: tensor([2115, 1751,  295, 1657, 1171, 1706, 3330,  302, 1755,  797, 1397, 3541,
          37, 3564, 3953,  463])
Epoch: 2012, Training Loss: 0.49, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2013 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 2489, 1973, 3309, 1415, 1279, 4119,  303,  441, 3246,  266, 2210,
        4133, 3769, 1879,   32])
Epoch: 2013, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2014 - Batch 1 ########################
IDs in batch 1: tensor([ 147, 1840, 3463, 1369,  391, 3349, 2148, 3115, 2402, 1647, 1935,  276,
        1364, 3286,  317, 2653])
Epoch: 2014, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2015 - Batch 1 ########################
IDs in batch 1: tensor([ 478, 2674, 2114, 2252, 1618,  245, 2142, 2641, 1012, 2017, 3954, 3680,
        1510,  438, 2388, 1390])
Epoch: 2015, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2016 - Batch 1 ########################
IDs in batch 1: tensor([  28,  781, 2031,  512, 3168, 2661, 1393, 3728,   10, 2461, 1041, 4253,
        3235,  835,  526, 3303])
Epoch: 2016, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2017 - Batch 1 ########################
IDs in batch 1: tensor([1761, 3751, 3930, 2781, 3278, 3351, 2581, 3398, 3432, 3406, 3387, 3053,
        1399,  947, 1773,  970])
Epoch: 2017, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2018 - Batch 1 ########################
IDs in batch 1: tensor([1590, 3326, 1530, 4246, 1026, 3151, 3807, 2506, 3194, 2849,  109,  219,
        3159, 2073, 2827,  303])
Epoch: 2018, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2019 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 3895, 2169, 2196, 2465, 2463, 2347, 2917, 3240, 1764, 3135, 3627,
        2863,  574, 3446,  382])
Epoch: 2019, Training Loss: 0.33, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2020 - Batch 1 ########################
IDs in batch 1: tensor([3447, 2204, 3303,  814, 3954, 3597, 1708, 3792, 2511, 3472, 3161, 3655,
         936, 2432, 3300, 2040])
Epoch: 2020, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2021 - Batch 1 ########################
IDs in batch 1: tensor([4225,  918,  377, 2514, 1507, 4203, 1636, 2734, 1648, 1551, 1274,  712,
        1911, 2382, 3655, 3545])
Epoch: 2021, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2022 - Batch 1 ########################
IDs in batch 1: tensor([2659, 1993, 3581, 2254, 2327, 1252, 1166, 1198,  848, 3832, 3197, 3353,
        1510,   10,  957,   92])
Epoch: 2022, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2023 - Batch 1 ########################
IDs in batch 1: tensor([ 852, 2121, 3604, 2902,  511, 2081, 3460,  492,  547,  516, 1861,  103,
         849, 2734, 2206, 1583])
Epoch: 2023, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2024 - Batch 1 ########################
IDs in batch 1: tensor([ 369, 1396,  943, 2529, 2324, 2155, 3831, 2252, 1900,   51, 1047, 1909,
        2157, 1853, 3974, 2046])
Epoch: 2024, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2025 - Batch 1 ########################
IDs in batch 1: tensor([1508, 2213, 3704,  583, 1027, 4195, 2947,  960, 2049,   15,  400, 3233,
        1279, 1711, 2439, 3660])
Epoch: 2025, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2026 - Batch 1 ########################
IDs in batch 1: tensor([2010,  257,  151, 3370,  595, 1369, 4234,  403, 1190, 3763, 2405,  111,
        2196, 3303,   22, 2465])
Epoch: 2026, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2027 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 2154, 2253, 4120, 1724, 1920,  667, 1787,  100,  813, 1375, 3552,
        2425,  488,  974,  811])
Epoch: 2027, Training Loss: 0.61, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2028 - Batch 1 ########################
IDs in batch 1: tensor([3112, 1437, 2391,  202, 1226,  277, 2192,  459, 3193,  971, 3544,  252,
        1810, 2907, 1126, 3398])
Epoch: 2028, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2029 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 3587,  852, 3632, 3190, 2352, 4103, 1651, 2746, 1885, 3529,  483,
        3287,   88, 1065, 4011])
Epoch: 2029, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2030 - Batch 1 ########################
IDs in batch 1: tensor([2149,  857, 1489,  649,  975, 1089,  155, 3537, 3031, 3267, 3755, 3930,
         637, 2461,  594, 2478])
Epoch: 2030, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2031 - Batch 1 ########################
IDs in batch 1: tensor([1153, 3632, 1161, 1909,  874, 2591, 3349, 1267, 1628, 2591, 3651, 1123,
        1614, 1376, 2111,  514])
Epoch: 2031, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2032 - Batch 1 ########################
IDs in batch 1: tensor([  32, 1247, 4146, 1545,  430, 2535, 4126, 2287, 3271, 3942, 2595, 2815,
        3570, 2350,   93, 2829])
Epoch: 2032, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2033 - Batch 1 ########################
IDs in batch 1: tensor([3813, 1346, 1012, 1947, 3275, 1136, 3401, 1802,  102,  106, 3709,  606,
         890, 4101,  442,  785])
Epoch: 2033, Training Loss: 0.37, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2034 - Batch 1 ########################
IDs in batch 1: tensor([3837, 2965, 4114, 4238,   28, 3023,  150, 1583, 1630, 1012,  788, 2780,
        2002, 1396,  994, 2401])
Epoch: 2034, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2035 - Batch 1 ########################
IDs in batch 1: tensor([2997, 3314, 3183, 1034, 3981, 3859, 1044, 1953, 1778, 2771,  529, 3486,
        3885, 2572, 3176, 1146])
Epoch: 2035, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2036 - Batch 1 ########################
IDs in batch 1: tensor([1417, 1601, 3743, 3367, 4236,  874,  888, 4114, 1409, 4101, 1463, 1073,
        1602, 1063, 3262,  135])
Epoch: 2036, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2037 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 1386, 4009, 2819, 3463, 2281,  924, 2999,  125, 4227, 1118,  987,
         640, 1004, 1765, 2674])
Epoch: 2037, Training Loss: 0.32, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2038 - Batch 1 ########################
IDs in batch 1: tensor([1152, 3160, 2261, 3692, 3039,  993, 4026, 3111, 2375, 1920,  678, 3469,
        2598, 3057, 2133, 1524])
Epoch: 2038, Training Loss: 0.43, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2039 - Batch 1 ########################
IDs in batch 1: tensor([1870, 2191,   95,  586, 2587,  926, 2230, 3127,  578, 2210, 3873, 2835,
          47, 1463, 1850,  190])
Epoch: 2039, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2040 - Batch 1 ########################
IDs in batch 1: tensor([3771,  520,   49, 1223, 3927, 2284,  538,  152, 4120,  424, 3772, 1369,
        2313, 3373,  305, 3242])
Epoch: 2040, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2041 - Batch 1 ########################
IDs in batch 1: tensor([1181, 2284, 1405, 1789,  320, 4046,   10,  816, 4118, 3672,   72, 1458,
         907, 2461, 3790, 1488])
Epoch: 2041, Training Loss: 0.58, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2042 - Batch 1 ########################
IDs in batch 1: tensor([4139,  368, 2555, 2796, 1973, 3099, 2337, 1457,  920, 4015, 1811,  891,
        4195, 2476, 2552,  333])
Epoch: 2042, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2043 - Batch 1 ########################
IDs in batch 1: tensor([1311, 1506, 2797,  888, 3226, 1649,  808, 3516,  348, 2011,   77,  820,
        1315, 3265, 3530, 3749])
Epoch: 2043, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2044 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 1979, 4195, 1318,   22,  290,  303, 1502, 3705,  143,  873, 2509,
        4140, 3444, 1822, 2036])
Epoch: 2044, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2045 - Batch 1 ########################
IDs in batch 1: tensor([ 257, 3272, 2522, 3135,  874, 2257, 1274, 1634, 1597, 1285,   96,  127,
        4099, 1370, 3200,  652])
Epoch: 2045, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2046 - Batch 1 ########################
IDs in batch 1: tensor([1762, 2973, 1673,   77,  252, 2661, 1458,  281, 3772, 1945,  373,  219,
        1410, 3847, 2196,  886])
Epoch: 2046, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2047 - Batch 1 ########################
IDs in batch 1: tensor([ 152,  869,  327, 1396, 2253, 3312,  444, 1458,  323,  727, 1279, 3410,
         407, 2035, 1286, 4251])
Epoch: 2047, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2048 - Batch 1 ########################
IDs in batch 1: tensor([1200, 3925,  870, 4139, 4046, 3569, 1385,   28, 1973,   18, 2056, 3258,
        1469,  771,  533, 1881])
Epoch: 2048, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2049 - Batch 1 ########################
IDs in batch 1: tensor([2682, 2970,  444,  401, 1734, 2373, 2957, 2787, 3343, 3202,   32, 3496,
        2553, 1624, 1604, 3437])
Epoch: 2049, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2050 - Batch 1 ########################
IDs in batch 1: tensor([1226,  104, 1030, 3298, 3333, 1391,  649, 4227, 3218, 1365, 2167, 3193,
        3991, 2013, 2367, 2134])
Epoch: 2050, Training Loss: 0.31, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2051 - Batch 1 ########################
IDs in batch 1: tensor([ 281, 1296,   52,  379,   61, 2508, 2943, 1010, 2090, 1152,  490, 3369,
        1024, 3121, 1226,  596])
Epoch: 2051, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2052 - Batch 1 ########################
IDs in batch 1: tensor([1748, 3896, 1853,  355, 3699, 1141, 1045, 2008, 2085, 1027,  523, 2857,
        1077, 1208, 3975, 4190])
Epoch: 2052, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2053 - Batch 1 ########################
IDs in batch 1: tensor([  52, 2355,  450, 3142, 1623, 1618, 2741, 3701, 2450,  821,  159, 1728,
        1965,  417, 2927,  953])
Epoch: 2053, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2054 - Batch 1 ########################
IDs in batch 1: tensor([1116, 2883, 1073, 1094,  442, 1650, 2681, 2408, 1920, 3473, 2934, 1530,
        3609, 1999, 4222, 2472])
Epoch: 2054, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2055 - Batch 1 ########################
IDs in batch 1: tensor([2261, 2648, 2938,  644, 3729, 4053, 3200, 3782,   18, 4105, 2876, 1819,
        2265, 1685, 1887,  936])
Epoch: 2055, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2056 - Batch 1 ########################
IDs in batch 1: tensor([3529,  143, 1754,  904, 3569, 2212, 2493, 2621, 2969, 4077, 2886, 3471,
        3336, 2667, 2579, 2614])
Epoch: 2056, Training Loss: 0.38, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 2057 - Batch 1 ########################
IDs in batch 1: tensor([1764, 1519, 2806, 3677, 1825, 1863, 2815, 2898, 1706, 3933, 4073, 2453,
        1117, 1762, 1201, 1056])
Epoch: 2057, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2058 - Batch 1 ########################
IDs in batch 1: tensor([2721, 1467, 3751, 3094,  842,  785,  191, 2133, 3607, 1762, 1104, 1317,
        1369, 3976, 4135, 1444])
Epoch: 2058, Training Loss: 0.44, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2059 - Batch 1 ########################
IDs in batch 1: tensor([3862, 4055, 2088, 3065, 1971, 1467, 3343, 3743, 4051, 3497, 1239,  316,
        3842, 1469, 3382, 1130])
Epoch: 2059, Training Loss: 0.54, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2060 - Batch 1 ########################
IDs in batch 1: tensor([ 532,  436, 3480, 2703, 2614, 2781, 1658, 2462, 2391, 2621,  842, 2213,
           5, 2600, 4254, 2802])
Epoch: 2060, Training Loss: 0.29, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2061 - Batch 1 ########################
IDs in batch 1: tensor([2879,  377, 4035, 2727, 3873, 2831, 4073,  750, 2723, 3256, 3333, 3049,
        1866,  397, 3337, 3977])
Epoch: 2061, Training Loss: 0.55, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2062 - Batch 1 ########################
IDs in batch 1: tensor([1985, 1994, 2191, 2656, 2555, 1034, 2103, 3283, 3607, 1711, 1869, 3677,
        4097, 2876, 1123,  803])
Epoch: 2062, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2063 - Batch 1 ########################
IDs in batch 1: tensor([3498, 3132, 3950,  646, 2350,  615,  221, 1551,  892, 1948, 1498, 2347,
        3812, 2098, 3997, 3516])
Epoch: 2063, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2064 - Batch 1 ########################
IDs in batch 1: tensor([1781, 3896, 1039, 1234, 4189, 2885, 3015, 3994,  505, 1634, 3437, 1044,
        1007, 1065,  807, 3926])
Epoch: 2064, Training Loss: 0.45, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2065 - Batch 1 ########################
IDs in batch 1: tensor([1641, 2166, 4134,  838,  808,  137, 3199, 3356, 2327, 2181, 2866, 2589,
        3911, 3282, 3211, 3953])
Epoch: 2065, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2066 - Batch 1 ########################
IDs in batch 1: tensor([3342,  289, 1096, 1272, 2003, 1752, 3088, 1206,  122, 3851, 2282, 2245,
        1979, 2182,  701, 1545])
Epoch: 2066, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 2067 - Batch 1 ########################
IDs in batch 1: tensor([2924, 3056,  851, 4149, 3582, 3082,  588, 1782, 1722, 1752, 1455, 1429,
        1455, 2760, 3503, 1951])
Epoch: 2067, Training Loss: 0.21, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2068 - Batch 1 ########################
IDs in batch 1: tensor([1532, 3389, 2036, 1763,  200, 2517, 1026, 3058, 3779, 2839, 4084, 1133,
        1737, 2146, 3284, 2732])
Epoch: 2068, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2069 - Batch 1 ########################
IDs in batch 1: tensor([1381, 1808,  741, 3234, 4072, 2851, 2555, 2624, 1733, 3673, 3588, 3176,
         974, 2901, 1373, 1835])
Epoch: 2069, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2070 - Batch 1 ########################
IDs in batch 1: tensor([3873, 4025, 1984, 2833, 2494, 1206, 3003, 2045, 3082, 3447, 3386,  794,
         657, 3082, 3370, 2189])
Epoch: 2070, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2071 - Batch 1 ########################
IDs in batch 1: tensor([2476, 1143, 2347, 3151, 3433, 1221, 2884, 1933, 2587, 2166, 2825, 3181,
        1798,  529, 3956,  315])
Epoch: 2071, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2072 - Batch 1 ########################
IDs in batch 1: tensor([3769, 2715, 3268, 2342,  201, 2993, 1349, 2075, 3557, 3723, 3964, 1634,
        3142, 3568,  603, 4007])
Epoch: 2072, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2073 - Batch 1 ########################
IDs in batch 1: tensor([2835,  942, 1399, 3016, 1283, 1098, 2401,  774, 2880, 2960, 1069, 1589,
        1699, 3812, 3671, 3078])
Epoch: 2073, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2074 - Batch 1 ########################
IDs in batch 1: tensor([3401, 3151, 1690, 3888,  121, 3976, 3078, 1043, 3829,  750, 2800,   59,
        2796, 2323, 3627, 1730])
Epoch: 2074, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2075 - Batch 1 ########################
IDs in batch 1: tensor([2542, 1020, 2572,  100, 1251, 1909, 3698, 2663, 2015, 2901, 2120, 3895,
        1190, 1388,  908, 2885])
Epoch: 2075, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2076 - Batch 1 ########################
IDs in batch 1: tensor([1767, 3700,  519, 2582, 3723, 3535,  891,   21, 2495,  417, 3749, 1799,
        2309,  596,  225,  417])
Epoch: 2076, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2077 - Batch 1 ########################
IDs in batch 1: tensor([4146,  846,  244,  362,  112, 3379,  387, 4117,  102, 2287, 1372,  808,
        1157, 1275,  184,  133])
Epoch: 2077, Training Loss: 0.72, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2078 - Batch 1 ########################
IDs in batch 1: tensor([2514, 2180,  773, 1025, 2710, 2712, 1765, 2327, 2555, 2126, 3473, 3339,
        2523, 4008, 4135,  463])
Epoch: 2078, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2079 - Batch 1 ########################
IDs in batch 1: tensor([1677, 3953,  380, 3830,  749,  475,  752, 2553, 3141, 1911, 1444, 4030,
        4261, 4086, 2399, 1799])
Epoch: 2079, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2080 - Batch 1 ########################
IDs in batch 1: tensor([2122, 3024,  827, 1984, 3360, 1476, 3894, 3815,  953, 1399, 1384, 2449,
        3518, 2373, 1611, 1128])
Epoch: 2080, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2081 - Batch 1 ########################
IDs in batch 1: tensor([3408,  848, 1171,  952,  713, 1125, 2828, 3739, 4015, 3020,  584, 3896,
        1821, 1056, 1525, 3790])
Epoch: 2081, Training Loss: 0.40, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2082 - Batch 1 ########################
IDs in batch 1: tensor([2581, 3489, 3047, 2538, 3399, 2595, 3391, 2479, 3852, 2884, 2440, 1312,
        1913, 2157, 3437,  808])
Epoch: 2082, Training Loss: 0.73, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2083 - Batch 1 ########################
IDs in batch 1: tensor([1154, 2322, 2731, 4026,  278, 1320,  217, 1038, 3039, 1174, 1868, 1641,
        1945, 3485, 1772, 4017])
Epoch: 2083, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2084 - Batch 1 ########################
IDs in batch 1: tensor([ 555, 3757,  908,  622, 2423, 3035, 1377, 1668, 3640, 2212, 1651, 1730,
        1305, 1255, 3810, 3993])
Epoch: 2084, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2085 - Batch 1 ########################
IDs in batch 1: tensor([1860, 2309,  105,  902,  667, 3548, 3329,  205, 2967, 2949,  384, 1894,
        1647,   73, 3400, 1295])
Epoch: 2085, Training Loss: 0.39, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2086 - Batch 1 ########################
IDs in batch 1: tensor([ 620, 2337,  258, 4039,  755, 2839,  206,  159, 1761, 4033, 4187, 1497,
         292,  652, 1402, 2858])
Epoch: 2086, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2087 - Batch 1 ########################
IDs in batch 1: tensor([3036, 1458, 3279, 2031, 1070, 3009, 2597, 1229,  777, 1313, 4135, 4185,
        3283, 1116, 3480, 2688])
Epoch: 2087, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2088 - Batch 1 ########################
IDs in batch 1: tensor([2334,  112, 2591, 3635, 2500, 1388, 3696,  342, 1821, 4065, 4261, 1201,
         430,  317, 3009, 1043])
Epoch: 2088, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2089 - Batch 1 ########################
IDs in batch 1: tensor([3688, 3340, 2561, 1559, 3147, 3936, 2537, 1932, 4222, 2132, 2488,  459,
        1024, 2232, 2262, 3057])
Epoch: 2089, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2090 - Batch 1 ########################
IDs in batch 1: tensor([ 252, 2950, 3692,   22, 3252, 2890, 2954, 3751, 1223, 2023, 1463, 1671,
        1765, 2943, 4230, 3669])
Epoch: 2090, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2091 - Batch 1 ########################
IDs in batch 1: tensor([4038, 2282, 3143, 3564, 1532, 2620, 3490,  390, 2070, 1994, 1726, 2377,
        2258, 1639,  263,  432])
Epoch: 2091, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2092 - Batch 1 ########################
IDs in batch 1: tensor([2974, 3342, 3283, 2478, 4235,  350, 2541, 4124, 1956,  237, 1923, 1782,
         855, 2894, 2496, 2645])
Epoch: 2092, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2093 - Batch 1 ########################
IDs in batch 1: tensor([ 895, 2632, 1835, 1556,  440, 3990, 2278, 1094,  747, 1216, 3831,  184,
         136, 1543, 3478, 3415])
Epoch: 2093, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2094 - Batch 1 ########################
IDs in batch 1: tensor([4119, 2279, 3497,  252, 1084, 3715,  691, 2298, 1051,  723, 2414, 2005,
        1623, 2794, 3719, 4251])
Epoch: 2094, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2095 - Batch 1 ########################
IDs in batch 1: tensor([1312, 1971, 1645, 3511, 1740, 1126, 1352,  723, 4134, 3206, 1677, 2051,
         743, 4070, 2940, 1484])
Epoch: 2095, Training Loss: 0.68, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2096 - Batch 1 ########################
IDs in batch 1: tensor([ 340, 2565,  338, 4170, 2629,  658, 3178, 2297, 2249, 2899,  343,  747,
        1023, 1125, 1045, 2271])
Epoch: 2096, Training Loss: 0.48, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2097 - Batch 1 ########################
IDs in batch 1: tensor([1007, 2166, 1753, 3248,   21, 3996,  434, 4000,  900, 2535, 1182, 2617,
        3668, 3604, 1961, 2388])
Epoch: 2097, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2098 - Batch 1 ########################
IDs in batch 1: tensor([2331, 3120, 1331, 1679, 3065, 3025, 3871, 1285,  452, 1733, 2247, 4152,
        3256, 4236, 1414,  955])
Epoch: 2098, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2099 - Batch 1 ########################
IDs in batch 1: tensor([2401, 3951, 2091, 2934, 2885, 2983, 1933, 2681, 3204,  475, 2891, 1872,
        1069, 1679,  823, 3060])
Epoch: 2099, Training Loss: 0.45, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2100 - Batch 1 ########################
IDs in batch 1: tensor([2305, 3375, 1775, 2462, 3903, 3499,  660,  547, 3535,  934, 2921, 2017,
         555, 4218,  666, 3883])
Epoch: 2100, Training Loss: 0.59, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2101 - Batch 1 ########################
IDs in batch 1: tensor([4069,  606,   26,  145, 2772, 2226, 1482,  635, 3521, 3878, 2312, 3185,
        3621, 1851,  337, 2320])
Epoch: 2101, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2102 - Batch 1 ########################
IDs in batch 1: tensor([3717, 2620, 2451, 1134,  350,  596, 3822, 1935,  934, 1070, 3960, 3640,
         964, 3276, 3439, 1364])
Epoch: 2102, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2103 - Batch 1 ########################
IDs in batch 1: tensor([2312, 1485, 2348, 3569, 2967, 2005, 3810, 2524, 2212, 1796, 2771, 2009,
        1480,  131,  900,  149])
Epoch: 2103, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2104 - Batch 1 ########################
IDs in batch 1: tensor([1281, 2014, 4242,   98, 2652, 1117, 1734, 2954, 2897, 3715, 2112, 1467,
        1567, 1428, 1878,  258])
Epoch: 2104, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2105 - Batch 1 ########################
IDs in batch 1: tensor([ 978,  954, 3939, 4015, 1977, 1156,  967, 2523, 2902, 2069,  680, 2562,
        2014, 3120,   61,  894])
Epoch: 2105, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2106 - Batch 1 ########################
IDs in batch 1: tensor([1633, 2044, 2511,  789, 1756, 3912, 2879, 1286, 2192, 3664, 3091,  520,
        2743, 3202, 1723, 2812])
Epoch: 2106, Training Loss: 0.47, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2107 - Batch 1 ########################
IDs in batch 1: tensor([ 275,  444,  164, 1281, 1595, 2617, 1305,   26,   28, 3969, 1277,  873,
         917, 2181, 1457, 3647])
Epoch: 2107, Training Loss: 0.41, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2108 - Batch 1 ########################
IDs in batch 1: tensor([3988, 2244, 2180, 2398, 1961, 2980,  937, 3921, 3976,  727, 1418, 1458,
         869, 2545, 1320, 2511])
Epoch: 2108, Training Loss: 0.47, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2109 - Batch 1 ########################
IDs in batch 1: tensor([1263,  321, 3118, 2691, 2137, 1752, 2599,  472, 1850, 1811, 3843, 2848,
        1197, 2018, 1376, 1480])
Epoch: 2109, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2110 - Batch 1 ########################
IDs in batch 1: tensor([3747,   20, 3389, 2546, 1899, 1891, 2575, 2406,  794, 2883, 1351, 1159,
          44, 2366, 3534, 1825])
Epoch: 2110, Training Loss: 0.38, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2111 - Batch 1 ########################
IDs in batch 1: tensor([4087,  520, 3642, 3126, 1418, 1318, 1201,  966, 2638, 2548, 3042, 3327,
        1372,  352,  936,  340])
Epoch: 2111, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2112 - Batch 1 ########################
IDs in batch 1: tensor([1959,  995, 1509, 3485,  612, 2483, 1178, 2500,  373, 2285,  318, 3744,
        1077,  724,  941, 1611])
Epoch: 2112, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2113 - Batch 1 ########################
IDs in batch 1: tensor([4008,  537,  841, 1120, 1047,  871, 1016, 3845, 3628, 2255, 2121, 3836,
        3818,   49,  475, 1457])
Epoch: 2113, Training Loss: 0.51, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2114 - Batch 1 ########################
IDs in batch 1: tensor([ 315, 2773, 3166, 1232, 2711, 3712, 1094, 2383, 3238,  920, 2841,  937,
        1500, 1299, 3123,  536])
Epoch: 2114, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2115 - Batch 1 ########################
IDs in batch 1: tensor([2959, 3423, 1822,  878,  839, 2797, 3743, 3438, 1558, 2978, 3894, 1281,
        1177, 1397,  409, 1656])
Epoch: 2115, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2116 - Batch 1 ########################
IDs in batch 1: tensor([3406,  360, 3223, 2242,  830, 2440, 2706, 3933, 1098, 2519, 4188,  658,
        1877, 3654, 2620, 1986])
Epoch: 2116, Training Loss: 0.28, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2117 - Batch 1 ########################
IDs in batch 1: tensor([1679, 2280, 1685, 2238, 2799,   78,  281, 4016, 3267, 1201, 2322, 3504,
          95,  601, 3329, 2275])
Epoch: 2117, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2118 - Batch 1 ########################
IDs in batch 1: tensor([3151, 3654, 1189, 2880, 3160,  439, 2615, 2173,  131, 1453,  871,  994,
        1595,  873, 3581,  139])
Epoch: 2118, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2119 - Batch 1 ########################
IDs in batch 1: tensor([4008,  986,   56, 3336, 3693, 3362,  899,  822, 4200,  140,   60,   15,
         981,  975, 4017, 3525])
Epoch: 2119, Training Loss: 0.27, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2120 - Batch 1 ########################
IDs in batch 1: tensor([1045, 2317,  741, 2656,  287,  171,  488, 2167, 2587, 3377, 2475,  969,
        2169, 4084, 4200,  139])
Epoch: 2120, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2121 - Batch 1 ########################
IDs in batch 1: tensor([4085, 2180, 1098, 1035, 2960, 1170, 2087, 1571, 2444, 3004, 3156,  161,
        2369,  673, 2773, 2794])
Epoch: 2121, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2122 - Batch 1 ########################
IDs in batch 1: tensor([1892, 2598, 1213, 1044, 3615, 3807, 3123, 2118, 3272,   98, 2726,   14,
         805,  637, 2469, 3975])
Epoch: 2122, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2123 - Batch 1 ########################
IDs in batch 1: tensor([1158, 2689,  835,  778,  848, 2842,  553, 2868, 1508,  823, 3496, 2060,
        1408, 4152, 4077, 2499])
Epoch: 2123, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2124 - Batch 1 ########################
IDs in batch 1: tensor([1567, 1316,  150, 3707, 4128, 2819, 1802,  400, 3178, 3885, 3197, 2715,
        2688, 1069,  245, 2223])
Epoch: 2124, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2125 - Batch 1 ########################
IDs in batch 1: tensor([3847, 1646, 3540,  145, 2173, 2234, 1963,  497,  360, 3833, 2970,  994,
        3610, 3914, 1178, 3020])
Epoch: 2125, Training Loss: 0.45, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2126 - Batch 1 ########################
IDs in batch 1: tensor([1031, 1057,   95, 2577, 3042, 1532,  306,  134, 2795, 4249, 3336, 3387,
        3470, 1979, 2137, 3501])
Epoch: 2126, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2127 - Batch 1 ########################
IDs in batch 1: tensor([2332, 2320, 1220, 3143,  375,  459, 3309, 1282, 1008, 2219,  109, 3428,
        1869, 3010, 2492, 2371])
Epoch: 2127, Training Loss: 0.31, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2128 - Batch 1 ########################
IDs in batch 1: tensor([3091, 3074, 1409, 3342, 2237, 2154, 3945, 2805, 1818,   70, 1044, 1712,
        3391,  419, 2258, 2357])
Epoch: 2128, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2129 - Batch 1 ########################
IDs in batch 1: tensor([3055,  620, 1965, 3780,  455,  685, 3729, 3878, 2026, 2242, 1536, 3127,
         869, 1704, 1030, 3282])
Epoch: 2129, Training Loss: 0.36, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2130 - Batch 1 ########################
IDs in batch 1: tensor([4032, 1472, 2666, 1563, 1770,  259,  435, 2484, 3744, 3544, 1809, 2986,
        2280, 3738, 4003, 2752])
Epoch: 2130, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2131 - Batch 1 ########################
IDs in batch 1: tensor([2969, 3017,  109, 3299, 1955, 1617, 1096, 3018, 1509, 2144, 4128,  985,
          50, 3360, 2480,  713])
Epoch: 2131, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2132 - Batch 1 ########################
IDs in batch 1: tensor([2943, 2999, 1698, 2236, 2915, 2993, 1026, 3009, 2450, 3534, 4179,  426,
        1309, 3404, 3432,  171])
Epoch: 2132, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2133 - Batch 1 ########################
IDs in batch 1: tensor([1916, 1258,  952,  441, 1573, 2524, 1811, 3236, 3711, 4157, 1673,  439,
         709,  511, 2765, 2695])
Epoch: 2133, Training Loss: 0.46, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2134 - Batch 1 ########################
IDs in batch 1: tensor([2671,  538, 3208, 1344, 2727, 1442, 2116, 2247, 3439,  755, 3822, 1249,
        3072, 1415,  160, 1376])
Epoch: 2134, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2135 - Batch 1 ########################
IDs in batch 1: tensor([ 465, 3643,  773, 2787,  670, 2157, 4126, 3299, 3699, 1154, 3538,  368,
        1959, 4228, 2348, 3196])
Epoch: 2135, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2136 - Batch 1 ########################
IDs in batch 1: tensor([3200, 3425, 4189, 1647, 2828, 3250, 4229, 3479, 2347, 1614, 2373,  170,
        3591,  354, 3570, 4049])
Epoch: 2136, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2137 - Batch 1 ########################
IDs in batch 1: tensor([2548,  821, 3914, 2182, 4235, 3497, 1274, 1196, 1124, 1154,  151, 2118,
        3113, 1299, 2480, 2041])
Epoch: 2137, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2138 - Batch 1 ########################
IDs in batch 1: tensor([4093, 2299,  781, 2996,  914, 1977,  161, 1154,   88, 3469, 1817, 2564,
        3351, 3123, 1655,  102])
Epoch: 2138, Training Loss: 0.34, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2139 - Batch 1 ########################
IDs in batch 1: tensor([1730, 3829,  956, 3453, 4203, 1685, 2616, 2717, 1082, 1178, 2668, 2736,
        2868, 4058, 1753, 3729])
Epoch: 2139, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2140 - Batch 1 ########################
IDs in batch 1: tensor([1954, 1384, 1093, 3108, 1543,  773, 3672,  969, 2863, 2761, 3211, 1200,
        4144, 2999, 2170, 2356])
Epoch: 2140, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2141 - Batch 1 ########################
IDs in batch 1: tensor([2179,  341, 2991, 2095, 1381, 1269, 2179,  776, 2423, 1761, 1193, 2841,
         391, 1051, 3415, 2436])
Epoch: 2141, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2142 - Batch 1 ########################
IDs in batch 1: tensor([4181,   26,   34, 2219, 1521, 2641,   51, 1672,  766,   81, 3455, 1754,
         970,  379, 1041, 1128])
Epoch: 2142, Training Loss: 0.68, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2143 - Batch 1 ########################
IDs in batch 1: tensor([3356,  341, 1225, 2448, 4036, 3511, 3699,  140, 2802,  821, 2051, 2632,
        3484, 2477, 1434,  212])
Epoch: 2143, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2144 - Batch 1 ########################
IDs in batch 1: tensor([3021, 4027, 3044, 3872,  314, 3426, 2632, 2794, 1891, 1916, 3427, 3860,
        3797,   34,  988, 1292])
Epoch: 2144, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2145 - Batch 1 ########################
IDs in batch 1: tensor([2036, 1119, 1120, 2030, 2169,  544,  497, 4056, 3101,  818, 3469,  832,
        3564, 3999, 3701, 2697])
Epoch: 2145, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2146 - Batch 1 ########################
IDs in batch 1: tensor([1111, 2788, 3756, 4166, 4006,  914, 2416, 2149, 2954, 3010,  198,   50,
        1948, 3032, 2439, 1982])
Epoch: 2146, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2147 - Batch 1 ########################
IDs in batch 1: tensor([1623, 1851,   21, 2517, 1320, 2261,  593,  137,  995,  572,  591,  991,
        1632, 3219,  455, 3521])
Epoch: 2147, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2148 - Batch 1 ########################
IDs in batch 1: tensor([2013, 2070, 1218, 3470, 3733, 2586, 1755, 2086,  942, 2902,  635,  343,
        3217, 3003, 2991,  890])
Epoch: 2148, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2149 - Batch 1 ########################
IDs in batch 1: tensor([3435, 1214,  195,  790, 1844, 3206, 3139, 1043, 1083, 3101, 2281, 2924,
        4099, 2466, 2824,  862])
Epoch: 2149, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2150 - Batch 1 ########################
IDs in batch 1: tensor([1094,  558, 3733, 3547,  636, 2516, 3940, 3105, 3147,  236, 3368, 2468,
        2731, 2013, 2567, 2529])
Epoch: 2150, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2151 - Batch 1 ########################
IDs in batch 1: tensor([ 274, 1752, 1931,  120,  236, 2788,  881, 1626,   50, 1177, 2511, 2468,
        1377, 2650, 2217, 4234])
Epoch: 2151, Training Loss: 0.31, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2152 - Batch 1 ########################
IDs in batch 1: tensor([2053, 3698, 1158, 4186, 1521, 2506, 3711, 1404, 2145, 4065, 1183, 1047,
        1200,   52, 1090, 3525])
Epoch: 2152, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2153 - Batch 1 ########################
IDs in batch 1: tensor([3437, 3194,  897, 1206, 2652,  943,  694, 3135, 1208, 2788, 2541,  232,
        1698, 2546,  195,  872])
Epoch: 2153, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2154 - Batch 1 ########################
IDs in batch 1: tensor([3582, 4014,  566,  949, 1175,  263,  426, 3953,  243,  609, 4134, 3388,
        2368, 2359, 2603, 2103])
Epoch: 2154, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2155 - Batch 1 ########################
IDs in batch 1: tensor([ 337, 2279,  459, 3659, 1218, 1098, 2133, 2664, 2508, 3481, 2817,  797,
        1085, 1677, 2640, 1370])
Epoch: 2155, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2156 - Batch 1 ########################
IDs in batch 1: tensor([ 418,  680, 2504, 1803, 2153,  636, 4095, 2317, 1968, 3554, 2610,  546,
        1491, 1613, 4040,  969])
Epoch: 2156, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2157 - Batch 1 ########################
IDs in batch 1: tensor([3592, 3885, 4013,  422,  888, 3789, 2632, 3642, 2356, 4000, 2947, 2703,
        4008, 2721, 3391,  568])
Epoch: 2157, Training Loss: 0.38, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2158 - Batch 1 ########################
IDs in batch 1: tensor([2739, 2823, 3779, 3914, 3529, 2729, 1672, 2393, 3842, 3945,  691,  849,
         884, 3179, 1162, 2819])
Epoch: 2158, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2159 - Batch 1 ########################
IDs in batch 1: tensor([1173, 3673, 1224, 2236, 2440, 2094, 3461, 2848, 2320, 2907, 3833, 1881,
        2418,  829, 3677, 4217])
Epoch: 2159, Training Loss: 0.49, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2160 - Batch 1 ########################
IDs in batch 1: tensor([1921, 3734, 1404, 1370,  537, 1049,  367, 1367,   61,  943, 3117, 2106,
         966, 3194, 1764, 2423])
Epoch: 2160, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2161 - Batch 1 ########################
IDs in batch 1: tensor([3837, 2764, 4197, 2721, 2650,  333, 3430, 2135,  412, 1645, 3291, 2228,
         855, 2126,  557,  440])
Epoch: 2161, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2162 - Batch 1 ########################
IDs in batch 1: tensor([2141, 3084, 3223, 2724, 3821,  194, 1045, 4108, 2917,  587,  255, 3704,
        1613, 3081, 2403,  678])
Epoch: 2162, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2163 - Batch 1 ########################
IDs in batch 1: tensor([2181, 3535, 4117,  183, 3438, 1432, 2708, 3227, 2620, 4158,  342,   52,
        4038,  928, 3881, 1589])
Epoch: 2163, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2164 - Batch 1 ########################
IDs in batch 1: tensor([2837, 2589, 3940, 3904, 3749, 3898,  899,  424, 3757, 1332, 2924, 4036,
        2328, 2110, 1208, 2010])
Epoch: 2164, Training Loss: 0.32, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2165 - Batch 1 ########################
IDs in batch 1: tensor([1501, 3036, 2510, 2885,   68, 1459,  899,   28,  896, 1823, 3658, 1794,
        1369, 1455, 2278, 4121])
Epoch: 2165, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2166 - Batch 1 ########################
IDs in batch 1: tensor([3441, 1996, 2292, 2989, 1318, 3781, 2080, 1341, 1399, 2405, 1012, 2176,
         850,  858, 1571,  226])
Epoch: 2166, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2167 - Batch 1 ########################
IDs in batch 1: tensor([2426, 1970, 3368, 1732, 3485,  372, 2359, 1099, 3826,  883,  604, 3304,
        2107, 1855,  326,  788])
Epoch: 2167, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2168 - Batch 1 ########################
IDs in batch 1: tensor([4076, 1453,  983, 2524,   39, 1376, 3111, 2155,  490, 2984, 4225, 1496,
         977, 2018, 3841, 1999])
Epoch: 2168, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2169 - Batch 1 ########################
IDs in batch 1: tensor([ 908,  477,  117,   25, 1193, 3312, 1733, 2912, 2989, 2255, 4070, 1454,
        4056, 4044, 1763, 1902])
Epoch: 2169, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2170 - Batch 1 ########################
IDs in batch 1: tensor([1090, 4094, 1408, 1076, 3016, 2370,  481, 1343, 2050, 1911, 4125, 3621,
        2828,  269, 1153,  482])
Epoch: 2170, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2171 - Batch 1 ########################
IDs in batch 1: tensor([1232, 1982, 3102, 2372, 3833, 3439, 1295, 2748, 3524, 2504, 3948, 2835,
        2257, 2449, 3531, 1170])
Epoch: 2171, Training Loss: 0.37, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2172 - Batch 1 ########################
IDs in batch 1: tensor([1745, 3816,  483, 1902, 2295, 4232,  424, 2238, 2732,  997,  653, 3604,
        2832,  332,  376, 2746])
Epoch: 2172, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2173 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 1910,  684, 2287,  388, 2210, 3465,  520,  577, 2964, 2354, 2741,
        2262, 1241, 3702,  213])
Epoch: 2173, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2174 - Batch 1 ########################
IDs in batch 1: tensor([2514, 4003, 2536,   10, 1901, 2510, 2383,  308, 4015, 2764, 3282, 2085,
         413, 4084, 2410, 3074])
Epoch: 2174, Training Loss: 0.34, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2175 - Batch 1 ########################
IDs in batch 1: tensor([3493, 1518, 3617, 1436, 2190, 2466, 1752,  584, 1574, 3960, 2740,  775,
        3552, 3342, 1004, 2023])
Epoch: 2175, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2176 - Batch 1 ########################
IDs in batch 1: tensor([3878, 3271,  546, 1008, 3938, 3903, 2132, 4146, 1863, 4093, 4226, 4215,
        1923, 1519, 3557, 2584])
Epoch: 2176, Training Loss: 0.74, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2177 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 2564, 2218,   43, 1281,  674, 1235, 1718,  825,   62, 1281, 3874,
        1937, 2641, 1413, 3702])
Epoch: 2177, Training Loss: 0.36, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2178 - Batch 1 ########################
IDs in batch 1: tensor([2973, 2526, 2099, 2377, 2092, 4049,  689, 2954,  710, 3751, 2206, 3060,
        1518, 3501, 1767, 3078])
Epoch: 2178, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2179 - Batch 1 ########################
IDs in batch 1: tensor([3430, 3196, 2254, 1264, 2131, 1457, 3453,  181, 2592, 2173,  833,  342,
        3286, 2161, 2737, 4011])
Epoch: 2179, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2180 - Batch 1 ########################
IDs in batch 1: tensor([4218, 2314,  380, 1274, 3298, 3970, 2999, 4200, 2040,  439, 3227, 1173,
         351, 2584, 1640, 2005])
Epoch: 2180, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2181 - Batch 1 ########################
IDs in batch 1: tensor([ 904, 2858,  574, 1617, 2332, 2182, 3856,  149, 2898,  212, 3238, 2730,
        1206, 2656, 1181, 1960])
Epoch: 2181, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2182 - Batch 1 ########################
IDs in batch 1: tensor([3446, 3100, 3016,  819, 3568, 2989,  401, 4007, 1005, 2338, 2959,  434,
        1911,  194, 1835, 3204])
Epoch: 2182, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2183 - Batch 1 ########################
IDs in batch 1: tensor([1310, 3997, 2899, 2548, 3875, 1279, 2090, 3394, 2234, 3016, 3503,  866,
        2604, 2905, 3568, 2004])
Epoch: 2183, Training Loss: 0.48, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2184 - Batch 1 ########################
IDs in batch 1: tensor([3406, 2209, 3927, 1639, 1196, 3692, 3279,  963, 1218, 3489,  660,  813,
        1962, 2394, 3144,  602])
Epoch: 2184, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2185 - Batch 1 ########################
IDs in batch 1: tensor([3241, 2341, 3486, 1895, 2229,  727, 4057, 3734,  729, 2290, 1005,  145,
         165,  397, 2833, 1512])
Epoch: 2185, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2186 - Batch 1 ########################
IDs in batch 1: tensor([ 315,   34, 2423, 3389, 1180,  732, 2363, 1028, 3648, 2825, 3973, 3220,
        2341, 3480, 3551, 2860])
Epoch: 2186, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2187 - Batch 1 ########################
IDs in batch 1: tensor([3614, 3593, 1868, 2191, 2895,  482, 3891, 2179, 3481,  846,  394, 3712,
         965,  487,  239,   42])
Epoch: 2187, Training Loss: 0.40, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2188 - Batch 1 ########################
IDs in batch 1: tensor([ 841, 1720,  120,  515, 2276, 1487, 4172, 1487, 4140,  185,  359, 3818,
        2189,  846, 1034, 1189])
Epoch: 2188, Training Loss: 0.89, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2189 - Batch 1 ########################
IDs in batch 1: tensor([3074, 3558, 3832, 2936, 2326, 2226, 2044,  546, 3253, 1380, 1618,  459,
         318,  843, 2113, 3895])
Epoch: 2189, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2190 - Batch 1 ########################
IDs in batch 1: tensor([2688, 3337,  816,  803, 2258, 3407, 2117, 3435,  108, 2242, 1061, 3250,
        2353, 1333, 3745, 3123])
Epoch: 2190, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2191 - Batch 1 ########################
IDs in batch 1: tensor([1108, 2219, 3968, 1469, 3674, 3327,  119, 2143, 1035, 3156,  717, 4095,
        3223, 2758, 3604, 1588])
Epoch: 2191, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2192 - Batch 1 ########################
IDs in batch 1: tensor([1559, 2218, 1850, 2177,  943,  354,  726,  954, 1500, 2884,  199,  553,
        3120, 4170, 2080, 1133])
Epoch: 2192, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2193 - Batch 1 ########################
IDs in batch 1: tensor([ 355,  499, 2018,  825,  488,   18, 4051,  873, 4099, 1684, 3358, 2056,
        1236, 1355,  207,  282])
Epoch: 2193, Training Loss: 0.53, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2194 - Batch 1 ########################
IDs in batch 1: tensor([2764, 3338,  207, 2624, 3481, 2650, 1062, 2153, 1206, 1299, 3922, 3390,
          25, 3092, 2505, 1996])
Epoch: 2194, Training Loss: 0.44, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2195 - Batch 1 ########################
IDs in batch 1: tensor([3583, 1290, 1504, 1675, 3525,  674, 3256, 2703, 1322, 1795, 3344,  610,
        1673, 3207, 2364, 4110])
Epoch: 2195, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2196 - Batch 1 ########################
IDs in batch 1: tensor([2386,    7,  872, 1223,  792, 3885, 3764, 1256, 3006, 1786, 3410, 3585,
        3456,   31,  779, 2870])
Epoch: 2196, Training Loss: 0.31, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2197 - Batch 1 ########################
IDs in batch 1: tensor([3704, 2349, 3188, 3123,  405, 1733, 3643, 3156,   13, 1044, 2664,  335,
        2529, 2329, 1429, 1170])
Epoch: 2197, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2198 - Batch 1 ########################
IDs in batch 1: tensor([2349, 2177, 1698,  342, 2784, 4100, 2535, 3306,  236, 1289, 1404, 1967,
        2149, 1518,  606,  945])
Epoch: 2198, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2199 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 3465, 1641,  789, 2550, 1670, 2316, 2278, 3663, 3432, 2253, 3069,
        1365, 3018,  678, 3371])
Epoch: 2199, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2200 - Batch 1 ########################
IDs in batch 1: tensor([ 141, 3756, 2851, 3711, 3700, 3278, 3696,  496,  257, 3113,  646, 1591,
        3490, 2479, 2829, 1408])
Epoch: 2200, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2201 - Batch 1 ########################
IDs in batch 1: tensor([1895,  601, 3177, 3366, 3908, 4110, 3823, 1723, 3882, 3233, 1751, 3083,
        1645, 3489, 3539,   86])
Epoch: 2201, Training Loss: 0.44, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2202 - Batch 1 ########################
IDs in batch 1: tensor([1333, 3505,  312, 1324, 4204,  926, 3197, 1250, 2251, 1007, 1228, 2674,
        2552, 2882, 1371, 2522])
Epoch: 2202, Training Loss: 0.26, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2203 - Batch 1 ########################
IDs in batch 1: tensor([ 822,  128, 4114, 3963,  991, 1390, 1132, 2444, 2718, 3545, 2244, 3243,
        4135, 2102, 1836,   95])
Epoch: 2203, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2204 - Batch 1 ########################
IDs in batch 1: tensor([2347, 2170, 1863, 1009,  874, 3298,  558, 3328, 4114, 1712, 2632, 1467,
        3764, 1312, 1830,  738])
Epoch: 2204, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2205 - Batch 1 ########################
IDs in batch 1: tensor([3044, 4235, 4108, 1887, 1233,  508, 2371, 1634,  993, 2189,  965, 2708,
        4065, 1866, 3084,  986])
Epoch: 2205, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2206 - Batch 1 ########################
IDs in batch 1: tensor([3651, 1020,  815, 3244, 2035, 3197, 1316, 2291,  434, 2013, 3469,  355,
        2867, 1310, 2064,  219])
Epoch: 2206, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2207 - Batch 1 ########################
IDs in batch 1: tensor([2276,  478, 1087, 3031, 3343,  892, 3990, 3308, 4224,  526, 3031,  556,
        2431, 3002, 2413, 2390])
Epoch: 2207, Training Loss: 0.33, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2208 - Batch 1 ########################
IDs in batch 1: tensor([ 985, 1306, 2561, 4009, 3904, 3964, 2457, 1200, 4227, 3253, 2671, 1540,
          25, 3581, 3460,  980])
Epoch: 2208, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2209 - Batch 1 ########################
IDs in batch 1: tensor([1728, 2383,  834,  524, 1892, 3932,  252, 1292, 2298, 2854,  139, 2108,
        1251,  532,  211, 1334])
Epoch: 2209, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2210 - Batch 1 ########################
IDs in batch 1: tensor([1070,   81,  250,  214,  881,  735, 2544,  676, 1104,  482,  688, 3756,
        1981,  436, 2095, 2697])
Epoch: 2210, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2211 - Batch 1 ########################
IDs in batch 1: tensor([2907, 1509, 3637, 2902, 1984,  105, 1457, 1328, 2347, 1589,  507, 1141,
        2777, 2452,  418, 2103])
Epoch: 2211, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2212 - Batch 1 ########################
IDs in batch 1: tensor([3476, 1951, 4057,  218, 1297, 1488,  265, 3507,   15, 1173, 1583, 3388,
        3621, 4197, 1414, 2703])
Epoch: 2212, Training Loss: 0.32, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2213 - Batch 1 ########################
IDs in batch 1: tensor([3358,  834, 3207,  434, 3782, 3135, 3369, 3042, 1680, 3968,  194,    4,
        3276, 1128,  917, 1684])
Epoch: 2213, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2214 - Batch 1 ########################
IDs in batch 1: tensor([2235, 3826, 2060, 3338, 3729,   25, 4007, 3176,  796, 1974, 2254, 1602,
         524,  997, 3787, 3192])
Epoch: 2214, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2215 - Batch 1 ########################
IDs in batch 1: tensor([2967,  278, 3718, 1421, 2034,  151, 1530, 3081, 2159, 1357, 3949, 1707,
        1496, 2499,  710,  758])
Epoch: 2215, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2216 - Batch 1 ########################
IDs in batch 1: tensor([3960, 2669, 4049, 2857, 1511,  463, 1959,  415,  628, 1619, 4116, 2840,
        2198, 1543, 3808,  121])
Epoch: 2216, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2217 - Batch 1 ########################
IDs in batch 1: tensor([3222, 1540, 3398, 2298, 2924,  351,  947, 1633, 4095,  469,  774, 1536,
         508, 1436, 1575, 1251])
Epoch: 2217, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2218 - Batch 1 ########################
IDs in batch 1: tensor([ 756, 2341, 2739, 3101,  630, 3261, 2317,  758,  225, 3856, 2669, 2765,
        4094, 1216, 1458, 3618])
Epoch: 2218, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2219 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 1413, 3363,  904, 3111, 1389, 2098, 3002, 2292,  955, 2178, 2851,
        2204,  964, 1650, 2363])
Epoch: 2219, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2220 - Batch 1 ########################
IDs in batch 1: tensor([1463, 3969, 2982, 3425, 1274, 1633, 1842, 3751, 4157, 2642, 2732, 1627,
         904, 1892, 2969, 3701])
Epoch: 2220, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2221 - Batch 1 ########################
IDs in batch 1: tensor([3032, 3372, 4085, 1579, 2724,  346, 4072,  809, 1423, 1452, 1315,  894,
         441, 3706, 1379, 3184])
Epoch: 2221, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2222 - Batch 1 ########################
IDs in batch 1: tensor([1123, 2825,  513, 4268, 3222, 2678, 3267, 2610,  280, 1727, 3782, 2170,
         945, 3238, 3259, 3968])
Epoch: 2222, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2223 - Batch 1 ########################
IDs in batch 1: tensor([3543, 2837, 3487,  533,  266,  201, 4226,  818, 1858,  212,  926,  125,
        3304, 1999, 1985, 2770])
Epoch: 2223, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2224 - Batch 1 ########################
IDs in batch 1: tensor([2583,  827, 3672, 4116, 3661, 2204, 3368, 1846, 2526, 1496, 2352, 3157,
        2827, 1730, 2009, 4240])
Epoch: 2224, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2225 - Batch 1 ########################
IDs in batch 1: tensor([ 191, 2831, 3058, 3999,  956,  828, 3258, 4103, 1979, 3336, 3121, 3025,
        3162, 1748, 1385,  277])
Epoch: 2225, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2226 - Batch 1 ########################
IDs in batch 1: tensor([2998, 1573, 1599,  362,  221, 1281,  397, 3789, 1630,  781, 3498, 1810,
        3114, 3161, 2886,  630])
Epoch: 2226, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2227 - Batch 1 ########################
IDs in batch 1: tensor([2085, 3069, 3408, 3352, 3018, 3065, 4222, 2616,  757,  591, 3016,  236,
         305, 2771,  345, 3689])
Epoch: 2227, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2228 - Batch 1 ########################
IDs in batch 1: tensor([1084, 1981, 2478, 3621, 3144, 4200, 4213, 2514, 1685, 1525, 3168, 1229,
        1193,   26, 2078, 4228])
Epoch: 2228, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2229 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 1562,   25,  680,  512, 3789,  673, 1580,  606,  534, 1306, 3526,
        2299, 1904, 2449,  996])
Epoch: 2229, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2230 - Batch 1 ########################
IDs in batch 1: tensor([ 395, 4114, 4234,  379, 2839, 3407, 3545,  302, 1084, 2727, 3246, 3354,
          39, 1454, 2931, 1979])
Epoch: 2230, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2231 - Batch 1 ########################
IDs in batch 1: tensor([1892,  928, 1218,  662,  323, 2220, 3812, 1942, 1748, 2125, 2871,  738,
        1464, 2306, 1733, 1782])
Epoch: 2231, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2232 - Batch 1 ########################
IDs in batch 1: tensor([1413, 1558,  187, 3036, 1566,  245, 1686, 3885,  378, 2256, 3651, 2485,
        4067, 2069,  969, 1072])
Epoch: 2232, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2233 - Batch 1 ########################
IDs in batch 1: tensor([3564, 3081, 3903, 3706, 2465,   74, 2938,  887, 2332,  873,  943, 2150,
        2015, 3911, 1014, 3493])
Epoch: 2233, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2234 - Batch 1 ########################
IDs in batch 1: tensor([ 326, 1237, 3100, 1143, 1168, 3452,  871,  126,  610, 2031,  712,  701,
        2763, 1684, 3111, 2572])
Epoch: 2234, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2235 - Batch 1 ########################
IDs in batch 1: tensor([2548, 3112,  472, 4061, 3640, 4026, 3146, 2998, 3354, 1467, 1196, 3603,
        2789, 2280,   26, 1938])
Epoch: 2235, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2236 - Batch 1 ########################
IDs in batch 1: tensor([1409,  523, 3927, 2463, 2516,  777, 1601,  308, 2300,  490,  674,  981,
        1784,  888, 1050,  475])
Epoch: 2236, Training Loss: 0.51, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2237 - Batch 1 ########################
IDs in batch 1: tensor([1138, 1954, 1455, 3425, 2238, 3131, 3764, 1312,   19, 3858, 2135, 4014,
        3757,  459, 2901, 3635])
Epoch: 2237, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2238 - Batch 1 ########################
IDs in batch 1: tensor([1167,  274, 3455, 2388, 3217, 3238, 3344, 1176, 3755,  287, 2131, 3925,
        2231, 1467,  884, 1229])
Epoch: 2238, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2239 - Batch 1 ########################
IDs in batch 1: tensor([2912,  356, 3632, 1341, 2022, 3661, 2859, 1375, 3000, 2224, 3753, 1852,
         788, 1849,  588, 3020])
Epoch: 2239, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2240 - Batch 1 ########################
IDs in batch 1: tensor([3557, 4181, 1891, 4267, 1473, 2805, 4152, 2494, 3258, 1116, 1183, 1334,
        2305, 2435, 2080, 3859])
Epoch: 2240, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2241 - Batch 1 ########################
IDs in batch 1: tensor([2451,  952,  786, 4157, 1198,   43,  767, 3121, 1328,  988, 3599,  538,
        2902, 3676, 2134, 3216])
Epoch: 2241, Training Loss: 0.27, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2242 - Batch 1 ########################
IDs in batch 1: tensor([ 332, 2961, 2671, 2343, 2876, 1567, 4049, 3913,  871, 2681, 3795, 1128,
        1793, 1488,  281, 1241])
Epoch: 2242, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2243 - Batch 1 ########################
IDs in batch 1: tensor([1731, 3852, 1782, 2028, 4044, 1866,  262, 3177, 2544, 2301, 1678, 2974,
        3123, 1010,  388, 2822])
Epoch: 2243, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2244 - Batch 1 ########################
IDs in batch 1: tensor([2376, 3597, 3429,  180, 1067, 3483, 2242, 3975, 3721, 3582, 3187, 1679,
        3047, 2795, 2476, 4184])
Epoch: 2244, Training Loss: 0.53, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2245 - Batch 1 ########################
IDs in batch 1: tensor([ 276, 2781, 3250, 1347, 2999, 1132, 4105,  672, 1881, 2982,  896, 1067,
        1005, 1321, 3028,  769])
Epoch: 2245, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2246 - Batch 1 ########################
IDs in batch 1: tensor([3300, 1575, 2433, 3651, 2036,   35, 3353, 2478, 4140, 3284,  515, 3600,
        2019,    4, 3478, 2150])
Epoch: 2246, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2247 - Batch 1 ########################
IDs in batch 1: tensor([2949, 3636, 2692, 3573, 1937, 4136, 2965,  281, 1668, 1821, 1818,  519,
        3614, 3674,  138,  183])
Epoch: 2247, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2248 - Batch 1 ########################
IDs in batch 1: tensor([1668, 2212, 1954, 2672, 2998,  490,  747, 2019, 2574, 4014, 2085, 4214,
         767, 2859, 2796, 4008])
Epoch: 2248, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2249 - Batch 1 ########################
IDs in batch 1: tensor([2965, 3721, 1325, 2290, 3000, 4110, 2828,   30, 1884, 2886,   93, 3126,
        2644, 2595, 3866,  662])
Epoch: 2249, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2250 - Batch 1 ########################
IDs in batch 1: tensor([1247, 3150, 1229, 1102,  409, 2671, 2016,  774, 3071, 3179, 3017,  770,
        2382,  465, 1904, 2851])
Epoch: 2250, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2251 - Batch 1 ########################
IDs in batch 1: tensor([ 982, 2990, 3713,  482,  389, 2964, 3192, 3056, 3382, 3907, 4186,  164,
        1602, 2551, 2783, 4033])
Epoch: 2251, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2252 - Batch 1 ########################
IDs in batch 1: tensor([1772, 2369, 1234, 4125,   57, 2017, 1419, 1287, 2540, 2457, 2236, 1795,
        3956, 1822, 3075, 1006])
Epoch: 2252, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2253 - Batch 1 ########################
IDs in batch 1: tensor([2726,  340,  220, 4154, 3680, 1376, 3951, 3589,  850, 1285, 2478, 1647,
        2135, 2045,  160, 3542])
Epoch: 2253, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2254 - Batch 1 ########################
IDs in batch 1: tensor([ 961, 1968, 3091, 1872, 1375, 2038, 1585, 2355, 3525,  953, 1426,  218,
        2664, 2455,  610,  279])
Epoch: 2254, Training Loss: 0.27, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2255 - Batch 1 ########################
IDs in batch 1: tensor([3616, 3262, 3286, 3278, 1260, 1658, 3688, 1312,   93,  337,   14, 3496,
        2542, 1081, 3478,  147])
Epoch: 2255, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2256 - Batch 1 ########################
IDs in batch 1: tensor([1718, 3108,  358, 1225, 1084, 2328, 1223, 1970, 3914, 3802, 2964, 3781,
        1720, 1975, 3032,  825])
Epoch: 2256, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2257 - Batch 1 ########################
IDs in batch 1: tensor([ 646, 3640, 1312,  689, 1521,  499,  851, 1761, 1661,  356, 3258, 2912,
        3392, 1780, 3834,  408])
Epoch: 2257, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2258 - Batch 1 ########################
IDs in batch 1: tensor([3588, 1372, 2297, 3368, 3182, 2094, 3912, 2371, 1054, 3309, 3378, 1728,
        1312, 1414, 1185, 3131])
Epoch: 2258, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2259 - Batch 1 ########################
IDs in batch 1: tensor([3407,  287, 2176, 1894, 2885, 3424, 3635, 3598, 3367, 2614, 2960, 3616,
         396, 3384, 2475, 3221])
Epoch: 2259, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2260 - Batch 1 ########################
IDs in batch 1: tensor([3139, 3081,  367, 2085, 2407, 1777, 1157, 2996, 1574,  874,  238,  306,
        2597, 3192,  508, 2907])
Epoch: 2260, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2261 - Batch 1 ########################
IDs in batch 1: tensor([3014, 3009, 3534, 1646, 1497, 4234,  757, 1255, 3506, 3083, 2123, 3630,
        1567, 1232, 1032,  411])
Epoch: 2261, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2262 - Batch 1 ########################
IDs in batch 1: tensor([4120, 2907, 1726,  441, 1028, 2275, 3187, 2989, 1473,  284, 1470,  593,
        1012, 2805, 2912, 2014])
Epoch: 2262, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2263 - Batch 1 ########################
IDs in batch 1: tensor([3589, 3818, 4140, 2967, 1414, 2360, 1171, 1080, 2092,  220, 1235,   31,
        3003, 1937, 4076, 1200])
Epoch: 2263, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2264 - Batch 1 ########################
IDs in batch 1: tensor([3430, 2484,  111, 2787,  259, 2727, 4115, 1786, 1642, 3874, 2782,  137,
        3928, 3460, 2890, 2664])
Epoch: 2264, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2265 - Batch 1 ########################
IDs in batch 1: tensor([3187, 3440, 2689, 3318, 4234, 4085,  229, 1660,  987, 1897,   74, 1057,
        2874, 1341, 1241,  351])
Epoch: 2265, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2266 - Batch 1 ########################
IDs in batch 1: tensor([2391, 1682, 1223, 3030, 3241, 4030, 1504, 2854, 3187,  682, 2653, 1490,
         672, 1419, 3956, 2286])
Epoch: 2266, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2267 - Batch 1 ########################
IDs in batch 1: tensor([1595, 2844, 2041, 3021,  448, 3994, 1490, 2169, 3992,  535, 3142, 2423,
        3850, 2693, 2898, 1570])
Epoch: 2267, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2268 - Batch 1 ########################
IDs in batch 1: tensor([2347,  266, 1886, 2044, 3321, 2403,  554, 1641, 1646, 1999, 1241, 1668,
        2075, 3765, 3197, 2755])
Epoch: 2268, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2269 - Batch 1 ########################
IDs in batch 1: tensor([3108,  876, 3992, 1351, 2822, 1487, 3518, 1819, 3136, 2120,  657, 1277,
        2550, 1003, 1678, 1161])
Epoch: 2269, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2270 - Batch 1 ########################
IDs in batch 1: tensor([3006, 3816, 1163, 2145,  379, 4159, 1508, 1954,  323,  683, 1196, 2642,
        2111, 2013, 4131, 1996])
Epoch: 2270, Training Loss: 0.31, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2271 - Batch 1 ########################
IDs in batch 1: tensor([3321, 2099, 2882,  827, 2529,  122, 2286, 2721, 1891, 2851, 3329, 3159,
         422, 1174, 2337, 3286])
Epoch: 2271, Training Loss: 0.37, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2272 - Batch 1 ########################
IDs in batch 1: tensor([1241, 3261,  897, 2292,  661,  854, 2115, 1497,  373, 2764, 1001, 3818,
        1226,  247, 1278,  792])
Epoch: 2272, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2273 - Batch 1 ########################
IDs in batch 1: tensor([2484,  832, 1102, 2038, 3022, 1349,  260, 2664, 4014,  151, 2885,  326,
           4, 1372, 1332,  437])
Epoch: 2273, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2274 - Batch 1 ########################
IDs in batch 1: tensor([ 763, 1498,  455,  129, 1589, 4235, 1381, 3020,  463, 3398, 2874, 3894,
        2796, 1308, 2826, 1345])
Epoch: 2274, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2275 - Batch 1 ########################
IDs in batch 1: tensor([3842, 2110,  794, 2329, 4141, 3147, 4240, 2428, 2287, 3468, 1162, 2117,
        3680,  448, 2791,  866])
Epoch: 2275, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2276 - Batch 1 ########################
IDs in batch 1: tensor([ 261, 2373, 2465, 1291, 3734, 3317, 1444,   68, 3421, 3895, 3813, 2452,
        1711, 2731, 3732, 2949])
Epoch: 2276, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2277 - Batch 1 ########################
IDs in batch 1: tensor([4119, 2751, 4228, 2272,  535, 3493, 1578,  365, 1480, 3669, 1086, 4236,
        2149, 1226,  393, 2761])
Epoch: 2277, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2278 - Batch 1 ########################
IDs in batch 1: tensor([ 259, 4163, 2661, 3872,  400, 2464, 1305, 2439,  237, 1241, 2951, 1879,
        3199, 1935, 3956,   32])
Epoch: 2278, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2279 - Batch 1 ########################
IDs in batch 1: tensor([1319, 1731, 1336, 1981,  750,  274, 3760, 2676, 2244, 1623, 2230, 3930,
        4230, 3388, 3990, 1472])
Epoch: 2279, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2280 - Batch 1 ########################
IDs in batch 1: tensor([1241, 2555,  794,  282, 1294,  924, 1628, 3374, 1553, 1370, 2470,   50,
        2369, 3468, 3127, 1862])
Epoch: 2280, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2281 - Batch 1 ########################
IDs in batch 1: tensor([4053, 3366, 1159, 2338, 2153,  667, 2265, 1977,  389, 2024, 3806, 3533,
         214,  936, 2157, 3121])
Epoch: 2281, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2282 - Batch 1 ########################
IDs in batch 1: tensor([4254, 3589, 1291,   84,  343, 3101,  160, 1247, 3465, 1251,  954, 2209,
        3127, 1935,  403,  120])
Epoch: 2282, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2283 - Batch 1 ########################
IDs in batch 1: tensor([3228, 2581, 3353, 1518, 2995,  833,  622, 3582, 2870, 1405, 4030, 2066,
        2937,  469,   20, 1067])
Epoch: 2283, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2284 - Batch 1 ########################
IDs in batch 1: tensor([ 892,  825, 2192, 1335, 2292,  282,  427, 2690, 2052, 2853,  678,  565,
        3582, 1312, 2225, 1611])
Epoch: 2284, Training Loss: 0.13, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2285 - Batch 1 ########################
IDs in batch 1: tensor([1536,  488, 1650, 2793, 3781,  436, 2403, 3162, 2478,  961, 4026, 3236,
         419, 2112, 3430, 3497])
Epoch: 2285, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2286 - Batch 1 ########################
IDs in batch 1: tensor([1984,  875, 4215, 3439, 3236, 2847, 2592, 2908, 1026, 2387, 3190, 3572,
        3102, 2255, 2271, 3235])
Epoch: 2286, Training Loss: 0.94, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2287 - Batch 1 ########################
IDs in batch 1: tensor([3831, 3337, 1026, 1050, 1770, 1459, 4186, 2523, 2036, 1034, 2583,  324,
        1994, 3313, 1592, 3544])
Epoch: 2287, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2288 - Batch 1 ########################
IDs in batch 1: tensor([2026, 1552, 2812, 3677,  752, 1251,  475, 2913, 4265, 2646, 1432,  389,
         632,  170, 4125, 3919])
Epoch: 2288, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2289 - Batch 1 ########################
IDs in batch 1: tensor([3073, 1080, 1857,  101,  890,  205, 3112, 2169, 2715, 2564, 3656, 4099,
        3704, 3148, 1103, 3652])
Epoch: 2289, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2290 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 2439, 3529, 1731,  812, 1711, 3698,  109, 3323, 1083, 3453, 1107,
         852, 1073, 3015, 1920])
Epoch: 2290, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2291 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 1232, 3345,  796, 1935, 1069, 1938,   26,  786, 1734, 3330,  665,
        1297, 1363, 2285, 2898])
Epoch: 2291, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2292 - Batch 1 ########################
IDs in batch 1: tensor([1641,  369,  751,  991, 2797, 1283, 3718, 3166,  361, 3459, 2789, 4065,
        1006, 3734, 2969, 3039])
Epoch: 2292, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2293 - Batch 1 ########################
IDs in batch 1: tensor([4190, 1656, 2870, 2696,  747,  691,  496,  238, 3409, 4089,  394, 2189,
        2678,   52, 3353, 3108])
Epoch: 2293, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2294 - Batch 1 ########################
IDs in batch 1: tensor([1096, 1988, 4144, 3688, 2441,  536,  363, 2582,  796, 2403, 1942, 3453,
        1374, 3675, 1670, 2571])
Epoch: 2294, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2295 - Batch 1 ########################
IDs in batch 1: tensor([ 432,  876, 1371, 3609, 1968, 4196,  544, 1180, 2736, 1990, 2641,  740,
        2056,   62, 2936,   41])
Epoch: 2295, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2296 - Batch 1 ########################
IDs in batch 1: tensor([2146, 4035, 3421, 1269, 3688, 3782, 2414, 1702, 1343, 2956, 1054, 4229,
        1039,  763,  701,  182])
Epoch: 2296, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2297 - Batch 1 ########################
IDs in batch 1: tensor([2693, 2284, 2110, 1311,  503, 1305, 2052,  327, 4136, 2306,   25, 2546,
        1084, 3698, 3084, 1111])
Epoch: 2297, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2298 - Batch 1 ########################
IDs in batch 1: tensor([ 987, 3217, 3497,  613, 1034,  741, 2390,  601, 3467, 2913, 2551, 2376,
        2627, 3523, 2676, 3021])
Epoch: 2298, Training Loss: 0.53, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2299 - Batch 1 ########################
IDs in batch 1: tensor([1570, 3271, 1297, 3593,  813,  872, 3729,   95, 2572, 4255, 3911, 2364,
        4006, 3128,  523, 3904])
Epoch: 2299, Training Loss: 0.40, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2300 - Batch 1 ########################
IDs in batch 1: tensor([ 252, 3627, 1153, 2376, 1132, 2357,  200, 1072, 2102, 2236, 1337, 2372,
         583,  730, 3945, 3241])
Epoch: 2300, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2301 - Batch 1 ########################
IDs in batch 1: tensor([3875,   92, 1583, 1356, 2030,  873,  829, 1583, 3756, 2067, 3318, 1996,
        3284,  199, 2161, 3500])
Epoch: 2301, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2302 - Batch 1 ########################
IDs in batch 1: tensor([3465, 4018, 4141, 1711, 1645, 1490,  921, 1918, 4095, 3705,  679, 1119,
        3615,  199,  842, 2806])
Epoch: 2302, Training Loss: 0.58, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2303 - Batch 1 ########################
IDs in batch 1: tensor([1611, 1405, 2075, 3975, 1397, 4186, 2452, 1507,  277, 3433,  234, 2030,
        4254, 1162, 4056, 3505])
Epoch: 2303, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2304 - Batch 1 ########################
IDs in batch 1: tensor([ 821,  444, 1088, 2235, 1699, 1075, 3712, 2936, 1817, 1208, 2022,  418,
        1567, 2973, 3407, 3530])
Epoch: 2304, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2305 - Batch 1 ########################
IDs in batch 1: tensor([2151, 3135, 1627,  978, 1351, 1740, 2752, 3079, 3466, 1375, 3052, 2073,
        2376, 2133, 1636, 2003])
Epoch: 2305, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2306 - Batch 1 ########################
IDs in batch 1: tensor([2271, 3598,  515, 2472, 3980, 3614, 2595,  219, 2650, 2207,  855, 2087,
         213, 2452, 1933, 1476])
Epoch: 2306, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2307 - Batch 1 ########################
IDs in batch 1: tensor([2597, 2393, 2991, 1167, 3638, 3883, 1284, 1558,  161, 3524, 2493,  185,
         893, 1885, 4266,  738])
Epoch: 2307, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2308 - Batch 1 ########################
IDs in batch 1: tensor([ 849, 4115, 3564,  893, 3715, 3714, 3688,  398, 1228,  730, 3964, 1933,
        3024, 3671, 1482, 2376])
Epoch: 2308, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2309 - Batch 1 ########################
IDs in batch 1: tensor([3785, 1196, 3536, 1763, 3397, 2099,  394,  910, 2250, 1294, 1130, 1845,
        2483, 1938, 3856, 2189])
Epoch: 2309, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2310 - Batch 1 ########################
IDs in batch 1: tensor([ 195, 3465, 1753, 3630,  657, 2555, 2552, 3922,  808, 3599, 2256, 4133,
         980,  274, 4232,  207])
Epoch: 2310, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2311 - Batch 1 ########################
IDs in batch 1: tensor([1810,   61, 1257, 1895, 1344,  937, 2112, 2755, 2601,  445, 1779,   14,
        2548, 3424,  279, 1371])
Epoch: 2311, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2312 - Batch 1 ########################
IDs in batch 1: tensor([3161, 2482,  709, 2169, 4051, 1605, 3244, 4051,  287, 1686, 2636, 2771,
          59, 2052, 2807, 1059])
Epoch: 2312, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2313 - Batch 1 ########################
IDs in batch 1: tensor([ 992, 1761, 1252, 2854, 3312, 3888,  375,  184, 3866, 1499, 2196, 1597,
        4049, 3705, 1860, 1826])
Epoch: 2313, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2314 - Batch 1 ########################
IDs in batch 1: tensor([ 126, 3131, 1882, 2275, 2632,   47, 1309, 2018,  278,  963, 3786, 2464,
        1851, 3079, 3131, 2649])
Epoch: 2314, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2315 - Batch 1 ########################
IDs in batch 1: tensor([4227, 2784, 1901,  949, 3271, 3668, 1009, 4125,  522, 3244, 3298, 1933,
        1734,  604, 2682, 3487])
Epoch: 2315, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2316 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 1499,  259, 1034, 1823, 3414, 1860, 2498, 1026,  781, 2516,  232,
        3540, 2592,  691, 4067])
Epoch: 2316, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2317 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 1316,  219, 1439, 1287, 4181,  712, 1042, 2844, 2382, 1588, 3527,
        1833, 2800,  490, 3157])
Epoch: 2317, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2318 - Batch 1 ########################
IDs in batch 1: tensor([2943, 3392, 4251,  467, 1567, 3954, 3220, 3381, 1904,  154, 3843, 2137,
         680, 2354, 1166,  636])
Epoch: 2318, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2319 - Batch 1 ########################
IDs in batch 1: tensor([ 969, 2575,   97,   50, 1971, 3891, 2145,  379, 2890, 3075, 3406,  103,
        2606,   41, 3504, 1396])
Epoch: 2319, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2320 - Batch 1 ########################
IDs in batch 1: tensor([1179, 2483, 3988, 1062, 3711, 1347, 3663, 2407, 1152,  942,  397, 3667,
        3668, 2353, 1141, 2295])
Epoch: 2320, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2321 - Batch 1 ########################
IDs in batch 1: tensor([ 970, 2537, 3501, 3404, 3065, 1070,  200, 3913,  983, 4022,   97, 3132,
        3925, 1752,   49, 1425])
Epoch: 2321, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2322 - Batch 1 ########################
IDs in batch 1: tensor([1117,  537, 2965, 1600,  236, 3018, 3995, 1765, 1576, 2117, 1934, 2229,
        2492, 2886, 2371,    7])
Epoch: 2322, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2323 - Batch 1 ########################
IDs in batch 1: tensor([2456, 4048, 1722, 3585, 1773,  942, 1977, 2213, 3024, 2299, 2410, 1413,
        3150, 3022, 3756, 3932])
Epoch: 2323, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2324 - Batch 1 ########################
IDs in batch 1: tensor([1459, 1255, 2134,  373,  398, 1887,  961, 3948, 2309, 4220, 1152, 3951,
         149, 1896, 2045, 3834])
Epoch: 2324, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2325 - Batch 1 ########################
IDs in batch 1: tensor([3981, 2848, 1296, 3329, 4048, 3476,  497, 3538, 3110, 3962,  206, 2050,
         851, 1960, 1579, 3355])
Epoch: 2325, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2326 - Batch 1 ########################
IDs in batch 1: tensor([ 318,  471, 2934, 3495, 1093,  335,  228, 3404,  790,  603,  360, 3856,
        3656,  180, 4037, 2035])
Epoch: 2326, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2327 - Batch 1 ########################
IDs in batch 1: tensor([2324, 3530,  967, 1885, 1464, 3627, 1484, 1851,  529, 3418,  583, 2432,
        2863, 3016, 2876, 1491])
Epoch: 2327, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2328 - Batch 1 ########################
IDs in batch 1: tensor([ 232, 2151, 2337, 2592, 4121, 1677, 1722, 3818, 3927, 3278, 1536, 4013,
        1331, 2242, 3461,  988])
Epoch: 2328, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2329 - Batch 1 ########################
IDs in batch 1: tensor([1218, 4136, 3032, 2483, 1605, 3447, 3470, 1968,  969,  388, 1290,  245,
        2726, 1809, 2500, 3704])
Epoch: 2329, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2330 - Batch 1 ########################
IDs in batch 1: tensor([2586, 3255, 1973, 1942, 1613, 3166, 3136,  170,  714, 2146, 1795, 2104,
        4154, 2314, 3843, 1219])
Epoch: 2330, Training Loss: 0.65, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2331 - Batch 1 ########################
IDs in batch 1: tensor([2973,  526, 2782, 1397, 1083, 1221, 1131,  887,  763, 3667, 2256, 2368,
        2231, 2610, 3808, 2399])
Epoch: 2331, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2332 - Batch 1 ########################
IDs in batch 1: tensor([1377, 2367, 2156, 4143, 2708, 2882, 4009,  184, 2331,    5, 1763, 2558,
        3265, 4010, 2755, 3321])
Epoch: 2332, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2333 - Batch 1 ########################
IDs in batch 1: tensor([2468, 1213,  535, 3991, 2473, 1320, 1349, 2132,  252, 4194, 2153,  978,
        3131, 2851,  849,  357])
Epoch: 2333, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2334 - Batch 1 ########################
IDs in batch 1: tensor([2225,  554, 3870,  770, 2645, 2045, 3746,  395, 3272,  710, 2956, 1328,
        1221,   61, 2538, 4113])
Epoch: 2334, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2335 - Batch 1 ########################
IDs in batch 1: tensor([3385, 1841,  835, 3184, 2681,  583,  797, 2571,  803,  417, 2041, 3473,
        2725,  910,  201, 1760])
Epoch: 2335, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2336 - Batch 1 ########################
IDs in batch 1: tensor([3082,  425,  127,  130, 2322, 1647, 4166, 2553, 4008, 3449, 4121, 2895,
          50, 3760, 1047,  191])
Epoch: 2336, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2337 - Batch 1 ########################
IDs in batch 1: tensor([2848,  510,  645, 3701,   27, 1256, 1166,  849,  930,   61, 2443, 2053,
          21, 3337,  694, 2868])
Epoch: 2337, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2338 - Batch 1 ########################
IDs in batch 1: tensor([2815, 4161, 3245, 2375, 2819, 2437,  503,  226, 1493,  483,   81, 2369,
        2631, 3308, 3374, 3496])
Epoch: 2338, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2339 - Batch 1 ########################
IDs in batch 1: tensor([3127, 2831,  565, 1879,  833,  726, 1521,  413, 2568, 1613, 3475, 3751,
        1126, 1275, 2299, 2961])
Epoch: 2339, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2340 - Batch 1 ########################
IDs in batch 1: tensor([2886, 4084,  568, 2578, 3654, 2116,  244, 2367,   62, 1860, 1223, 1156,
         280,  545, 1855, 2018])
Epoch: 2340, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2341 - Batch 1 ########################
IDs in batch 1: tensor([2485, 2050,  372, 1340, 3964,  450, 1081, 1902, 3466, 2912, 2382, 1017,
        2291,  130, 3981, 2224])
Epoch: 2341, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2342 - Batch 1 ########################
IDs in batch 1: tensor([1404, 3721, 2621, 3159, 1488,  680, 3630, 1213, 1955, 2917, 1857, 3031,
        1017, 3424, 1235, 1374])
Epoch: 2342, Training Loss: 0.37, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2343 - Batch 1 ########################
IDs in batch 1: tensor([  19, 1263, 3886,    5, 3382,  408, 3822, 3248, 3179, 2264,   98, 2529,
        3762, 2809, 2575, 1226])
Epoch: 2343, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2344 - Batch 1 ########################
IDs in batch 1: tensor([2919, 1822,  359, 2798, 2664,  907, 3010, 4126, 2440,  471, 3970, 3218,
        2703, 2123, 1660, 1404])
Epoch: 2344, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2345 - Batch 1 ########################
IDs in batch 1: tensor([3254, 2565,   77, 2577, 1267, 3644, 1810,  821, 2627,  106, 2028,  627,
        1101, 3058, 2353, 1851])
Epoch: 2345, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2346 - Batch 1 ########################
IDs in batch 1: tensor([ 899, 4062, 2977, 1661,  149,   50, 3278,  401, 2151, 1540, 3168, 1252,
        3907,  437, 1861, 2945])
Epoch: 2346, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2347 - Batch 1 ########################
IDs in batch 1: tensor([2636, 2581,  552, 2118, 2840,  862, 1138, 3051, 3374, 1524, 4067, 4080,
        2401, 4084, 4058, 3668])
Epoch: 2347, Training Loss: 0.36, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2348 - Batch 1 ########################
IDs in batch 1: tensor([2856,  805, 2976, 3980, 3300, 1390, 2729, 2332, 3610,  967, 1060, 3545,
        3852,  283,  917, 3251])
Epoch: 2348, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2349 - Batch 1 ########################
IDs in batch 1: tensor([4072, 1031, 4075, 2019, 1818,  554, 2476,  762, 1445, 2706,   84,  151,
        3047,  362, 4195,  282])
Epoch: 2349, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2350 - Batch 1 ########################
IDs in batch 1: tensor([2950, 4246, 1469, 2394, 1508, 2367, 1406, 2851, 1161, 3144, 1138, 1034,
        3407, 2074, 2339,  251])
Epoch: 2350, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2351 - Batch 1 ########################
IDs in batch 1: tensor([2520, 1545, 3869, 3710,  140, 3627, 3552, 1047, 1793, 2832, 3821, 1054,
        1251, 4257, 4212,  811])
Epoch: 2351, Training Loss: 0.50, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2352 - Batch 1 ########################
IDs in batch 1: tensor([1104, 1473, 1198, 1731, 1628, 2223, 1525, 2331,  944,  858,  586, 1352,
        1405,  332,  503, 3738])
Epoch: 2352, Training Loss: 0.72, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2353 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 4122, 2661, 1266,  575, 2775, 4046, 1894, 1965, 3532, 3466, 3933,
         946,  393,   49, 3822])
Epoch: 2353, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2354 - Batch 1 ########################
IDs in batch 1: tensor([3712, 1706, 3588,  490, 1026, 2882, 1942, 2044, 1218, 3372, 3963,  888,
        1056, 3423, 1868,  584])
Epoch: 2354, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2355 - Batch 1 ########################
IDs in batch 1: tensor([2835,  625,   30, 1061, 4039, 4005, 1913, 3119, 2452, 1030, 4134, 3769,
         603, 3278, 3643, 1024])
Epoch: 2355, Training Loss: 0.43, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2356 - Batch 1 ########################
IDs in batch 1: tensor([2737, 3740, 4172, 3822, 3010, 1241, 4105,  913, 1286,  959,   57, 1628,
         622,  756,  207,  413])
Epoch: 2356, Training Loss: 0.55, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2357 - Batch 1 ########################
IDs in batch 1: tensor([1377,  785, 1704, 1657,  897, 2279, 3057,  983, 1408, 2546, 3193, 3447,
        3529, 3052, 3453, 1799])
Epoch: 2357, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2358 - Batch 1 ########################
IDs in batch 1: tensor([ 239, 2177, 3227,   71, 2277, 2693, 4057, 2399, 2472,  694,  762,   11,
        4046, 1332,  111, 1374])
Epoch: 2358, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2359 - Batch 1 ########################
IDs in batch 1: tensor([1131, 2866, 4051, 1740, 3037, 1685,  228, 2064,  607, 1160, 2408, 2367,
        1787,  327, 3832, 2262])
Epoch: 2359, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2360 - Batch 1 ########################
IDs in batch 1: tensor([ 155, 2426, 3374,  684,  511, 3448, 2122, 4265, 4245, 2937,  111, 1331,
         250,  681,  789, 2710])
Epoch: 2360, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2361 - Batch 1 ########################
IDs in batch 1: tensor([3256,   59, 3478, 1526, 3938, 2715, 3818, 1138, 2733, 1570, 1811, 3765,
        3919, 1241, 2967, 3364])
Epoch: 2361, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2362 - Batch 1 ########################
IDs in batch 1: tensor([3945, 4157, 2802, 2641, 3904, 3375,  418, 1822, 3545,   93, 2672,  674,
        2504,  930,  723, 3506])
Epoch: 2362, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2363 - Batch 1 ########################
IDs in batch 1: tensor([3184, 3037, 1630, 4121,  407, 4135, 1025, 2387, 1473, 1901,  569, 1049,
         596, 3290,  667, 2097])
Epoch: 2363, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2364 - Batch 1 ########################
IDs in batch 1: tensor([ 463, 3530, 1682, 2559, 1495,  544,  577, 1722,  751, 2516, 1039, 4140,
        1471, 1294, 3590, 2783])
Epoch: 2364, Training Loss: 0.35, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2365 - Batch 1 ########################
IDs in batch 1: tensor([2376,   49, 1381,  401, 2908, 2845,  965, 2529, 3406, 3385, 2746, 3971,
        3222, 2973,   43, 1232])
Epoch: 2365, Training Loss: 0.25, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2366 - Batch 1 ########################
IDs in batch 1: tensor([3239, 4199,  152,  816,  683, 2872, 3109, 1886,  774, 3258, 2537, 2251,
        1796, 2892, 3308, 3958])
Epoch: 2366, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2367 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 1519,  778, 1264, 2539, 1125, 1090, 3961, 2386, 1321, 2980,  359,
         866, 2492, 1985,   19])
Epoch: 2367, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2368 - Batch 1 ########################
IDs in batch 1: tensor([1892,  625, 1994, 1088, 1920, 2648,  186, 1737, 2412,  455, 1035,  645,
        2213,  384, 2229,  803])
Epoch: 2368, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2369 - Batch 1 ########################
IDs in batch 1: tensor([2218, 3549, 1096, 2433, 4018, 2715, 3150, 3902, 2145,  451, 3110, 1454,
        1010, 3207, 1153, 1445])
Epoch: 2369, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2370 - Batch 1 ########################
IDs in batch 1: tensor([1119, 2616,  456, 3998,  953, 1016, 1220,  858, 4254, 2479,  863, 2255,
        2641, 2538, 3458, 2577])
Epoch: 2370, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2371 - Batch 1 ########################
IDs in batch 1: tensor([3875,   86, 3151, 2373, 4232, 2597,  646, 3318, 3557, 1655, 3238, 2297,
         601, 3826,  789, 3267])
Epoch: 2371, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2372 - Batch 1 ########################
IDs in batch 1: tensor([3608,  247, 3501,  882, 2226, 3655, 4050,  827, 1591, 3676,  934, 1375,
         341, 1126, 2459, 2280])
Epoch: 2372, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2373 - Batch 1 ########################
IDs in batch 1: tensor([3507,  140, 4200,  282,   13, 2473, 3928,  982, 4166, 2986,  359,  459,
        2256, 1862, 3917, 3980])
Epoch: 2373, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2374 - Batch 1 ########################
IDs in batch 1: tensor([2726, 3494, 2039,   18,  402, 1156,  478, 3207, 2028, 3025,  771,  976,
        2290, 1212, 3541, 3159])
Epoch: 2374, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2375 - Batch 1 ########################
IDs in batch 1: tensor([ 104, 2385, 2446, 4189, 2463, 2010,  871, 3327, 1196, 1546, 2934,  476,
        2365, 4227, 4257, 1077])
Epoch: 2375, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2376 - Batch 1 ########################
IDs in batch 1: tensor([2745, 1027, 2669, 3504, 2668, 1128,  303, 2278, 2377, 1273, 2840, 1953,
        1579, 3607, 2749, 3181])
Epoch: 2376, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2377 - Batch 1 ########################
IDs in batch 1: tensor([2429, 3432, 2086, 2144,  613, 2931, 4213, 1180,  770, 2025,  387, 1185,
        1290,  855, 2473,  822])
Epoch: 2377, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2378 - Batch 1 ########################
IDs in batch 1: tensor([2869,  519, 2836, 1176, 2204, 1823, 3073,  790,  243, 1147, 2040,  419,
        3573, 3197, 2976, 3355])
Epoch: 2378, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2379 - Batch 1 ########################
IDs in batch 1: tensor([3905, 1990,  279, 1218,  757, 3272, 3460, 2536, 1988, 2407, 3178, 2742,
        3009,  483, 2620, 4222])
Epoch: 2379, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2380 - Batch 1 ########################
IDs in batch 1: tensor([2106, 1295,  108,  332, 2067, 3701,  910, 3808, 2989, 3762, 2354, 1133,
        1885, 3058, 2656, 2848])
Epoch: 2380, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2381 - Batch 1 ########################
IDs in batch 1: tensor([3545, 3223, 2659,  834, 2476,  890, 2885,  879, 2670,  357, 1420,  512,
        2455, 3400, 2433, 2851])
Epoch: 2381, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2382 - Batch 1 ########################
IDs in batch 1: tensor([3760, 1364, 3338, 2475, 3977, 2731, 3731, 3871, 1111, 2297, 1967, 2281,
        1971, 2546,  117, 2218])
Epoch: 2382, Training Loss: 0.36, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2383 - Batch 1 ########################
IDs in batch 1: tensor([3051, 2179, 3203, 1138, 3101,  442, 2912, 2798,  681,  858, 2661, 3883,
         995, 1766, 1681, 2854])
Epoch: 2383, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2384 - Batch 1 ########################
IDs in batch 1: tensor([2344, 2442, 2441,  968,  517, 1232,  884,  893, 2711, 3733, 1823, 1370,
        2366, 2842,  717, 3447])
Epoch: 2384, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2385 - Batch 1 ########################
IDs in batch 1: tensor([2026, 2296, 1389, 3505,  224, 1953,  474, 1413, 2446, 1923, 3451, 2002,
          10, 1390, 1794, 2402])
Epoch: 2385, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2386 - Batch 1 ########################
IDs in batch 1: tensor([2494, 3286, 1763,  430, 3782, 1239, 2017, 3746,  277, 1993, 3283,  496,
        1982,  334, 3830,  887])
Epoch: 2386, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2387 - Batch 1 ########################
IDs in batch 1: tensor([ 283, 1284,  237, 1707, 3327, 1740, 3406,  229, 1026, 3081, 1835, 3368,
        3311, 3650,  219, 3458])
Epoch: 2387, Training Loss: 0.29, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2388 - Batch 1 ########################
IDs in batch 1: tensor([1583, 1360, 3904, 2812,  566, 3234, 3990, 1267, 3797, 1956, 1869,   71,
        4003,  456, 4118, 2514])
Epoch: 2388, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 2389 - Batch 1 ########################
IDs in batch 1: tensor([4118, 3182,  967, 1376, 2364,  186,  955, 2953, 1866,  590,  977, 3284,
        3500,  337, 3021, 1956])
Epoch: 2389, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2390 - Batch 1 ########################
IDs in batch 1: tensor([3238,  630, 3894, 2804, 2173, 1220, 3354, 2687,  105, 4149,   93, 1439,
         188, 1804, 3598, 4215])
Epoch: 2390, Training Loss: 0.14, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 2391 - Batch 1 ########################
IDs in batch 1: tensor([2320, 2872,  605, 2868, 2726,  921, 3353,  145, 3782, 3608,  590,   35,
         488, 1034, 2044, 3871])
Epoch: 2391, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2392 - Batch 1 ########################
IDs in batch 1: tensor([ 526,  871,   49,  656, 2034, 1158, 2709, 1354, 3028, 2800, 4143, 3216,
          88,  494, 1347, 2171])
Epoch: 2392, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2393 - Batch 1 ########################
IDs in batch 1: tensor([1642, 1812,  834, 1244, 3898,  946,  721, 3219, 3310,  234,  108, 4258,
        2023, 1645, 2849, 3853])
Epoch: 2393, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2394 - Batch 1 ########################
IDs in batch 1: tensor([1006, 1490, 2458, 2655, 4148, 3712, 1518,  424, 2296, 2407, 1624, 3900,
        1347, 2796, 2349,  263])
Epoch: 2394, Training Loss: 0.25, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2395 - Batch 1 ########################
IDs in batch 1: tensor([3995, 3438,  195, 2376, 3446,  758,  947, 1070,  684,  869, 2974,  223,
        1321, 2232, 1578, 2510])
Epoch: 2395, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2396 - Batch 1 ########################
IDs in batch 1: tensor([4134, 3888,  149, 4097, 2964, 1740, 3614, 2366, 3876, 3677, 2571, 2226,
        2638, 2375,  537,  449])
Epoch: 2396, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2397 - Batch 1 ########################
IDs in batch 1: tensor([3036,  100, 2853,  154,  372, 3418, 2545, 2228,  519, 3865, 4039, 3952,
        2242,  119, 3859, 2730])
Epoch: 2397, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 2398 - Batch 1 ########################
IDs in batch 1: tensor([2120,  532, 4103, 1157, 4062, 1568, 3193, 1849, 1496, 2838, 2990,  182,
          95, 2715, 3258,  751])
Epoch: 2398, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2399 - Batch 1 ########################
IDs in batch 1: tensor([3387, 3113, 2655, 3466, 4100, 1133, 1746, 2995, 3713,  320, 2666,  220,
        2669, 1612, 3016, 1727])
Epoch: 2399, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2400 - Batch 1 ########################
IDs in batch 1: tensor([2022, 3538,  893, 1563,  685, 3781, 3483, 2993, 3947, 1163, 3286, 3035,
        3823,  108, 3304, 3956])
Epoch: 2400, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2401 - Batch 1 ########################
IDs in batch 1: tensor([3581, 2420, 1610, 2226,  183, 3127, 2206, 4185,  776, 3994, 1425, 3473,
        1803, 2171,  121, 3364])
Epoch: 2401, Training Loss: 0.43, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2402 - Batch 1 ########################
IDs in batch 1: tensor([ 628, 1954, 3366, 4046, 4251, 1178,  129, 3740, 1213, 1962, 1510,  430,
         170,  237, 2182, 1204])
Epoch: 2402, Training Loss: 0.25, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2403 - Batch 1 ########################
IDs in batch 1: tensor([ 941, 1751, 4037, 3108, 3443, 2332, 3135, 3135, 2469,   50, 2603, 2688,
        3120, 1417, 3258, 2999])
Epoch: 2403, Training Loss: 0.37, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2404 - Batch 1 ########################
IDs in batch 1: tensor([ 926, 3128,  195, 2087,  838, 3753,  437, 3182, 4220, 3881,  896,  181,
        2044,  870, 2496,  371])
Epoch: 2404, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2405 - Batch 1 ########################
IDs in batch 1: tensor([1356, 2052,  887,  894, 3797, 4194,  476, 3928, 1008, 3333, 1005, 3671,
        3009, 3000, 3554, 4101])
Epoch: 2405, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2406 - Batch 1 ########################
IDs in batch 1: tensor([2638, 1706, 1330,  546, 2692, 2586,  442, 3585, 2219, 2959,   26, 4077,
        1793, 4139, 2489,  387])
Epoch: 2406, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2407 - Batch 1 ########################
IDs in batch 1: tensor([3421, 3803,  282, 3669, 4072, 2464, 2809, 1639,  196,  736, 1748, 3440,
        4105, 3913, 4030, 3597])
Epoch: 2407, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2408 - Batch 1 ########################
IDs in batch 1: tensor([3475, 3938, 3355, 3370, 3726, 3866, 3006, 1279, 4115, 3239, 2320, 1597,
        1959, 3235, 3734, 1818])
Epoch: 2408, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2409 - Batch 1 ########################
IDs in batch 1: tensor([4080,  408, 4234,  933, 2646, 4037,  658,  417, 3466, 2793,  130, 2968,
         918, 2795, 1404, 1067])
Epoch: 2409, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2410 - Batch 1 ########################
IDs in batch 1: tensor([3478, 3042,  140, 2487, 2822, 2023, 2236, 4057, 2523, 3408, 3950, 2833,
        3838, 1343, 2589, 3177])
Epoch: 2410, Training Loss: 0.64, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2411 - Batch 1 ########################
IDs in batch 1: tensor([3779,  247, 4139, 2313, 2542, 3376, 1083, 3386, 3781, 2894, 1296,  350,
        2426, 2253, 3151, 2069])
Epoch: 2411, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2412 - Batch 1 ########################
IDs in batch 1: tensor([4026,  252, 2051, 2689, 3051, 1231, 3728, 2760, 3714, 1279, 1196, 4103,
        3509, 3573, 1504, 1762])
Epoch: 2412, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2413 - Batch 1 ########################
IDs in batch 1: tensor([3004, 2680, 1070, 1808,  526, 1372, 1077,  896, 2225,  649, 2229, 1994,
        2426,  430, 4131, 2730])
Epoch: 2413, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2414 - Batch 1 ########################
IDs in batch 1: tensor([3697, 3572, 1060,  491,  409, 2636, 3414, 2505, 1682, 2376, 2185, 3389,
         644, 1869, 2070,  582])
Epoch: 2414, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2415 - Batch 1 ########################
IDs in batch 1: tensor([2443, 3265, 1171, 1185,  508, 2544, 3981, 1900, 3617, 2224, 2984, 2942,
        3876,  902, 1951, 2441])
Epoch: 2415, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2416 - Batch 1 ########################
IDs in batch 1: tensor([3427, 4245, 2014, 3091, 3947, 1251,  132, 2755, 1069, 3467,  964, 1612,
        2249,  964, 2206, 3024])
Epoch: 2416, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2417 - Batch 1 ########################
IDs in batch 1: tensor([4011,  201, 1153,  467, 1363, 1111, 3121, 1469, 1558, 2388, 1920, 3950,
         888, 1562, 2620, 1651])
Epoch: 2417, Training Loss: 0.42, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2418 - Batch 1 ########################
IDs in batch 1: tensor([ 895, 1731, 2113, 2217, 3114, 2086, 2919, 2683, 4076, 2444, 4261,  101,
        2280, 2485, 2926, 1850])
Epoch: 2418, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2419 - Batch 1 ########################
IDs in batch 1: tensor([2960,  256, 1591, 2805,  584, 1290, 4040, 4080, 2645, 3696,  890, 3299,
         982, 2688, 4149, 2476])
Epoch: 2419, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2420 - Batch 1 ########################
IDs in batch 1: tensor([ 909, 1313, 1700, 2286, 2840, 3652, 3664, 1859,  411, 1445,  372,  995,
        2632, 2641, 3424, 3298])
Epoch: 2420, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2421 - Batch 1 ########################
IDs in batch 1: tensor([ 203,  662, 1945, 3728,  463, 1028, 2961, 1780, 3309, 3908, 3969, 1993,
        1458, 1760,  519, 1506])
Epoch: 2421, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2422 - Batch 1 ########################
IDs in batch 1: tensor([4126, 1957, 3991, 2797, 4179, 2425, 3253, 3178, 3542, 2661, 3879, 3447,
        3524, 2466, 3917,  610])
Epoch: 2422, Training Loss: 0.81, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2423 - Batch 1 ########################
IDs in batch 1: tensor([2398, 1836, 2936, 3603, 2653, 2278, 3652, 3354, 1459, 1380, 2151, 3428,
        1351, 2954, 2258, 2466])
Epoch: 2423, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2424 - Batch 1 ########################
IDs in batch 1: tensor([2913, 3446, 3913,  243, 3126,  717, 3964, 3945, 3807,  514, 1981,  382,
        3182,   68, 2976,  343])
Epoch: 2424, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2425 - Batch 1 ########################
IDs in batch 1: tensor([2146, 2590, 3507, 2027, 2295,  890, 3271,  110, 3414, 2782,   81, 1252,
         986, 4196, 2095, 3143])
Epoch: 2425, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2426 - Batch 1 ########################
IDs in batch 1: tensor([1272, 1578,  679,  733,  886,  656,  436, 4036, 2950, 1589, 2095, 2078,
        2751, 4094, 1553,   84])
Epoch: 2426, Training Loss: 0.57, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2427 - Batch 1 ########################
IDs in batch 1: tensor([3025, 4228, 3939, 1671, 2597, 1747, 2280, 3523, 1182, 3822, 2805, 1176,
         965, 1296,  278, 2323])
Epoch: 2427, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2428 - Batch 1 ########################
IDs in batch 1: tensor([1976,  211, 3098, 1287, 2487, 2172,  149, 1225, 3367, 1971,  105, 1625,
        4033,  752,  988, 1882])
Epoch: 2428, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2429 - Batch 1 ########################
IDs in batch 1: tensor([3083, 3853, 3075, 1333, 1201, 3767, 1954, 2642, 3244, 3027, 3863, 3765,
        1186, 4077, 2363, 1371])
Epoch: 2429, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2430 - Batch 1 ########################
IDs in batch 1: tensor([2497, 3105, 1613, 1103,  662, 1495, 3846, 3151, 1938, 2095, 3935, 3603,
         454, 2807, 2191,   50])
Epoch: 2430, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2431 - Batch 1 ########################
IDs in batch 1: tensor([2074,  967, 2225, 1260, 1634, 1638,  816, 3806,  964, 1175, 2950, 2951,
         292, 2627, 1374, 2676])
Epoch: 2431, Training Loss: 0.34, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2432 - Batch 1 ########################
IDs in batch 1: tensor([ 747, 2812, 2271,  883,  710, 3917,  517, 3262, 1934, 2188, 1991, 4264,
          74, 2125,  470, 1625])
Epoch: 2432, Training Loss: 0.28, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2433 - Batch 1 ########################
IDs in batch 1: tensor([ 519, 3680,  887, 2539, 1644, 4118, 2821,  666, 4015, 2185, 4014, 1476,
        3952, 2292, 2114, 1209])
Epoch: 2433, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2434 - Batch 1 ########################
IDs in batch 1: tensor([1972, 2968, 1782, 3052, 2752,  854, 1012,  996, 2645, 1054,  522, 1748,
        2122, 1186, 3194, 2951])
Epoch: 2434, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2435 - Batch 1 ########################
IDs in batch 1: tensor([2917, 1935,  640, 1089, 1450, 1133,  743, 3541, 4068, 2708,  478, 1237,
        3199,  389,  674, 1126])
Epoch: 2435, Training Loss: 0.38, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2436 - Batch 1 ########################
IDs in batch 1: tensor([  11, 4170, 1970, 4097, 1472,  954, 1590, 2180, 1923, 1824, 3661,  726,
         161, 2339, 2046, 1047])
Epoch: 2436, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2437 - Batch 1 ########################
IDs in batch 1: tensor([2908, 3717, 1766, 2271,  566, 3423, 2731, 2842, 3065,  361, 2456, 2107,
         305, 1057, 1910,  709])
Epoch: 2437, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2438 - Batch 1 ########################
IDs in batch 1: tensor([2476, 1131, 3743, 4113, 1224,  594, 2400,  572, 3728, 3652,  539,  412,
        2618, 3148, 1672, 2348])
Epoch: 2438, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2439 - Batch 1 ########################
IDs in batch 1: tensor([2947, 2249,  904, 1367,  740, 3600, 2943, 2121, 3971, 3743, 1490, 1567,
        3344, 3299, 2010, 4026])
Epoch: 2439, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2440 - Batch 1 ########################
IDs in batch 1: tensor([ 110, 1825, 2943, 3179, 1025, 3524, 2426, 3379,  928, 2483, 3152, 2280,
        2559, 2185, 2847, 2387])
Epoch: 2440, Training Loss: 0.43, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2441 - Batch 1 ########################
IDs in batch 1: tensor([1872, 4267,  511, 1200,  874,  503, 2511,  750, 2258,  873, 1397, 4227,
        2448, 2219, 3688, 3373])
Epoch: 2441, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2442 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 2362,  701, 3100, 2519, 2019, 1953,  266,  302, 1999, 2660,  515,
        1532, 2844, 2671, 2885])
Epoch: 2442, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2443 - Batch 1 ########################
IDs in batch 1: tensor([3511, 1879,  908, 2950,  709, 3648,  355, 3192, 1423, 3487, 1289, 3771,
        2726, 3787, 3939, 1548])
Epoch: 2443, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2444 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 1423,  361,  749,  651, 4049, 3144, 3553, 2440,  887,  372, 1707,
        2472, 2954, 1216, 2362])
Epoch: 2444, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2445 - Batch 1 ########################
IDs in batch 1: tensor([3463,  908, 4266,  255, 3813, 4131, 1451,  326, 2752,  805, 2008, 1393,
        1219,  258, 1212,  923])
Epoch: 2445, Training Loss: 0.34, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2446 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 3148, 3628,  320, 3945, 1006, 3588, 1731, 2516, 2645, 2275, 2670,
        1155,  824, 2329, 1390])
Epoch: 2446, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2447 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 3804,  207, 2516, 2150, 3471, 3278, 3709,  829, 3208,  854, 3865,
          57, 3845, 1540, 3940])
Epoch: 2447, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2448 - Batch 1 ########################
IDs in batch 1: tensor([2601, 2015, 3729,  945, 4075, 2073, 2173,  269, 2805, 2661, 3433,   13,
        1991, 1649,  828, 2894])
Epoch: 2448, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2449 - Batch 1 ########################
IDs in batch 1: tensor([ 324,  628,  149,  915, 3052, 4026, 1277, 1994, 2499, 2708, 3499,  550,
        4044, 1089, 3507, 2284])
Epoch: 2449, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2450 - Batch 1 ########################
IDs in batch 1: tensor([1168,  969, 3911, 3543,  316, 3254, 1137, 3299, 3804, 2732,  136, 1497,
        2467, 2743, 2081, 2921])
Epoch: 2450, Training Loss: 0.29, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2451 - Batch 1 ########################
IDs in batch 1: tensor([1386, 2373, 1878, 1420, 3470,  321, 2281, 1825, 1219, 1767, 3223, 4139,
        3283, 1107, 1747, 1648])
Epoch: 2451, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2452 - Batch 1 ########################
IDs in batch 1: tensor([3993, 2415,  523, 2247, 1935, 3214, 1357, 2494,  348,  485, 2894, 1765,
        3930, 3661, 3949, 1024])
Epoch: 2452, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2453 - Batch 1 ########################
IDs in batch 1: tensor([4115, 2428, 3963, 3275, 4187, 3253, 2885, 2812,  259, 3782, 1056,  325,
        3543, 1130, 3005,  552])
Epoch: 2453, Training Loss: 0.31, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2454 - Batch 1 ########################
IDs in batch 1: tensor([2855, 1763, 1286, 1009,  676, 3353, 2495, 1767,  896, 1294, 3456, 1821,
        2908, 3436,  688, 2072])
Epoch: 2454, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2455 - Batch 1 ########################
IDs in batch 1: tensor([2419,  812, 3894, 3161, 3674, 3897, 1737, 4170,  511,  949, 3557,  743,
        2605, 1110, 3436, 2278])
Epoch: 2455, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2456 - Batch 1 ########################
IDs in batch 1: tensor([2932, 2452,  137, 1999, 3751,  750, 2378, 3740, 3479, 1248, 1686,  475,
        1886, 3583,   96, 1897])
Epoch: 2456, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2457 - Batch 1 ########################
IDs in batch 1: tensor([2116, 1491, 3894, 1432, 1130, 2458, 4068, 2796,  829, 3234, 3543, 2114,
        2695, 1056, 1811,  517])
Epoch: 2457, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2458 - Batch 1 ########################
IDs in batch 1: tensor([3572, 2246, 3642,  399,   46, 1156, 3829,  988, 2669, 3787, 4165,  679,
        3928, 4056, 3928, 2805])
Epoch: 2458, Training Loss: 0.72, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2459 - Batch 1 ########################
IDs in batch 1: tensor([3128, 2983, 1762, 2837, 1055, 1993, 3057, 2131, 1933, 2343,  496, 1959,
         498, 3549,  120, 4180])
Epoch: 2459, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2460 - Batch 1 ########################
IDs in batch 1: tensor([  19,  871, 2008, 2444, 2710,  900,  478, 2860, 1216, 3589, 1569, 3585,
        1216, 3787, 1201, 2863])
Epoch: 2460, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2461 - Batch 1 ########################
IDs in batch 1: tensor([ 471,  605, 1175,  405,   30, 3480, 3651, 3534,  289,  243, 1658, 1417,
         390, 1959, 1117, 3985])
Epoch: 2461, Training Loss: 0.52, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2462 - Batch 1 ########################
IDs in batch 1: tensor([2976, 1161, 1840, 3351,  475, 2417,  803, 1271, 1821, 3771, 4086,  119,
        3436, 2529, 4200, 2701])
Epoch: 2462, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2463 - Batch 1 ########################
IDs in batch 1: tensor([ 683,  661, 1199, 4203, 4205, 3264,  933, 3234, 1336, 4190, 1374, 1740,
        2624, 2439,  637, 2542])
Epoch: 2463, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2464 - Batch 1 ########################
IDs in batch 1: tensor([2150, 1037, 1678, 3962, 1804, 3680, 1537,  184, 3025, 2718, 3112, 1545,
        4022, 1623, 3196, 2664])
Epoch: 2464, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2465 - Batch 1 ########################
IDs in batch 1: tensor([1038, 1789, 3257, 2575, 2835, 1111, 1289, 3783, 4070, 2870, 3279, 1671,
        3185, 2328,   77,  186])
Epoch: 2465, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2466 - Batch 1 ########################
IDs in batch 1: tensor([ 484,  988, 2960, 1138, 1414, 4189, 2447, 4254, 3630, 4093, 1780, 2312,
        1139, 3238, 2309, 1103])
Epoch: 2466, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2467 - Batch 1 ########################
IDs in batch 1: tensor([3749, 1506, 2876, 2883,  701, 1090, 3704, 2097, 4258,  829, 4095, 2406,
        3970, 3452, 3157, 2249])
Epoch: 2467, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2468 - Batch 1 ########################
IDs in batch 1: tensor([2452,  957, 2191, 1406, 4188, 1103,    5, 3451,  833, 3330, 1054, 2819,
        1383, 3338,  640, 2692])
Epoch: 2468, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2469 - Batch 1 ########################
IDs in batch 1: tensor([ 980, 1472, 1012, 3078, 4017, 1821, 1016, 3427, 2291, 3141, 2363, 1077,
        3643, 1543, 3667, 3518])
Epoch: 2469, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2470 - Batch 1 ########################
IDs in batch 1: tensor([1812, 4014,  727,  262, 1960, 3187, 2913, 2433, 2921, 1275,  435, 2997,
        3177, 1287,  422, 2359])
Epoch: 2470, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2471 - Batch 1 ########################
IDs in batch 1: tensor([3696, 1872,  662, 2496,  767, 2552, 1470, 3518, 4110, 1901, 2687,  888,
        2185, 2098, 3443, 4099])
Epoch: 2471, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2472 - Batch 1 ########################
IDs in batch 1: tensor([4146,  602, 3928, 2682, 3286, 3926, 3092, 3904, 2787, 4003, 1421,  435,
        4227, 3985, 3786,  333])
Epoch: 2472, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2473 - Batch 1 ########################
IDs in batch 1: tensor([1269, 2034, 2005,   61, 3988, 1672, 2805,   32,  218, 1979, 3159, 3458,
        1391, 4255, 3074, 2746])
Epoch: 2473, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2474 - Batch 1 ########################
IDs in batch 1: tensor([4229, 3248, 3921, 3738, 3970,  455, 2553, 3638,  957, 2712, 2372, 1927,
        3444,  762, 3133,  593])
Epoch: 2474, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2475 - Batch 1 ########################
IDs in batch 1: tensor([3271,   11, 3088, 2153,  617, 3278,  785,  841, 1111, 2417, 1595,  684,
        3810, 2090, 1679, 2902])
Epoch: 2475, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2476 - Batch 1 ########################
IDs in batch 1: tensor([1003, 1204, 3976, 2738, 1438, 2358, 4146, 3130, 2823,  823,  362, 1877,
         981, 3934, 1209, 1225])
Epoch: 2476, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2477 - Batch 1 ########################
IDs in batch 1: tensor([ 869, 1804, 2275, 1322, 1877,   74, 3642, 2120, 2495, 2782, 3467, 2435,
         803, 1619, 1355, 3239])
Epoch: 2477, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2478 - Batch 1 ########################
IDs in batch 1: tensor([ 989, 3548, 1237, 3726,  508, 3075, 1920, 3381, 4068,  459, 2692, 2854,
        2807,  909, 2354, 2957])
Epoch: 2478, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2479 - Batch 1 ########################
IDs in batch 1: tensor([ 566, 2279, 1443, 4022, 2347, 2483, 2038,  740,  459, 3821, 1476, 2617,
        2109, 3258, 3338,  501])
Epoch: 2479, Training Loss: 0.31, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2480 - Batch 1 ########################
IDs in batch 1: tensor([1786,  401, 1257, 3991, 2024, 3031,  276, 3648,  497, 2287, 3152, 1177,
        1388,  792, 2435, 1257])
Epoch: 2480, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2481 - Batch 1 ########################
IDs in batch 1: tensor([3973,  658, 3551, 3942, 3399,  837, 3386,  211, 2493, 3778, 2672, 1331,
        4195,  269, 4018, 2564])
Epoch: 2481, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2482 - Batch 1 ########################
IDs in batch 1: tensor([ 750, 2143,  120, 1143,  863, 1913, 1740, 3552, 1393, 2666, 3226,  315,
        2365, 3948, 3252, 2742])
Epoch: 2482, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2483 - Batch 1 ########################
IDs in batch 1: tensor([3321,  770,  517,  612, 1478, 3073,    7, 1937,  459, 2731,  815, 2131,
        1646, 3355, 1305, 1076])
Epoch: 2483, Training Loss: 0.30, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2484 - Batch 1 ########################
IDs in batch 1: tensor([ 478, 1736, 1517, 1752, 1004, 1722, 2368,  683, 1399, 3196, 3590, 3015,
        1156, 3693, 1731, 3930])
Epoch: 2484, Training Loss: 0.35, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2485 - Batch 1 ########################
IDs in batch 1: tensor([ 646, 2783, 3353, 1330,  858, 2565, 3785,  434, 3823,   50, 1385, 4256,
        3993, 3569, 4134, 2433])
Epoch: 2485, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2486 - Batch 1 ########################
IDs in batch 1: tensor([ 750,  206, 3176, 1504,  308, 2472,  538, 3938,  252, 2219, 3479, 3573,
         892,  317, 2978, 3960])
Epoch: 2486, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2487 - Batch 1 ########################
IDs in batch 1: tensor([4220,  917, 2286,  749, 3930, 1756, 3337, 3499,  382, 1573,  989, 2451,
        3239, 3487, 1567, 1160])
Epoch: 2487, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2488 - Batch 1 ########################
IDs in batch 1: tensor([1681, 3246,  302, 3486, 1440, 1866,  959,  969, 4266, 1532, 2575,  471,
        4126,  699, 1855, 2797])
Epoch: 2488, Training Loss: 0.39, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2489 - Batch 1 ########################
IDs in batch 1: tensor([1999,  755, 3002, 3109, 2442, 3388, 1675, 2299,  155, 2189, 4229, 2737,
        3199, 1830, 1305,  651])
Epoch: 2489, Training Loss: 0.33, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2490 - Batch 1 ########################
IDs in batch 1: tensor([1585, 3458, 1779, 2614, 2601, 3217,  909,  154, 2297, 4120, 2652, 2643,
        2382, 1241, 1160, 3308])
Epoch: 2490, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2491 - Batch 1 ########################
IDs in batch 1: tensor([2368, 1570, 1256, 1756, 4152,  393, 2010, 1902, 3392, 2212,  727,  854,
         394,  787, 1497,  172])
Epoch: 2491, Training Loss: 0.30, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2492 - Batch 1 ########################
IDs in batch 1: tensor([2480, 1443,  173, 1193, 2099,  199, 2624, 3182, 1244,  741, 3712, 3756,
        1324, 2514, 2599, 3765])
Epoch: 2492, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2493 - Batch 1 ########################
IDs in batch 1: tensor([2986, 2070, 3218,  277, 3200, 2400, 3907, 2940, 2157, 3496, 1221,  229,
        2600,  944, 3734, 1370])
Epoch: 2493, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2494 - Batch 1 ########################
IDs in batch 1: tensor([4255,  455,  497, 3217, 3234, 1710, 1647, 3852, 3382, 2721, 1213, 3930,
        3927, 4261, 1377, 2248])
Epoch: 2494, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2495 - Batch 1 ########################
IDs in batch 1: tensor([3310, 3023,  444, 3591,  530, 2674,  155,    5,  918, 2382,  610,  987,
        2745, 1069, 2299,  185])
Epoch: 2495, Training Loss: 0.46, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2496 - Batch 1 ########################
IDs in batch 1: tensor([3115, 3460, 1405,   24, 2383, 1053, 1525, 3697, 2859,  588, 3643, 2619,
        3500, 1299, 3557, 3544])
Epoch: 2496, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2497 - Batch 1 ########################
IDs in batch 1: tensor([1976, 2403, 3423, 3357, 1286, 2791, 4232, 1023, 2986, 2853, 2209, 3113,
         244, 1938, 2783, 2969])
Epoch: 2497, Training Loss: 0.60, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2498 - Batch 1 ########################
IDs in batch 1: tensor([3372, 1636, 2853, 4144,  279, 2025, 4229, 2924, 3859,  603, 2031, 3897,
        1862, 1559, 3704, 2905])
Epoch: 2498, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2499 - Batch 1 ########################
IDs in batch 1: tensor([3655, 1459,  483, 2171, 1991, 4103,  499, 2224,  850, 3834, 2517, 2631,
        1453,  327, 1059, 3040])
Epoch: 2499, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2500 - Batch 1 ########################
IDs in batch 1: tensor([1810,  274,  537, 1916, 3234, 2974,  490, 2984, 2385, 3692, 1158, 2697,
        3699, 3438, 1948, 4232])
Epoch: 2500, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2501 - Batch 1 ########################
IDs in batch 1: tensor([ 221, 2541, 1963, 3792, 1471, 2535, 4184, 1855, 1269, 1283, 2349, 2337,
        3242,  887, 1437,  413])
Epoch: 2501, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2502 - Batch 1 ########################
IDs in batch 1: tensor([2996, 4057, 2292, 3603,  536, 4126, 3999, 1405,  346, 2610, 2497, 3710,
        1330, 1116, 2831, 1273])
Epoch: 2502, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2503 - Batch 1 ########################
IDs in batch 1: tensor([3337, 3318,  305, 3023, 3856, 1596, 3009,  295, 2546, 2731,  487, 3745,
         413, 4093, 1754, 3289])
Epoch: 2503, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2504 - Batch 1 ########################
IDs in batch 1: tensor([2113, 4232, 1720, 3506, 1425, 1372, 4254,  333, 1423, 2574, 4235, 4002,
         620,  930, 2347, 2725])
Epoch: 2504, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2505 - Batch 1 ########################
IDs in batch 1: tensor([3731, 2114, 2151, 4075, 1809,  945, 1798, 1882, 1937, 1044, 1476,   97,
        1675,  449,  841, 3187])
Epoch: 2505, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2506 - Batch 1 ########################
IDs in batch 1: tensor([  95, 3113, 2015, 3272,  281, 2839, 3101,  841, 2169, 3144, 3183,  814,
        2925,  532, 3953,  915])
Epoch: 2506, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2507 - Batch 1 ########################
IDs in batch 1: tensor([1958, 2323, 3242,   85, 2119, 3886, 3370, 3932, 2899,  229, 3745, 1610,
         609,  926, 3953,  937])
Epoch: 2507, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2508 - Batch 1 ########################
IDs in batch 1: tensor([1082, 1365, 1173, 1022, 1457, 4116, 4225, 2099, 2624, 2443, 4040,  128,
        3564, 2178, 1163, 3938])
Epoch: 2508, Training Loss: 0.34, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2509 - Batch 1 ########################
IDs in batch 1: tensor([1727,  243,  340, 1500, 3792, 1326, 3077, 3972,  408, 3847, 3265, 1273,
        1179, 2542, 2721, 3399])
Epoch: 2509, Training Loss: 0.41, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2510 - Batch 1 ########################
IDs in batch 1: tensor([4060, 1517,  758, 1753, 4187,  604, 1140,  430, 1668, 1120, 4076, 4003,
        3928, 2015,  194,   49])
Epoch: 2510, Training Loss: 0.70, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2511 - Batch 1 ########################
IDs in batch 1: tensor([ 637, 1367, 2945, 2522, 3526, 1258, 1354, 3886,  661, 1182,  387,  943,
        1189,  827, 2378, 2721])
Epoch: 2511, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2512 - Batch 1 ########################
IDs in batch 1: tensor([2226, 3812, 1131, 3667, 1241,  351, 3874, 2137, 2732, 3020, 3308,  343,
        2610,  351, 1170, 2292])
Epoch: 2512, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2513 - Batch 1 ########################
IDs in batch 1: tensor([3389,  287, 2045, 1133, 3920, 1402, 2851, 2505, 2069, 3000, 1731, 1458,
        1530, 2839, 2500, 2986])
Epoch: 2513, Training Loss: 0.36, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2514 - Batch 1 ########################
IDs in batch 1: tensor([2161, 1122, 3187, 3060,  651, 2352,  492, 2827, 1626, 2373, 2815, 1980,
        2377, 1213, 1962, 2579])
Epoch: 2514, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2515 - Batch 1 ########################
IDs in batch 1: tensor([  96, 1778, 2777, 1657, 1493, 1229, 4258, 2406, 3883, 1979,  660,  382,
        1975, 2435, 2703, 2317])
Epoch: 2515, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2516 - Batch 1 ########################
IDs in batch 1: tensor([1925, 1186, 2961, 3876, 1049,  541, 4058,  678, 2688, 1267,  757, 1455,
         198, 2281, 3988, 3523])
Epoch: 2516, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2517 - Batch 1 ########################
IDs in batch 1: tensor([1101, 2899, 2182,  680, 2644,  396, 3369, 3882, 2887, 3015, 3827, 2494,
        3259, 1144, 1953, 1748])
Epoch: 2517, Training Loss: 0.34, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2518 - Batch 1 ########################
IDs in batch 1: tensor([1037, 1161, 1146, 3990,   95, 2315, 1710, 1090, 2586, 3326, 2947, 1556,
        2461, 1708,  963, 2558])
Epoch: 2518, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2519 - Batch 1 ########################
IDs in batch 1: tensor([2299, 3010, 3509, 2019, 3434,   37, 4078, 3135, 1085, 1910, 3272, 3907,
        1388, 1363, 1491, 4156])
Epoch: 2519, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2520 - Batch 1 ########################
IDs in batch 1: tensor([1182, 3939,  934,  320, 1326, 3443, 1419, 2425, 4022, 3850, 1451,  417,
        2997, 4088, 3866, 4110])
Epoch: 2520, Training Loss: 0.37, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2521 - Batch 1 ########################
IDs in batch 1: tensor([3948, 2279, 1092, 1958, 2207, 2261, 1146, 1958, 1270,  234, 3494,  317,
        2317, 1035, 2416, 2338])
Epoch: 2521, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2522 - Batch 1 ########################
IDs in batch 1: tensor([1823,  387, 1859, 4189, 3056,   70, 1508,  833, 4198, 2561,  407, 1166,
         915, 3262, 3257, 3040])
Epoch: 2522, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2523 - Batch 1 ########################
IDs in batch 1: tensor([  97, 3252, 1960,  490, 3983,  881, 1001,  346, 3476, 1295, 4154, 1225,
        4027, 4084, 3969,  769])
Epoch: 2523, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2524 - Batch 1 ########################
IDs in batch 1: tensor([2209, 1970, 3968, 3182, 2102, 2074, 1625, 3444, 3176, 1315, 2365, 3688,
         718, 2804, 3486, 3197])
Epoch: 2524, Training Loss: 0.62, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2525 - Batch 1 ########################
IDs in batch 1: tensor([3935, 3523, 2480, 2876,  191, 2947,  316, 3039,  824,  809, 2945,   68,
        3644, 1810, 2280, 2526])
Epoch: 2525, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2526 - Batch 1 ########################
IDs in batch 1: tensor([  18, 3598, 1851, 2937, 3969, 2170, 4011, 1937,  494,   56, 3650, 3524,
         236, 1286, 1956, 1146])
Epoch: 2526, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2527 - Batch 1 ########################
IDs in batch 1: tensor([1157, 3858,  264, 2761, 1178,  213, 4006,  620, 2498,  126, 3448, 2370,
        2967, 2027,  250, 2346])
Epoch: 2527, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2528 - Batch 1 ########################
IDs in batch 1: tensor([2314, 3177, 1881,  591,  111,  505, 3911, 1030, 3226,  625, 2989, 1646,
        2406, 4097, 2982, 3672])
Epoch: 2528, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2529 - Batch 1 ########################
IDs in batch 1: tensor([3950, 2860, 1347, 3108, 1376, 2999, 3984, 3845, 1635, 2313,  955, 2179,
        2488,  989, 1994, 3327])
Epoch: 2529, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2530 - Batch 1 ########################
IDs in batch 1: tensor([ 190, 2016,  186, 2671, 1356, 4215, 1645, 3094, 3384, 2135, 3928, 1379,
        2204, 1305, 3356, 1644])
Epoch: 2530, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2531 - Batch 1 ########################
IDs in batch 1: tensor([3092,  805, 3544, 2148,  518, 2412, 3243, 3705, 1649, 3706,  439, 1060,
        2666,  552, 1049,  954])
Epoch: 2531, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2532 - Batch 1 ########################
IDs in batch 1: tensor([2159, 1623, 3760, 1418, 3746, 1057,  743,  685,  451, 1043, 1347, 4024,
         186, 3540, 1878, 2760])
Epoch: 2532, Training Loss: 0.34, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2533 - Batch 1 ########################
IDs in batch 1: tensor([ 842, 4038,  314, 1507,  790, 2500,  606, 1283, 3592, 3040, 3371, 2524,
        3527,  151, 2589,  397])
Epoch: 2533, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2534 - Batch 1 ########################
IDs in batch 1: tensor([2586, 2730, 2367,  382, 1296, 3879, 3461, 2963,  714,   52, 1116, 3375,
         964, 3718, 3554,  612])
Epoch: 2534, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2535 - Batch 1 ########################
IDs in batch 1: tensor([1951,   81, 3461, 4055, 2470, 3705, 1390, 2041, 2378, 3118, 3583, 1871,
        1139, 4228, 1845, 1670])
Epoch: 2535, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2536 - Batch 1 ########################
IDs in batch 1: tensor([4235,  489, 2141,  472, 2377, 4069,  308, 2188, 3798, 3451, 1415, 1128,
        3368,  330, 1294,  835])
Epoch: 2536, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2537 - Batch 1 ########################
IDs in batch 1: tensor([2339, 3278, 2212, 2661, 4215,  812,  639,  223,  357,  356, 3542, 1834,
        4056, 4114, 2664, 2953])
Epoch: 2537, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2538 - Batch 1 ########################
IDs in batch 1: tensor([2053, 2070,  306,  476, 3333,  415, 1698,  277,   81, 1337,  498, 1639,
        1835, 2697,  774, 1730])
Epoch: 2538, Training Loss: 0.29, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2539 - Batch 1 ########################
IDs in batch 1: tensor([ 356,  685,  858, 2734, 1312,  167, 1277,  106, 1448, 2776,  591, 1644,
         811, 2073, 3242, 4057])
Epoch: 2539, Training Loss: 0.35, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2540 - Batch 1 ########################
IDs in batch 1: tensor([1442, 3503, 2368, 4056,   88, 3795,  684, 3525,  132, 4195, 3733, 3977,
        1727, 2965, 1418, 1195])
Epoch: 2540, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2541 - Batch 1 ########################
IDs in batch 1: tensor([2442, 3540, 1032,  775, 3130,  199, 2725, 2301, 2146, 2045,  591, 3105,
         961, 1498, 3025, 1892])
Epoch: 2541, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2542 - Batch 1 ########################
IDs in batch 1: tensor([3718, 1284,  120, 1495, 2891, 1566, 3822, 4173, 3058, 1239,  122, 2406,
        3004, 3352,  921, 4227])
Epoch: 2542, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2543 - Batch 1 ########################
IDs in batch 1: tensor([ 520, 2167, 2014,  985,   70, 1067, 1333, 1130, 3275, 3289, 2324, 1086,
        2721, 1050, 3723, 2669])
Epoch: 2543, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2544 - Batch 1 ########################
IDs in batch 1: tensor([2937, 4227, 4078, 1344, 2868, 3192,  993, 3056, 2996, 2113, 1292, 3535,
        2990, 3390, 4033, 2761])
Epoch: 2544, Training Loss: 0.39, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 2545 - Batch 1 ########################
IDs in batch 1: tensor([3726, 2655,  864, 2565, 3239, 4110, 2640,  290, 2645, 2280, 1842, 2465,
         893,  432, 1861, 3812])
Epoch: 2545, Training Loss: 0.17, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 2546 - Batch 1 ########################
IDs in batch 1: tensor([3433, 1877,  147,  449, 2871, 3969, 1551,  152,  758, 2341,  710, 1006,
        3020,  523, 3554, 2497])
Epoch: 2546, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2547 - Batch 1 ########################
IDs in batch 1: tensor([2015, 3511,  448,  503, 4149,  184,  814, 4039, 2022,  575, 3397, 3409,
        1835, 2656, 2688,  300])
Epoch: 2547, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2548 - Batch 1 ########################
IDs in batch 1: tensor([1270, 2292,  572, 1610, 3465, 3111, 1733, 4038, 3726, 3696, 2921, 3436,
        1957,  858,  666, 2241])
Epoch: 2548, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2549 - Batch 1 ########################
IDs in batch 1: tensor([1884, 1860, 2052, 2066, 3554, 1945, 1563, 4036, 1849, 2976, 2458, 1349,
        3920, 2225,  787, 3830])
Epoch: 2549, Training Loss: 0.22, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2550 - Batch 1 ########################
IDs in batch 1: tensor([2178,  415, 3259, 1332, 3630, 1947, 2672, 4070, 1044, 3268, 2542, 2655,
        1647, 3180, 2271, 3583])
Epoch: 2550, Training Loss: 0.54, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2551 - Batch 1 ########################
IDs in batch 1: tensor([3563, 3300,  983, 1387, 1808,  821,   74, 2986, 2398, 2915,  112, 2242,
        1795, 3463,   27, 2225])
Epoch: 2551, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2552 - Batch 1 ########################
IDs in batch 1: tensor([1244, 2521, 1084, 3154, 3812, 3934, 2754, 2181, 3537, 2017,  694, 3674,
        3706, 1118, 2754, 2413])
Epoch: 2552, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 2553 - Batch 1 ########################
IDs in batch 1: tensor([ 835, 2180, 4002, 3553, 2504, 1700, 2049, 3275, 1052, 2824,  275, 2300,
         346, 1438, 1336,  952])
Epoch: 2553, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2554 - Batch 1 ########################
IDs in batch 1: tensor([3721, 3689, 3771, 3514,  335,   39, 3246, 4068,  481, 2810,  750, 2752,
         769, 2605, 2485, 3663])
Epoch: 2554, Training Loss: 0.26, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2555 - Batch 1 ########################
IDs in batch 1: tensor([  81, 3526, 2241, 3719, 4190, 2478, 2428, 3030, 2290, 3609,   81, 3772,
        1256, 1951, 1032, 2452])
Epoch: 2555, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2556 - Batch 1 ########################
IDs in batch 1: tensor([ 424, 3168,  330, 2568,  770, 2167, 1229, 2371, 3094,   21, 4046, 3675,
         767, 1914, 1354, 1213])
Epoch: 2556, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2557 - Batch 1 ########################
IDs in batch 1: tensor([ 955,   92, 4235,  990, 1054, 1732, 4013, 3795, 4086,   11, 1794, 1181,
        1493,   74, 3671,  813])
Epoch: 2557, Training Loss: 0.65, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2558 - Batch 1 ########################
IDs in batch 1: tensor([3459, 3438, 2965, 3943,  837, 2983, 3015, 1290, 3845,  113, 3807, 2949,
         828, 3327, 1585, 1083])
Epoch: 2558, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2559 - Batch 1 ########################
IDs in batch 1: tensor([1374, 3872, 1053, 2584, 1001, 4158, 3434,   77,  173,  131, 2282, 4037,
        2418, 3808,  963, 4170])
Epoch: 2559, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2560 - Batch 1 ########################
IDs in batch 1: tensor([ 874, 3475, 2264, 2196, 2183, 1143, 2264, 1487, 1574,  863, 1022,  320,
        1020, 3908, 3128, 2109])
Epoch: 2560, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2561 - Batch 1 ########################
IDs in batch 1: tensor([3426, 1380, 3740,  314, 3999,  470, 1812, 3503,  361, 1085,  657, 1802,
        1942, 2571, 2467, 1255])
Epoch: 2561, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2562 - Batch 1 ########################
IDs in batch 1: tensor([ 797, 3395, 2202, 2276, 3124, 2223, 1179, 3882, 1274, 3040, 3044,  322,
         947, 2355, 3731,  442])
Epoch: 2562, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2563 - Batch 1 ########################
IDs in batch 1: tensor([ 258,  323, 1209, 3928, 2086, 3540,  198, 4266, 1510, 2125, 3311,  147,
         417, 1824,  908, 2110])
Epoch: 2563, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2564 - Batch 1 ########################
IDs in batch 1: tensor([1588, 3222, 2666, 2542,  872, 2091, 1872,  908, 2640, 1476, 3493, 1331,
        4224, 1228, 4215, 3160])
Epoch: 2564, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2565 - Batch 1 ########################
IDs in batch 1: tensor([3676, 2838, 2504,  530, 2970, 1389, 2044, 1110, 1375, 1377, 1628, 4152,
        2932, 3949,  569, 3891])
Epoch: 2565, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2566 - Batch 1 ########################
IDs in batch 1: tensor([3143,  195,  439, 2135, 2499, 2719, 3831, 1233, 2112,  190, 3254, 2505,
         147, 2857, 2034, 2791])
Epoch: 2566, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2567 - Batch 1 ########################
IDs in batch 1: tensor([1524, 2313, 3947, 1138, 2230,   25, 3256, 3473, 1911, 3831, 1322,  593,
        3540, 4060, 2280, 1455])
Epoch: 2567, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2568 - Batch 1 ########################
IDs in batch 1: tensor([1980, 3993, 2480, 4002,  899,  491, 2789, 2315, 3492, 3021, 2008,  334,
        2731, 3608, 1530, 2597])
Epoch: 2568, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2569 - Batch 1 ########################
IDs in batch 1: tensor([3564, 3222,  212,  512, 1364, 4069, 1644, 1206, 1439,  439, 3466,  872,
        3988, 3466,   71, 3590])
Epoch: 2569, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2570 - Batch 1 ########################
IDs in batch 1: tensor([2324,  829, 2688, 2242,   35,  704, 1704, 3328, 1035, 3692, 3025, 2740,
        1133, 3077,  723, 3905])
Epoch: 2570, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2571 - Batch 1 ########################
IDs in batch 1: tensor([3951, 3782, 3314, 1698, 1474, 4125,  332,   82,  259, 1490,  827, 3527,
        2789,  517, 3680, 2740])
Epoch: 2571, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2572 - Batch 1 ########################
IDs in batch 1: tensor([3259, 3994, 1351, 2326, 1718, 1707, 2476, 2372, 3435, 3779, 3373, 1124,
        2645,  852, 3261, 2408])
Epoch: 2572, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2573 - Batch 1 ########################
IDs in batch 1: tensor([ 452, 2746, 1229, 2364,   46, 2833, 1883, 3255, 1636, 1014, 1423, 2780,
        4165, 1913, 4173, 3740])
Epoch: 2573, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2574 - Batch 1 ########################
IDs in batch 1: tensor([3865, 4266, 3701, 2884, 1406, 3506,  344, 3251,  987, 1840, 1498, 2391,
        4060, 1777, 3591, 2610])
Epoch: 2574, Training Loss: 0.29, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2575 - Batch 1 ########################
IDs in batch 1: tensor([2886,  387, 2810,  812, 2049, 1434, 1491,  195, 2296, 3600, 2276, 2960,
          63, 2223,  122, 1360])
Epoch: 2575, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2576 - Batch 1 ########################
IDs in batch 1: tensor([ 950, 4236,  578, 3702, 2516, 4166, 1751, 1855,  161, 3284, 3406,  544,
         430,  753, 3614, 2141])
Epoch: 2576, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2577 - Batch 1 ########################
IDs in batch 1: tensor([3971, 1417,  577, 2365, 1138,  869, 4135, 1131, 1571,  441, 3991, 3468,
        2264, 2663, 2339, 2326])
Epoch: 2577, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2578 - Batch 1 ########################
IDs in batch 1: tensor([1794, 2257, 2371, 3340,  408,  289, 1563, 1037, 2876, 2689, 4093, 2348,
        2196, 3634, 2456,  400])
Epoch: 2578, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2579 - Batch 1 ########################
IDs in batch 1: tensor([2412, 1782, 2213, 1060,  346, 3567, 3975,  878, 1597, 2281, 1955, 3829,
        2041, 3409,   74,  908])
Epoch: 2579, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2580 - Batch 1 ########################
IDs in batch 1: tensor([4228, 1045, 3539, 2252, 1672, 4105, 3744, 3369, 1712, 3609, 4257, 1942,
        3290, 1051,  890,  583])
Epoch: 2580, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2581 - Batch 1 ########################
IDs in batch 1: tensor([2516, 4113,  141, 2106,  775, 1131, 2776, 3242, 1934, 3973,  356,  816,
        1232,  880, 1107, 3014])
Epoch: 2581, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2582 - Batch 1 ########################
IDs in batch 1: tensor([3680, 3223,  260,  603, 3485, 1032, 2461, 2943, 2088, 4107, 2980, 1727,
         207, 2107,  846, 3040])
Epoch: 2582, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2583 - Batch 1 ########################
IDs in batch 1: tensor([4224, 2433,  377, 3392, 3757, 3870, 3545,  763, 2451, 1650, 1038, 2730,
        1716, 3157,  315, 2810])
Epoch: 2583, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2584 - Batch 1 ########################
IDs in batch 1: tensor([1545, 3025, 3023, 2815,  314, 1097, 3597, 3772, 3236,  752, 1614, 1409,
        2664, 1722, 1933,  687])
Epoch: 2584, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2585 - Batch 1 ########################
IDs in batch 1: tensor([1613, 1402, 3780, 1828,  666, 1798,  391, 2399, 3739,  730,  785, 2249,
        2809,  306, 3010, 4060])
Epoch: 2585, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2586 - Batch 1 ########################
IDs in batch 1: tensor([ 119, 2752,  566, 3866, 2352, 2456,  390, 3651, 1199, 3117, 2342,  596,
        3077,  388, 3917, 2800])
Epoch: 2586, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2587 - Batch 1 ########################
IDs in batch 1: tensor([ 756, 1104, 1509, 1935, 2829, 1672, 2724, 1746, 1361, 2024, 3518, 1861,
        3585,   14, 1896, 1626])
Epoch: 2587, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2588 - Batch 1 ########################
IDs in batch 1: tensor([3970, 3039, 3058, 2030, 3082, 4097, 3888, 1720,  289, 1851, 2479, 1275,
         539, 2688, 4238,  953])
Epoch: 2588, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2589 - Batch 1 ########################
IDs in batch 1: tensor([2871, 2478, 3989,  983, 2800, 4232, 3507, 3027, 3000, 2584, 2305, 2199,
        3999, 1614, 3671, 3084])
Epoch: 2589, Training Loss: 0.49, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2590 - Batch 1 ########################
IDs in batch 1: tensor([3806, 2567, 2232, 3410, 2970, 1083,  498, 3632,  533,  644, 2999, 2743,
        1347,  100, 2631, 1746])
Epoch: 2590, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2591 - Batch 1 ########################
IDs in batch 1: tensor([ 415, 1402,  900, 2936,  484, 4012, 1053, 3997, 1681,  320, 1591, 2154,
        1032, 1914,  544,  228])
Epoch: 2591, Training Loss: 0.32, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2592 - Batch 1 ########################
IDs in batch 1: tensor([2798,  718, 1974,  891, 3025, 2172, 3032, 1154,   27, 3455, 2410, 3453,
         478, 3661,  985, 3079])
Epoch: 2592, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2593 - Batch 1 ########################
IDs in batch 1: tensor([2796, 1011, 2169, 2749, 1125, 1676, 1395,  471, 2601, 1334, 2329, 3919,
         988, 1610, 1861, 3495])
Epoch: 2593, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2594 - Batch 1 ########################
IDs in batch 1: tensor([ 644, 2872, 4189, 1925, 3634, 4156, 2393, 1222,   19, 1988, 2497, 2113,
         787, 2286,  920, 1932])
Epoch: 2594, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2595 - Batch 1 ########################
IDs in batch 1: tensor([2477, 2664, 3939,  876, 1601, 2787, 1175, 1575,  952, 3921, 1892, 1624,
        1146, 1321, 3972, 2258])
Epoch: 2595, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2596 - Batch 1 ########################
IDs in batch 1: tensor([2005, 3401, 2390, 3021, 2070, 2378, 2231,  936, 3751, 3088, 2882, 1601,
         976,  465, 1147, 3936])
Epoch: 2596, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2597 - Batch 1 ########################
IDs in batch 1: tensor([1008, 3252,  147, 1183,  316, 1590, 2322, 2516, 2403,  327, 4008, 1473,
        1152, 1130, 1328, 2739])
Epoch: 2597, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2598 - Batch 1 ########################
IDs in batch 1: tensor([ 122, 3907, 3465, 1727, 4227, 2727, 1367, 1821,  953,  494, 1931, 2060,
        3841, 3220, 3303, 1037])
Epoch: 2598, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2599 - Batch 1 ########################
IDs in batch 1: tensor([3548, 3130, 1275, 1877, 2866, 3071, 1143, 1862, 2500, 1220, 1657, 1693,
        2467, 3527,  351,  405])
Epoch: 2599, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2600 - Batch 1 ########################
IDs in batch 1: tensor([1428, 2370, 4268, 1563, 2949, 3587, 3258,  891,  902, 2700,  477, 1862,
        1443, 2166, 2876, 1571])
Epoch: 2600, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2601 - Batch 1 ########################
IDs in batch 1: tensor([2025, 1540, 1020, 1511, 3991, 2024, 2810, 1638, 2687, 4038, 3268, 3421,
         236, 2170, 4263,  963])
Epoch: 2601, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2602 - Batch 1 ########################
IDs in batch 1: tensor([4268, 3371, 3338, 2364, 2913, 2229,  588, 3417, 2377, 2343, 3993,  766,
        1567,  666, 1110,  223])
Epoch: 2602, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2603 - Batch 1 ########################
IDs in batch 1: tensor([2224, 3196, 4055, 2727, 2080, 4030, 2743, 2428, 2710, 1610, 1495, 1154,
        2970, 4002,  819, 1954])
Epoch: 2603, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2604 - Batch 1 ########################
IDs in batch 1: tensor([2177, 3368, 1282, 3456, 4067, 1871, 3141,   60,  913, 2286, 1863, 3289,
        2991, 3743, 1391, 1970])
Epoch: 2604, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2605 - Batch 1 ########################
IDs in batch 1: tensor([2415, 1614, 3655, 4228, 1537, 2670, 3100, 2295, 1596, 3481, 1170,  848,
        3438, 3299, 2583, 1569])
Epoch: 2605, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2606 - Batch 1 ########################
IDs in batch 1: tensor([ 907, 1451, 1274, 2412, 3168, 1552, 2746, 1511, 2400, 2116,  472, 1138,
        2102, 2849, 3616,  411])
Epoch: 2606, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2607 - Batch 1 ########################
IDs in batch 1: tensor([2553, 2752, 1711, 2934,  545, 4022, 3671, 1596, 3834, 4133, 2133, 4121,
         851, 1308, 3321,   11])
Epoch: 2607, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2608 - Batch 1 ########################
IDs in batch 1: tensor([1774, 1113,  725,  389, 1817, 2940, 3081,  821, 2210,  389,  180, 3802,
        2966, 4214, 2016, 1067])
Epoch: 2608, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2609 - Batch 1 ########################
IDs in batch 1: tensor([ 390, 3721, 3638, 3830, 2770, 3997,  962, 3997, 4078, 3581, 3709, 3056,
         594, 2031,  135, 1063])
Epoch: 2609, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 2610 - Batch 1 ########################
IDs in batch 1: tensor([1588, 2170, 2298,  466,  814, 3406, 3255, 2552, 2261, 3409, 1352, 1139,
        3391,  517, 2063,  357])
Epoch: 2610, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2611 - Batch 1 ########################
IDs in batch 1: tensor([2363, 1119,   26, 3822, 2497, 2462, 1863, 3745, 3299, 2196,  956, 2038,
        3318, 3242, 2370, 2355])
Epoch: 2611, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2612 - Batch 1 ########################
IDs in batch 1: tensor([3371,  879, 3474, 2731, 2749, 2826, 4197, 3030,   32,  342, 3926, 3792,
        2455, 2891, 1818, 4236])
Epoch: 2612, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2613 - Batch 1 ########################
IDs in batch 1: tensor([ 541, 1551, 1638,  947, 2257, 3430,  945, 4152, 4265, 2831,  864, 1763,
        1464,  688, 3581, 3636])
Epoch: 2613, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2614 - Batch 1 ########################
IDs in batch 1: tensor([1495, 1094,  704, 2892,  483,  753,  323,  402,  467, 2169, 1850, 3733,
        3827, 2188,  362, 2431])
Epoch: 2614, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2615 - Batch 1 ########################
IDs in batch 1: tensor([2601, 1025,  553, 2017, 1798,  970,  937, 1868, 1200, 3707,  289,  529,
         184,  848, 3797, 4118])
Epoch: 2615, Training Loss: 0.29, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2616 - Batch 1 ########################
IDs in batch 1: tensor([3329, 1808,  775, 2823, 3406, 2018, 1590, 3092, 3786, 2369, 3908, 2974,
         148, 1131, 2115, 1124])
Epoch: 2616, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2617 - Batch 1 ########################
IDs in batch 1: tensor([2260,  676,  869,  323, 3731, 1945, 2300, 1530, 3248, 1508,  854,   93,
        1736, 3689, 1073,  892])
Epoch: 2617, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2618 - Batch 1 ########################
IDs in batch 1: tensor([2799, 1235, 3286,  103, 2539,  536,  499, 2379,  954, 1180, 2706, 1884,
        1835, 3208,  517, 2856])
Epoch: 2618, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2619 - Batch 1 ########################
IDs in batch 1: tensor([3338, 2868, 2356, 1442, 3615,  219,  651, 3603, 2696, 2262,  274, 2806,
        2272,  811, 1232, 1955])
Epoch: 2619, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2620 - Batch 1 ########################
IDs in batch 1: tensor([2561,   37,  823,   60, 3869, 3594, 3446, 4227, 1389, 1507,  941,  602,
        3618, 1500, 1283, 1319])
Epoch: 2620, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2621 - Batch 1 ########################
IDs in batch 1: tensor([1942, 1356, 1440,  642, 2519,  360, 1155, 1090, 3883, 3962, 3533, 3803,
        2274, 3921, 2965, 2771])
Epoch: 2621, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2622 - Batch 1 ########################
IDs in batch 1: tensor([2957,  653, 3401,  489, 3869, 4096, 2545, 3119, 3203, 3374, 2212, 1070,
        4254, 3022, 2798, 2279])
Epoch: 2622, Training Loss: 0.34, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2623 - Batch 1 ########################
IDs in batch 1: tensor([1592, 3133,  129, 3719,  237, 1822, 1174,  631, 1501, 3675, 3677,  986,
        4246, 3850, 3248, 3664])
Epoch: 2623, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2624 - Batch 1 ########################
IDs in batch 1: tensor([1406, 3132, 1282, 1054, 2868, 4204, 3516, 1836, 2583, 1860, 2600,   70,
         769,  515, 3160, 2945])
Epoch: 2624, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2625 - Batch 1 ########################
IDs in batch 1: tensor([4048,   44, 2453, 2912,  289, 1306, 3554,  642, 3211, 4062, 2429,  933,
        2652, 3497, 2871, 2213])
Epoch: 2625, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2626 - Batch 1 ########################
IDs in batch 1: tensor([3558, 1421, 2376, 4267, 4108, 1042,  965, 4101, 2028,  440, 2688, 3570,
         295,  899, 4108, 4190])
Epoch: 2626, Training Loss: 0.60, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2627 - Batch 1 ########################
IDs in batch 1: tensor([3390,  850,  103, 2542, 1634, 2252, 1212,  390, 2649,  341, 2644, 1163,
        3440, 1947, 3006, 1731])
Epoch: 2627, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2628 - Batch 1 ########################
IDs in batch 1: tensor([3176, 3995, 3002, 2858, 2701, 2681, 4187, 2773,  535, 1251, 3780,  809,
         957, 3853, 3334, 2869])
Epoch: 2628, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2629 - Batch 1 ########################
IDs in batch 1: tensor([2157, 3267, 1881, 3309,   28, 2721, 1101, 4161, 4251,  909,  412, 3723,
        3753, 4057, 3314,  883])
Epoch: 2629, Training Loss: 0.31, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2630 - Batch 1 ########################
IDs in batch 1: tensor([1043, 1822, 3058, 3628, 1678, 3964, 1775, 3323, 2954, 1092, 2401, 4195,
        3667, 1986, 3311, 2740])
Epoch: 2630, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2631 - Batch 1 ########################
IDs in batch 1: tensor([ 653, 1897, 2167, 2934, 1006, 1089,  352,   20, 2080, 3851, 4127,  750,
         818, 3551, 3592, 2035])
Epoch: 2631, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2632 - Batch 1 ########################
IDs in batch 1: tensor([1122, 3334, 3424, 1126, 2196, 3976, 2002, 1006,  515, 3907,   11,  476,
         880,  130, 2676, 3368])
Epoch: 2632, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2633 - Batch 1 ########################
IDs in batch 1: tensor([2615, 2053, 3177, 3526, 1090,  952, 1349, 1369, 3841, 3993, 1795, 4223,
        2879,  554, 3460, 1041])
Epoch: 2633, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2634 - Batch 1 ########################
IDs in batch 1: tensor([ 350,  897,  289, 3836,   63, 3637, 1780, 4188,  507, 1798, 1834, 1668,
        2169, 2060, 3980, 2732])
Epoch: 2634, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2635 - Batch 1 ########################
IDs in batch 1: tensor([2255, 1276, 2738, 2148, 1789, 4176, 3234, 3642,  870,  900, 2538, 2373,
        2718, 3709,  904, 2715])
Epoch: 2635, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2636 - Batch 1 ########################
IDs in batch 1: tensor([1137, 3254, 2763, 2119,  978, 3228, 3816, 3184, 2291,  213,  766,  674,
        4031, 3675, 3401, 2667])
Epoch: 2636, Training Loss: 0.49, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2637 - Batch 1 ########################
IDs in batch 1: tensor([ 943, 2225, 3395, 3960, 2597, 2171,  835,  900, 1450,  819,  409, 1973,
        3474,  467, 2793, 3663])
Epoch: 2637, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2638 - Batch 1 ########################
IDs in batch 1: tensor([1311,  526, 1208,   81,  488,  586,  198, 3930, 1740, 1014, 1857, 3539,
        1651, 2415, 4124, 3771])
Epoch: 2638, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2639 - Batch 1 ########################
IDs in batch 1: tensor([3114,  164, 3258, 2555, 3589, 1567, 2364, 1633, 1894,  252, 2681, 3440,
        4198, 4005,  825, 1443])
Epoch: 2639, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2640 - Batch 1 ########################
IDs in batch 1: tensor([2354,  234, 1161, 1196,  524,  926, 1794, 3541,  923, 2990,  279,  512,
         505,  556, 2141, 1685])
Epoch: 2640, Training Loss: 0.33, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2641 - Batch 1 ########################
IDs in batch 1: tensor([ 994, 3255, 3388,  411,  952,  996,  747, 1055, 3166, 3816,  628, 1645,
        3349,  639, 1067, 1197])
Epoch: 2641, Training Loss: 0.53, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2642 - Batch 1 ########################
IDs in batch 1: tensor([2099, 1596,  610, 1780, 2934, 2514,   68,  519, 2806, 1680, 3850, 4024,
        3035, 2251, 1684, 1182])
Epoch: 2642, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2643 - Batch 1 ########################
IDs in batch 1: tensor([3706,  343, 2497, 3284, 2782, 1704, 1421, 2173, 1971,  290, 2563, 3930,
        1252,  545,  317, 1794])
Epoch: 2643, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2644 - Batch 1 ########################
IDs in batch 1: tensor([ 545, 3355, 1055,  375, 2590, 2550,  819,  440, 2521, 1104, 1786, 4080,
         190,  893, 2676, 2137])
Epoch: 2644, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2645 - Batch 1 ########################
IDs in batch 1: tensor([3765,   14, 3423, 3304,  779,  843, 3161,  682, 3435, 2189, 3376,    4,
        1954,  456, 1384,  919])
Epoch: 2645, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2646 - Batch 1 ########################
IDs in batch 1: tensor([2170, 4238, 2924, 3754, 3998,   30, 2051, 4033, 2010, 2847, 3352, 1371,
        2065,  609, 1661, 3806])
Epoch: 2646, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2647 - Batch 1 ########################
IDs in batch 1: tensor([3238, 4222, 3042,  974, 1380, 3939, 2226,  612, 1271,   95, 2692,  653,
        2254, 2648,  390, 3942])
Epoch: 2647, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2648 - Batch 1 ########################
IDs in batch 1: tensor([3509, 1921, 1894,  988, 2894, 3313,  976, 2295, 4073,  578, 3060, 1258,
        1896, 1601,  422, 3314])
Epoch: 2648, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2649 - Batch 1 ########################
IDs in batch 1: tensor([4256,  308, 3211,  682, 3900,  627, 1451, 4267, 3421, 2060, 1271, 3430,
        1379, 1646, 2025,  379])
Epoch: 2649, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2650 - Batch 1 ########################
IDs in batch 1: tensor([2505, 3238, 1423, 1310,  103, 1994, 1459, 3647, 2912, 1722, 2921, 1453,
        3366, 2800, 3102,  790])
Epoch: 2650, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2651 - Batch 1 ########################
IDs in batch 1: tensor([3972, 2418, 2339, 4158, 2845,  514, 2691, 2898, 3949, 3765, 1126, 1553,
        3166, 1080, 1832, 3188])
Epoch: 2651, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2652 - Batch 1 ########################
IDs in batch 1: tensor([1545, 4173, 1116, 3859,  974, 4138, 1180, 3869, 2005,  496,  105,  890,
        1958,  642,  795, 1125])
Epoch: 2652, Training Loss: 0.36, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2653 - Batch 1 ########################
IDs in batch 1: tensor([2963, 1832,  171, 1373, 1732, 3746, 1139, 3366, 2664, 2196, 1270, 2664,
        2161,  960, 1668, 1395])
Epoch: 2653, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2654 - Batch 1 ########################
IDs in batch 1: tensor([ 747, 1497, 3858, 1506, 1809, 1049, 3589, 1913, 1857, 4057, 4018, 3401,
        1569, 1408, 2393, 1273])
Epoch: 2654, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2655 - Batch 1 ########################
IDs in batch 1: tensor([1093, 2368, 3200, 2567, 3525, 2278,  312, 3254,  269, 1726, 2669,  280,
         752, 2734,  491,  378])
Epoch: 2655, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2656 - Batch 1 ########################
IDs in batch 1: tensor([2115, 2085, 1999, 4133, 1258, 2523,  688, 1174, 1635, 3793, 1986, 1081,
        1170,  361, 3628, 3896])
Epoch: 2656, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2657 - Batch 1 ########################
IDs in batch 1: tensor([ 680,  714,  121, 2339, 1981, 1740,  276, 2280, 3183, 3110,  846, 2024,
        3987, 3507, 2275, 1518])
Epoch: 2657, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2658 - Batch 1 ########################
IDs in batch 1: tensor([3286, 2339, 4031, 1319,  606, 2795,  946, 4003, 2915, 1699, 1784, 2508,
        3211,  770, 2179,   11])
Epoch: 2658, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2659 - Batch 1 ########################
IDs in batch 1: tensor([1952,  960, 3035, 3904,  968,  205,   96,  140, 4205, 2505, 1942, 2231,
        2564,  963, 1213, 3298])
Epoch: 2659, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2660 - Batch 1 ########################
IDs in batch 1: tensor([2672, 3130, 2237, 1733, 1634, 2617, 2046, 1130, 3781, 2299,  401, 3764,
        2282, 2412, 2072, 2586])
Epoch: 2660, Training Loss: 0.42, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2661 - Batch 1 ########################
IDs in batch 1: tensor([3553, 1118, 1121, 3364, 1252, 2433, 1082, 3948, 2157,  228, 3692, 1636,
        2789,  376, 3777, 3262])
Epoch: 2661, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2662 - Batch 1 ########################
IDs in batch 1: tensor([2410, 4224, 1144, 3996, 3142, 3780, 1782, 2060, 4212, 3760, 3785, 3851,
        1793, 2280,  101, 2667])
Epoch: 2662, Training Loss: 0.42, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2663 - Batch 1 ########################
IDs in batch 1: tensor([ 221,  245, 3558, 2334,  729,  517, 2618,  455, 1316, 1501, 2180,  826,
        2856,  388, 3818, 3895])
Epoch: 2663, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2664 - Batch 1 ########################
IDs in batch 1: tensor([2067, 4070, 3480, 3308,  950, 2291,  346, 3438, 1619,  409, 1218, 1660,
         395, 1439, 3109, 2926])
Epoch: 2664, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2665 - Batch 1 ########################
IDs in batch 1: tensor([4268,  919, 1249, 3883, 2059, 3992, 3860, 1501, 3676, 1305, 1126, 3190,
        3476, 3815, 2412, 3757])
Epoch: 2665, Training Loss: 0.42, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2666 - Batch 1 ########################
IDs in batch 1: tensor([2519, 2537, 4267,  452, 3832, 2398, 2352, 3461, 1321,  387,  330, 3974,
        1274, 3406,  997,  379])
Epoch: 2666, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2667 - Batch 1 ########################
IDs in batch 1: tensor([2873, 2492, 3254, 2950, 3950, 1214, 3156, 3728, 3202, 1956, 1228, 3499,
        1624, 3789, 1043, 4039])
Epoch: 2667, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2668 - Batch 1 ########################
IDs in batch 1: tensor([2761, 1235, 1199, 3248, 1272,  858, 2423, 2038, 2845, 1170, 3526, 1860,
         960,  399, 3983, 2103])
Epoch: 2668, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2669 - Batch 1 ########################
IDs in batch 1: tensor([2210, 1437, 1507, 2086, 1551, 1133,  725,   52, 3674,  605, 2605, 3534,
         991,  758,  401, 1489])
Epoch: 2669, Training Loss: 0.44, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2670 - Batch 1 ########################
IDs in batch 1: tensor([4121, 2776, 1383, 4157, 3069, 1103, 2118, 2005, 3897, 3039, 3151, 2674,
        4114, 3963,  563, 3476])
Epoch: 2670, Training Loss: 0.29, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2671 - Batch 1 ########################
IDs in batch 1: tensor([2934, 3182, 1508, 3386, 1708, 4046,  177, 3461, 1588, 1037, 1456, 3451,
        3395,   71,  670, 3500])
Epoch: 2671, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2672 - Batch 1 ########################
IDs in batch 1: tensor([1128, 2274,  332,  302, 3740, 4154, 3536, 3259, 2924,  789,  545, 2090,
        4268, 2950, 4120, 1958])
Epoch: 2672, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2673 - Batch 1 ########################
IDs in batch 1: tensor([3455, 2817, 2478, 2417,  523, 1273, 3709,  733, 1334, 2659, 3862, 1179,
        2285, 1502, 3017, 2793])
Epoch: 2673, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2674 - Batch 1 ########################
IDs in batch 1: tensor([3262, 1665, 3829, 2752, 3701, 4263, 1355, 3355,  704, 1216,  908, 1832,
        3376, 2320, 1310, 2544])
Epoch: 2674, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2675 - Batch 1 ########################
IDs in batch 1: tensor([1012, 1996,  109, 1799,  399, 1283, 3810, 1779, 4163, 1281, 3787, 1219,
        3862,  896, 3439, 2196])
Epoch: 2675, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2676 - Batch 1 ########################
IDs in batch 1: tensor([ 152, 1160, 4224, 1506, 3927, 3712, 1896, 1886, 2787,  436,  674, 1716,
         879, 2879, 1130,  679])
Epoch: 2676, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2677 - Batch 1 ########################
IDs in batch 1: tensor([ 544, 4110, 3894, 3039,  934, 4249,  127,  337, 2440, 3701, 1237, 3829,
        2145, 3998, 1511, 1206])
Epoch: 2677, Training Loss: 0.49, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2678 - Batch 1 ########################
IDs in batch 1: tensor([1699,  834, 1223, 1518, 2262, 1730,  523, 3891, 1069, 2680, 1456, 2379,
        1248, 3452,  382, 1870])
Epoch: 2678, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2679 - Batch 1 ########################
IDs in batch 1: tensor([3521, 2583, 2282, 2441, 4158,  320, 4245, 1821,  395,  419, 3434, 1113,
        4139, 3781,  430,  121])
Epoch: 2679, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2680 - Batch 1 ########################
IDs in batch 1: tensor([3114, 1803,  483, 1913, 2795, 1138, 3375, 3833, 4197, 1110, 3936, 2455,
          98,  710,  481, 1410])
Epoch: 2680, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2681 - Batch 1 ########################
IDs in batch 1: tensor([2991, 2993,  415, 3056,  489,  218,  588,  409,  451, 1778, 2996, 1661,
        2388, 4126, 2102,   71])
Epoch: 2681, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2682 - Batch 1 ########################
IDs in batch 1: tensor([4268,  606, 3823, 2931, 3016, 4030, 1372,   30, 3357, 3377, 3943, 3474,
        3042,  478, 2073, 2010])
Epoch: 2682, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2683 - Batch 1 ########################
IDs in batch 1: tensor([2085, 1857, 1050,  672, 2619, 2956, 1482,  312,  985, 1015,  355, 2492,
          57, 4080, 3851, 4062])
Epoch: 2683, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2684 - Batch 1 ########################
IDs in batch 1: tensor([3180, 1094, 3838, 3925, 1007, 1123, 2429, 2798, 1284, 2871, 1061,  550,
        2649, 3271, 2385, 1089])
Epoch: 2684, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2685 - Batch 1 ########################
IDs in batch 1: tensor([3888,  186,  839, 3943, 1879,  811,  130, 1474,  265, 2149, 3719, 2667,
        2117, 4223,  824,  343])
Epoch: 2685, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2686 - Batch 1 ########################
IDs in batch 1: tensor([ 574, 1726, 2360, 3498, 1934, 2135, 1746, 3452, 3022, 2871, 4050, 1850,
        1620, 1504, 3150,  164])
Epoch: 2686, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2687 - Batch 1 ########################
IDs in batch 1: tensor([2173, 1756, 2712, 3798, 2316, 3287, 2517, 2643, 2787,  352, 1432, 1532,
        3815, 3105, 2019, 2320])
Epoch: 2687, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2688 - Batch 1 ########################
IDs in batch 1: tensor([ 503, 1872, 3829, 3513, 1949, 3998,  713, 3278, 4067, 1155, 1056, 1591,
        3913, 3003, 3465, 2363])
Epoch: 2688, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2689 - Batch 1 ########################
IDs in batch 1: tensor([3833, 2826, 3397,  646, 4036, 3378, 3875, 3160, 2470, 1779, 1439,  108,
        4073, 2282, 3446, 3253])
Epoch: 2689, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2690 - Batch 1 ########################
IDs in batch 1: tensor([4149, 3757, 3739, 3710,  858, 2692, 2661,  316, 1933, 3936, 1066, 1049,
        3252, 3417,  150, 3859])
Epoch: 2690, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2691 - Batch 1 ########################
IDs in batch 1: tensor([ 143, 3003, 1438,  531, 1425, 2799, 2539, 2350, 1218, 3603,  172, 1602,
        2448, 3132, 1707, 1809])
Epoch: 2691, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2692 - Batch 1 ########################
IDs in batch 1: tensor([1072, 1642, 4195, 1910, 1972,  639, 2170,  968,  513,  834, 1733, 3395,
        3552, 1297, 3306, 3896])
Epoch: 2692, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2693 - Batch 1 ########################
IDs in batch 1: tensor([2746, 1730, 1580,  335, 3795,  173, 4149, 1798, 2692, 4086, 3343, 2827,
        1507,  875,  441, 2127])
Epoch: 2693, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2694 - Batch 1 ########################
IDs in batch 1: tensor([4012, 4255, 2926,  219, 2506, 2563, 1835, 3677, 2791, 3594, 3483,  640,
        3357, 1952, 3925,  596])
Epoch: 2694, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2695 - Batch 1 ########################
IDs in batch 1: tensor([3859, 1871, 1417,  617, 2879, 1418,  961, 4105, 3387, 1467, 3762, 1552,
          26,  322, 2279, 3524])
Epoch: 2695, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2696 - Batch 1 ########################
IDs in batch 1: tensor([ 262, 3842,  441, 1097, 3644,  934, 3815, 1260,  878,  574, 1197, 3092,
        3065, 3514, 3833, 2085])
Epoch: 2696, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2697 - Batch 1 ########################
IDs in batch 1: tensor([3187,  303, 3726, 1137, 1496, 2724, 1037, 3455, 1381, 3749, 1176, 1993,
        2617, 1090,   41, 1349])
Epoch: 2697, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2698 - Batch 1 ########################
IDs in batch 1: tensor([1464, 3049, 3429, 3326, 2053,  661, 1294,  602,  503,  918, 3882, 3177,
        3314, 1322, 3219,  514])
Epoch: 2698, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2699 - Batch 1 ########################
IDs in batch 1: tensor([2709, 2902,  524, 4205,  219, 3371, 3075,  864,  736,   27, 2400, 3447,
          31, 3052, 1467, 1162])
Epoch: 2699, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2700 - Batch 1 ########################
IDs in batch 1: tensor([2246, 3831, 1842, 3349, 2493, 1795,  913, 2959, 1331,  850, 3704, 3914,
         876, 3607,  584, 1351])
Epoch: 2700, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2701 - Batch 1 ########################
IDs in batch 1: tensor([ 275, 1177, 1552,  201, 2730, 4256, 3523, 3410, 1897, 3468,  344,  344,
        1590, 3521,  774, 1710])
Epoch: 2701, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2702 - Batch 1 ########################
IDs in batch 1: tensor([ 229, 3375, 3984,  977, 3789, 3218, 2372, 2177,  751, 3702, 2797,  403,
        1163,  455, 3417, 1656])
Epoch: 2702, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2703 - Batch 1 ########################
IDs in batch 1: tensor([1660, 3721,  814, 1670, 2552, 3397, 2866,   56, 3384, 2040, 2342,  601,
         387, 1993,  727,  440])
Epoch: 2703, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2704 - Batch 1 ########################
IDs in batch 1: tensor([ 568, 2133, 1072, 2627, 3159,  963, 3734, 1826, 3476, 3917, 3227, 2182,
         663, 2416,  879, 3618])
Epoch: 2704, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2705 - Batch 1 ########################
IDs in batch 1: tensor([2660, 3983, 1886,  182, 1500, 2272, 2025, 2315,  202, 1156, 3258, 2772,
         306, 2851, 3594, 2063])
Epoch: 2705, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2706 - Batch 1 ########################
IDs in batch 1: tensor([4203, 2153,  483, 1163, 1200, 4026, 2414, 3282, 3131, 2365, 1080, 1825,
        1357, 1909, 2938, 2257])
Epoch: 2706, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2707 - Batch 1 ########################
IDs in batch 1: tensor([2278,   14, 3389, 1237, 3146,  432, 4251, 3311, 3755, 3936, 1545, 2420,
        3110,  555, 2097,  970])
Epoch: 2707, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2708 - Batch 1 ########################
IDs in batch 1: tensor([  10, 3377, 2961, 3734, 4046, 1868, 1642, 3261, 2298, 3065, 1054, 2652,
         732, 1125, 2866, 3779])
Epoch: 2708, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2709 - Batch 1 ########################
IDs in batch 1: tensor([ 838,  678, 2390, 3743, 3806, 4107,  484,  632, 2764, 2092, 2509, 3763,
         239, 1139,  520, 1377])
Epoch: 2709, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2710 - Batch 1 ########################
IDs in batch 1: tensor([3036, 3898, 2996, 3803, 3792,   64, 1855, 3023, 3214,  595, 1455, 1247,
         300, 2237, 3099, 1051])
Epoch: 2710, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2711 - Batch 1 ########################
IDs in batch 1: tensor([2567, 3608, 2465, 2678, 1155,  171, 3609, 3197, 1985, 2991, 1143, 3016,
        2899, 1996, 2614, 3261])
Epoch: 2711, Training Loss: 0.28, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2712 - Batch 1 ########################
IDs in batch 1: tensor([4099, 2366,  346, 1396, 3699, 3410,   51,  412, 3220, 3400, 1453, 1857,
        2956, 1228,  881,  693])
Epoch: 2712, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2713 - Batch 1 ########################
IDs in batch 1: tensor([2137,  995, 3441,  237, 3369, 3222, 2915, 1297, 4235, 1083,  476, 1540,
        2848, 3265, 2456, 3771])
Epoch: 2713, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2714 - Batch 1 ########################
IDs in batch 1: tensor([ 786, 1015, 2789, 2148, 3847, 3284, 1279, 1154,  369, 3947, 1556, 2733,
        1655, 1518, 3345,  513])
Epoch: 2714, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2715 - Batch 1 ########################
IDs in batch 1: tensor([1380, 3862, 1990, 4022, 2959, 4242, 2196, 3837,  308, 4148, 1748, 2809,
         704, 2506,  712,  257])
Epoch: 2715, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2716 - Batch 1 ########################
IDs in batch 1: tensor([3016, 1894, 4125, 3279, 3833,  172, 1641, 2423, 1857,  855, 2383,  300,
         554, 1177, 2171,  971])
Epoch: 2716, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2717 - Batch 1 ########################
IDs in batch 1: tensor([3021,  883, 2726,  539, 2074,  584, 3912, 1295, 3739, 2510, 1634, 3459,
         141, 3963, 2298,  471])
Epoch: 2717, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2718 - Batch 1 ########################
IDs in batch 1: tensor([3377, 3327, 1313, 3289, 1448, 1223, 1113, 1001, 3202, 2419, 4188,  930,
         170, 1678,  815, 2035])
Epoch: 2718, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2719 - Batch 1 ########################
IDs in batch 1: tensor([3644, 1482, 2738, 2401, 1347, 2407,  290, 3087, 2734, 2541, 1234,  963,
        1297, 2252, 2049, 2977])
Epoch: 2719, Training Loss: 0.27, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2720 - Batch 1 ########################
IDs in batch 1: tensor([ 280, 2887, 1284, 4025, 1038, 1967, 1039, 1632, 3197, 2425, 1562, 2429,
        3655,  213,  944, 3493])
Epoch: 2720, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2721 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 4014, 1132,  897, 2202, 1495,  771, 3065,  365, 3939, 4197,  876,
        1559,  376, 3461, 1840])
Epoch: 2721, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2722 - Batch 1 ########################
IDs in batch 1: tensor([  78, 1146, 1519,  942, 1171, 4077, 2493, 1285, 1798,  276, 1887, 4175,
        3873, 3997, 2209, 3826])
Epoch: 2722, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2723 - Batch 1 ########################
IDs in batch 1: tensor([2509, 1357, 1536,  812, 2070, 3211,  595, 1277,   42, 2541, 2015, 3461,
         424, 4184,  684, 2553])
Epoch: 2723, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2724 - Batch 1 ########################
IDs in batch 1: tensor([4264, 3851, 2538, 3618, 3004,  505, 1826, 3353, 1670, 1976, 1655, 3843,
        1220, 3004, 3786,  324])
Epoch: 2724, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2725 - Batch 1 ########################
IDs in batch 1: tensor([2780, 3933, 1481, 1526,  758, 2589, 1704, 1420, 2810,  917, 1177,  824,
        3022, 2379, 3161,  787])
Epoch: 2725, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2726 - Batch 1 ########################
IDs in batch 1: tensor([1180, 2842, 1346, 2005, 1852, 2745, 4114,  947,    7, 1315, 2739, 2847,
        1028,  769, 2416, 1870])
Epoch: 2726, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2727 - Batch 1 ########################
IDs in batch 1: tensor([1925, 1777,  485, 2039, 2009, 3362, 4232,  262, 3726, 2440, 1895, 2926,
         709, 2170,  858, 3563])
Epoch: 2727, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2728 - Batch 1 ########################
IDs in batch 1: tensor([2898, 3836, 4010, 4027,  900,  155, 2432, 3394, 4114, 3004,  379, 3780,
        2407,  467, 3439,  354])
Epoch: 2728, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2729 - Batch 1 ########################
IDs in batch 1: tensor([1276, 3314, 1736, 3585,  203,  594, 3438, 3488,  360, 3015, 2754, 3282,
        1536, 3755,  602, 1610])
Epoch: 2729, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2730 - Batch 1 ########################
IDs in batch 1: tensor([2305,  149, 1855, 2425,  753, 1866, 1292, 3928,  946,  627,  779,  512,
        2624, 1375, 1275, 1751])
Epoch: 2730, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2731 - Batch 1 ########################
IDs in batch 1: tensor([2767, 4000,  213, 1634, 2391, 3829,  729, 3233, 3313, 3936,  766,  105,
        4197, 1166, 1985, 3851])
Epoch: 2731, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2732 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 2726, 3597, 3417, 1819, 1317, 1588, 1921, 4088, 4175, 2751, 3250,
         701,  534, 2246, 3837])
Epoch: 2732, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2733 - Batch 1 ########################
IDs in batch 1: tensor([3638,  244,   11, 2831,  126,  177,  279, 3044, 3306,   57,  667, 1548,
        4225, 4036,  237,  147])
Epoch: 2733, Training Loss: 0.45, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2734 - Batch 1 ########################
IDs in batch 1: tensor([ 149, 1979, 2014, 1471, 1618, 3913, 1138,  200, 3455, 1786, 2338,  408,
        1157,  547, 3222, 1313])
Epoch: 2734, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2735 - Batch 1 ########################
IDs in batch 1: tensor([  95, 2331, 3806,  397, 2044, 3146,  522, 2169, 2886, 3712, 1009,   73,
        4159, 3488, 1426, 1032])
Epoch: 2735, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2736 - Batch 1 ########################
IDs in batch 1: tensor([3881, 1911,  730, 1282, 1953, 3874, 1270, 2857, 3484,  558, 3647,  665,
         255,  259, 1319,  475])
Epoch: 2736, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2737 - Batch 1 ########################
IDs in batch 1: tensor([2703, 3873, 1464,  983,  723,  825, 3278, 1063, 1297, 1147, 2052, 1942,
        2125,  402, 3094, 3786])
Epoch: 2737, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2738 - Batch 1 ########################
IDs in batch 1: tensor([3838, 1706, 3572, 2518,  497,  325, 1578, 2339, 2127,  894, 3535, 4226,
        3545, 3723, 1988, 3327])
Epoch: 2738, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2739 - Batch 1 ########################
IDs in batch 1: tensor([ 334, 3723, 3838, 1777,  214, 2977, 3299,  752,  491, 3888,  980, 3914,
        1166, 2831, 4228, 3701])
Epoch: 2739, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2740 - Batch 1 ########################
IDs in batch 1: tensor([2116, 1551, 1996,  727, 2482,  108, 1269,  334,  974,  770, 1278, 4255,
         996, 1229, 2942, 3121])
Epoch: 2740, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2741 - Batch 1 ########################
IDs in batch 1: tensor([ 844, 3518, 1991, 1221, 1061, 3832,  491,  565, 3842, 1393, 1942, 2872,
         492, 1881,  959, 1228])
Epoch: 2741, Training Loss: 0.38, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2742 - Batch 1 ########################
IDs in batch 1: tensor([1459,  278, 2365, 1811, 2417, 1459, 3254, 2873, 3598, 1417, 2859, 1730,
        1495,  212, 1010, 1434])
Epoch: 2742, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2743 - Batch 1 ########################
IDs in batch 1: tensor([3558, 4245,  283,  967, 4125, 1163, 3094, 1088, 3488, 2999, 3132,  314,
        2810, 2432, 2841, 3513])
Epoch: 2743, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2744 - Batch 1 ########################
IDs in batch 1: tensor([2604, 3714, 2353, 1267, 3438, 3615,  613, 3374, 1375,  520, 1414,  573,
        2961, 3628, 1589, 3448])
Epoch: 2744, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2745 - Batch 1 ########################
IDs in batch 1: tensor([  74, 2002, 2393, 4230, 3126, 1870, 2529, 2357,  212,  417, 3441,  173,
         753, 2148, 1993, 1644])
Epoch: 2745, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2746 - Batch 1 ########################
IDs in batch 1: tensor([ 833, 3036, 3388, 4232, 3309, 3334, 1578,  739, 2986, 2619, 3392, 3408,
        3372, 3506, 2521, 1710])
Epoch: 2746, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2747 - Batch 1 ########################
IDs in batch 1: tensor([1573, 1690, 1784, 2606,  198, 4035, 1290, 3870,  849, 2109, 2652,  568,
        2536, 2236,  333, 3545])
Epoch: 2747, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2748 - Batch 1 ########################
IDs in batch 1: tensor([3500,  851, 1920, 4218, 1977, 3206, 1540, 1137,  928, 4238, 2122, 1766,
        1897,  326, 1724,  281])
Epoch: 2748, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2749 - Batch 1 ########################
IDs in batch 1: tensor([1802, 2149, 1925, 2545, 4230, 1471, 1612, 2938, 2729,  848,  893, 2115,
         501, 2431, 1580, 2357])
Epoch: 2749, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2750 - Batch 1 ########################
IDs in batch 1: tensor([1006, 4044,  632,  198, 1927,  726, 4076, 2039, 1012, 4009, 3964, 1413,
        2765, 3044, 3870, 3711])
Epoch: 2750, Training Loss: 0.29, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2751 - Batch 1 ########################
IDs in batch 1: tensor([1004,  317, 3949, 3858,  752, 3806, 3032, 1085,  644, 1649,  292, 3414,
         969,  936, 2643, 1143])
Epoch: 2751, Training Loss: 0.32, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2752 - Batch 1 ########################
IDs in batch 1: tensor([1932, 1990, 1578, 1680,  467, 3250, 2855, 2040, 1050, 1881, 3323, 3124,
          39, 1596, 3634, 1419])
Epoch: 2752, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2753 - Batch 1 ########################
IDs in batch 1: tensor([ 394,  991,  628, 1613,  756, 1195, 3000, 1947, 2167,  554, 1159, 1439,
         154, 3239, 3705, 1832])
Epoch: 2753, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2754 - Batch 1 ########################
IDs in batch 1: tensor([3866, 4078, 3557, 1849, 3323, 2974, 2202, 2652, 3425, 3543, 1634, 1567,
        1809, 3891, 2770, 2050])
Epoch: 2754, Training Loss: 0.42, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2755 - Batch 1 ########################
IDs in batch 1: tensor([4186,   59, 1295, 1364, 2017, 1206,  465, 2102, 3914, 3478, 1601, 2443,
        1195, 1704,  701,  426])
Epoch: 2755, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2756 - Batch 1 ########################
IDs in batch 1: tensor([1824,  537, 4232, 3797, 3426, 3197, 1952, 3417, 4055,  913,  316, 1244,
         363, 1681,  149, 2494])
Epoch: 2756, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2757 - Batch 1 ########################
IDs in batch 1: tensor([ 982,  489,  497, 2457, 1287, 3829, 3588, 1745, 3429, 2127,  258, 1764,
        1841, 1354, 3373,  873])
Epoch: 2757, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2758 - Batch 1 ########################
IDs in batch 1: tensor([2819, 2558, 3353, 3360,   82, 2003, 3945, 1526, 2874, 2998,  148, 4038,
        1570,  430, 1605,  843])
Epoch: 2758, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2759 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 1092,  417,  858, 2627, 4134, 3925,  350, 2352, 1428, 3614, 2775,
        2489, 1478, 1084, 3778])
Epoch: 2759, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2760 - Batch 1 ########################
IDs in batch 1: tensor([ 483, 4234, 2736,  199,  334,   56,  135, 3479, 1045,  172, 3253,  688,
        1937, 1970,  908, 1270])
Epoch: 2760, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2761 - Batch 1 ########################
IDs in batch 1: tensor([ 261, 1085, 3242, 1740, 3243, 2022, 3219, 2309,  596, 2605, 4203, 1937,
        2964,  862, 1102, 2807])
Epoch: 2761, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2762 - Batch 1 ########################
IDs in batch 1: tensor([  84, 1299,  352, 3271, 3757, 1842, 4084, 1627, 4157, 3762,  490, 1335,
        1156, 4139, 3540,  522])
Epoch: 2762, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2763 - Batch 1 ########################
IDs in batch 1: tensor([3385, 1274, 3891, 1423, 2261, 3917, 3958, 1899, 2111, 3136, 3756, 1925,
        1774, 2655, 3585, 2730])
Epoch: 2763, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2764 - Batch 1 ########################
IDs in batch 1: tensor([3968, 2726, 2551, 3676, 2005, 3465, 2178, 2562, 1419, 3765, 4048, 1440,
         757,  223, 1062, 2347])
Epoch: 2764, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2765 - Batch 1 ########################
IDs in batch 1: tensor([1626, 2249, 3996, 4257, 3583, 3672, 1134,  966, 3925, 2228, 2113, 2689,
        1399, 1984, 3468,  741])
Epoch: 2765, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2766 - Batch 1 ########################
IDs in batch 1: tensor([1841, 2711, 1493, 3438, 4089, 1916, 2565, 4139,   35,  827, 1284, 2352,
         961, 3956, 1753, 1163])
Epoch: 2766, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2767 - Batch 1 ########################
IDs in batch 1: tensor([3927,  946, 1252,  532, 2854,  919,  632, 3821,  205, 1679, 2869,   27,
         341, 1006,  821, 1639])
Epoch: 2767, Training Loss: 0.39, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2768 - Batch 1 ########################
IDs in batch 1: tensor([3022, 4158, 1309,  206,  203,  323,  437, 2870, 1900, 2730, 1012, 4188,
        1042, 3053, 3553, 1320])
Epoch: 2768, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2769 - Batch 1 ########################
IDs in batch 1: tensor([3936,  302, 1183,  112, 3091, 1085,  245, 2496, 3343, 1278, 4049, 4108,
        3836, 1700, 2649, 2378])
Epoch: 2769, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2770 - Batch 1 ########################
IDs in batch 1: tensor([2013,  539, 1122,  155, 2279, 1469, 1916, 1778, 1250,  497, 2913, 1951,
        3451, 3714,  897, 3465])
Epoch: 2770, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2771 - Batch 1 ########################
IDs in batch 1: tensor([3278, 4058, 3241, 2535, 3264, 2745, 3908, 3787, 2236, 2505, 4154, 1496,
        1718, 2274,   22, 4051])
Epoch: 2771, Training Loss: 0.48, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2772 - Batch 1 ########################
IDs in batch 1: tensor([2743,  199, 3940, 2514, 2879, 1932, 3152, 2692, 2761,  488, 3123, 1231,
        2241, 2169,  214, 3042])
Epoch: 2772, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2773 - Batch 1 ########################
IDs in batch 1: tensor([1331, 2710, 1326, 4040,  714, 2475, 2188,  572,  159, 3271, 2470, 3256,
        3021, 2292, 1059,  211])
Epoch: 2773, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2774 - Batch 1 ########################
IDs in batch 1: tensor([1143, 3168, 3075, 4234, 3460,  838, 3614, 1118, 2204, 1558, 2403, 3680,
        1863, 1428, 3490,   34])
Epoch: 2774, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2775 - Batch 1 ########################
IDs in batch 1: tensor([1257, 3896, 2782, 2827, 2073, 4038, 2839, 2601, 3647, 2228,  320, 1706,
        2315, 1643, 1985,  794])
Epoch: 2775, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2776 - Batch 1 ########################
IDs in batch 1: tensor([1950, 1596, 1224, 2066,  909, 1081, 3866, 2272, 1678,  909, 2144, 2278,
        2109,  644,   38,  344])
Epoch: 2776, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2777 - Batch 1 ########################
IDs in batch 1: tensor([2789,  239, 2443, 3970, 2649, 3052,  688, 2885, 2516,  444, 3426, 3071,
        4099, 1823,  434, 2316])
Epoch: 2777, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2778 - Batch 1 ########################
IDs in batch 1: tensor([3953,  411, 4199, 1072, 1834,  632, 3732, 3516, 3529, 1263,  854,  127,
         344,  653, 3696,   19])
Epoch: 2778, Training Loss: 0.34, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2779 - Batch 1 ########################
IDs in batch 1: tensor([1012, 3162, 2103, 1034,  119,  498,  790, 4100,  967,  819, 2615, 3035,
         747, 1047, 4140, 1562])
Epoch: 2779, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2780 - Batch 1 ########################
IDs in batch 1: tensor([1794, 4131, 2064, 3078, 2523,  462, 3594, 1789, 1775, 4077, 1123, 2277,
         403, 2306, 2110,  405])
Epoch: 2780, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2781 - Batch 1 ########################
IDs in batch 1: tensor([1711, 1344, 1063, 1295, 2236, 2872, 1901,  523, 1981,  279, 1152,  505,
        3216, 3002, 3272, 2300])
Epoch: 2781, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2782 - Batch 1 ########################
IDs in batch 1: tensor([ 832, 3032,  617, 2365, 1863, 2362,  278,  658, 2099,  812, 2027, 3958,
        2950, 3002, 3461, 2271])
Epoch: 2782, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2783 - Batch 1 ########################
IDs in batch 1: tensor([3974, 1026,  883, 1901,  712, 3190, 3438, 2606, 3998,  154, 3598, 2161,
        1649, 3765, 4036, 2350])
Epoch: 2783, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2784 - Batch 1 ########################
IDs in batch 1: tensor([ 229, 3398, 1525, 3337, 2331, 3740, 1911, 3656, 1613, 3767, 3387, 2518,
        1923, 2619,  805, 2489])
Epoch: 2784, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2785 - Batch 1 ########################
IDs in batch 1: tensor([ 575, 4215, 1612, 4031, 1060,  966,  396, 2284,  300, 3437,   32, 3196,
        4256, 2498,   51, 2236])
Epoch: 2785, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2786 - Batch 1 ########################
IDs in batch 1: tensor([2844, 3115, 3568, 3384, 2166, 2393,  844, 1799, 3843, 4229, 1183, 3676,
        3392, 3360, 1467, 2484])
Epoch: 2786, Training Loss: 0.40, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2787 - Batch 1 ########################
IDs in batch 1: tensor([1751, 2781,  841, 3756, 2892, 1200, 3432,  419, 1023,  635, 4156,  191,
        3845, 3437,  396, 2961])
Epoch: 2787, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2788 - Batch 1 ########################
IDs in batch 1: tensor([1384, 3168,  665, 1679, 1954, 4254, 1322,  207,  470, 1333, 3683, 3938,
         514,  959, 1031, 3617])
Epoch: 2788, Training Loss: 0.32, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2789 - Batch 1 ########################
IDs in batch 1: tensor([ 870,  805,  872, 1861,  261, 2341, 3389, 2499, 3259,  250, 1294, 3009,
        3707, 4189,  942,  229])
Epoch: 2789, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2790 - Batch 1 ########################
IDs in batch 1: tensor([3474,  577, 3241, 2710, 1779,  622, 3706, 2046, 3253, 1580, 2111, 2999,
        4105, 2382, 1680, 3406])
Epoch: 2790, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2791 - Batch 1 ########################
IDs in batch 1: tensor([2734, 2748, 2444, 3984, 1780, 1273, 2218,  563, 1001, 2198,  403,  141,
        3329, 1204,  308, 3286])
Epoch: 2791, Training Loss: 0.44, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2792 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 3956,  226, 3664, 1299,  566, 2191, 4068,  228, 2178, 2567, 2731,
        2364, 3493, 2217, 1918])
Epoch: 2792, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2793 - Batch 1 ########################
IDs in batch 1: tensor([3603, 2526, 2886,  171,   71, 1767, 1448, 1960, 2224, 1825, 2073,  980,
        4157, 1128, 1218, 2132])
Epoch: 2793, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2794 - Batch 1 ########################
IDs in batch 1: tensor([2993, 1050, 1290,  607, 2295, 2154, 2719, 2369,  685,  710, 1509,  188,
        2618, 2798, 2545, 1774])
Epoch: 2794, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2795 - Batch 1 ########################
IDs in batch 1: tensor([1980, 3424, 3391, 2373, 1110,  693, 2837, 2064, 2458,  432, 1724,  466,
         659, 1220, 2027, 1519])
Epoch: 2795, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2796 - Batch 1 ########################
IDs in batch 1: tensor([3847, 2435, 1380,  682, 1175, 1655, 2908, 3112,  342, 2951,  900, 1676,
        2188, 2561, 1070, 2678])
Epoch: 2796, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2797 - Batch 1 ########################
IDs in batch 1: tensor([ 704, 1770,  200, 2394, 1233, 3398, 4073, 1272,  218,  978, 2315,  121,
         211,  818, 3525,  660])
Epoch: 2797, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2798 - Batch 1 ########################
IDs in batch 1: tensor([2418, 4016, 3278, 3524, 1334, 3308, 1499, 3552, 3643, 3810,  100, 2600,
        1122, 3930, 1824,   25])
Epoch: 2798, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2799 - Batch 1 ########################
IDs in batch 1: tensor([ 199, 1010,  448, 2879, 1476, 2493,  212, 2170,   63, 1556, 2845,  368,
        1103, 1355, 1061, 2236])
Epoch: 2799, Training Loss: 0.28, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2800 - Batch 1 ########################
IDs in batch 1: tensor([2145, 3881, 1476, 1984,  879, 2815, 3200,  563, 1745, 2189,  389, 3999,
        3930, 4012,   26, 3257])
Epoch: 2800, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2801 - Batch 1 ########################
IDs in batch 1: tensor([1551, 1909, 2743,  596, 3786, 2009, 4186, 3304, 3999, 1212, 2369, 2993,
        1934, 1706, 4133,  413])
Epoch: 2801, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2802 - Batch 1 ########################
IDs in batch 1: tensor([1455, 1563, 2025, 2938, 3446, 1102, 2281, 1812,  876,  384, 3146,  919,
        3135, 1396, 2254, 3156])
Epoch: 2802, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2803 - Batch 1 ########################
IDs in batch 1: tensor([1488,   70, 2207, 3101, 4007,  369, 3078, 3023,  956, 1834, 2558,  602,
         128, 3589, 1059, 3696])
Epoch: 2803, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2804 - Batch 1 ########################
IDs in batch 1: tensor([1008,  371, 1781, 1832, 2399,  395,  944, 3471,  137,  394, 1272, 1510,
        3960, 2114, 2724, 2291])
Epoch: 2804, Training Loss: 0.24, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2805 - Batch 1 ########################
IDs in batch 1: tensor([3650, 1090, 2578,   85, 3430, 1592,  340, 3547, 4005,  411,  327,  133,
         658,  106, 1346, 3960])
Epoch: 2805, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2806 - Batch 1 ########################
IDs in batch 1: tensor([1087, 4198, 3592, 2156,  201, 1996, 3489, 3951, 2467, 1297,  880, 2030,
         821, 3514, 2788,  407])
Epoch: 2806, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2807 - Batch 1 ########################
IDs in batch 1: tensor([3264, 4158, 2463, 1212, 3207, 4072, 1181, 3815, 4134, 1345,  642,  507,
        3982, 3968, 1369, 3516])
Epoch: 2807, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2808 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 2480,  747, 3853, 3999, 3254, 3753,    5, 1808, 2497, 3069, 4140,
         402,  950, 3235, 3157])
Epoch: 2808, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2809 - Batch 1 ########################
IDs in batch 1: tensor([4159, 3223,  356,  578,  954,  228, 3438, 2827, 3922, 2656, 1803, 2696,
        1081, 2114,  730, 3823])
Epoch: 2809, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2810 - Batch 1 ########################
IDs in batch 1: tensor([1444, 2492, 1028, 2848, 1305,  894, 3990,  467, 1128, 1183, 1386, 2493,
        2182, 4046, 2945, 1195])
Epoch: 2810, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2811 - Batch 1 ########################
IDs in batch 1: tensor([2309,   64,   64, 1508,  401, 4245, 1708, 1073, 2205, 3400, 2253, 1857,
        3704, 1044, 3669, 3015])
Epoch: 2811, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2812 - Batch 1 ########################
IDs in batch 1: tensor([4014, 1190,  149, 2393, 1648, 1942, 1595,  378,  213, 3487, 3971, 3388,
        2209, 1473, 4180, 3181])
Epoch: 2812, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2813 - Batch 1 ########################
IDs in batch 1: tensor([1573, 1425, 2640, 1195, 3841, 1512, 2103,  419,  785,  159,  987, 2287,
        1459, 2390,  769,  757])
Epoch: 2813, Training Loss: 0.43, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2814 - Batch 1 ########################
IDs in batch 1: tensor([3453,  541, 2449, 2671, 1822, 1315, 2246, 4088, 2170, 2349, 4076, 3363,
        2977, 2912, 3992,  896])
Epoch: 2814, Training Loss: 0.41, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2815 - Batch 1 ########################
IDs in batch 1: tensor([ 628, 1448, 3427,  762, 2085,  826, 2632, 2509, 1094,  250, 1766, 1599,
        2851, 3277, 2065,   92])
Epoch: 2815, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2816 - Batch 1 ########################
IDs in batch 1: tensor([1234,  762, 3474, 1988, 4168, 1733, 1272, 1084, 3123, 2680,  786, 1310,
        1049, 3615, 3458, 2337])
Epoch: 2816, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2817 - Batch 1 ########################
IDs in batch 1: tensor([3984, 3044, 3531, 3925,  991, 3321, 1410, 2173,  315, 2571, 3541, 1860,
        3632, 2358, 3088, 3557])
Epoch: 2817, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2818 - Batch 1 ########################
IDs in batch 1: tensor([3822, 3557, 2046, 1861, 1610,  110, 1968, 1973, 2880, 3306,  261, 2523,
        1291, 3831,  887,  538])
Epoch: 2818, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2819 - Batch 1 ########################
IDs in batch 1: tensor([3486, 3507, 2306, 3018, 3490, 2681, 1439, 3039, 2741, 2207, 3336, 2912,
         281,  807, 3751, 1229])
Epoch: 2819, Training Loss: 0.35, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2820 - Batch 1 ########################
IDs in batch 1: tensor([4010, 1650, 2553, 3146, 2324, 2440, 2074, 4089, 2442, 3344, 2209,  377,
        4161,  586, 2991,  111])
Epoch: 2820, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2821 - Batch 1 ########################
IDs in batch 1: tensor([1927, 3470,  730, 1326, 1336, 1910,  139, 2192, 3615, 3021, 2376,  871,
         704, 2809, 1047, 1868])
Epoch: 2821, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2822 - Batch 1 ########################
IDs in batch 1: tensor([3447, 4220, 1808, 3429, 3661, 1793, 3357, 4115, 2125,  454, 4184, 2423,
         679, 3964,  413, 3345])
Epoch: 2822, Training Loss: 0.33, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2823 - Batch 1 ########################
IDs in batch 1: tensor([1485, 1370, 3057,  709, 3609, 3569, 3637,  320, 4224, 3488, 2781, 1063,
        4113,  990, 1317, 1991])
Epoch: 2823, Training Loss: 0.57, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2824 - Batch 1 ########################
IDs in batch 1: tensor([1589,  730, 3896, 2990, 1767,  785,  896, 2590, 1712, 3573, 2081, 2660,
        2989, 2806, 1886, 1685])
Epoch: 2824, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2825 - Batch 1 ########################
IDs in batch 1: tensor([3157,  324, 3698, 1677, 1420, 1082, 4095, 3859, 2353, 3544, 3577, 2817,
        2874, 1113, 1602,  796])
Epoch: 2825, Training Loss: 0.41, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2826 - Batch 1 ########################
IDs in batch 1: tensor([  59,  113, 1396, 1158,  996, 4159, 2749, 3078, 3549, 3874,  809, 1613,
         991, 3847, 2579,   73])
Epoch: 2826, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2827 - Batch 1 ########################
IDs in batch 1: tensor([1417,  490,  691, 1885, 4212, 3754, 1646, 2120, 4228,  340, 3823, 1897,
         505, 1506,  953, 3447])
Epoch: 2827, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2828 - Batch 1 ########################
IDs in batch 1: tensor([2993,   64, 2423, 1420, 3621, 2799, 2219, 3570,  919, 1330, 1324, 2664,
        3529, 3557, 2535, 3876])
Epoch: 2828, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2829 - Batch 1 ########################
IDs in batch 1: tensor([3663, 3939,   37, 3035, 3440, 3936, 2193, 3610,  120, 3627, 4144, 3598,
        1811, 2817, 3644, 2228])
Epoch: 2829, Training Loss: 0.86, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2830 - Batch 1 ########################
IDs in batch 1: tensor([2927,  379, 2618, 1850, 2697, 2758, 2287,  689, 3968, 4025, 2672, 2483,
         869,  117,  435,  335])
Epoch: 2830, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2831 - Batch 1 ########################
IDs in batch 1: tensor([2213, 2539, 4082, 3110, 1001, 2605, 2014, 2217, 2498, 2780, 2926,  723,
         723, 1059, 4214, 2874])
Epoch: 2831, Training Loss: 0.18, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2832 - Batch 1 ########################
IDs in batch 1: tensor([3601, 2432, 1390,  426, 1559, 1863, 2107, 1454, 2085, 1974, 1507, 1963,
         127, 1376, 3400, 4013])
Epoch: 2832, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2833 - Batch 1 ########################
IDs in batch 1: tensor([3243, 3853,  689, 3548, 4044, 3203, 2857, 1365, 3704, 4245, 1315, 4115,
        2726, 3922, 4013, 2575])
Epoch: 2833, Training Loss: 0.53, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2834 - Batch 1 ########################
IDs in batch 1: tensor([4103, 1602, 3473, 3400, 2342, 3540, 2518,  864, 3132, 1996,  603,  628,
         402,  260, 2495, 1868])
Epoch: 2834, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2835 - Batch 1 ########################
IDs in batch 1: tensor([3135, 1420,   21, 3081, 3660, 3956, 1840, 1585,   98, 3816, 1443, 2514,
         667, 2323, 1235, 1335])
Epoch: 2835, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2836 - Batch 1 ########################
IDs in batch 1: tensor([2758, 3234,  957,   84, 3523,  701, 1404, 1646, 3883, 2074, 2027, 2191,
         846,  937, 1174, 1094])
Epoch: 2836, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2837 - Batch 1 ########################
IDs in batch 1: tensor([2022, 3298,  975, 1882, 1679, 2002,  858, 2251, 1126, 4218, 3352, 1375,
         967, 1296, 2500, 2726])
Epoch: 2837, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2838 - Batch 1 ########################
IDs in batch 1: tensor([1067, 1305, 1334,  356, 3943, 2065,  351, 1025, 2065, 1134, 3831, 3368,
        1198, 2435,  881, 1612])
Epoch: 2838, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2839 - Batch 1 ########################
IDs in batch 1: tensor([3124,  539, 4088, 2956,  384,  482,  878, 2254, 2203, 1208,  338, 2209,
        3715, 4134, 1364, 2497])
Epoch: 2839, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2840 - Batch 1 ########################
IDs in batch 1: tensor([2500, 4198, 3513, 3968, 2966,  646, 3549, 3009, 4158, 3448,  469,  474,
        1023,  809, 4077, 2755])
Epoch: 2840, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2841 - Batch 1 ########################
IDs in batch 1: tensor([2429, 1005, 2241, 3888, 2895,  546, 2847, 4089, 4115, 2254, 3051, 2472,
         601, 3589, 3697,  474])
Epoch: 2841, Training Loss: 0.37, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2842 - Batch 1 ########################
IDs in batch 1: tensor([2844, 3866, 2802, 2423,  701, 2978, 1950, 1734, 2120, 2990, 3632, 1481,
        3863,  154, 1467, 3433])
Epoch: 2842, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2843 - Batch 1 ########################
IDs in batch 1: tensor([1070,  437,  607,  921, 1173, 1024, 3339, 1277,  591, 1619,  613, 3983,
        4235, 1141,  238, 1803])
Epoch: 2843, Training Loss: 0.62, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2844 - Batch 1 ########################
IDs in batch 1: tensor([1267, 3214, 2317, 2873, 1160, 3025, 3802, 2848, 1249, 4055, 2466, 3534,
        2031, 1233, 4184, 2950])
Epoch: 2844, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2845 - Batch 1 ########################
IDs in batch 1: tensor([3610, 3660,  661, 2802,  125, 2725, 3291, 2115, 1035, 3547, 4181,  943,
        3523, 3829, 3414, 1482])
Epoch: 2845, Training Loss: 0.23, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2846 - Batch 1 ########################
IDs in batch 1: tensor([ 514, 1032, 2710, 2338, 3943,  555, 1299, 3709,  220,  399, 1861, 1237,
        3523, 3693, 2034, 2902])
Epoch: 2846, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2847 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 3356, 1484,  862, 1825, 1602, 3591, 1589, 2219, 1501, 3356, 3812,
         247, 3493, 2108, 1977])
Epoch: 2847, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2848 - Batch 1 ########################
IDs in batch 1: tensor([2791, 2809, 3040, 4146,  295, 1753, 2844, 4159, 3021, 1999, 3839, 1291,
        1833, 2393,  152,  434])
Epoch: 2848, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2849 - Batch 1 ########################
IDs in batch 1: tensor([1773, 2299, 3711, 2429, 1762, 1429, 3161, 3112, 1213, 2767, 2524,  858,
        2631, 1469, 2185, 4203])
Epoch: 2849, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2850 - Batch 1 ########################
IDs in batch 1: tensor([ 970,  605,  514, 2181, 2539, 1810, 1196, 4266, 1212, 2782, 3869, 1344,
         137,  557, 1812, 2899])
Epoch: 2850, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2851 - Batch 1 ########################
IDs in batch 1: tensor([2236, 2949, 3528, 3468, 4235, 1870, 1525, 1958, 4009,  177,  229,  282,
        2172, 2484,  183,  330])
Epoch: 2851, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2852 - Batch 1 ########################
IDs in batch 1: tensor([3337, 1504, 1113, 3993, 3135, 3697, 3533, 4253, 2150, 2287, 2553, 4049,
        1012,   74, 2555,  946])
Epoch: 2852, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2853 - Batch 1 ########################
IDs in batch 1: tensor([ 682, 1089, 3058,  401, 2825, 1155, 1201, 4159, 3769, 2291, 1363, 1589,
         918,  220, 2732,  964])
Epoch: 2853, Training Loss: 0.41, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2854 - Batch 1 ########################
IDs in batch 1: tensor([2997, 1604,  352, 3379,  141,  739,  110, 1990, 2708, 3058, 3329, 1406,
         351, 1196,  710, 2542])
Epoch: 2854, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2855 - Batch 1 ########################
IDs in batch 1: tensor([ 928, 2523,  333, 1098, 3333, 3078, 3037, 1958, 3429,  914, 2249, 2812,
        4143,  823, 3060, 1861])
Epoch: 2855, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2856 - Batch 1 ########################
IDs in batch 1: tensor([1111,  841, 2016, 1553, 2081, 2086,  583, 4044, 1459, 3275, 2823,  111,
        3014, 3426, 1087, 4140])
Epoch: 2856, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2857 - Batch 1 ########################
IDs in batch 1: tensor([2261, 4121,  450,  141,  427, 2741,  412, 1155, 3537, 1559, 2027,  876,
        3488, 3683,  882, 3585])
Epoch: 2857, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2858 - Batch 1 ########################
IDs in batch 1: tensor([1868, 2629,  196, 2745, 3475, 3594, 4017,  952, 2451,  933, 1942,  724,
        1540, 1237, 4058, 1497])
Epoch: 2858, Training Loss: 0.25, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2859 - Batch 1 ########################
IDs in batch 1: tensor([2905, 1402, 1352, 1490,   44,  978, 3587, 3035, 2157, 2797,  434,  292,
         332, 4194, 3069, 2238])
Epoch: 2859, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2860 - Batch 1 ########################
IDs in batch 1: tensor([ 630,  534, 2437, 3208, 2326, 2463, 3425, 3492, 3895,  510, 2784, 2601,
        1283, 2212, 3112, 2202])
Epoch: 2860, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2861 - Batch 1 ########################
IDs in batch 1: tensor([3414,  398, 2209, 1504, 3400, 1357, 4242, 1844,  645, 3461, 3049,  778,
        1920,  762,  762,  910])
Epoch: 2861, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2862 - Batch 1 ########################
IDs in batch 1: tensor([1284,  264,  736,  866, 3585,  367, 4076,  135, 1340, 3360, 1107,  245,
         858, 3458, 1260, 2577])
Epoch: 2862, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2863 - Batch 1 ########################
IDs in batch 1: tensor([1851, 3478,  278, 2144, 3942, 2511, 2232,  195,  871, 2821, 1482, 3311,
        3745,  228, 2405, 3747])
Epoch: 2863, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2864 - Batch 1 ########################
IDs in batch 1: tensor([1760, 1186, 3952, 1663, 4056, 3079, 2860, 1125, 1845, 2385, 1605, 2453,
         568, 1376, 2106, 2995])
Epoch: 2864, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2865 - Batch 1 ########################
IDs in batch 1: tensor([1152,  456,  788, 1481, 3098, 3246,  276,  811, 1737, 4235,  943, 2255,
        1063, 2710,  803, 1083])
Epoch: 2865, Training Loss: 0.33, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2866 - Batch 1 ########################
IDs in batch 1: tensor([2218,  919,  578, 1035, 4172, 2423, 1478, 1426, 4050, 2693, 1710,   92,
        2292, 1540,  181, 2419])
Epoch: 2866, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2867 - Batch 1 ########################
IDs in batch 1: tensor([3342, 3117, 1780, 1328, 4056, 1955, 1426, 3654, 3521, 4113, 2957, 2154,
        3254, 3438, 1250,   49])
Epoch: 2867, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2868 - Batch 1 ########################
IDs in batch 1: tensor([2703, 3851, 2559, 2572, 2031,  815, 2476,  545, 4215,  960, 3372, 3433,
         790,   34,  732, 2010])
Epoch: 2868, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2869 - Batch 1 ########################
IDs in batch 1: tensor([3226, 3109,   60, 1448, 4220, 1567, 4131, 1055,  292, 2376, 2178, 1934,
         992, 2609, 3252, 2493])
Epoch: 2869, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2870 - Batch 1 ########################
IDs in batch 1: tensor([ 575, 3822, 1264, 1260, 1065, 2258, 3372, 1108, 3384, 2617, 3475,  413,
         610, 1951, 3881, 1383])
Epoch: 2870, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2871 - Batch 1 ########################
IDs in batch 1: tensor([ 201, 2464, 2436,  164, 2741,  534,  224, 3480, 1020, 3886, 1500, 1646,
        1795, 3754, 3058,  143])
Epoch: 2871, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2872 - Batch 1 ########################
IDs in batch 1: tensor([1809, 2484,  952,  194, 1878, 3397, 4217, 1559, 2968,   14, 4170, 2399,
        2542, 3120, 4055, 2858])
Epoch: 2872, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2873 - Batch 1 ########################
IDs in batch 1: tensor([3554, 2618, 2027, 3220, 1509, 4181, 3601, 1458,  363, 1076, 1798, 3858,
        1247, 2070, 1510, 1004])
Epoch: 2873, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2874 - Batch 1 ########################
IDs in batch 1: tensor([3157, 3762, 2199, 2098, 3148, 2433, 2924,  947, 3762, 2520, 2459, 4141,
        3795,  154, 3865,  651])
Epoch: 2874, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2875 - Batch 1 ########################
IDs in batch 1: tensor([2254, 1496, 1580,  501, 3148, 1387,  315, 1171, 1887, 2232, 2551,  413,
         944, 3002,  991, 3470])
Epoch: 2875, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2876 - Batch 1 ########################
IDs in batch 1: tensor([3120, 3802, 2645, 2256, 1413, 2995, 2220, 2069,  501, 2511, 2504,  430,
         639, 1015, 2440, 3648])
Epoch: 2876, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2877 - Batch 1 ########################
IDs in batch 1: tensor([ 389, 3414, 1406, 3729,  904, 1250, 3600, 1434, 2821, 2508, 2734,  820,
         538, 1315,  594, 1177])
Epoch: 2877, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2878 - Batch 1 ########################
IDs in batch 1: tensor([ 413, 2146, 2993, 3184, 3528, 3896, 2235, 1638, 1152, 4189,   30, 2839,
         532,  211, 2151, 1672])
Epoch: 2878, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2879 - Batch 1 ########################
IDs in batch 1: tensor([1189,  874, 1980, 3049, 3852,  474,  225, 2199, 3265, 1389, 2159,  281,
         676, 2649,  173, 3994])
Epoch: 2879, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2880 - Batch 1 ########################
IDs in batch 1: tensor([1500,  513, 3710, 1364, 2688, 1601, 1803, 2237,  358,  886, 1844,  475,
        1183, 3783, 3117,  663])
Epoch: 2880, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2881 - Batch 1 ########################
IDs in batch 1: tensor([4082, 2386, 4046,  713, 1108, 3952, 2104, 2668, 3495, 3638,  155, 2798,
        2809,  558, 3655, 2015])
Epoch: 2881, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2882 - Batch 1 ########################
IDs in batch 1: tensor([ 899, 1490,  537, 3886, 2250, 2887, 3589,  968, 2124, 3428, 1228,   25,
        1772,  426, 2897, 1496])
Epoch: 2882, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2883 - Batch 1 ########################
IDs in batch 1: tensor([2149, 2114, 3313,  591, 3251, 2880, 1380,  295,  891,  113, 3472, 1956,
        1661, 2271,  575, 3894])
Epoch: 2883, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2884 - Batch 1 ########################
IDs in batch 1: tensor([ 615, 3366, 2369, 3523, 4072,  203, 1504, 3920, 3073, 1484,  785, 3704,
        2142, 1388,  640, 1980])
Epoch: 2884, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2885 - Batch 1 ########################
IDs in batch 1: tensor([3092, 3614,  226, 3244, 3207, 1281, 1050, 1396, 2499, 2708, 3358, 2213,
         823, 3202, 3990, 4068])
Epoch: 2885, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2886 - Batch 1 ########################
IDs in batch 1: tensor([ 376, 2894, 1179, 4099, 1155, 1866,  384, 2461, 3310, 4082, 1146, 2921,
        1085,  172, 3469, 1417])
Epoch: 2886, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2887 - Batch 1 ########################
IDs in batch 1: tensor([2143, 1678,  953,  920, 1185, 1464, 2065,  751,  604, 3743,  250, 1932,
        1886, 2279,  659, 3950])
Epoch: 2887, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2888 - Batch 1 ########################
IDs in batch 1: tensor([1661, 1869, 1748, 2102, 2087, 3485, 2331,  518, 2199, 2761, 1055, 4135,
        2157, 3621, 1271, 1979])
Epoch: 2888, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2889 - Batch 1 ########################
IDs in batch 1: tensor([1470,  944, 2004, 3152, 3696, 1990, 1027,  523, 3772, 3516, 1001, 1224,
        3798,  807, 3913, 1559])
Epoch: 2889, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2890 - Batch 1 ########################
IDs in batch 1: tensor([ 862, 2437, 2141, 3178, 3439, 3353, 3608,    5, 2465, 4056, 3418,  550,
         991,  338, 1354, 1102])
Epoch: 2890, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2891 - Batch 1 ########################
IDs in batch 1: tensor([1559, 2991, 1944,  314, 4238,  205, 1050, 1171,  978, 4245, 2458, 2109,
        3330, 2945, 2969,  982])
Epoch: 2891, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2892 - Batch 1 ########################
IDs in batch 1: tensor([1737, 2581,  470, 1850,  391, 3894, 3911, 1308,  258,  432, 3866, 1266,
        2644, 1811, 3790,  306])
Epoch: 2892, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2893 - Batch 1 ########################
IDs in batch 1: tensor([2275, 1496,   57, 1241, 1567,  665, 3655,  397, 1963, 2074,  962, 3384,
        2882, 4082, 2370, 2546])
Epoch: 2893, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2894 - Batch 1 ########################
IDs in batch 1: tensor([3497, 2002, 1355, 1101, 3438, 3939, 3870, 1454, 3702, 1583,  405,  170,
        2763, 3544, 3018, 2872])
Epoch: 2894, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2895 - Batch 1 ########################
IDs in batch 1: tensor([3990, 3133,  481, 3485, 3747,  735, 3570, 1426, 1453, 1308, 3404, 1317,
        2188,  837, 3492,  921])
Epoch: 2895, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2896 - Batch 1 ########################
IDs in batch 1: tensor([ 787, 1396, 3073,   37, 1389, 2646, 1360, 1308, 4009, 1297,  815, 3406,
          99, 4103, 1976, 2817])
Epoch: 2896, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2897 - Batch 1 ########################
IDs in batch 1: tensor([ 792, 1491, 2831, 4026, 3963, 2652,  613,  642, 3810,  660, 1963, 1017,
        1377, 4035,  779, 2350])
Epoch: 2897, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2898 - Batch 1 ########################
IDs in batch 1: tensor([1282, 1551, 1952, 2872, 3767, 1143, 3728, 1050, 1102, 4157, 3947, 3997,
        3786,  891, 2961,  724])
Epoch: 2898, Training Loss: 0.44, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2899 - Batch 1 ########################
IDs in batch 1: tensor([ 577, 2431,  356, 3557,  678, 3934, 1336, 1241, 1241, 3256, 1487,  207,
         544,  807, 2355,  539])
Epoch: 2899, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2900 - Batch 1 ########################
IDs in batch 1: tensor([1935, 4256, 3435, 3528, 3792, 3267, 3114, 3680,  736,  941, 1331,  219,
        2541, 1408,  127,  199])
Epoch: 2900, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2901 - Batch 1 ########################
IDs in batch 1: tensor([ 426, 3184, 2108, 1086, 1732, 2305,  498, 1704,  607,  533, 3408, 3425,
        2706, 1968,   50,  190])
Epoch: 2901, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2902 - Batch 1 ########################
IDs in batch 1: tensor([3146, 2189, 2982, 2516, 1206, 2970, 4078, 2717, 1811,  413,  663, 1897,
        1004, 3843,  513, 3112])
Epoch: 2902, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2903 - Batch 1 ########################
IDs in batch 1: tensor([3073, 2740,  694, 3588, 3453, 1626, 2188, 2297, 1419, 2983,  360, 2870,
        4158, 3219, 1229, 3537])
Epoch: 2903, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2904 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 3204, 3180, 4003, 2739, 2185, 3568, 2405, 1938, 2976, 2226, 3446,
        3105,  295, 1956, 2541])
Epoch: 2904, Training Loss: 0.92, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2905 - Batch 1 ########################
IDs in batch 1: tensor([3943,  672, 1641, 1318, 3717, 2279, 3781,  476, 3444, 3343, 4255, 4004,
        3547,  338, 1699, 2886])
Epoch: 2905, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2906 - Batch 1 ########################
IDs in batch 1: tensor([ 794, 1316, 2682, 2956, 2752, 2835, 2764, 1234, 3711, 3243,  435, 2599,
         926, 3058, 2461, 4179])
Epoch: 2906, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2907 - Batch 1 ########################
IDs in batch 1: tensor([2659, 3524, 4242, 1732, 3075, 3461, 1317, 1237, 2648, 1633, 2615,  919,
        1579, 1222, 2261, 4254])
Epoch: 2907, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2908 - Batch 1 ########################
IDs in batch 1: tensor([4093, 3329, 1017, 1337, 2998, 2456, 3715, 4035,  663, 1569,  835,  478,
        1563, 3785, 3152, 1133])
Epoch: 2908, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2909 - Batch 1 ########################
IDs in batch 1: tensor([ 511, 3030,  875, 2848,  223, 2248, 3079, 1796, 1798, 1736, 3676, 1551,
         251, 1602, 3998, 3870])
Epoch: 2909, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2910 - Batch 1 ########################
IDs in batch 1: tensor([  86,  275,  908, 1590, 1546, 1787, 2859,  200, 1467, 1271, 2172,  971,
        2386,   44,  127, 3161])
Epoch: 2910, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2911 - Batch 1 ########################
IDs in batch 1: tensor([1034,  264,  829, 1335, 2886,   52, 4025, 3782,  261,  582, 2373,  957,
        1437, 3950,  164, 3005])
Epoch: 2911, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2912 - Batch 1 ########################
IDs in batch 1: tensor([4257, 1625, 3920,   35, 2124, 3616, 2339, 3414, 3985,  202, 1508, 4215,
         680, 4058, 3501, 2257])
Epoch: 2912, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2913 - Batch 1 ########################
IDs in batch 1: tensor([1291, 2111, 2202,  577, 4124, 3478,  371, 1956, 3527, 2383, 2851, 1716,
          57, 3049, 3705, 4263])
Epoch: 2913, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2914 - Batch 1 ########################
IDs in batch 1: tensor([3973, 3543, 3783, 3998,  424, 1333,  503, 2730, 1420, 1712, 3826, 4264,
        1470, 3190, 1937, 2398])
Epoch: 2914, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2915 - Batch 1 ########################
IDs in batch 1: tensor([3594, 1690, 1933, 2095, 1309, 2171, 2863, 1281, 3333, 1927, 3914, 1337,
         875, 3448, 1613, 1658])
Epoch: 2915, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2916 - Batch 1 ########################
IDs in batch 1: tensor([2257, 1708, 3002, 3813, 3121, 3531, 3693, 4069, 2669, 2800,  572, 3353,
         683, 3995, 1209,  516])
Epoch: 2916, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2917 - Batch 1 ########################
IDs in batch 1: tensor([1680,   78, 1972, 1711,  358, 1626, 2537, 3821, 2088, 1399, 2125,  346,
        2806, 3905, 1014,  368])
Epoch: 2917, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2918 - Batch 1 ########################
IDs in batch 1: tensor([ 103, 1080, 2645, 3340, 1332,  752, 3313,  636, 2142, 1618,  281, 4016,
        3432, 3860, 2352, 1985])
Epoch: 2918, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2919 - Batch 1 ########################
IDs in batch 1: tensor([2299,  626,  620, 2091,  513, 3088, 3449,  988, 1591,  324, 2976, 3253,
        3914, 2342, 1442, 1655])
Epoch: 2919, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2920 - Batch 1 ########################
IDs in batch 1: tensor([2825, 2252, 2465, 3648, 1318, 2550, 3836, 1073,  767, 1991, 3470,  245,
        1731, 2237, 3128, 2419])
Epoch: 2920, Training Loss: 0.33, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2921 - Batch 1 ########################
IDs in batch 1: tensor([1937, 4175, 1655, 2949,  857, 1706,  112, 4257, 3056,  345, 4014, 1060,
        3895, 1421, 2974, 3309])
Epoch: 2921, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2922 - Batch 1 ########################
IDs in batch 1: tensor([3779, 2879, 2341, 1012, 3970, 1077, 4140,    5, 2783, 1321, 3564, 3177,
         996,  130,  727, 1052])
Epoch: 2922, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2923 - Batch 1 ########################
IDs in batch 1: tensor([2921, 3847, 3927, 2883, 3024, 3712, 3823, 1007,  944, 1320, 1625, 1532,
        1367, 2863, 3150, 1085])
Epoch: 2923, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2924 - Batch 1 ########################
IDs in batch 1: tensor([1248, 1319,  882, 1485,  776, 2081,  122, 3275, 1493, 4173, 2751, 3570,
        2114, 2250, 3514, 3113])
Epoch: 2924, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2925 - Batch 1 ########################
IDs in batch 1: tensor([3081, 3603, 3161, 2153, 2191, 1740, 3423, 2343, 1241, 1885,  531, 4148,
        3607, 3806, 1935,  617])
Epoch: 2925, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2926 - Batch 1 ########################
IDs in batch 1: tensor([2210,  266,  832, 3815, 1167,   32,  135,  472,  348, 3123, 2606, 2866,
        3742, 1638, 3968,  834])
Epoch: 2926, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2927 - Batch 1 ########################
IDs in batch 1: tensor([ 607, 2965, 3745, 4149, 3027, 2640, 3219, 2606,  274, 2252, 4016, 2066,
        2081,  604, 2343, 3391])
Epoch: 2927, Training Loss: 0.27, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2928 - Batch 1 ########################
IDs in batch 1: tensor([3668,  914,  138, 4172, 4240, 2398,  305,  864,  391, 2368, 2355, 1830,
        4046, 3023, 4134, 2080])
Epoch: 2928, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2929 - Batch 1 ########################
IDs in batch 1: tensor([ 839, 1578, 2781, 2276,  880, 1027, 3113, 2487, 1774, 1553,  953, 2749,
        2984,  325, 2599, 1450])
Epoch: 2929, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2930 - Batch 1 ########################
IDs in batch 1: tensor([2687, 3168, 3024, 3642, 2229,  934, 1766, 1156, 2457, 3808, 3391,  351,
        2485, 3499,  526,   84])
Epoch: 2930, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2931 - Batch 1 ########################
IDs in batch 1: tensor([2370, 2091, 3833, 4212, 2038, 2603, 1626, 3206,  278, 3473, 2839, 1882,
        4044, 3344, 2926, 2091])
Epoch: 2931, Training Loss: 0.68, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2932 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 2841,  952, 2220,  459, 2980, 1085, 4143,  148, 3942, 3018, 4097,
        2210,  775, 3259, 1804])
Epoch: 2932, Training Loss: 0.47, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 2933 - Batch 1 ########################
IDs in batch 1: tensor([4072, 1162, 2053, 2154,  965, 2536, 2604, 1787, 2257, 1779, 1625, 4049,
        2482, 3753, 2796, 1649])
Epoch: 2933, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2934 - Batch 1 ########################
IDs in batch 1: tensor([ 263,  757, 1278, 1618,  537, 3656, 4146,  995, 3863,  317, 3599, 3514,
        3475, 2842,  876, 3339])
Epoch: 2934, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2935 - Batch 1 ########################
IDs in batch 1: tensor([1834, 1832,  190, 2855, 3624, 2506,  687,  646,  165, 2452, 1753, 2206,
        2436, 1583,  986,  143])
Epoch: 2935, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2936 - Batch 1 ########################
IDs in batch 1: tensor([2804, 3731, 2681, 2035,  792, 1953, 1123, 1332, 3926,  717, 2949,  627,
        1536,   25, 3874, 3483])
Epoch: 2936, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2937 - Batch 1 ########################
IDs in batch 1: tensor([ 908,    4, 2237, 1942, 4172, 2110,  455, 2356, 3876, 1377, 1133, 2109,
        2402,  583, 2357,  466])
Epoch: 2937, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2938 - Batch 1 ########################
IDs in batch 1: tensor([ 223, 2886, 2670, 1469,  483, 1897, 2479,  130, 1484, 2780, 1061,  602,
        4049, 2798,  394, 1426])
Epoch: 2938, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2939 - Batch 1 ########################
IDs in batch 1: tensor([2086,  952, 1784,  490,  975, 3939,  398, 2812,  137, 2709,  122,  516,
        2932, 2921, 3135, 3284])
Epoch: 2939, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2940 - Batch 1 ########################
IDs in batch 1: tensor([ 803, 3114, 1519,  522, 2097, 4038, 2060,  531, 2749, 2627, 2075, 3742,
        4088, 3608, 3154,  622])
Epoch: 2940, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2941 - Batch 1 ########################
IDs in batch 1: tensor([ 160,  475, 3599, 3115,  220,  818,  247, 3250,  371, 2284, 1354, 4148,
         735,  959, 3337, 3187])
Epoch: 2941, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2942 - Batch 1 ########################
IDs in batch 1: tensor([ 601,  471, 3647,  237, 3496, 2891, 1767, 2526,  822, 2905,  463, 1931,
        1226, 2011, 3268, 1434])
Epoch: 2942, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2943 - Batch 1 ########################
IDs in batch 1: tensor([ 269, 3754,  141, 3830, 1866, 2198, 1267, 2420, 2031, 1223, 3245, 3637,
        1459, 2497,   96, 1963])
Epoch: 2943, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2944 - Batch 1 ########################
IDs in batch 1: tensor([1080, 3888, 3385, 1390,  565,  795, 4253, 3650, 2458, 2126, 2095,  902,
        3458, 3239, 3227,  191])
Epoch: 2944, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 2945 - Batch 1 ########################
IDs in batch 1: tensor([ 266, 2457, 1084, 1282, 2890,  395,  969,  674,  794,  881, 2331, 1456,
        3139,  919, 3807,  713])
Epoch: 2945, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2946 - Batch 1 ########################
IDs in batch 1: tensor([1267, 3542, 1884, 1578,  323, 1041, 1782, 2447, 2064, 3651,  393, 1038,
        3993, 2777, 1228, 2441])
Epoch: 2946, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2947 - Batch 1 ########################
IDs in batch 1: tensor([3778, 4258,  546, 3987, 2986, 2353,  685, 2998, 1478, 3885,  779, 3426,
        4217,  213, 3476, 1176])
Epoch: 2947, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2948 - Batch 1 ########################
IDs in batch 1: tensor([1039, 3127, 3057, 1740, 2977,  825, 3111, 2312, 4036, 3715,  565,  862,
        3808,  202,  185,  568])
Epoch: 2948, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2949 - Batch 1 ########################
IDs in batch 1: tensor([1022, 4037,  899, 2498, 4163,  207, 3177, 1455, 2059, 3526, 3696, 2081,
        1055, 2475, 2423,  275])
Epoch: 2949, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2950 - Batch 1 ########################
IDs in batch 1: tensor([3342,  180, 2669,   84,  430, 3945, 1057, 1754, 3628,  964, 1734, 3698,
         290,  399, 1640, 1501])
Epoch: 2950, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2951 - Batch 1 ########################
IDs in batch 1: tensor([3569, 2926, 3842, 1895,  733, 3789, 4186,  819,  200,  603, 2970, 2124,
        1471, 2296, 3370, 2218])
Epoch: 2951, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2952 - Batch 1 ########################
IDs in batch 1: tensor([2763, 3856, 1111, 3461, 3516, 4007, 1308, 1014,  282,  969, 1039, 1862,
         255,  546, 3797, 1684])
Epoch: 2952, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2953 - Batch 1 ########################
IDs in batch 1: tensor([1480,  738, 3009, 1295, 1810, 4131, 1517,  400, 2026,    7, 2520,  866,
        1507,  365, 2315,  463])
Epoch: 2953, Training Loss: 0.22, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2954 - Batch 1 ########################
IDs in batch 1: tensor([ 864,  317, 1373,  482, 1042,  666, 2137, 1973, 1297,  496, 1804,  419,
        2265, 2231, 2871, 3970])
Epoch: 2954, Training Loss: 0.19, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2955 - Batch 1 ########################
IDs in batch 1: tensor([4261, 2902,  850, 1828, 3272, 4224, 2579, 2224, 1451,  365,  419, 2451,
         863, 1961,  910, 3661])
Epoch: 2955, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2956 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 2511, 3456, 2827, 3500, 4097, 2131, 1723,  125, 1602, 1599, 1481,
        2192, 4070,  691, 2229])
Epoch: 2956, Training Loss: 0.19, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 2957 - Batch 1 ########################
IDs in batch 1: tensor([2617, 1220, 3712, 3838,  183, 3435, 1183, 3360, 3715, 3939, 1383, 2681,
        3523,  870,  260, 3671])
Epoch: 2957, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 2958 - Batch 1 ########################
IDs in batch 1: tensor([2838, 1111,  138, 1650,  403,  573, 1438, 2212,  154, 1185, 1299, 2459,
          71, 1069, 1711,  875])
Epoch: 2958, Training Loss: 0.52, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 2959 - Batch 1 ########################
IDs in batch 1: tensor([3661, 1213, 4223,  451, 2674, 2977, 1006, 1015, 2787, 3523, 1589, 3276,
        1010, 2957, 3356, 4165])
Epoch: 2959, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 2960 - Batch 1 ########################
IDs in batch 1: tensor([2739, 1252, 1264,  830,  956, 4089, 4198,  417,  637,  838,   20,  774,
         967, 2377, 2013,  439])
Epoch: 2960, Training Loss: 0.18, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 2961 - Batch 1 ########################
IDs in batch 1: tensor([2841, 2469,   70, 4048, 1543, 2492, 1469, 2337, 2375, 3226,  405, 2041,
        2891, 4253, 2663,  449])
Epoch: 2961, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 2962 - Batch 1 ########################
IDs in batch 1: tensor([1031, 2017, 1256, 1568, 4051, 1812, 2064, 2022, 3689,  533, 2732,  517,
        3731, 2429, 3668, 3498])
Epoch: 2962, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 2963 - Batch 1 ########################
IDs in batch 1: tensor([1472, 2812, 3780, 2485, 2131,  928, 1471, 3119, 1932, 1802,  767, 4203,
        2067,  975, 3088, 2483])
Epoch: 2963, Training Loss: 0.24, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 2964 - Batch 1 ########################
IDs in batch 1: tensor([ 145, 3053, 4124, 4242, 3243, 1753, 3615, 1134,  109,  211, 2693, 4072,
        2018, 1993, 4077, 1641])
Epoch: 2964, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 2965 - Batch 1 ########################
IDs in batch 1: tensor([1380, 4185,  432, 2016, 3284, 1724,  137, 2097, 3539, 3935, 4072, 3676,
        1219,  947,  815, 2505])
Epoch: 2965, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2966 - Batch 1 ########################
IDs in batch 1: tensor([4242, 1473, 4218, 3395, 3930,  343, 2386, 3718, 4128, 3244, 3908, 3699,
         822, 3870,  538, 3009])
Epoch: 2966, Training Loss: 0.55, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2967 - Batch 1 ########################
IDs in batch 1: tensor([3952,   35, 2124,  211,  733,  723, 2232, 2746,  415, 1163, 2279,  397,
        3105, 3166, 2204, 3118])
Epoch: 2967, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.74
######################## Epoch 2968 - Batch 1 ########################
IDs in batch 1: tensor([2760, 2943, 2146, 1610, 3283, 2230, 1168, 3159, 3444, 1235,  440,  167,
        2358, 2505,  135, 1014])
Epoch: 2968, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 2969 - Batch 1 ########################
IDs in batch 1: tensor([3083, 2134, 2754, 1986, 3812, 3589, 3343, 3772,   38,  990, 3732, 1640,
        2232, 1042, 1467, 1437])
Epoch: 2969, Training Loss: 0.24, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 2970 - Batch 1 ########################
IDs in batch 1: tensor([2551, 1894, 1096, 1438, 3545,  591, 4037,  808, 3194, 4087, 4095, 1009,
        2951, 2198, 4242, 3156])
Epoch: 2970, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 2971 - Batch 1 ########################
IDs in batch 1: tensor([ 725,   64, 1977, 2329,  396,  225, 3739, 1668, 3290, 1670,  531, 1436,
        2740, 2449, 2091, 1628])
Epoch: 2971, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 2972 - Batch 1 ########################
IDs in batch 1: tensor([3862,  673, 3674, 1799, 2217, 2653, 3256, 4088, 3689,  726,  352, 1545,
        2080,  523, 3303, 3632])
Epoch: 2972, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2973 - Batch 1 ########################
IDs in batch 1: tensor([3999, 2034, 2499, 2536, 2938, 1508, 1491, 2448, 3554, 3900,  394, 1334,
        1097, 1938,   13,  426])
Epoch: 2973, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2974 - Batch 1 ########################
IDs in batch 1: tensor([2954,  743, 3267, 2322, 3934,  612, 1849, 2429,  482, 1571,  455, 1181,
         441, 2927, 2535,   34])
Epoch: 2974, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2975 - Batch 1 ########################
IDs in batch 1: tensor([3856, 3956, 3545,  417, 3248, 3875, 3763, 3079, 2568,   63,  797,  752,
        2855,  787,  225, 1331])
Epoch: 2975, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2976 - Batch 1 ########################
IDs in batch 1: tensor([2356, 1487,   71,  575, 3838,  290, 2151, 2196, 1869,  361, 2015, 1316,
         112, 3451, 1409, 2235])
Epoch: 2976, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2977 - Batch 1 ########################
IDs in batch 1: tensor([2690,  676, 2185, 2204, 3637, 3463, 3123, 4175, 3808,  770, 2618, 2250,
        1089, 3015, 3496, 2002])
Epoch: 2977, Training Loss: 0.31, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2978 - Batch 1 ########################
IDs in batch 1: tensor([ 228, 1945, 2638, 1397, 3239, 3696,  125, 3451, 4115, 2060, 3919,   20,
        2111, 1063,  809,  828])
Epoch: 2978, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 2979 - Batch 1 ########################
IDs in batch 1: tensor([1959, 1625,  805,  103, 3262, 2763,  255, 3438,  201, 3767,  718, 3927,
        3831, 2598, 4214,  238])
Epoch: 2979, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 2980 - Batch 1 ########################
IDs in batch 1: tensor([1111, 2947, 3197, 2297, 1231, 1923, 1140,  194, 1678, 4236, 4126, 2950,
        1120, 2113,  196, 1734])
Epoch: 2980, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 2981 - Batch 1 ########################
IDs in batch 1: tensor([3327, 3344, 1302, 1231,  815, 3671,  367, 2848, 3609, 2751, 2540, 1305,
         871, 2115,  497, 1727])
Epoch: 2981, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 2982 - Batch 1 ########################
IDs in batch 1: tensor([ 991, 2111,  858, 2548, 1830, 1665, 3002, 1410, 2565,  606, 4093, 3339,
         382,  463, 1737,  373])
Epoch: 2982, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 2983 - Batch 1 ########################
IDs in batch 1: tensor([3117, 1097, 1092, 2546,  862, 2102, 2848, 1388, 1502, 1818, 1278,  193,
        3430, 3505, 4039,  676])
Epoch: 2983, Training Loss: 0.27, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 2984 - Batch 1 ########################
IDs in batch 1: tensor([ 857, 3077, 2880,  824,  409, 2287, 2348, 1390, 1290,  857, 3480, 1197,
        3372, 1602, 3494, 2483])
Epoch: 2984, Training Loss: 0.31, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2985 - Batch 1 ########################
IDs in batch 1: tensor([3851, 3388,   35, 1764, 4198, 4179, 1910, 2432,  485,  957, 1318, 3521,
        1138,  244, 2489, 3865])
Epoch: 2985, Training Loss: 0.23, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 2986 - Batch 1 ########################
IDs in batch 1: tensor([2010, 2265, 3264, 1120,   71, 1624,  753, 1767, 2973, 2236, 2315,  483,
        4127, 2235, 3936, 1627])
Epoch: 2986, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 2987 - Batch 1 ########################
IDs in batch 1: tensor([ 652,  679,  923,  137, 1921, 2262,   28, 1498, 3400, 3858, 3544, 2143,
         532,  475, 2977, 1655])
Epoch: 2987, Training Loss: 0.20, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2988 - Batch 1 ########################
IDs in batch 1: tensor([2337, 2354,  259, 2912,  244,  117, 1532, 2521, 3194, 2070, 2505,   61,
         133,  338,  529,  966])
Epoch: 2988, Training Loss: 0.14, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2989 - Batch 1 ########################
IDs in batch 1: tensor([ 604, 2327, 4005,  577, 2086, 1802, 3196,  914, 1671, 3391,  190, 3051,
        1340,  699, 1524, 3424])
Epoch: 2989, Training Loss: 0.17, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 2990 - Batch 1 ########################
IDs in batch 1: tensor([ 656,   35, 1552, 3283,  221,  517, 1985, 2795, 1318, 3601, 2298, 2574,
         826, 1166, 2810, 1134])
Epoch: 2990, Training Loss: 0.17, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 2991 - Batch 1 ########################
IDs in batch 1: tensor([3453, 3323, 3044, 3593,  448, 2064, 1077, 1509, 3299,  102, 3952,  871,
        2773, 2472, 1822,  573])
Epoch: 2991, Training Loss: 0.21, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 2992 - Batch 1 ########################
IDs in batch 1: tensor([1931,  129, 1599, 3826,  578, 3243,  440, 2217, 2674, 1834, 1237, 3470,
         995, 1308, 1585, 2099])
Epoch: 2992, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.74
######################## Epoch 2993 - Batch 1 ########################
IDs in batch 1: tensor([ 259, 1476, 2202,  645, 2723, 1386, 1918, 2682,  518, 3875, 1103,  160,
        2942,  964, 2131, 2223])
Epoch: 2993, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 2994 - Batch 1 ########################
IDs in batch 1: tensor([ 134, 2555, 2902, 2256, 1588,  266, 3746, 3111, 1432, 1330, 2095,  536,
         415, 1395, 1425, 2831])
Epoch: 2994, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.75
######################## Epoch 2995 - Batch 1 ########################
IDs in batch 1: tensor([ 874,  844, 1041,  134, 3624,  556, 4016, 1059, 3740, 1963, 2295,  430,
        3025, 2643, 3604, 3485])
Epoch: 2995, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 2996 - Batch 1 ########################
IDs in batch 1: tensor([2332, 3178, 2050, 1512, 2436, 3126, 3471, 3467, 2760,  321, 2072, 1640,
         236, 1803, 1569, 3972])
Epoch: 2996, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 2997 - Batch 1 ########################
IDs in batch 1: tensor([ 814,  653, 1249,  667, 1444, 3239,  148, 3981, 2587, 2322,  739, 4101,
         833, 1269,  852,  444])
Epoch: 2997, Training Loss: 0.30, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 2998 - Batch 1 ########################
IDs in batch 1: tensor([2005,  879, 3777,  981, 1014, 2996, 2278, 3769, 3379, 2489, 3531, 3503,
        1576, 3065, 2483, 3108])
Epoch: 2998, Training Loss: 0.38, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 2999 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 2359, 1499, 2770, 1167, 3206, 1869, 3342, 1324, 3792, 3669, 2743,
        2167, 2822, 2111, 2828])
Epoch: 2999, Training Loss: 0.36, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3000 - Batch 1 ########################
IDs in batch 1: tensor([1007, 2344,  218,  986, 1221, 3795, 2582, 1333, 2884,  975, 1299, 3047,
        2945, 1635,  871,  181])
Epoch: 3000, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3001 - Batch 1 ########################
IDs in batch 1: tensor([1204, 3822,  483, 3385, 4040, 3963, 3112, 1354,  350,  221,  199,  827,
        3418, 4149,  418,  753])
Epoch: 3001, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3002 - Batch 1 ########################
IDs in batch 1: tensor([ 908, 3514,   86, 3299,  344, 2228, 3972, 2538,  255, 3570, 2898, 4214,
        3036,  544,  688,  478])
Epoch: 3002, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3003 - Batch 1 ########################
IDs in batch 1: tensor([2326, 3713, 4097, 3659, 3689, 1985, 3874, 3091, 3446,   24, 2755, 3259,
        2254, 3793, 1852,  378])
Epoch: 3003, Training Loss: 0.59, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3004 - Batch 1 ########################
IDs in batch 1: tensor([3453, 2337,  992, 2842, 1752, 2142, 2741, 1641,  538,  969, 2631,  262,
        1855, 2230, 1491, 1305])
Epoch: 3004, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3005 - Batch 1 ########################
IDs in batch 1: tensor([1681, 1094, 1218, 3648, 2729,  312, 4037, 2767, 2690,  477,  234, 3981,
         822, 2339, 4257,  128])
Epoch: 3005, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3006 - Batch 1 ########################
IDs in batch 1: tensor([ 713, 1292, 1326,  282,  219,  527, 3567, 1296, 1990,  841, 2444, 3511,
        3382, 1734,  730, 2748])
Epoch: 3006, Training Loss: 0.41, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3007 - Batch 1 ########################
IDs in batch 1: tensor([1404,  823, 3142, 1880, 1543, 1734, 2780, 3660, 3609, 3709, 2170, 1209,
        3913, 3021, 2053,  320])
Epoch: 3007, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3008 - Batch 1 ########################
IDs in batch 1: tensor([3661, 1700, 3545, 2296, 3895, 1996, 2388, 2932, 3253, 3845,  733, 2472,
        4125, 2847, 3497, 2733])
Epoch: 3008, Training Loss: 0.52, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3009 - Batch 1 ########################
IDs in batch 1: tensor([2582,  660,  337, 3379,  405, 2885,  134, 3387, 1934, 3270, 2660, 3234,
        2329, 3723, 3073, 2480])
Epoch: 3009, Training Loss: 0.27, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3010 - Batch 1 ########################
IDs in batch 1: tensor([3009,  202, 3655, 1552,  340, 1830, 3099, 2064, 2529, 2003,  960, 4002,
        3154, 2555, 3304,  820])
Epoch: 3010, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3011 - Batch 1 ########################
IDs in batch 1: tensor([2181, 3981, 2254, 2399,  164, 2132, 1086,  300, 3537, 3604, 1720, 2195,
        1464,  950,  111, 3452])
Epoch: 3011, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3012 - Batch 1 ########################
IDs in batch 1: tensor([3763, 1947, 3222, 4200, 2067,  448,  373, 4084, 2541, 4149, 3845, 1799,
        3136,  181,  550, 3531])
Epoch: 3012, Training Loss: 0.20, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3013 - Batch 1 ########################
IDs in batch 1: tensor([ 978, 1484,  245, 1351,  491, 2669, 3581, 3943, 2442, 1428, 3531, 4163,
         369, 4065, 3507, 3883])
Epoch: 3013, Training Loss: 0.29, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3014 - Batch 1 ########################
IDs in batch 1: tensor([2601, 2019, 1927, 3304, 2135, 1474,  516, 3250, 3739, 1070, 4011,  239,
         303,  510,  763, 2984])
Epoch: 3014, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3015 - Batch 1 ########################
IDs in batch 1: tensor([2721, 2113,  544, 1011, 1128, 1842,  220, 2366,  713, 4010,  101, 1026,
        2053, 2376, 2797, 3740])
Epoch: 3015, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3016 - Batch 1 ########################
IDs in batch 1: tensor([1488, 1371, 4113, 3044, 2842, 1204, 1671, 3652, 3014, 1585, 2999,  606,
         545, 1317, 2800, 1626])
Epoch: 3016, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3017 - Batch 1 ########################
IDs in batch 1: tensor([ 615, 3168, 1159, 3721,  196,  262, 1644, 3300, 3178, 2316, 1842,  101,
         947, 2231,  177, 2045])
Epoch: 3017, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3018 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 3146,  456, 3053,  402, 2354, 2349, 2932,  277, 4026,  967, 1305,
         214,  642, 2542, 2400])
Epoch: 3018, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3019 - Batch 1 ########################
IDs in batch 1: tensor([1080, 2402, 3015, 1955, 2132, 3364, 3842, 1844,  177, 2107, 1337, 2277,
        1923, 2226, 1315, 2730])
Epoch: 3019, Training Loss: 0.30, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3020 - Batch 1 ########################
IDs in batch 1: tensor([1482,  631, 1884,  354, 3470, 1330, 3286, 3734, 2745, 2178, 2210, 4010,
        1852, 3985,  234, 1456])
Epoch: 3020, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3021 - Batch 1 ########################
IDs in batch 1: tensor([2926,  482,  537, 1566,  827, 1070,  165, 2286, 3782, 2114, 3127,  682,
         635, 4076,  820, 1960])
Epoch: 3021, Training Loss: 0.13, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3022 - Batch 1 ########################
IDs in batch 1: tensor([4120,  890, 2369, 1579, 1655, 2681,  316, 1138, 3166,  890, 2231, 3330,
        4267, 2826,  605, 3760])
Epoch: 3022, Training Loss: 0.15, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3023 - Batch 1 ########################
IDs in batch 1: tensor([3094,  513,  193, 1566,  229, 2161, 2804, 1536, 2487, 1229, 4007, 3342,
        2775, 1451, 3885, 3355])
Epoch: 3023, Training Loss: 0.05, Validation Loss: 0.86, accuracy = 0.69
######################## Epoch 3024 - Batch 1 ########################
IDs in batch 1: tensor([2983, 1956, 3031,  432, 1334, 3132, 1490, 3364, 3721, 1143, 2990, 3220,
        3680, 1383, 3589, 1454])
Epoch: 3024, Training Loss: 0.13, Validation Loss: 0.86, accuracy = 0.69
######################## Epoch 3025 - Batch 1 ########################
IDs in batch 1: tensor([1618, 2401, 3079, 2496,  399, 3610,  882, 3157, 1212, 2752,  841, 1862,
        3099,  462,   19,  649])
Epoch: 3025, Training Loss: 0.10, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3026 - Batch 1 ########################
IDs in batch 1: tensor([1004, 2936, 4126, 1331,  792, 3842, 1043, 3291, 3101, 4003,  510, 2950,
         942,  151, 4048, 3739])
Epoch: 3026, Training Loss: 0.20, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3027 - Batch 1 ########################
IDs in batch 1: tensor([3179, 1901, 2592, 1866, 3643, 3410, 3734, 1467,  472, 2095, 2672, 3832,
        1698, 2044, 1699, 1313])
Epoch: 3027, Training Loss: 0.22, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3028 - Batch 1 ########################
IDs in batch 1: tensor([2148, 4223, 3696,  701, 2727, 3261, 1229,  239,  177, 3988, 3610, 1812,
        2964, 3582,  749,  282])
Epoch: 3028, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3029 - Batch 1 ########################
IDs in batch 1: tensor([3875, 2161,  488, 2710,  873, 1098,  513, 3911, 1934,  879, 3042, 3356,
        2565,  639,  112,  950])
Epoch: 3029, Training Loss: 0.25, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3030 - Batch 1 ########################
IDs in batch 1: tensor([2754,  957, 3154, 1506, 3830, 2087, 3795, 3132, 1852, 2173,  714, 1825,
        3181, 2317, 2258, 2145])
Epoch: 3030, Training Loss: 0.65, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3031 - Batch 1 ########################
IDs in batch 1: tensor([1627, 3581, 3199, 1186,  318,  884,  244, 2261, 1026, 1237, 2485, 1005,
        1391,  756, 1421, 2437])
Epoch: 3031, Training Loss: 0.31, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3032 - Batch 1 ########################
IDs in batch 1: tensor([2019, 2433, 2583,  206, 2019, 3250, 3647, 3303, 1984, 3373, 3871, 3276,
         427, 3813, 4033, 1613])
Epoch: 3032, Training Loss: 0.26, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3033 - Batch 1 ########################
IDs in batch 1: tensor([ 117, 3494, 3390,  490, 4018, 1256,  232, 3920, 1968, 3426, 2869, 4061,
         552, 2470, 3895, 1054])
Epoch: 3033, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3034 - Batch 1 ########################
IDs in batch 1: tensor([2660, 1823,  682,  102, 2833,  555, 1500, 1008, 1450, 1624, 2931, 3821,
        1484,   97, 2966, 2332])
Epoch: 3034, Training Loss: 0.17, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3035 - Batch 1 ########################
IDs in batch 1: tensor([1487, 1386, 2141,  402, 3790, 2789, 2410, 3291, 2115, 2159, 2238, 1552,
        1328, 4214,  434, 1826])
Epoch: 3035, Training Loss: 0.09, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3036 - Batch 1 ########################
IDs in batch 1: tensor([2624,  220,  487, 2217, 1723, 2489, 1678, 1316, 1476,  505,  399, 2678,
        3418,  113,  869, 1600])
Epoch: 3036, Training Loss: 0.48, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3037 - Batch 1 ########################
IDs in batch 1: tensor([3993, 4194, 3110, 3790, 1910, 1546, 2028, 1104, 2393, 2487, 3123, 2218,
         133, 1218, 1818, 3564])
Epoch: 3037, Training Loss: 0.21, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3038 - Batch 1 ########################
IDs in batch 1: tensor([2696, 3778, 3834, 3222, 2643,   49, 1371, 4039, 3113, 2304, 1344, 3143,
        2724, 3859, 3427, 1008])
Epoch: 3038, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3039 - Batch 1 ########################
IDs in batch 1: tensor([1786, 1625, 1007, 1974, 1601, 1660,   71,  110, 4108, 1726,  199, 3489,
        1591, 2587, 2414, 3534])
Epoch: 3039, Training Loss: 0.13, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3040 - Batch 1 ########################
IDs in batch 1: tensor([2765, 3494, 2451, 2148, 4014, 1252, 3744, 2921, 2949, 3886, 3160,  122,
         326,  824, 1948,  371])
Epoch: 3040, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3041 - Batch 1 ########################
IDs in batch 1: tensor([2546,  282, 1986,  575, 1108,  908, 3548, 1566,  257, 1037,  368, 1017,
        3115, 3950,  172, 2275])
Epoch: 3041, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3042 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 2770, 1384, 3858, 2927,   61, 2712, 1049,  645, 3108, 2571, 3353,
        2352, 2727, 2499,  577])
Epoch: 3042, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3043 - Batch 1 ########################
IDs in batch 1: tensor([2238, 1134,  946, 1437,  485, 2495, 3475,   88, 3433, 3047, 1052, 1605,
         982, 2091, 3221, 2039])
Epoch: 3043, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3044 - Batch 1 ########################
IDs in batch 1: tensor([1459, 3389,  224, 1285, 1733, 2824, 4261, 1623, 2469, 2641, 2784, 1639,
        1672, 2905,  606, 3699])
Epoch: 3044, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3045 - Batch 1 ########################
IDs in batch 1: tensor([1026, 4253, 3852, 1618,  857, 1186,  914, 1945, 3479, 3114, 2961, 2789,
        3497,  450,  739, 2853])
Epoch: 3045, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3046 - Batch 1 ########################
IDs in batch 1: tensor([2297, 1336, 3058, 1799, 3589, 4022, 3607, 3728, 1845, 2004, 3075, 2133,
        3553, 3110, 3265, 1028])
Epoch: 3046, Training Loss: 0.41, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3047 - Batch 1 ########################
IDs in batch 1: tensor([1155,  971, 4093, 3035, 3031,  399, 3030, 1498, 1795, 3326, 1870, 2540,
         786, 1436, 1321, 2496])
Epoch: 3047, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3048 - Batch 1 ########################
IDs in batch 1: tensor([ 631, 2765, 4003, 1043, 2932, 2480, 3640,  595,  342,  960, 2223,  710,
          37, 2099, 1094, 2758])
Epoch: 3048, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3049 - Batch 1 ########################
IDs in batch 1: tensor([1920, 1383, 1365, 3259, 2352, 2738,  968, 2400, 2002, 2120, 1066,   97,
         483, 3160,  786,  689])
Epoch: 3049, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3050 - Batch 1 ########################
IDs in batch 1: tensor([1134, 1318,  496, 3591, 4125, 1796, 2567, 4135, 3734,  660,  590, 3435,
        2018, 2582,  149, 2913])
Epoch: 3050, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3051 - Batch 1 ########################
IDs in batch 1: tensor([2468, 3290, 2141, 2624, 1373, 3262, 1845, 4118, 4157,  520, 1927, 3078,
        1979, 1732, 4220, 3081])
Epoch: 3051, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3052 - Batch 1 ########################
IDs in batch 1: tensor([3289,  653, 2157,  539, 2817, 2210,  652, 3289, 3743,  818, 1661, 2112,
        4121,  275,  225, 3108])
Epoch: 3052, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3053 - Batch 1 ########################
IDs in batch 1: tensor([ 642, 2847, 3271, 3970, 2072, 4268,  880, 4263,  171,  213, 1306,  308,
         247, 3366, 4135,  206])
Epoch: 3053, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3054 - Batch 1 ########################
IDs in batch 1: tensor([ 807,  615, 2666, 3336, 2092,  382, 1256, 3659, 2967, 1639, 2385, 3577,
        3006,  870, 1798,  967])
Epoch: 3054, Training Loss: 0.27, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3055 - Batch 1 ########################
IDs in batch 1: tensor([3168,  191, 1222, 2477, 2711, 1077, 1229, 3432, 1861, 3772, 2683, 3813,
        3272, 3919,  717, 3120])
Epoch: 3055, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3056 - Batch 1 ########################
IDs in batch 1: tensor([3279, 1802, 3258, 1472, 1111, 2991, 2739, 3514, 3267, 1414, 3992, 1116,
        3704,  252, 2568, 3699])
Epoch: 3056, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3057 - Batch 1 ########################
IDs in batch 1: tensor([2664, 2640, 2772, 4232,  398,  954, 1578, 1196, 3241,  604, 1833, 3197,
         890, 2644, 3961,  411])
Epoch: 3057, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3058 - Batch 1 ########################
IDs in batch 1: tensor([3271, 1897, 3373, 2028, 2423, 3897, 2788, 2740, 2921, 1866,  284, 1871,
        1094, 1658, 1053, 4022])
Epoch: 3058, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3059 - Batch 1 ########################
IDs in batch 1: tensor([1862,  112, 1957, 1289, 1335, 2824, 4194, 3408, 4203, 2783, 2708, 3455,
        2840,  255, 1710, 3806])
Epoch: 3059, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3060 - Batch 1 ########################
IDs in batch 1: tensor([3065, 2782, 3340, 3473,  674,  670, 3257,   41, 1808, 4170, 3587,  335,
         266, 1510, 1763, 3475])
Epoch: 3060, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3061 - Batch 1 ########################
IDs in batch 1: tensor([1751, 1196,   13,  258,  247, 3160, 3398,  959, 3244, 1480, 3827, 3524,
        4049,  190,  899, 2751])
Epoch: 3061, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3062 - Batch 1 ########################
IDs in batch 1: tensor([1442, 3264,  484, 1328, 2963, 1146, 3304, 2831, 3010, 2977, 1753, 1648,
        1442, 2405, 1950, 3469])
Epoch: 3062, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3063 - Batch 1 ########################
IDs in batch 1: tensor([2437, 3886,  873, 4049, 2858,  586, 1787, 3227, 1781,  344, 1491, 3334,
         688,   13, 2248, 2603])
Epoch: 3063, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3064 - Batch 1 ########################
IDs in batch 1: tensor([4121, 3337, 4011, 3009, 2853, 2149, 4253,  849,   25, 1979, 3779, 3338,
        2368, 1136,  852, 1181])
Epoch: 3064, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3065 - Batch 1 ########################
IDs in batch 1: tensor([2466, 2787, 2314, 3255,  854,  518, 4131, 2902,  701,  398, 1244, 3640,
        2646, 2977,  688, 2067])
Epoch: 3065, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3066 - Batch 1 ########################
IDs in batch 1: tensor([  32, 2300,  899, 3714, 1497, 1276, 3321, 1830, 2821, 2854, 3975, 3830,
        1899, 1237, 2018,  971])
Epoch: 3066, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3067 - Batch 1 ########################
IDs in batch 1: tensor([1595,  117,  660, 1647, 2146, 2731, 1973,  649,  125,  969, 3204, 2023,
        2378, 1910,  321,  891])
Epoch: 3067, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3068 - Batch 1 ########################
IDs in batch 1: tensor([2526, 3969, 2866, 2179,  875, 2144, 4135, 3882, 1891, 1740, 2357, 3651,
         943,  352, 2475, 2653])
Epoch: 3068, Training Loss: 0.25, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3069 - Batch 1 ########################
IDs in batch 1: tensor([3581, 3581,  236, 3837, 2581, 1269, 2334, 1032, 4254, 4114, 1680,  488,
        3022, 1111, 1551, 3136])
Epoch: 3069, Training Loss: 0.39, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3070 - Batch 1 ########################
IDs in batch 1: tensor([2065, 3036, 3218, 1663, 2059,  212, 3875,  317, 1798,  809, 3838, 3907,
        3547,  435,  252,  957])
Epoch: 3070, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3071 - Batch 1 ########################
IDs in batch 1: tensor([1436,  615, 3534, 2572, 1062,  150, 3459,  522, 4144, 1469, 2730, 2365,
        1859, 3781, 3187,  676])
Epoch: 3071, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3072 - Batch 1 ########################
IDs in batch 1: tensor([2884, 2320, 4190, 4238,  225,  522,  400, 1124,  213,  869, 3058, 3593,
         511,  360, 3358,  117])
Epoch: 3072, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3073 - Batch 1 ########################
IDs in batch 1: tensor([3463, 1454,  520,  283,  986, 2692,  342, 3763, 3398, 1682,   43, 2942,
        3833, 2176, 4242, 3746])
Epoch: 3073, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3074 - Batch 1 ########################
IDs in batch 1: tensor([ 994, 3856, 2110,  987, 3415,  202, 3109,   37,  341,  603, 1883,  709,
        1009, 1774, 2695,  770])
Epoch: 3074, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3075 - Batch 1 ########################
IDs in batch 1: tensor([1675, 1698,  871, 2942,  830, 3953, 3087, 2857,  247, 1457, 2676,  572,
        4097, 1948, 3506, 1767])
Epoch: 3075, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3076 - Batch 1 ########################
IDs in batch 1: tensor([1772, 2410, 3843,  537, 1628, 1319, 3180, 1418, 2748,  556,  264, 1076,
        4166, 1877, 2719, 2581])
Epoch: 3076, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3077 - Batch 1 ########################
IDs in batch 1: tensor([1278, 1054, 3947, 4215, 3262,  850, 2817,  881, 1085, 2545, 3638, 1084,
        3071, 2104, 3591, 2553])
Epoch: 3077, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3078 - Batch 1 ########################
IDs in batch 1: tensor([2890,  172,  129, 1766, 1354, 4194, 1408,  821, 1954, 2149,  164,  247,
        2485,  129, 3367, 2320])
Epoch: 3078, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3079 - Batch 1 ########################
IDs in batch 1: tensor([3608, 3928, 2023, 2821, 1170, 4048, 1170, 2510, 2598, 2235, 1088, 2248,
         274, 3408, 1612, 4238])
Epoch: 3079, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3080 - Batch 1 ########################
IDs in batch 1: tensor([2736, 1352,  173, 3511, 3715, 1295, 2238, 2459, 4234,  852,  850,  870,
         225, 3354, 2737, 2845])
Epoch: 3080, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3081 - Batch 1 ########################
IDs in batch 1: tensor([3343,  401, 3466, 3317, 2364, 2228, 3769, 3847,  363, 2157, 1278, 4027,
        3401, 2638, 3914,  140])
Epoch: 3081, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3082 - Batch 1 ########################
IDs in batch 1: tensor([ 814, 4056,  450,  424, 1249, 2327, 3373, 2369, 1497, 3554, 1990, 3465,
        3334,  680,  795, 4230])
Epoch: 3082, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3083 - Batch 1 ########################
IDs in batch 1: tensor([3734, 1233, 2358,   97,   24, 4053, 3360,  934, 3993,  516, 1682, 1808,
        1116, 1630, 2106,  832])
Epoch: 3083, Training Loss: 0.40, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3084 - Batch 1 ########################
IDs in batch 1: tensor([ 266,  767, 2764, 2109, 4152, 1443, 1862, 3015, 3339, 4015,  373, 1804,
          78, 3792,  797,  843])
Epoch: 3084, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3085 - Batch 1 ########################
IDs in batch 1: tensor([4053, 1869,  646, 1962, 3960, 1075, 2437, 3334, 2092, 1826, 4007, 1444,
        3829, 3336,  753, 2435])
Epoch: 3085, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3086 - Batch 1 ########################
IDs in batch 1: tensor([ 640, 4099,  797, 3920, 1470, 3983, 2982, 3022, 4035,  380, 3524, 3793,
        3057,   22, 2366, 1787])
Epoch: 3086, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3087 - Batch 1 ########################
IDs in batch 1: tensor([1295,  164, 4240, 2758, 2879, 2967, 2964, 1157,  149, 3088, 1974, 3159,
         739, 1710, 1459, 2050])
Epoch: 3087, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3088 - Batch 1 ########################
IDs in batch 1: tensor([2693, 2260, 2754, 3711, 4007,  514,  694, 3676, 2563, 2867, 1980, 3710,
          88,  435, 3652, 2244])
Epoch: 3088, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3089 - Batch 1 ########################
IDs in batch 1: tensor([2390, 3663, 4072, 3460, 2099, 2455, 3541,  186, 2949, 1417, 3573, 1884,
        1508,  904,  956, 2107])
Epoch: 3089, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3090 - Batch 1 ########################
IDs in batch 1: tensor([3661, 1034, 1082, 3082, 2095, 1363, 2378, 4114, 2568, 2192,  630, 3002,
        1579,  498, 1913, 4100])
Epoch: 3090, Training Loss: 0.02, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3091 - Batch 1 ########################
IDs in batch 1: tensor([4253, 3374, 2837, 1451, 1409, 2583, 4152, 3702,  238, 2034,  360, 3351,
         982, 1464, 2938,  960])
Epoch: 3091, Training Loss: 0.29, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3092 - Batch 1 ########################
IDs in batch 1: tensor([ 828,  247, 2540, 2551,  753, 3715, 1956, 1251,  644, 1356, 1331,  552,
        2984, 1027, 3475, 1439])
Epoch: 3092, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3093 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 2025, 3644, 2327,  290, 1016, 3179,  439,  237,  864, 1540, 3496,
         674,  287, 3538, 2796])
Epoch: 3093, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3094 - Batch 1 ########################
IDs in batch 1: tensor([2155, 1636, 3699, 4125, 1636, 2822, 4048, 3672, 2036,  645, 3783, 2013,
         736,  498,  826, 4232])
Epoch: 3094, Training Loss: 0.34, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3095 - Batch 1 ########################
IDs in batch 1: tensor([2795,  101, 2500,  379, 2751, 2067, 1818, 3351,   82,  202, 3786, 3275,
        1672, 1321, 3483, 2521])
Epoch: 3095, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3096 - Batch 1 ########################
IDs in batch 1: tensor([2213, 3866,    7,  652, 2343, 3435, 3711, 1955,  736,  367, 2494, 1933,
        2737, 3795, 3904, 3509])
Epoch: 3096, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3097 - Batch 1 ########################
IDs in batch 1: tensor([1985, 4268, 1248,  796, 2670, 4253, 1385,  893, 3667, 3660, 3765,  771,
         701, 1010, 2019, 3178])
Epoch: 3097, Training Loss: 0.24, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3098 - Batch 1 ########################
IDs in batch 1: tensor([3308,  281,  871,  797, 1239, 3891, 1786, 1960, 2298, 2731, 3101, 2914,
        3317, 2936, 1333,  756])
Epoch: 3098, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3099 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1118,  691, 3598, 2748, 1157,  941,  980, 3994, 3185,  749, 1684,
         924,  552,  422, 2149])
Epoch: 3099, Training Loss: 0.66, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3100 - Batch 1 ########################
IDs in batch 1: tensor([4009, 4229, 2632, 3470, 2579,  151,  850,  552, 4024, 3435,  127,  976,
        3573,  290, 2945, 2464])
Epoch: 3100, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3101 - Batch 1 ########################
IDs in batch 1: tensor([1077, 4046,  436, 1990,  558,  636, 1146, 2437, 1152, 2364, 4114, 1994,
        4014, 2254, 2391,  968])
Epoch: 3101, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3102 - Batch 1 ########################
IDs in batch 1: tensor([4126, 4134, 1677, 1473, 1556,  324, 3747, 1183, 2066, 2951, 3537, 1633,
        2116,  688, 3312, 2247])
Epoch: 3102, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3103 - Batch 1 ########################
IDs in batch 1: tensor([3567, 1844, 1472, 3073, 1967, 2496, 2891, 1330, 2246, 3541,  141, 3185,
        3250,  967, 3168, 2413])
Epoch: 3103, Training Loss: 0.39, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3104 - Batch 1 ########################
IDs in batch 1: tensor([4181, 2652, 2118, 2871, 2902, 1569, 4119, 1038, 3949, 1410,  407, 3408,
        3507, 2282,  558, 3132])
Epoch: 3104, Training Loss: 0.11, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3105 - Batch 1 ########################
IDs in batch 1: tensor([ 680, 1286, 1308, 1123, 2371, 3429,  851, 3912, 1733, 1982, 3311, 1961,
         818,  849,  360, 3047])
Epoch: 3105, Training Loss: 0.22, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3106 - Batch 1 ########################
IDs in batch 1: tensor([2943,  343, 3903, 1879,  852, 3000, 3950, 2977, 4048,  632, 3588, 1454,
        4067, 1580,  583,  895])
Epoch: 3106, Training Loss: 0.33, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3107 - Batch 1 ########################
IDs in batch 1: tensor([ 620, 2931,  188,  101, 2116,  415, 3437, 4229, 2272, 4035,  106, 2028,
        2069, 2764,   20, 1508])
Epoch: 3107, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3108 - Batch 1 ########################
IDs in batch 1: tensor([2824, 3500, 1372,  172,  724, 3286, 1576,  673, 2746,  196, 3065, 3668,
        2902, 1660, 1517, 3697])
Epoch: 3108, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3109 - Batch 1 ########################
IDs in batch 1: tensor([3227, 2306, 4004, 2145, 3859, 3020, 3487, 2540, 2363,  982, 1354, 2815,
         876,  395, 3300, 1677])
Epoch: 3109, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3110 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 3614, 3810, 2391,  829,  965, 3074, 2053, 2845, 1498, 4163, 2230,
        2044, 4053,  732, 2086])
Epoch: 3110, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3111 - Batch 1 ########################
IDs in batch 1: tensor([ 265, 1482, 3242,  644, 3087, 3592, 1931, 1976, 1736, 1828,  926, 2942,
        2252, 3664, 3071, 1490])
Epoch: 3111, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3112 - Batch 1 ########################
IDs in batch 1: tensor([ 736, 1352,  789,  842, 2149, 1408,  854, 2646, 2250, 4172,  321, 1102,
        2506, 2370, 1420,  667])
Epoch: 3112, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3113 - Batch 1 ########################
IDs in batch 1: tensor([4105, 4127, 1204, 1949, 3441, 1643, 4012, 1897, 3557, 2141, 3353, 1324,
        3728,  398,  878,  151])
Epoch: 3113, Training Loss: 0.31, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3114 - Batch 1 ########################
IDs in batch 1: tensor([3047, 2562,  968, 2017,  778, 2041,   70, 2982, 4078, 4180, 2921, 4050,
        3037, 2228, 2156, 3485])
Epoch: 3114, Training Loss: 0.38, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3115 - Batch 1 ########################
IDs in batch 1: tensor([1853,  814, 3139, 1075, 1179, 1425,  250,  442, 1570,  363, 1570,  797,
         224, 2456, 3900, 2312])
Epoch: 3115, Training Loss: 0.32, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3116 - Batch 1 ########################
IDs in batch 1: tensor([2723, 3786,  659,  762, 2664, 4143, 3673, 1051,   61,  477,  332, 2329,
        2370,  469, 3384, 2109])
Epoch: 3116, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3117 - Batch 1 ########################
IDs in batch 1: tensor([1421,  776,  391,  879, 1367, 1372, 1417,   70, 3785, 2692, 4227, 3974,
        2913, 1375,  577,  631])
Epoch: 3117, Training Loss: 0.39, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3118 - Batch 1 ########################
IDs in batch 1: tensor([3282,  962, 3600, 1614,  221, 2236,  513, 1949, 3032, 4073, 1779, 3428,
        3948, 1532, 3476, 2681])
Epoch: 3118, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3119 - Batch 1 ########################
IDs in batch 1: tensor([1699, 1718,  876,  402, 1972, 2650, 3778,  149,  141, 1123, 2449, 3891,
        2092, 2067, 1626,  723])
Epoch: 3119, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3120 - Batch 1 ########################
IDs in batch 1: tensor([3277,  191, 1730, 2954, 1440, 2367, 1410,  312, 2237, 2572, 1330, 1879,
        3756, 4087, 1098, 2150])
Epoch: 3120, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3121 - Batch 1 ########################
IDs in batch 1: tensor([1781, 2350,  129,    7, 2932, 2291, 3016, 2548, 3308,  223, 3830, 4105,
        3246, 2461, 4166,  394])
Epoch: 3121, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3122 - Batch 1 ########################
IDs in batch 1: tensor([2859,  959, 1140, 2740, 3180, 2509,   37, 2732, 2488, 2299,  264,  965,
         767, 1049, 2902, 2249])
Epoch: 3122, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3123 - Batch 1 ########################
IDs in batch 1: tensor([2609, 3449, 2401, 2645, 2271, 2879, 3333, 1096,  159,  812,  490, 3650,
        1884, 1321, 1418, 2853])
Epoch: 3123, Training Loss: 0.27, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3124 - Batch 1 ########################
IDs in batch 1: tensor([1242, 3314,  874, 2087, 1728, 3751, 3003, 3234, 3272,  340, 2487, 2795,
        3969, 1863, 2937, 4196])
Epoch: 3124, Training Loss: 0.19, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3125 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 3455, 1775, 1935,  112, 4077, 3745, 1961,  402, 4100, 2508, 3196,
        1414, 2331,  218, 2739])
Epoch: 3125, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3126 - Batch 1 ########################
IDs in batch 1: tensor([ 459,  487,  795, 3193, 3663,  729,  813,  122, 4246, 1970, 3998, 3518,
         849, 2179,  896, 3881])
Epoch: 3126, Training Loss: 0.23, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3127 - Batch 1 ########################
IDs in batch 1: tensor([  39,  269, 3078, 2632, 2317, 2379, 1186,  529, 3437, 2329, 2094,  396,
        3488, 1244, 3264, 2009])
Epoch: 3127, Training Loss: 0.28, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3128 - Batch 1 ########################
IDs in batch 1: tensor([2219,  100, 2327, 1141, 1808,  915, 1069, 4200, 1009, 1292, 3357,  649,
         369,  125, 2627, 2524])
Epoch: 3128, Training Loss: 0.18, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3129 - Batch 1 ########################
IDs in batch 1: tensor([1490, 1010, 2914,  769, 3192, 2133, 2092, 3630,  928, 2509,  843,  327,
        1618, 2219, 1988,  110])
Epoch: 3129, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3130 - Batch 1 ########################
IDs in batch 1: tensor([3568, 2480, 3184, 2009, 2195, 1780, 2219,  959, 1257,  219, 2913,  910,
        3667,  306, 3936, 1397])
Epoch: 3130, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3131 - Batch 1 ########################
IDs in batch 1: tensor([2784,  395, 1756,  373,  135, 2352, 2901, 4013,  701, 1134,  796, 1537,
        3408,  201, 2653, 3947])
Epoch: 3131, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3132 - Batch 1 ########################
IDs in batch 1: tensor([1065, 2246, 3337, 2499, 3081,  243, 1795, 2073, 2659, 1075,  243, 2806,
        2035, 4230, 2712, 4116])
Epoch: 3132, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3133 - Batch 1 ########################
IDs in batch 1: tensor([1334, 3460, 3284, 2965, 1167, 1553,  199, 2688,  623, 2441, 1081, 2146,
        2398, 3525, 1281,  858])
Epoch: 3133, Training Loss: 0.20, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3134 - Batch 1 ########################
IDs in batch 1: tensor([1060,   51, 3632,  450, 1870, 3028, 3792, 3683, 1532, 2551, 4255, 3390,
        3792, 1321, 2782,  824])
Epoch: 3134, Training Loss: 0.20, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3135 - Batch 1 ########################
IDs in batch 1: tensor([ 574, 1270, 3253,  211, 1225, 3742, 2664, 2478,  640, 2455, 4125,  848,
        1990, 1104, 3233, 1736])
Epoch: 3135, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3136 - Batch 1 ########################
IDs in batch 1: tensor([ 289,  588, 1555, 3132,  141,  902, 2320,  415,  838, 4254, 3949, 1502,
        3675, 2226, 1825, 2388])
Epoch: 3136, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3137 - Batch 1 ########################
IDs in batch 1: tensor([ 980, 3836, 2126,   21, 2951, 3904, 2693, 1326,  829,  398, 2191, 2005,
         736, 1423,  391, 3969])
Epoch: 3137, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3138 - Batch 1 ########################
IDs in batch 1: tensor([1144, 2802, 4159, 3628, 1763,  985, 2192, 2993,  956, 1670, 2508, 2697,
         612, 1248, 4126, 3377])
Epoch: 3138, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3139 - Batch 1 ########################
IDs in batch 1: tensor([3199, 2678, 1399, 1543, 1779, 3950, 1913, 4249, 2934, 3030, 3795, 1712,
         419, 3911, 4197, 3337])
Epoch: 3139, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3140 - Batch 1 ########################
IDs in batch 1: tensor([2936, 1317,  177,  330,  437,  358, 1770, 2388, 1485, 2905, 1257,  569,
        3934, 2056, 1434,   95])
Epoch: 3140, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3141 - Batch 1 ########################
IDs in batch 1: tensor([4037, 1371, 3258, 4188, 2563, 3616, 4175, 3693, 2229,  849, 1937, 1853,
        3279, 4030, 4125, 1824])
Epoch: 3141, Training Loss: 0.64, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3142 - Batch 1 ########################
IDs in batch 1: tensor([2247, 1796, 3807,  243, 1022, 1504, 2855, 2565, 4134,  866, 2332, 3147,
        2030,  437, 4199, 2835])
Epoch: 3142, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3143 - Batch 1 ########################
IDs in batch 1: tensor([1551, 1144,  256,  755, 1321, 1310, 1623, 1098, 3710, 1920, 2912,  955,
        3792,  435,  524, 3265])
Epoch: 3143, Training Loss: 0.50, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3144 - Batch 1 ########################
IDs in batch 1: tensor([2996, 1543, 2255, 3025, 1984, 2605, 3874, 2419, 1313, 1567,  851, 1794,
        2417, 2016, 1140, 3002])
Epoch: 3144, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3145 - Batch 1 ########################
IDs in batch 1: tensor([2575, 1885, 3746,  989, 3151,  365,  202, 3277, 3468,  601, 3693,  926,
         575,  497, 3238, 2149])
Epoch: 3145, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3146 - Batch 1 ########################
IDs in batch 1: tensor([1014, 2051, 3337, 3052,  628, 2142, 3000,  587, 2436, 2295, 1852, 4058,
        2038, 1597, 3235, 2951])
Epoch: 3146, Training Loss: 0.49, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3147 - Batch 1 ########################
IDs in batch 1: tensor([3481, 1027, 2157, 1026, 2582, 1219, 2963, 3056,  221,  625,  516, 1011,
         346, 3258,  387,  211])
Epoch: 3147, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3148 - Batch 1 ########################
IDs in batch 1: tensor([1923, 1226,  786, 1933, 2546, 1087, 2867,  469, 1289, 3339, 2710, 3036,
        2827, 1862, 1336, 3706])
Epoch: 3148, Training Loss: 0.32, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3149 - Batch 1 ########################
IDs in batch 1: tensor([1084, 3226,  805, 1198, 1910,  730, 3638, 1417, 3856, 2473, 2332, 1762,
        3472, 3372, 1256, 3503])
Epoch: 3149, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3150 - Batch 1 ########################
IDs in batch 1: tensor([1855, 2367, 2328, 3211, 3674, 1167, 2420, 1182, 1777, 3136,  978, 2489,
        2823,  963, 1579,  873])
Epoch: 3150, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3151 - Batch 1 ########################
IDs in batch 1: tensor([3313,  260, 3065,  950, 4256, 1110, 1200, 4128,   98, 2854, 2425, 3985,
         807,  397, 1070, 1795])
Epoch: 3151, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3152 - Batch 1 ########################
IDs in batch 1: tensor([1704, 2444, 3738, 3192, 4143,  919, 2742,  405, 1405, 1124, 1317,   88,
        4138, 1618, 3194, 2051])
Epoch: 3152, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3153 - Batch 1 ########################
IDs in batch 1: tensor([2399,  133, 1418, 1024, 2506, 1519, 3286, 1176, 2618, 1834, 2794, 1421,
         645,  943, 1947, 2378])
Epoch: 3153, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3154 - Batch 1 ########################
IDs in batch 1: tensor([2497, 1062,  738, 1199, 1881,  145, 1257, 2328,  907, 2370, 2108,  400,
         507, 3386, 1168, 2106])
Epoch: 3154, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3155 - Batch 1 ########################
IDs in batch 1: tensor([1472, 3364,  450,  663, 2700, 1319,  841,  863, 1159, 1166, 3218, 1899,
        2990, 2354, 1613, 3200])
Epoch: 3155, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3156 - Batch 1 ########################
IDs in batch 1: tensor([2524, 3545, 2484, 4173, 2209, 2148,  512,  401,  574, 2732, 1859,  880,
        3618, 2346, 2871, 3004])
Epoch: 3156, Training Loss: 0.47, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3157 - Batch 1 ########################
IDs in batch 1: tensor([2879, 4134,  151, 1196, 2978, 4148,  490, 2678, 2241, 3185,  897, 3886,
        3988, 1406, 1437, 2135])
Epoch: 3157, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3158 - Batch 1 ########################
IDs in batch 1: tensor([2120, 3057,  673, 3118, 3009, 2016, 2775, 3912, 2815, 2241, 2990, 4213,
        2858, 3672, 3987,  818])
Epoch: 3158, Training Loss: 0.53, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3159 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 2024, 2436, 2870, 4215,  652,  244, 2014, 3242, 4200, 3234, 3609,
        3726, 3100, 2323,   97])
Epoch: 3159, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3160 - Batch 1 ########################
IDs in batch 1: tensor([2880, 1808, 1235, 2563, 3860, 1017, 3241, 3839, 3182,  261, 1836, 1017,
         740, 1630,  258, 4261])
Epoch: 3160, Training Loss: 0.56, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3161 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 3765, 3415, 2620,  796,   13,  149, 3468,  516, 3563,  807, 1835,
         391,   24,  952, 3762])
Epoch: 3161, Training Loss: 0.36, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3162 - Batch 1 ########################
IDs in batch 1: tensor([1272, 3381, 1123, 4255,  966,  586, 2156,  777, 3308, 2828, 2192, 3390,
        1088, 2885, 1944, 4180])
Epoch: 3162, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3163 - Batch 1 ########################
IDs in batch 1: tensor([ 511, 1853, 1519, 3029,  713, 2538, 2416,  672, 3873, 3426,  402, 3025,
         372,  930,  573, 1935])
Epoch: 3163, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3164 - Batch 1 ########################
IDs in batch 1: tensor([4139, 1005, 2133, 2402, 1552, 2469,  874,  402, 1809, 3570, 1973,  327,
          77, 2921,  489,  637])
Epoch: 3164, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3165 - Batch 1 ########################
IDs in batch 1: tensor([1146,  824,  904, 1231,  323,   31, 2772,  872,  462,  338, 1675,  352,
        4006,  103, 1371, 1552])
Epoch: 3165, Training Loss: 1.16, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3166 - Batch 1 ########################
IDs in batch 1: tensor([4032, 3688, 2949, 3434, 4046, 3949, 1209, 2692, 1104, 3871, 2741, 2176,
        1521, 1684, 2537, 3523])
Epoch: 3166, Training Loss: 0.41, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3167 - Batch 1 ########################
IDs in batch 1: tensor([3797, 2959,  259,  503, 2614, 1945, 2399, 3873, 1161,  884, 2688, 3962,
         694, 2169, 3479,  104])
Epoch: 3167, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3168 - Batch 1 ########################
IDs in batch 1: tensor([1707, 3925, 3778,  821, 3826,  379, 1740,  426, 2375, 1384,  108, 2375,
        3843, 3963,  138,  568])
Epoch: 3168, Training Loss: 0.33, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3169 - Batch 1 ########################
IDs in batch 1: tensor([3873, 1722,  640, 3406, 1108, 1387,  225,  403, 1272, 2905, 1925, 1501,
        1364, 2366, 2934, 1868])
Epoch: 3169, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3170 - Batch 1 ########################
IDs in batch 1: tensor([2447, 1087, 2224, 3711,  710, 2477, 3922,  863, 1868, 3009, 3551, 4138,
         508,  218, 3498, 2500])
Epoch: 3170, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3171 - Batch 1 ########################
IDs in batch 1: tensor([1724,  517, 3192,  214, 2996,  752, 2467,  355, 1287,  390, 2235, 3499,
         622,  111, 3981, 1819])
Epoch: 3171, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3172 - Batch 1 ########################
IDs in batch 1: tensor([1925, 1471, 1380, 3111, 1872, 2435, 3568, 3479, 3388, 4242,  196, 1190,
          61, 3053,  345, 4128])
Epoch: 3172, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3173 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 1387, 2141,  459, 1005, 3463, 1388,  736, 3304, 2212, 1330, 2428,
        1781, 3300, 3392, 1980])
Epoch: 3173, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3174 - Batch 1 ########################
IDs in batch 1: tensor([3313, 3996,  544, 1526, 1610, 3159, 1600, 1417, 1628,  425, 3616,  403,
        2559, 1702,  223,  396])
Epoch: 3174, Training Loss: 0.66, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3175 - Batch 1 ########################
IDs in batch 1: tensor([4037, 4152,  590, 1047, 2022, 4038,  735,  121, 3668, 2280, 2661, 1860,
         205, 1555,  725, 4256])
Epoch: 3175, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3176 - Batch 1 ########################
IDs in batch 1: tensor([1370, 2653,  738,  557, 1951,  360, 3161, 3055, 3865, 2131, 3272, 3079,
        1808, 2257, 1597, 3762])
Epoch: 3176, Training Loss: 0.50, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3177 - Batch 1 ########################
IDs in batch 1: tensor([2879,  790, 3047,  228, 3238, 2118,  266, 3994, 2469, 1524, 2489, 2730,
         721, 3267, 2796, 2092])
Epoch: 3177, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3178 - Batch 1 ########################
IDs in batch 1: tensor([4146, 3091, 2563, 3871, 3549, 2690,  569, 2309, 3139, 3494, 3632, 2689,
          10, 2120, 2287, 1317])
Epoch: 3178, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3179 - Batch 1 ########################
IDs in batch 1: tensor([1718, 2742, 3843, 1379,  781, 3156,  855, 2287, 1638,  721, 3831, 3695,
        4107,  694, 4061, 1728])
Epoch: 3179, Training Loss: 0.41, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3180 - Batch 1 ########################
IDs in batch 1: tensor([4149, 3256, 2475,   71, 3483, 3187, 1638, 3374,  578,  949,  615,  896,
        1504, 2274, 1092, 3945])
Epoch: 3180, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3181 - Batch 1 ########################
IDs in batch 1: tensor([3747,  369, 4136, 4246, 2546, 2117, 3718, 3176, 3987, 3282, 2609,  318,
        1448,   60, 1354, 3753])
Epoch: 3181, Training Loss: 0.67, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3182 - Batch 1 ########################
IDs in batch 1: tensor([4200, 2504,  262, 2701,  418, 3436, 3869,  226,  444, 2367, 3009, 2314,
        2060, 2296, 3098, 3569])
Epoch: 3182, Training Loss: 0.23, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3183 - Batch 1 ########################
IDs in batch 1: tensor([1781, 3610, 1950, 1809, 3583,  763, 1639, 2161,  332, 1766, 2524, 3120,
        2927, 3466, 4053, 3114])
Epoch: 3183, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3184 - Batch 1 ########################
IDs in batch 1: tensor([3488, 3942, 3060, 4039, 1469, 2771, 4105, 1237,  425, 3781, 1140, 2945,
        1453,  170, 3472,  325])
Epoch: 3184, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3185 - Batch 1 ########################
IDs in batch 1: tensor([1642, 1974,  515, 3113, 3255,  131, 2508, 3449, 2777, 1774, 3769,  575,
         653, 2179, 3351, 2858])
Epoch: 3185, Training Loss: 0.31, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3186 - Batch 1 ########################
IDs in batch 1: tensor([2008, 2423, 2708, 2056,  676, 3094,  974,  855, 3500, 3583, 1283,  448,
        3036, 3863, 1439, 1178])
Epoch: 3186, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3187 - Batch 1 ########################
IDs in batch 1: tensor([2010,  776,  450,  133, 3739, 3349, 4039, 1519, 1097, 3474, 1980, 3667,
        3016, 3384,  195, 3306])
Epoch: 3187, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3188 - Batch 1 ########################
IDs in batch 1: tensor([2999, 2440, 2189, 2659, 1345, 1871, 1428, 3027,  344, 1760, 3245,   86,
         102, 2563, 1594, 1343])
Epoch: 3188, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3189 - Batch 1 ########################
IDs in batch 1: tensor([1573, 2376, 2721, 1232,   21, 1537, 3841, 2334, 2562, 2787, 3417, 2618,
        1863, 1405, 2721,  201])
Epoch: 3189, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3190 - Batch 1 ########################
IDs in batch 1: tensor([2724, 2025, 2328,  256, 1258,  477, 1451, 2664, 1971, 1506,  492, 3677,
        2680,  160,  583, 4085])
Epoch: 3190, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3191 - Batch 1 ########################
IDs in batch 1: tensor([3983, 3408,  274,  843, 2453, 1395, 1881, 2167, 3262, 3238,  740, 1066,
         477, 3707, 1204, 1204])
Epoch: 3191, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3192 - Batch 1 ########################
IDs in batch 1: tensor([1626, 3494, 3754,  517,  258, 1032, 3373, 3183, 1003,  937, 3996,  902,
        1385,  276, 3374, 2357])
Epoch: 3192, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3193 - Batch 1 ########################
IDs in batch 1: tensor([3516, 1196, 3244,  756, 2721, 2443, 1981, 3614, 3518, 2998, 3947,  662,
        2956, 2280, 1612, 1901])
Epoch: 3193, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3194 - Batch 1 ########################
IDs in batch 1: tensor([2980, 3329, 3094, 1501, 2672, 2432, 2841, 3439, 2359,  481, 2218, 3187,
        4080,  343, 3049,  709])
Epoch: 3194, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3195 - Batch 1 ########################
IDs in batch 1: tensor([3994, 1158, 3452, 3592, 1285,  693,  371, 1264, 2898, 1053, 1255, 4184,
         100, 3453, 3375,  280])
Epoch: 3195, Training Loss: 0.33, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3196 - Batch 1 ########################
IDs in batch 1: tensor([ 387, 1509, 2003, 1009, 1415,  252, 4097,  787,  149, 3177, 1189,  456,
        1409, 2370, 3810,  360])
Epoch: 3196, Training Loss: 0.32, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3197 - Batch 1 ########################
IDs in batch 1: tensor([1356,  203, 2177, 2583, 1974, 3327, 3417, 1009, 4197, 1822, 2993, 1836,
        1020, 2541, 1229, 3392])
Epoch: 3197, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3198 - Batch 1 ########################
IDs in batch 1: tensor([4053, 2050,  862,  733,  239, 1017, 3785, 1511, 3753, 4188, 1099, 2737,
        1193, 3275,  362, 1540])
Epoch: 3198, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3199 - Batch 1 ########################
IDs in batch 1: tensor([3984,  965,  279,   11, 4051, 3049, 1051,  846, 3168, 1372,  194, 1923,
         639, 1962,  492, 2755])
Epoch: 3199, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3200 - Batch 1 ########################
IDs in batch 1: tensor([3161, 3630, 2080,  687, 2631,  523, 3676, 1478, 2292,  388, 2636,  188,
        3254, 2306, 2097,  259])
Epoch: 3200, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3201 - Batch 1 ########################
IDs in batch 1: tensor([ 727, 3829, 2506, 3990, 2866,  287, 3094, 3029, 3749, 1782, 3998, 2432,
        2271, 1322, 2299, 3471])
Epoch: 3201, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3202 - Batch 1 ########################
IDs in batch 1: tensor([1591, 4024, 1754, 3094, 4076, 1183, 3983, 3435, 2161, 3277, 1006, 4149,
        1247, 4173, 2260,  382])
Epoch: 3202, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3203 - Batch 1 ########################
IDs in batch 1: tensor([1746, 1665,  152, 4099, 2188, 3376,  507, 1868, 2976,  187, 2180, 3710,
        4113, 2495, 3660, 3610])
Epoch: 3203, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3204 - Batch 1 ########################
IDs in batch 1: tensor([1087, 1716,  590, 2465, 1408, 1316, 2874, 3783, 3058, 2462, 2938,  332,
        1766,    7, 1372, 4087])
Epoch: 3204, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3205 - Batch 1 ########################
IDs in batch 1: tensor([ 826, 2669, 3907, 2601,  155, 2511, 4072, 1775,  203,  356, 2030, 1810,
        2304,   93, 3272, 1543])
Epoch: 3205, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3206 - Batch 1 ########################
IDs in batch 1: tensor([ 946, 3240, 2873,  362,  201, 2190, 2327,  908, 1834,  322,  228, 2241,
        1931,  173, 3740, 3446])
Epoch: 3206, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3207 - Batch 1 ########################
IDs in batch 1: tensor([2185, 3734, 3354, 2317,  312, 1658, 1094, 1576,  725,  379,  483, 1844,
        3650,  529, 4117,   86])
Epoch: 3207, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3208 - Batch 1 ########################
IDs in batch 1: tensor([1001,  277, 1436, 3717,  180,  665, 2915,  644, 2640,   68, 3014, 3483,
        1648,  434, 2696, 1272])
Epoch: 3208, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3209 - Batch 1 ########################
IDs in batch 1: tensor([1275, 2039, 2853,  422,  752, 3914,   86, 2696, 3060, 3035,  606, 2536,
        2420, 3509, 2538, 4215])
Epoch: 3209, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3210 - Batch 1 ########################
IDs in batch 1: tensor([1287, 3858, 3433, 2452, 2983,  483, 1559, 3603, 2132, 3727, 2370, 1053,
        2475, 1387, 1977, 4139])
Epoch: 3210, Training Loss: 0.43, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3211 - Batch 1 ########################
IDs in batch 1: tensor([1974, 1047,  827,  317, 2210, 2649, 2517, 1679, 3989, 1668, 2352,   38,
        4176,  959, 1335, 2672])
Epoch: 3211, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3212 - Batch 1 ########################
IDs in batch 1: tensor([1613, 3917,  610,  442, 3908, 1118,  713, 2385, 2169, 2591, 1982, 2265,
        1390,  996, 3021, 3283])
Epoch: 3212, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3213 - Batch 1 ########################
IDs in batch 1: tensor([ 683, 3671, 3938, 1010, 2655,  891,  245, 3327, 1655, 2550,  965,  676,
        3652, 2540, 1963, 2354])
Epoch: 3213, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3214 - Batch 1 ########################
IDs in batch 1: tensor([2371, 3570,   86,   51, 2236, 3474, 1548,   73, 1488, 3896,  275, 1157,
        2902, 2408, 2320, 3926])
Epoch: 3214, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3215 - Batch 1 ########################
IDs in batch 1: tensor([3355, 4198, 3494, 4058, 3982, 1548, 4075, 1665, 2733, 1595, 1104, 4122,
        1698, 1237, 1480, 1248])
Epoch: 3215, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3216 - Batch 1 ########################
IDs in batch 1: tensor([4245, 2659, 4037,  620, 2026, 4062, 1299, 1877, 2851,  422, 4218, 2352,
        3573, 1377, 1456, 3667])
Epoch: 3216, Training Loss: 0.40, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3217 - Batch 1 ########################
IDs in batch 1: tensor([4044, 2936, 3789, 1927, 1658,  262, 1996, 3202, 4234,  445, 2537, 1501,
         327, 3220, 1881, 1054])
Epoch: 3217, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3218 - Batch 1 ########################
IDs in batch 1: tensor([2229,  281, 2179, 1241, 1482, 2755, 1530,  312, 3094, 3426, 2597, 3994,
         335,  337, 3655,  790])
Epoch: 3218, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3219 - Batch 1 ########################
IDs in batch 1: tensor([2167, 1297, 1665,  393, 1320, 2655, 1160, 1963, 1777,  965, 1760,  533,
        2115, 3543, 2456, 3492])
Epoch: 3219, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3220 - Batch 1 ########################
IDs in batch 1: tensor([ 508, 1632, 3279, 3409, 3298, 3345, 3974, 2274, 1808, 1896,  974, 2540,
        1346,  277, 1498, 4214])
Epoch: 3220, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3221 - Batch 1 ########################
IDs in batch 1: tensor([ 450, 3900,  485, 4011, 1649, 1426, 1755, 4217,  649, 3404, 1281, 3554,
         411, 2343,  133, 3268])
Epoch: 3221, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3222 - Batch 1 ########################
IDs in batch 1: tensor([2581, 2386, 3154,  356, 3020, 3268, 1256, 3692,  537,  441, 4119, 2195,
        3998,  258,  200, 3827])
Epoch: 3222, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3223 - Batch 1 ########################
IDs in batch 1: tensor([1755,  587, 4073, 2982, 2049, 4067, 1747, 3474, 2872, 1011, 4008, 2581,
        3603, 3435, 2991, 1859])
Epoch: 3223, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3224 - Batch 1 ########################
IDs in batch 1: tensor([2551, 2739,  511, 2902, 1655, 4217, 2371, 1140, 3211, 3705, 4031, 4089,
        1869, 2132,  779,  588])
Epoch: 3224, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3225 - Batch 1 ########################
IDs in batch 1: tensor([ 126,  330,  100, 4204,   72,  469, 2166, 4158, 2232, 1417,   93, 2682,
        2456, 3377, 1977, 3079])
Epoch: 3225, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3226 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 1283, 3363, 1177, 3614, 1834, 3739,  986, 1671, 2478, 2642, 1077,
        1318,  919, 2125, 3202])
Epoch: 3226, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3227 - Batch 1 ########################
IDs in batch 1: tensor([ 260, 3660, 2761, 3875,  358, 2114, 1229, 1242, 2563,   24, 4203, 2869,
        1319,   27,  920,  709])
Epoch: 3227, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3228 - Batch 1 ########################
IDs in batch 1: tensor([ 936, 1345, 4246,   86,   51, 1168, 1341, 2492, 2401, 3088, 4158, 2034,
         900, 1365, 3355, 3547])
Epoch: 3228, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3229 - Batch 1 ########################
IDs in batch 1: tensor([ 546, 1485,  112,  575, 2024, 3374, 1524, 1442,  171, 3732, 2859, 3772,
        2247,  439, 4016, 3279])
Epoch: 3229, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3230 - Batch 1 ########################
IDs in batch 1: tensor([ 199, 2339, 2073, 2256, 1453,  964, 2097, 1752, 4004, 3044, 3872, 4078,
        3075,  732, 3719, 2050])
Epoch: 3230, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3231 - Batch 1 ########################
IDs in batch 1: tensor([1884, 3524, 3860,  489, 3370, 3466, 1423, 2446, 1226, 3971, 2726, 1222,
        1098, 3264, 2577, 4225])
Epoch: 3231, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3232 - Batch 1 ########################
IDs in batch 1: tensor([1857, 1061, 3257, 2366,  520, 2837,  995, 2791,  755, 2616, 3278, 2229,
        2207, 3449, 3029, 3827])
Epoch: 3232, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3233 - Batch 1 ########################
IDs in batch 1: tensor([1937, 2706, 2746, 4030,  263, 3963,  183, 2788, 1975,  699, 2802, 3194,
        3558, 2473, 1166, 4224])
Epoch: 3233, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3234 - Batch 1 ########################
IDs in batch 1: tensor([1958, 2183, 3895, 3091,  108,  411,   35, 1437,  849,  454,  803, 2496,
        1421, 1442,   51, 4119])
Epoch: 3234, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3235 - Batch 1 ########################
IDs in batch 1: tensor([1537, 1777, 1976, 2682,  306, 3250, 2587,   92, 2751, 2431,  832, 2868,
        3121, 1200,  820,  942])
Epoch: 3235, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3236 - Batch 1 ########################
IDs in batch 1: tensor([2795, 1181, 3525,   93,  467, 3859, 1443, 1633, 2644,  662, 3002, 3276,
         842, 4087,  252, 1633])
Epoch: 3236, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3237 - Batch 1 ########################
IDs in batch 1: tensor([2401, 4015, 2331, 1054, 1650,  741, 1017,  451, 3707, 1291, 2723,  136,
        3823,   99, 1592, 1618])
Epoch: 3237, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3238 - Batch 1 ########################
IDs in batch 1: tensor([1770, 1336,  770, 1332, 3031,  171, 2579, 2225,  995, 3717, 1880, 2241,
        1138, 1076, 2540,  290])
Epoch: 3238, Training Loss: 0.25, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3239 - Batch 1 ########################
IDs in batch 1: tensor([4084, 1024,  183, 4144, 1634, 3982, 1077, 4179, 1589, 1817,  138,  601,
        1518, 3298, 3075, 3053])
Epoch: 3239, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3240 - Batch 1 ########################
IDs in batch 1: tensor([3660, 3310, 1175, 4165, 1590,  612, 2848, 3453, 3242, 1640, 2974, 1037,
        1344, 2632, 1932, 3040])
Epoch: 3240, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3241 - Batch 1 ########################
IDs in batch 1: tensor([1661, 1720, 3949,  908, 2375,  623,  261,  897, 1182, 3168, 4134, 3200,
        1281, 4125, 2729,   56])
Epoch: 3241, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3242 - Batch 1 ########################
IDs in batch 1: tensor([ 739, 3702, 1596, 2772,  727, 2405, 2448, 2312, 1163, 2599, 3807, 2448,
        2070, 1850, 2169,  926])
Epoch: 3242, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3243 - Batch 1 ########################
IDs in batch 1: tensor([2526, 3643, 1161, 1853, 1596, 1731, 2892, 4187, 3975, 2780, 2849, 2480,
        2095, 1415, 2086, 1702])
Epoch: 3243, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3244 - Batch 1 ########################
IDs in batch 1: tensor([  92, 2004, 2366, 3329, 2063, 4157, 4099, 2712, 2832,   98, 2462, 4013,
          50, 4024, 2075, 1676])
Epoch: 3244, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3245 - Batch 1 ########################
IDs in batch 1: tensor([2646,  354, 1183, 2190,  966, 2523, 2824, 2710, 2009, 2839,  199,  987,
        2506,  155,  472,  104])
Epoch: 3245, Training Loss: 0.37, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3246 - Batch 1 ########################
IDs in batch 1: tensor([ 207, 3614,  665, 2472, 3018, 1510, 2363,  534,  547, 3376, 2586, 3745,
        2304, 2925, 4138, 2337])
Epoch: 3246, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3247 - Batch 1 ########################
IDs in batch 1: tensor([1419, 1189, 2204, 2617, 2255, 2583, 2641, 1470, 4225,  899, 1961,  409,
          30,  959,  314, 1748])
Epoch: 3247, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3248 - Batch 1 ########################
IDs in batch 1: tensor([1472, 3259, 2446, 2885, 1077, 2526, 2247, 4119, 1879, 3258, 3624, 4256,
         139, 3862, 3113, 2956])
Epoch: 3248, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3249 - Batch 1 ########################
IDs in batch 1: tensor([ 402, 2449, 1117, 3507,  545,  400, 1553,  763,  787, 1935, 3144, 2436,
        3823,  733, 1670, 1746])
Epoch: 3249, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3250 - Batch 1 ########################
IDs in batch 1: tensor([3105,  894, 2874, 1546, 1585,  976, 2028, 2703, 3142, 1500, 1024, 2783,
        3551, 2074, 3461,   70])
Epoch: 3250, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3251 - Batch 1 ########################
IDs in batch 1: tensor([1383,  477, 2171, 1204, 3624,  530, 3275, 3321,   47, 3838, 2004, 1511,
        2797, 3987, 1182, 2257])
Epoch: 3251, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3252 - Batch 1 ########################
IDs in batch 1: tensor([3291,  575, 2837, 1796, 4088, 3130, 1635, 2348, 2287, 1405, 1913, 2334,
        3894, 1285, 4264, 4186])
Epoch: 3252, Training Loss: 0.30, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3253 - Batch 1 ########################
IDs in batch 1: tensor([4025, 4140, 2788, 1722,  887, 3911,   32, 1098, 3287, 3505, 2107, 1973,
        1846, 3676, 1518,  967])
Epoch: 3253, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3254 - Batch 1 ########################
IDs in batch 1: tensor([3500,  138,  963, 3803, 3795, 1282,    7, 1994,  198,  949, 2315,  105,
         858, 2599, 2950, 2352])
Epoch: 3254, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3255 - Batch 1 ########################
IDs in batch 1: tensor([4146, 2598, 2558,  463, 2453,  232, 1968, 3168, 1073,  824, 4228,  721,
        3399, 2024, 2912, 2075])
Epoch: 3255, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3256 - Batch 1 ########################
IDs in batch 1: tensor([ 689,  914, 3540, 1484,  507, 3509, 3554, 1614, 2247, 1042, 3208, 2749,
        1885, 3309, 3934, 2989])
Epoch: 3256, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3257 - Batch 1 ########################
IDs in batch 1: tensor([2710, 2309, 3328, 3983, 4006, 2192,  454, 1686, 2121,  334, 2890, 3907,
        1862, 2322,  425,   42])
Epoch: 3257, Training Loss: 0.11, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3258 - Batch 1 ########################
IDs in batch 1: tensor([4097, 2521, 2111, 1229,  815, 3617, 2832, 2234, 4121, 2284, 3875, 3897,
        3376, 2771,  212,  539])
Epoch: 3258, Training Loss: 0.19, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3259 - Batch 1 ########################
IDs in batch 1: tensor([  84, 1415, 4105, 1443,   15, 1950, 2178, 3053,  184, 3100, 3714, 2655,
          27,  933, 3804,  260])
Epoch: 3259, Training Loss: 0.33, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3260 - Batch 1 ########################
IDs in batch 1: tensor([2375, 4253, 2360, 3098, 4226, 3270, 2953, 1232, 1506,  961, 4057,   21,
        4089,  318,  976, 3721])
Epoch: 3260, Training Loss: 0.31, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3261 - Batch 1 ########################
IDs in batch 1: tensor([ 128, 3697, 1708,   20,   13,  820, 2114, 3370, 1406, 2284, 3244, 1239,
        1953, 2285,  682,   22])
Epoch: 3261, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3262 - Batch 1 ########################
IDs in batch 1: tensor([4067, 3458, 4218, 2476, 2352,  375, 2659, 2844,  797, 1085, 3592, 3343,
         738, 2857, 1292, 1737])
Epoch: 3262, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3263 - Batch 1 ########################
IDs in batch 1: tensor([3321, 3368, 2845, 1218, 2332,  434,  814, 3327, 3351, 3548, 4030, 3991,
        3453, 3545, 3593, 3947])
Epoch: 3263, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3264 - Batch 1 ########################
IDs in batch 1: tensor([1755, 3677,   74, 3548, 3072,  552, 3803, 1650, 4133, 2832, 1098, 1219,
        3369,  269,  957, 2217])
Epoch: 3264, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3265 - Batch 1 ########################
IDs in batch 1: tensor([3718, 3734, 2324, 1774, 1343, 2521, 4100, 1321,  869, 3314, 3414,  399,
        3697, 3179, 2542, 1139])
Epoch: 3265, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3266 - Batch 1 ########################
IDs in batch 1: tensor([3378, 1102,  797, 1389, 1417, 2309, 2367, 1066, 4266, 2281, 2664, 1481,
        2897, 2169,  556, 2959])
Epoch: 3266, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3267 - Batch 1 ########################
IDs in batch 1: tensor([2248, 2459, 1438,  983, 2365, 3873, 4213, 2265, 2697, 1916, 2627, 4220,
        1251, 2539, 3913, 1589])
Epoch: 3267, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3268 - Batch 1 ########################
IDs in batch 1: tensor([ 747,  180, 3841, 4095, 2509, 1290, 3006, 3423, 2996, 2965,  789, 2696,
        1509, 3000, 3945, 2322])
Epoch: 3268, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3269 - Batch 1 ########################
IDs in batch 1: tensor([1619,  439,   50, 2420, 1551, 4099, 2966, 2936, 4253, 1737, 4094, 3472,
        1302, 1334,  724, 2805])
Epoch: 3269, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3270 - Batch 1 ########################
IDs in batch 1: tensor([3972, 3018, 1374,  470, 3651,  530, 3355,  713,  488,  199,  155, 3564,
         224, 4077, 2339, 2143])
Epoch: 3270, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3271 - Batch 1 ########################
IDs in batch 1: tensor([1190,   11, 2970, 1869,  356,   47,  238,  743,  578,   96, 3549, 2711,
        1902, 2508, 1732, 2567])
Epoch: 3271, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3272 - Batch 1 ########################
IDs in batch 1: tensor([1737,  864,  920, 2432,  133, 2156, 1971, 2390, 1248, 3601, 2620, 2237,
        3599,   46, 1649, 2590])
Epoch: 3272, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3273 - Batch 1 ########################
IDs in batch 1: tensor([3495, 2887, 2696, 2144, 2775,  881, 1818, 2378, 1497, 2541,  182, 1089,
        4203, 3501, 2182, 4157])
Epoch: 3273, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3274 - Batch 1 ########################
IDs in batch 1: tensor([1166,  803,  244, 1053, 1574, 2019, 3995, 2169, 2457, 2520, 1186, 4138,
        1957, 2748, 2544,  770])
Epoch: 3274, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3275 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 2272, 2521, 1860, 2950, 1315, 2945, 3038,  684, 1877, 1297,  314,
        1383,  904, 4139, 3917])
Epoch: 3275, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3276 - Batch 1 ########################
IDs in batch 1: tensor([3498, 2228, 1763,  635, 1752, 3845,  417, 1993, 4249, 1944, 2049,  330,
        1967, 3289, 3117, 1387])
Epoch: 3276, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3277 - Batch 1 ########################
IDs in batch 1: tensor([ 452, 3962, 3449, 4088, 2600, 4122, 3697, 1724,  119, 3072,  915, 1628,
        1092, 3467, 2284, 1962])
Epoch: 3277, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3278 - Batch 1 ########################
IDs in batch 1: tensor([4011, 4084, 2113, 1720,  325, 4200,  610, 2601, 3323,   73,  790, 1173,
        1789, 3440, 2314, 1025])
Epoch: 3278, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3279 - Batch 1 ########################
IDs in batch 1: tensor([1131, 4255,  413,  573, 2107, 1733,  755, 3709, 1034,  736, 4127, 1088,
        1613, 1642, 2251,  992])
Epoch: 3279, Training Loss: 0.47, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3280 - Batch 1 ########################
IDs in batch 1: tensor([1453,  788,  820,  960, 3355,   22,  895,  582, 3395, 1668, 1155, 3771,
        4114, 3372, 3627, 2583])
Epoch: 3280, Training Loss: 0.27, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3281 - Batch 1 ########################
IDs in batch 1: tensor([2614, 2433, 2740,  108, 2951, 1614, 2788, 1803, 4139, 3180, 2644, 1809,
         342, 3268,  956, 2359])
Epoch: 3281, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3282 - Batch 1 ########################
IDs in batch 1: tensor([1600, 3503, 2379, 2179, 2352, 1476, 3057,  986,  379, 1157, 2957, 4251,
        1190, 2099, 1463, 3588])
Epoch: 3282, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3283 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 1600, 4088,  969, 4082, 4117, 2743, 1016,  368, 2313, 3252, 3339,
        1724, 2095, 3609, 2028])
Epoch: 3283, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3284 - Batch 1 ########################
IDs in batch 1: tensor([2727,  960, 3564, 3121,  583, 4099, 2440, 3535,  181, 2845,  866, 1312,
         604, 2880, 3351, 3366])
Epoch: 3284, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3285 - Batch 1 ########################
IDs in batch 1: tensor([3308, 3648, 1136, 4261, 3831, 3483, 1933, 1512,  656, 2010, 2468,   18,
        3952, 2983, 2644, 1731])
Epoch: 3285, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3286 - Batch 1 ########################
IDs in batch 1: tensor([2591, 3271, 1344, 3357, 1426, 3432, 3973, 2040, 2504, 4134, 3261, 3123,
        1777, 1901, 1452, 2609])
Epoch: 3286, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3287 - Batch 1 ########################
IDs in batch 1: tensor([3282, 3958, 1472, 1208, 3782, 1555,  776, 2297, 3272, 1024, 1999, 3997,
        1472, 2103,  987, 1624])
Epoch: 3287, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3288 - Batch 1 ########################
IDs in batch 1: tensor([3028,  363, 2741, 1877, 3715,  376, 1957, 2262,  875, 1726, 1440,  833,
         880, 2324, 3530, 4088])
Epoch: 3288, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3289 - Batch 1 ########################
IDs in batch 1: tensor([3951, 2648, 1118, 2394, 3822, 2225, 3035, 1072, 1154,  730, 1214, 1480,
         371, 2652, 3113, 3553])
Epoch: 3289, Training Loss: 0.20, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3290 - Batch 1 ########################
IDs in batch 1: tensor([2398, 1010, 1649, 4135, 1284, 3409, 1258, 3744, 2182, 2617, 2347, 2292,
         623, 3498, 1511,  376])
Epoch: 3290, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3291 - Batch 1 ########################
IDs in batch 1: tensor([ 190, 3397, 2932, 2398,  399, 4038, 1454, 4065, 4085, 1310,  129, 4136,
        3953,  749, 2453,  300])
Epoch: 3291, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3292 - Batch 1 ########################
IDs in batch 1: tensor([2195,  627,  921, 4199, 1003,  426, 1476, 2451, 3187, 3452, 2653, 2278,
        2872, 3404,  626,  167])
Epoch: 3292, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3293 - Batch 1 ########################
IDs in batch 1: tensor([3872, 1638,  547, 1137, 3524, 1748, 2494,   56,  136, 3518, 3509, 1152,
        1364,  183, 1690, 2511])
Epoch: 3293, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3294 - Batch 1 ########################
IDs in batch 1: tensor([3963, 2517,  534, 2177, 3988, 2770, 3404,  926,  252,  603, 3177, 2275,
        3677, 2260, 3765, 3304])
Epoch: 3294, Training Loss: 0.32, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3295 - Batch 1 ########################
IDs in batch 1: tensor([1234,  186, 4065,  897, 1698, 3099, 1804, 4024, 3219, 4204, 1218, 1042,
         818,  475, 1156, 3399])
Epoch: 3295, Training Loss: 0.28, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3296 - Batch 1 ########################
IDs in batch 1: tensor([ 751,  851, 1185,  139, 1032, 1634,  284, 2219,  485,  181,  419, 4070,
         141,  593,  657, 1602])
Epoch: 3296, Training Loss: 1.21, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3297 - Batch 1 ########################
IDs in batch 1: tensor([1643, 1668, 3458,  756, 2423, 1241, 2749, 3368, 1684, 4096, 4095, 3441,
        2156, 3570, 1324, 1552])
Epoch: 3297, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3298 - Batch 1 ########################
IDs in batch 1: tensor([1418, 2724,  499, 2436, 3246, 3363,  797, 2616, 2907, 2432, 2095,  465,
        2697, 2249, 1458, 1369])
Epoch: 3298, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3299 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 3126,  593, 1840,  792, 3317, 1568, 4056, 2085, 1734, 1102, 4224,
          20, 3746, 4165, 4214])
Epoch: 3299, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3300 - Batch 1 ########################
IDs in batch 1: tensor([2199, 1495, 3793, 2996,  450,  941, 3987,   85, 1938, 3328, 3312, 1521,
        4075, 2470,   43,  846])
Epoch: 3300, Training Loss: 0.27, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3301 - Batch 1 ########################
IDs in batch 1: tensor([ 756,  396, 2867,  141, 1700, 1281, 2957, 1283, 3147, 2681, 2867, 2206,
        1117,  399, 4180, 2804])
Epoch: 3301, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3302 - Batch 1 ########################
IDs in batch 1: tensor([3677,  866, 1357, 3400, 4159, 1306, 3616, 1923, 2641,   98,   85, 2458,
         550, 4131, 2586, 1977])
Epoch: 3302, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3303 - Batch 1 ########################
IDs in batch 1: tensor([2719,  322,  491,  393, 3005, 3278, 1508, 1437, 3696, 1489, 1961, 3859,
        1463, 1885,  306, 2018])
Epoch: 3303, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3304 - Batch 1 ########################
IDs in batch 1: tensor([3460, 3219,  278,  417, 1093,  334, 2108, 3617,   84, 1016, 2443, 1333,
        3258, 2642, 3726, 1685])
Epoch: 3304, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3305 - Batch 1 ########################
IDs in batch 1: tensor([1981, 1585, 2742, 1196,   27, 2942, 1481, 1419, 4133, 3961,  387,  632,
        3922, 3624, 1896, 2680])
Epoch: 3305, Training Loss: 0.31, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3306 - Batch 1 ########################
IDs in batch 1: tensor([1568, 1322,  781, 2183, 3217, 2487, 1087, 1006, 1087,  122, 2122, 3197,
        1222, 2997, 2959, 1075])
Epoch: 3306, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3307 - Batch 1 ########################
IDs in batch 1: tensor([ 694, 1537, 2453,  508, 1502, 1146, 3797,  314, 1846,  680,  244, 4077,
         546, 1842, 2949, 2629])
Epoch: 3307, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3308 - Batch 1 ########################
IDs in batch 1: tensor([1781, 2366,  239, 1975, 1070, 2795, 3749, 1308, 2914, 1484, 4004,  138,
         803,  135, 1183,  510])
Epoch: 3308, Training Loss: 0.40, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3309 - Batch 1 ########################
IDs in batch 1: tensor([ 743, 1811, 3526, 1347, 2492, 2874, 2524,  439, 3039, 1337, 3337, 2326,
         108, 3098, 4131,  858])
Epoch: 3309, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3310 - Batch 1 ########################
IDs in batch 1: tensor([3806,  839, 3336, 1592, 1861, 3016, 3317, 2400, 2282, 3287, 3000, 3704,
         113,  305, 3617,  196])
Epoch: 3310, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3311 - Batch 1 ########################
IDs in batch 1: tensor([4078, 3581, 3888, 1524, 1981, 2329, 2349, 3441, 3253,  944, 1296, 3940,
        4011, 2154,  892, 2511])
Epoch: 3311, Training Loss: 0.72, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3312 - Batch 1 ########################
IDs in batch 1: tensor([2885, 1408, 3634, 3557, 3771,  121,  343, 2663, 1532, 2261, 3975, 2316,
        2540, 1632, 3368, 3862])
Epoch: 3312, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3313 - Batch 1 ########################
IDs in batch 1: tensor([1976,  919,  721, 2867, 4014, 3439, 4017, 1975, 2925,  287, 2405, 2796,
        3506, 1452, 2636, 1429])
Epoch: 3313, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3314 - Batch 1 ########################
IDs in batch 1: tensor([ 188, 3920,  995, 3379, 2102, 3587, 1056, 2659,  354,  358, 2538, 2695,
        1852,  891, 1841, 3467])
Epoch: 3314, Training Loss: 0.18, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3315 - Batch 1 ########################
IDs in batch 1: tensor([3535,  337, 4143,  165, 1170, 2568, 1704, 3837,  849, 2337, 1630, 1747,
        3956, 2400, 2332,  317])
Epoch: 3315, Training Loss: 0.23, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3316 - Batch 1 ########################
IDs in batch 1: tensor([1789, 1182,  205, 1226, 1882,  593, 2739, 1755, 3199,  346, 3838,   39,
        2729, 2149, 2468,  312])
Epoch: 3316, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3317 - Batch 1 ########################
IDs in batch 1: tensor([2450, 2198,  770, 1232,  129, 1004,  725, 2489, 1576, 1658, 3226, 3876,
        2117,  739, 2176, 3162])
Epoch: 3317, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3318 - Batch 1 ########################
IDs in batch 1: tensor([ 481, 1263, 3531, 2856,  202,  693,  128,  879, 1562, 2262, 3385, 2046,
        3982, 4194, 2829,   84])
Epoch: 3318, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3319 - Batch 1 ########################
IDs in batch 1: tensor([ 967,  645, 2015, 1634,  909,  300, 1624, 2690, 1322, 3475, 4148, 4236,
        3980,  688,  462, 2377])
Epoch: 3319, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3320 - Batch 1 ########################
IDs in batch 1: tensor([3387, 2688, 1113,  382,  713, 3486, 1730, 2858, 1740, 2189, 1402, 3002,
        1361,  277, 1297,  606])
Epoch: 3320, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3321 - Batch 1 ########################
IDs in batch 1: tensor([3636, 4065, 1256,  623, 1811, 2695, 3785, 1682, 3781, 2173, 2919,   50,
        1223, 1501, 1824, 2449])
Epoch: 3321, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3322 - Batch 1 ########################
IDs in batch 1: tensor([2009,  361, 1693, 2023, 1055,  544, 2595, 1214, 3505,  537,   84, 2195,
        3972, 4075, 2387,  884])
Epoch: 3322, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3323 - Batch 1 ########################
IDs in batch 1: tensor([1093, 3182, 1651, 3356, 3714, 2418, 3148, 3765, 3358,  171, 3448, 1901,
        2444, 3925, 2907, 3018])
Epoch: 3323, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3324 - Batch 1 ########################
IDs in batch 1: tensor([4149, 1448, 3098,  673, 4222, 4234, 1456,  280, 1310, 4199, 1016, 3945,
        2206, 2968, 3940, 3344])
Epoch: 3324, Training Loss: 0.33, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3325 - Batch 1 ########################
IDs in batch 1: tensor([3866, 2195,  305, 2225, 2181, 3130, 2113, 4067, 4040, 1646, 2442, 4005,
        1050, 1678, 1991, 1860])
Epoch: 3325, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3326 - Batch 1 ########################
IDs in batch 1: tensor([2322, 3284, 2590, 1770, 1886,  752, 1454, 2046, 1647, 1107, 3726, 4051,
        2148,  851, 1436, 2749])
Epoch: 3326, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3327 - Batch 1 ########################
IDs in batch 1: tensor([2401, 3698, 1793, 2740,  155, 1396, 2886, 1894,  122, 2176,  334, 2676,
        2752, 2258, 3680,  190])
Epoch: 3327, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3328 - Batch 1 ########################
IDs in batch 1: tensor([ 269, 2291, 1883, 1968, 4149, 2070, 3349, 4181, 1950,  194,  723, 4246,
         430, 3290, 2050, 3337])
Epoch: 3328, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3329 - Batch 1 ########################
IDs in batch 1: tensor([3683, 2183, 4008, 3567,  970, 3858, 3627, 2562, 2595, 1409, 3859, 2879,
        1478,  376, 3598, 3143])
Epoch: 3329, Training Loss: 0.65, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3330 - Batch 1 ########################
IDs in batch 1: tensor([ 666, 3434, 3406, 1711,  387, 2726, 1736, 1670,  245, 3615,  884, 1005,
        3963, 2373, 1772, 3713])
Epoch: 3330, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3331 - Batch 1 ########################
IDs in batch 1: tensor([  72, 3652, 3157, 3415,  113, 1273, 2286, 3535, 4218, 1356, 3588, 3960,
        3458,  941, 2858, 1671])
Epoch: 3331, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3332 - Batch 1 ########################
IDs in batch 1: tensor([3049,  566, 1055, 4030, 1975, 4084,  321, 3529, 4139, 3850, 1949, 1312,
         512, 3197,  896,  494])
Epoch: 3332, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3333 - Batch 1 ########################
IDs in batch 1: tensor([4116, 3014,  219, 3440, 2590, 2476, 3199, 2891, 1748, 3250,  971, 1663,
        1069, 3058, 1857, 3660])
Epoch: 3333, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3334 - Batch 1 ########################
IDs in batch 1: tensor([ 476, 4165, 3583, 2107, 3904, 1625,   41,  384, 2536, 2179, 1895, 3458,
        4057,  966, 2919, 2338])
Epoch: 3334, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3335 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 2258,  340, 2199, 3693, 1835,  344, 3821, 2429, 4222, 2542,  666,
         440,  785,  171,  950])
Epoch: 3335, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3336 - Batch 1 ########################
IDs in batch 1: tensor([ 320, 2678, 1923, 1808, 3079, 3192, 2377, 1764, 3962, 2597, 4230,  544,
        4099,  284, 1237, 1389])
Epoch: 3336, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3337 - Batch 1 ########################
IDs in batch 1: tensor([ 154, 2479,  837, 1056, 1925, 1089, 2841, 1325, 1086,  343,  815, 3344,
        2915, 1778, 3124, 3397])
Epoch: 3337, Training Loss: 0.38, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3338 - Batch 1 ########################
IDs in batch 1: tensor([2250,  350, 2052,  100, 1563, 2780, 3264, 3717,  342, 3208, 1399, 1376,
           7, 3891, 2542, 3023])
Epoch: 3338, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3339 - Batch 1 ########################
IDs in batch 1: tensor([2703, 2264,  884,  615, 2648,  835, 1028, 1646, 1482, 4175,  635, 3581,
        3429,  419,  727, 2255])
Epoch: 3339, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3340 - Batch 1 ########################
IDs in batch 1: tensor([3545, 3490, 2951, 1563,  476, 4125, 1239,  642, 1752,  452, 4103,  918,
        1236, 3771, 3252,  287])
Epoch: 3340, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3341 - Batch 1 ########################
IDs in batch 1: tensor([1986, 2597, 3597, 4194,  991, 1376, 2414,  417, 4175, 3468, 2210, 1121,
        3667, 1429, 1965,  476])
Epoch: 3341, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3342 - Batch 1 ########################
IDs in batch 1: tensor([1369, 2606, 2038, 4152, 3414,   25, 4110, 4003, 1754, 3589, 1845, 4267,
        2629, 2945, 2244, 1175])
Epoch: 3342, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3343 - Batch 1 ########################
IDs in batch 1: tensor([2285,  263, 1050, 3698, 4061, 1317, 3587, 2986,   21, 3712, 1931, 3490,
        2730,  368, 4088, 1623])
Epoch: 3343, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3344 - Batch 1 ########################
IDs in batch 1: tensor([1501, 1975,  167, 4180, 3534,  188, 3490, 1799, 2784, 4230, 2924, 3363,
        2582,  959, 3601, 2097])
Epoch: 3344, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3345 - Batch 1 ########################
IDs in batch 1: tensor([2643, 3030, 1623, 1053,  965, 2574, 3323, 1214,  438, 1385, 2237, 3372,
         601, 1299, 2723, 3463])
Epoch: 3345, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3346 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 3496, 2824,  787, 1470, 3265, 1005,  623, 3094, 4002, 2793, 1272,
        3972, 3570, 4095, 1821])
Epoch: 3346, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3347 - Batch 1 ########################
IDs in batch 1: tensor([2154,  295, 1059, 2092, 4024,  766, 2433, 2710, 2479, 2835, 2117, 2497,
        2826,  718, 2927, 2377])
Epoch: 3347, Training Loss: 0.52, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3348 - Batch 1 ########################
IDs in batch 1: tensor([4128,  357, 3675, 2736,  494,  262, 2367, 2653, 2960, 2199, 1613,  439,
         636, 3102,  514, 2443])
Epoch: 3348, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3349 - Batch 1 ########################
IDs in batch 1: tensor([ 685, 2510, 3704, 2670, 3999, 1244, 1660, 1677, 2842,  991, 1868, 3729,
         262, 2309, 3223,  709])
Epoch: 3349, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3350 - Batch 1 ########################
IDs in batch 1: tensor([ 601,  323, 3017, 3994, 1331,  182, 2344, 4257, 2225, 1073, 2359, 1176,
        3443, 1170, 3518,  829])
Epoch: 3350, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3351 - Batch 1 ########################
IDs in batch 1: tensor([2542, 3744, 3999,  261,  645, 3327,  575, 4217, 4190, 1330, 4085, 2749,
         554, 1331, 3767, 2477])
Epoch: 3351, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3352 - Batch 1 ########################
IDs in batch 1: tensor([4125, 1720, 3807, 2978,  997, 4072, 1248, 3548, 1646, 2600, 1178, 3448,
        3856,  395, 2362, 3564])
Epoch: 3352, Training Loss: 0.28, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3353 - Batch 1 ########################
IDs in batch 1: tensor([1174, 2290, 2737, 1597,  255, 2871, 3469, 1043, 2316, 2727, 4143,  191,
        3030,  352,  487,  213])
Epoch: 3353, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3354 - Batch 1 ########################
IDs in batch 1: tensor([3632,  281, 1472,  897, 1999, 1500, 3148,   78, 3917, 2858,   31, 1377,
        2967, 2510, 4134,  851])
Epoch: 3354, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3355 - Batch 1 ########################
IDs in batch 1: tensor([2185, 1248,   28, 2287, 3934, 2493, 2064, 3513, 1389, 3378,  725,  165,
        3118, 1923, 1182, 2924])
Epoch: 3355, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3356 - Batch 1 ########################
IDs in batch 1: tensor([4215, 1371, 1032,  150,  674, 2782,  964, 2592, 2783,  963, 1707, 2455,
        3993, 1107,  523, 3981])
Epoch: 3356, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3357 - Batch 1 ########################
IDs in batch 1: tensor([1274, 3548, 3509, 1794, 2180, 2497, 2167,  974,   46,  590, 2226, 2137,
        2155, 1575, 3954, 3651])
Epoch: 3357, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3358 - Batch 1 ########################
IDs in batch 1: tensor([3895, 2207, 2721, 2114,  105, 1341, 4188, 3397, 4048, 3143, 3271, 1798,
         257,   86, 1406, 3668])
Epoch: 3358, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3359 - Batch 1 ########################
IDs in batch 1: tensor([3161, 3479, 3582,  520, 3743, 2856, 1237, 2899, 3029, 2709, 1786, 1328,
         324, 3531,   78, 1037])
Epoch: 3359, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3360 - Batch 1 ########################
IDs in batch 1: tensor([1171, 2281, 2176, 3386,  568, 3366, 3992, 2894, 3728,  556,  135, 2723,
        1088, 2487, 3744, 3053])
Epoch: 3360, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3361 - Batch 1 ########################
IDs in batch 1: tensor([ 605, 2202, 2828, 1451, 2436, 2299,  818, 3432, 3060, 1833,  854, 2313,
        1868, 4218, 3503, 2519])
Epoch: 3361, Training Loss: 0.34, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3362 - Batch 1 ########################
IDs in batch 1: tensor([1052, 3797, 2282, 2476, 2190,  577, 3718,  373, 3208, 4115, 3052, 2450,
         255,  154, 2614, 1540])
Epoch: 3362, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3363 - Batch 1 ########################
IDs in batch 1: tensor([3638, 4154,   96, 2802, 1133, 3547, 3652, 1409,  970,  897, 2298, 3660,
        1025, 1724, 1197, 2425])
Epoch: 3363, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3364 - Batch 1 ########################
IDs in batch 1: tensor([3863, 2344, 4006, 4038, 1686,  492,  394, 3930, 3339, 1247, 1052, 2036,
        3330, 2437,  774, 3382])
Epoch: 3364, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3365 - Batch 1 ########################
IDs in batch 1: tensor([3533, 4198, 3541, 2550,  470, 1519, 1097, 3352, 2087, 1179, 1322,  727,
        2246, 3989, 2825, 3865])
Epoch: 3365, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3366 - Batch 1 ########################
IDs in batch 1: tensor([2477, 2198, 1861,  918, 3617, 4070, 1208,  895, 3711, 3637, 1140,  968,
        2800, 2078, 2306, 3065])
Epoch: 3366, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3367 - Batch 1 ########################
IDs in batch 1: tensor([3871,  101, 2479,  295,  713, 1279, 1686,  165, 3246, 2440, 2449, 1640,
         893,  824, 4084,  262])
Epoch: 3367, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3368 - Batch 1 ########################
IDs in batch 1: tensor([3961, 3309,  355, 3541, 2666, 3624, 4100, 4213,  609, 4189, 3338, 2719,
        3745,   73, 1242,  795])
Epoch: 3368, Training Loss: 0.37, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3369 - Batch 1 ########################
IDs in batch 1: tensor([ 969,  203, 2621, 3334,  684, 3193, 3092, 2563,  295,  694, 4179,   31,
        4152, 2789, 1830, 1090])
Epoch: 3369, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3370 - Batch 1 ########################
IDs in batch 1: tensor([3330,  565, 2256, 1073, 3362,  653, 4214, 1471, 2708, 1370,  917, 3747,
         137, 1273, 3505,  665])
Epoch: 3370, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3371 - Batch 1 ########################
IDs in batch 1: tensor([2706,  342, 2316, 1464, 3669, 1026, 3321,   37, 2990, 1870, 3382, 3876,
          37, 1132, 1256, 4037])
Epoch: 3371, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3372 - Batch 1 ########################
IDs in batch 1: tensor([2254, 1958, 2014, 2695, 1764, 2203,  411,  688, 1720,  430,  538,  363,
         658, 1506,  855, 2957])
Epoch: 3372, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3373 - Batch 1 ########################
IDs in batch 1: tensor([2718, 1011, 3926,  683,  276, 2246, 3362,  957, 1682, 3081, 3938, 2690,
        1220, 4156, 1945, 1963])
Epoch: 3373, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3374 - Batch 1 ########################
IDs in batch 1: tensor([ 733, 2331,  876, 3017,  739, 3381, 1225,  610, 2432, 3739,  527, 2228,
         613, 3558,  149, 1833])
Epoch: 3374, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3375 - Batch 1 ########################
IDs in batch 1: tensor([3878, 3367, 3265, 1260, 3002,  762, 4136, 1016,  966, 1517,  770, 4060,
        3749,  184, 2258,   18])
Epoch: 3375, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3376 - Batch 1 ########################
IDs in batch 1: tensor([4134, 2108, 2678, 3549, 3183, 1728,  554, 4242, 3030, 1727, 3673,  199,
         805, 3101, 1174, 3886])
Epoch: 3376, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3377 - Batch 1 ########################
IDs in batch 1: tensor([ 730, 3418,  953,  378,  324, 3395, 1231, 3492,   88,  244,  503, 3738,
         161, 4189, 3298, 2450])
Epoch: 3377, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3378 - Batch 1 ########################
IDs in batch 1: tensor([ 218, 1251,  394, 3339, 2727, 2439, 4026, 3688, 1222, 4266, 1355, 1480,
        2793,  127, 3023, 4116])
Epoch: 3378, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3379 - Batch 1 ########################
IDs in batch 1: tensor([1646, 1707, 1540,  825, 2692, 2419,  572,  337, 4096,  245, 4176, 1824,
        4000,  714,  908, 1346])
Epoch: 3379, Training Loss: 0.44, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3380 - Batch 1 ########################
IDs in batch 1: tensor([2567, 2823, 3509, 1670,  141,  426, 1954,  688, 3180, 3496,  454,  573,
        1685, 1274, 1555,  471])
Epoch: 3380, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3381 - Batch 1 ########################
IDs in batch 1: tensor([3221, 3795, 1600, 4251, 2776,  626, 2578,  679, 3452, 1782, 2478, 3246,
        3843,  992, 1712, 3143])
Epoch: 3381, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3382 - Batch 1 ########################
IDs in batch 1: tensor([3002,  980, 2391, 3132,  402, 3114, 2245, 4226,  405, 2860, 2189, 3499,
        3355, 3599, 2555, 1034])
Epoch: 3382, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3383 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 2151, 1849, 2355, 2646,  733,  893, 3371, 1761,  275,  359,  852,
        4251, 4253, 2739, 2412])
Epoch: 3383, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3384 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 4258, 3032, 3921, 1677, 1133, 1763, 3472, 1035, 2764,  181, 1595,
        2727, 2475,  531, 1308])
Epoch: 3384, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3385 - Batch 1 ########################
IDs in batch 1: tensor([2620,  902, 3355, 2758, 2776,  369, 1641, 4246, 1763, 2045, 2648, 4035,
        3570, 3490, 3617, 1404])
Epoch: 3385, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3386 - Batch 1 ########################
IDs in batch 1: tensor([2018, 1051, 2181, 1707, 3370, 2826, 3202, 3632, 3265, 2238,  771,   19,
        3696,  541, 2377,  287])
Epoch: 3386, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3387 - Batch 1 ########################
IDs in batch 1: tensor([2143, 3221, 4217, 1747, 4158, 1778,  350, 2954, 3016, 4067,  303,  226,
        1665, 3308, 1445, 2927])
Epoch: 3387, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3388 - Batch 1 ########################
IDs in batch 1: tensor([ 132, 3926, 2681, 3505, 1948, 2668, 1404, 1132, 2926,  357,  777, 1370,
         476, 4179, 1686, 3452])
Epoch: 3388, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3389 - Batch 1 ########################
IDs in batch 1: tensor([3304, 2966, 2368, 1632,  556, 1039, 4258, 1543, 1870, 1020, 3672, 2355,
        2026, 3217, 1802, 1782])
Epoch: 3389, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3390 - Batch 1 ########################
IDs in batch 1: tensor([ 656, 3573, 3470, 1467, 1953, 1497, 2973, 1232, 1349,    5, 2236,  788,
        3882, 3717,  390, 1025])
Epoch: 3390, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3391 - Batch 1 ########################
IDs in batch 1: tensor([1704, 1519, 3921, 3772, 1364, 3846, 1883, 3837, 4003,  934, 2149,  445,
        3227, 1863, 1869, 4107])
Epoch: 3391, Training Loss: 0.48, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3392 - Batch 1 ########################
IDs in batch 1: tensor([ 373, 4088, 4004, 3932,  315, 1087, 1862, 3604,  790, 2278, 4080, 3356,
        4223,  415, 2226, 3532])
Epoch: 3392, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3393 - Batch 1 ########################
IDs in batch 1: tensor([ 605, 2907, 1026,  356, 1511, 3674, 3058, 3902, 1754, 1380, 3812, 1630,
        3466, 1602, 2638,  919])
Epoch: 3393, Training Loss: 0.39, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3394 - Batch 1 ########################
IDs in batch 1: tensor([2314, 3636, 2193,  475,  876, 2845, 2317,  857, 3020, 3587, 1980, 3764,
         565,  914, 1360, 2892])
Epoch: 3394, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3395 - Batch 1 ########################
IDs in batch 1: tensor([3671, 2932, 2780, 1108, 1008, 3932, 1297, 4004, 2620, 4011, 1751, 2914,
        3940, 2537, 1297, 1108])
Epoch: 3395, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3396 - Batch 1 ########################
IDs in batch 1: tensor([ 969,  652, 3834, 2386, 1617, 2195,  913, 4143,  591, 2791, 1480, 1010,
        1283, 2081, 1456,  128])
Epoch: 3396, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3397 - Batch 1 ########################
IDs in batch 1: tensor([3942, 2323, 1393, 3787, 2144, 3527, 3823, 1331,  481, 3179, 4266,  739,
        2664,  498, 3468,  430])
Epoch: 3397, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3398 - Batch 1 ########################
IDs in batch 1: tensor([3375, 2383, 1937, 1354,  343,  302, 1455, 2536, 1291,  165, 4065, 1415,
         402, 3471, 2190, 3194])
Epoch: 3398, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3399 - Batch 1 ########################
IDs in batch 1: tensor([1467, 1052, 3484,  104, 2823,  813, 3943, 2824,  985,  187, 1173, 3176,
         317, 4140, 2284, 2156])
Epoch: 3399, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3400 - Batch 1 ########################
IDs in batch 1: tensor([ 508, 2823,  786, 3876, 2869, 2536, 3236, 2236, 2693, 4003, 3707, 2487,
         172, 4218, 3530, 1228])
Epoch: 3400, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3401 - Batch 1 ########################
IDs in batch 1: tensor([4050, 2645, 1311,  503, 3812, 1555,  424, 2185, 1444, 3882, 1271, 1005,
        2828, 1588, 3939, 2236])
Epoch: 3401, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3402 - Batch 1 ########################
IDs in batch 1: tensor([1732, 1973,  395, 1032, 2542, 2646, 1367, 1451, 2926,  149,  520, 2733,
        1977, 4119, 2976, 2516])
Epoch: 3402, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3403 - Batch 1 ########################
IDs in batch 1: tensor([ 601, 3283, 1236, 4152, 1014,  983, 3044,  747, 1228,  125,  258, 3630,
        3312, 1546,  871,   35])
Epoch: 3403, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3404 - Batch 1 ########################
IDs in batch 1: tensor([1098, 3829, 3993, 1953, 1374, 3398, 3594, 1084,  359, 2912, 2591, 1851,
        2754, 3015, 1764, 1311])
Epoch: 3404, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3405 - Batch 1 ########################
IDs in batch 1: tensor([2387, 2370, 3850, 2887, 2653, 1076, 3317, 1878, 3409,  526, 3792,  327,
        4114, 2011, 3372, 1957])
Epoch: 3405, Training Loss: 0.60, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3406 - Batch 1 ########################
IDs in batch 1: tensor([3505,  732, 1260, 2073, 3156, 1772, 4046, 4072, 2641, 2237, 3726, 3056,
        2484, 2719, 1574, 1442])
Epoch: 3406, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3407 - Batch 1 ########################
IDs in batch 1: tensor([2706, 1881,  663, 1953,  986, 2034, 2337, 1290, 2564, 1147, 3131, 1020,
        2644,  488, 3609, 2921])
Epoch: 3407, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3408 - Batch 1 ########################
IDs in batch 1: tensor([ 813,  338, 1668, 1134, 1027,  805, 1132, 3176, 1226,  887,  314,  894,
        3162,  207, 2429,  826])
Epoch: 3408, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3409 - Batch 1 ########################
IDs in batch 1: tensor([1281,  358,  312, 1780, 1228,  725, 2969, 1271,  341,   68,  139,  788,
        1599, 2731, 3056, 3029])
Epoch: 3409, Training Loss: 0.30, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3410 - Batch 1 ########################
IDs in batch 1: tensor([ 488, 2603,  539,  101, 1143, 1069, 2416, 1627, 2447,   71, 2412, 2581,
        1756, 1285,  767, 3486])
Epoch: 3410, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3411 - Batch 1 ########################
IDs in batch 1: tensor([2776,  537,  974,  827, 1057, 2461, 1340, 1610,  741,  645, 2526, 1379,
         131,  837, 1498,  489])
Epoch: 3411, Training Loss: 0.31, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3412 - Batch 1 ########################
IDs in batch 1: tensor([ 773, 3568,  187, 2627,  826, 1373, 4009,  550, 2674, 3473, 2461,   81,
        1067, 2352, 1234, 2646])
Epoch: 3412, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3413 - Batch 1 ########################
IDs in batch 1: tensor([3658,  491, 3156, 1138, 2038, 2212,  255, 3204, 3663, 3471, 3765, 1773,
        1611, 1517,  186, 1493])
Epoch: 3413, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3414 - Batch 1 ########################
IDs in batch 1: tensor([ 941,  527,  445,  129, 2518, 1880,  988, 1835,  637, 1218, 3196,  980,
        2897, 2640, 3742, 2986])
Epoch: 3414, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3415 - Batch 1 ########################
IDs in batch 1: tensor([1605, 2257,  691, 2618, 2358, 3304,  644, 1017, 3821, 3523,  910, 3060,
        1798, 1331, 1545,  398])
Epoch: 3415, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3416 - Batch 1 ########################
IDs in batch 1: tensor([ 170, 3355,  910, 2399, 2745,  766, 4196, 3486, 2825, 3637, 3898,  676,
        1020, 2729, 3475, 3936])
Epoch: 3416, Training Loss: 0.29, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3417 - Batch 1 ########################
IDs in batch 1: tensor([2123, 3767, 1181, 4002, 3742, 1525, 2375,  627, 1747, 1113, 1623, 2463,
         171,  837,  689, 1601])
Epoch: 3417, Training Loss: 0.32, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3418 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 3830, 2343, 4010, 3220, 1369, 1023,  194, 3603, 3154, 2408, 2473,
         803, 2419, 1322, 2169])
Epoch: 3418, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3419 - Batch 1 ########################
IDs in batch 1: tensor([2791, 1580, 2741, 1138, 2258, 1851, 3306, 1934,  558, 2272, 1344,  828,
        2135, 1409, 1623, 3638])
Epoch: 3419, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3420 - Batch 1 ########################
IDs in batch 1: tensor([2616,  135,  816, 2362, 4242, 1793,  554,   99, 1644, 1942, 3242, 1089,
        2829,  857,  612, 2606])
Epoch: 3420, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3421 - Batch 1 ########################
IDs in batch 1: tensor([ 628, 1420, 3604, 2461, 2285, 1092, 4030, 3822,  980, 3928, 1456,  305,
        2934, 3094, 3147,   99])
Epoch: 3421, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3422 - Batch 1 ########################
IDs in batch 1: tensor([4188, 3870, 1325, 3891,  721, 4234, 1545,  588, 3286, 2348, 1733, 2667,
        4038, 3051,   84, 2993])
Epoch: 3422, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3423 - Batch 1 ########################
IDs in batch 1: tensor([2295, 2492, 2399, 3376, 3250, 1984, 2429, 1736, 3841, 1459, 1061, 3885,
        1471, 3479, 3399, 3865])
Epoch: 3423, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3424 - Batch 1 ########################
IDs in batch 1: tensor([3545,  961, 3088, 2137, 3609, 2305, 4230, 2143,  259,  928,  232,  110,
        3719, 3238,  211,  577])
Epoch: 3424, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3425 - Batch 1 ########################
IDs in batch 1: tensor([2241, 3878, 3479, 3357, 2863, 4205, 3468, 3507, 1495, 1031, 3681,  727,
        2090, 3468, 2872, 2584])
Epoch: 3425, Training Loss: 0.34, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3426 - Batch 1 ########################
IDs in batch 1: tensor([ 159, 2609, 3441, 3136, 2787, 4251, 2693, 2845,  884, 1781, 3636,  513,
        3983,  113, 2542, 1990])
Epoch: 3426, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3427 - Batch 1 ########################
IDs in batch 1: tensor([1310,  956, 3487,  687, 2236, 2951,  478, 2537, 3610,  372, 3181, 2595,
         171, 3069, 2656, 1294])
Epoch: 3427, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3428 - Batch 1 ########################
IDs in batch 1: tensor([2938, 1354,   10, 2097,  516, 3935, 3286,  418, 1116, 2013, 2375,  375,
        2182, 1526, 2725,  820])
Epoch: 3428, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3429 - Batch 1 ########################
IDs in batch 1: tensor([2520, 1655, 3621, 3052, 2956, 2804, 1239, 1120, 1994, 2968,  415, 2260,
        1321, 3898,   10, 1163])
Epoch: 3429, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3430 - Batch 1 ########################
IDs in batch 1: tensor([1093, 1121, 3021, 2899, 1657, 2443, 4240,  992, 2412, 3310,  177, 2195,
        2295, 1605,  899,  910])
Epoch: 3430, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3431 - Batch 1 ########################
IDs in batch 1: tensor([  84,  546, 4232, 3434, 2660, 4084,  269, 1402, 1108, 3206, 1840, 4096,
        2539, 4181,  936, 2984])
Epoch: 3431, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3432 - Batch 1 ########################
IDs in batch 1: tensor([1646, 2274,  342, 4013,   35, 3537, 1285, 3143, 4110, 2151, 2763, 2031,
        4174, 3479, 3834, 2947])
Epoch: 3432, Training Loss: 0.40, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3433 - Batch 1 ########################
IDs in batch 1: tensor([ 362, 3226, 1604, 3133, 2540, 2724, 2372, 1755, 1282,  910, 3710, 3006,
        2301,  190, 1490,  393])
Epoch: 3433, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3434 - Batch 1 ########################
IDs in batch 1: tensor([2620, 4037,  503, 1590, 2225,  345, 3667,  407, 2510, 2797, 1004, 3513,
         496, 3925, 3261, 3928])
Epoch: 3434, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3435 - Batch 1 ########################
IDs in batch 1: tensor([2137, 1170, 3500, 4077,  659, 3802, 2754, 2154, 4146,  741, 3242, 1600,
        3731, 1961, 3124,  726])
Epoch: 3435, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3436 - Batch 1 ########################
IDs in batch 1: tensor([3485, 3460, 1780,  897, 2915, 4095, 2403, 1980, 1632, 3740, 2860, 1073,
        1647, 3087, 1994,  121])
Epoch: 3436, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3437 - Batch 1 ########################
IDs in batch 1: tensor([1241, 1910,  317, 4189, 3564, 1425, 3846, 3074,  975, 4010,  534, 4255,
        4224, 1518, 3732, 4240])
Epoch: 3437, Training Loss: 0.37, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3438 - Batch 1 ########################
IDs in batch 1: tensor([2441,  823, 1793, 3406, 1155, 3146, 1117,  850, 2959, 1003, 3304, 1256,
        3390, 3073, 4094,  751])
Epoch: 3438, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3439 - Batch 1 ########################
IDs in batch 1: tensor([3000,   61,  360, 1049, 1726, 3765, 3146,  555, 4016,  287, 3988, 3378,
        2328, 1092,  809, 4000])
Epoch: 3439, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3440 - Batch 1 ########################
IDs in batch 1: tensor([4144, 2590, 2452, 1644,  435, 3083, 1720,  721, 3621, 2038,  620, 3838,
        1218, 3987, 2126, 1604])
Epoch: 3440, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3441 - Batch 1 ########################
IDs in batch 1: tensor([3456,  514,   62, 2884, 3385,  384, 1434, 2275, 2217, 1057, 1138, 3368,
        1633,  103, 4013, 2743])
Epoch: 3441, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3442 - Batch 1 ########################
IDs in batch 1: tensor([2141, 1793, 3593,  813,  881,  427, 1134,  152, 3055,  121, 3830,  494,
        1911, 2499, 2621,  121])
Epoch: 3442, Training Loss: 0.24, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3443 - Batch 1 ########################
IDs in batch 1: tensor([3554, 1828, 3635,   73, 2873,  699, 1219, 1325,  387, 1975, 2690, 2783,
        3616, 2586, 2284, 1086])
Epoch: 3443, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3444 - Batch 1 ########################
IDs in batch 1: tensor([ 396, 4172, 2371, 1866, 1842, 2142, 3434, 2414, 1467, 3601, 4136, 3832,
        3975, 3000, 2810,  196])
Epoch: 3444, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3445 - Batch 1 ########################
IDs in batch 1: tensor([1290, 2429, 1050,  566,  425,  689, 4089,  496, 2173, 3962, 1883,  137,
        2908, 3032, 2223, 1322])
Epoch: 3445, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3446 - Batch 1 ########################
IDs in batch 1: tensor([2400, 2631,  395, 3506, 1399, 1437, 4000, 1229, 1132, 1171, 1594, 2367,
        1410, 1570,  967,  713])
Epoch: 3446, Training Loss: 0.33, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3447 - Batch 1 ########################
IDs in batch 1: tensor([2646,  165,  878, 1950, 3016, 4218, 3992, 3246, 1386,  960, 3615, 1341,
        3913, 4115, 1457, 4127])
Epoch: 3447, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3448 - Batch 1 ########################
IDs in batch 1: tensor([ 976, 3981, 2711, 3655, 2418, 1045,  323,  537,  122,  363, 3996,  813,
        1944,  117, 2046, 3014])
Epoch: 3448, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3449 - Batch 1 ########################
IDs in batch 1: tensor([3327,  303, 2674,  684,  454, 2605,  704, 1471,  314, 1296,  832,   14,
        4165,  788, 4186, 2891])
Epoch: 3449, Training Loss: 0.24, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3450 - Batch 1 ########################
IDs in batch 1: tensor([4012,  322, 2305, 2842, 3000, 3729, 1809,  517,  565, 2804, 3440, 1861,
        4038, 4099, 1063, 3374])
Epoch: 3450, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3451 - Batch 1 ########################
IDs in batch 1: tensor([ 823, 2536, 2151,  422, 1545,  659, 2907, 2965, 3287, 2306,  514, 3453,
        2959, 1770,   15, 2309])
Epoch: 3451, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3452 - Batch 1 ########################
IDs in batch 1: tensor([ 685,  886, 1540, 2822, 2002, 1009, 2121,  211, 3987,  335, 1634,  879,
        2767, 3466, 2667, 3876])
Epoch: 3452, Training Loss: 0.03, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3453 - Batch 1 ########################
IDs in batch 1: tensor([1899, 3656, 2161, 4166, 2504,  996, 4230,  323, 3278, 2577, 2995, 2669,
        2419, 3717,  513, 2734])
Epoch: 3453, Training Loss: 0.12, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3454 - Batch 1 ########################
IDs in batch 1: tensor([1399, 1826, 1932, 3432, 2738, 1480, 2248, 4040, 2431, 1670, 1347,  352,
         195, 3039, 2002, 4097])
Epoch: 3454, Training Loss: 0.13, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3455 - Batch 1 ########################
IDs in batch 1: tensor([3989, 4251,  934,  775,  332, 4159, 2839, 1810, 3786, 1679,  510,  753,
         519,  732, 3663, 3415])
Epoch: 3455, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3456 - Batch 1 ########################
IDs in batch 1: tensor([ 887, 3373, 2327, 1369,  924,  507,  970, 1383, 3470,  930, 1596, 3352,
        4253,  545, 2080,  694])
Epoch: 3456, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3457 - Batch 1 ########################
IDs in batch 1: tensor([2097, 2606, 2236, 3136, 3443, 2005,  967, 3218,  661, 1760, 1237, 3547,
        3505, 1372, 1060,  252])
Epoch: 3457, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3458 - Batch 1 ########################
IDs in batch 1: tensor([1025, 1231, 3866, 2661, 4070, 3727, 3394, 2368,  430, 3308, 1086, 1264,
        1504,  257,  265, 2636])
Epoch: 3458, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3459 - Batch 1 ########################
IDs in batch 1: tensor([2761, 1580, 3119, 1175, 1821, 1060, 3992, 4051, 2423, 1231, 4072, 2275,
        2386, 2495,   88, 2133])
Epoch: 3459, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3460 - Batch 1 ########################
IDs in batch 1: tensor([  43, 1049, 2282, 3760, 2343, 3132, 2331, 2544,  165,  662,  399, 1008,
        2856, 3524,  769,  497])
Epoch: 3460, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3461 - Batch 1 ########################
IDs in batch 1: tensor([3139, 3282, 2940,   92, 3732,  415, 3439, 1043, 3701, 2236, 4000, 1685,
        2304, 4031, 4184, 1432])
Epoch: 3461, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3462 - Batch 1 ########################
IDs in batch 1: tensor([3254, 1832, 1789, 3567, 1975, 1706, 1551, 2780, 2040, 2476, 2036, 1965,
         121, 3714, 3985,  355])
Epoch: 3462, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3463 - Batch 1 ########################
IDs in batch 1: tensor([1049, 1419,  247, 2950, 1668, 1383, 3898, 2183, 1140, 3394, 2118, 3127,
         427,  245, 1955, 3455])
Epoch: 3463, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3464 - Batch 1 ########################
IDs in batch 1: tensor([ 121,  226, 1722, 2099, 1349, 2771, 3461, 3458, 3049, 3793,  440, 1698,
         137,  610,  827, 3551])
Epoch: 3464, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3465 - Batch 1 ########################
IDs in batch 1: tensor([3939,  792, 2094, 3661, 2017, 3971, 3813,  203,  306, 3783, 2883, 1032,
        3196, 3328,   73,  277])
Epoch: 3465, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3466 - Batch 1 ########################
IDs in batch 1: tensor([3328, 2695, 1346,  584, 2982, 2104, 3352, 2229, 2120, 3490, 1277,  186,
        3994, 2326, 2578, 2118])
Epoch: 3466, Training Loss: 0.35, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3467 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 4258, 2663, 1014, 3984,  181,  789, 2097, 2899, 3843, 2700,  747,
        2467,   14,  113,  105])
Epoch: 3467, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3468 - Batch 1 ########################
IDs in batch 1: tensor([1088,  238, 4075, 4093,  854, 2548, 2495, 3535,  132, 1122, 1968,  660,
        1052, 1228, 2305,  508])
Epoch: 3468, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3469 - Batch 1 ########################
IDs in batch 1: tensor([ 494,  402, 3958, 2496, 1051, 2538, 2018,   49, 2521,  827, 3765, 2688,
        2343, 3378,  193, 2997])
Epoch: 3469, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3470 - Batch 1 ########################
IDs in batch 1: tensor([2347,    5, 3157, 2898,   56, 1592, 1316, 3091, 3461,  173, 4053, 4121,
        1913, 1521, 3079, 3863])
Epoch: 3470, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3471 - Batch 1 ########################
IDs in batch 1: tensor([  24,  937, 2432, 1532, 2883,  855, 3813, 2334, 3398, 3853, 1222, 1132,
         424, 1128, 2968,  978])
Epoch: 3471, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3472 - Batch 1 ########################
IDs in batch 1: tensor([3360, 1642, 3516, 3866, 2440,  869, 4199, 3425,  261,  717, 3112,  308,
        2595, 2072, 3433, 2398])
Epoch: 3472, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3473 - Batch 1 ########################
IDs in batch 1: tensor([2789, 3802, 1499, 4230, 3423, 3583, 1718, 2365, 1585, 3926,  214, 3475,
        2466, 1257, 3060,  609])
Epoch: 3473, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3474 - Batch 1 ########################
IDs in batch 1: tensor([ 399, 2876,  813, 2433, 3765, 2536, 1900, 1570, 2591, 2177,   51, 1633,
         794, 1364,  604, 3078])
Epoch: 3474, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3475 - Batch 1 ########################
IDs in batch 1: tensor([2159, 3900, 1256, 2023, 4124, 4265, 2429,  105, 1900,   21, 2034, 1087,
        1548, 1509, 2219, 2281])
Epoch: 3475, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3476 - Batch 1 ########################
IDs in batch 1: tensor([2737, 2148, 3250, 4165, 1020, 2069, 1536, 2278, 3092,  713, 3257, 3487,
         522, 1573, 3660, 2540])
Epoch: 3476, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3477 - Batch 1 ########################
IDs in batch 1: tensor([2475, 4184, 1747,  160, 4234, 1223, 3563, 2495, 1841, 4232, 3010, 2649,
        2615, 3463, 2656, 1896])
Epoch: 3477, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3478 - Batch 1 ########################
IDs in batch 1: tensor([1490, 1780,  214,  994, 1039, 3534, 2447,  221, 3426, 4154, 1599,  405,
        1718,  635,  738,  287])
Epoch: 3478, Training Loss: 0.34, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3479 - Batch 1 ########################
IDs in batch 1: tensor([2619, 2053, 2276, 1573, 1406, 1197, 4048, 3570, 2121, 2203, 3640, 4187,
        3503, 2286, 3842,  518])
Epoch: 3479, Training Loss: 0.25, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3480 - Batch 1 ########################
IDs in batch 1: tensor([3509, 2597, 2066,  152, 2997, 4268, 1882, 4107, 2435,  417, 1107, 4163,
        3052, 1497, 2514, 1113])
Epoch: 3480, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3481 - Batch 1 ########################
IDs in batch 1: tensor([3451, 2891, 3456, 3262, 2960, 4073, 2789,  185, 1500, 3969, 2495, 1918,
        3377, 3257,  891, 4174])
Epoch: 3481, Training Loss: 0.64, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3482 - Batch 1 ########################
IDs in batch 1: tensor([1507,  546, 1065,  389, 3328, 2060, 1553, 2523, 3516,  777, 1909, 2827,
        1356, 3994,  325,   31])
Epoch: 3482, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3483 - Batch 1 ########################
IDs in batch 1: tensor([2874, 1686,  758,  913, 1753, 1773,  251, 2742, 1521, 3270, 3706, 4053,
        3822, 2041, 3435, 3643])
Epoch: 3483, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3484 - Batch 1 ########################
IDs in batch 1: tensor([2895, 1951,  155, 1088,  184, 2737,  337,   73, 1163,  736, 2886,  819,
        2591, 2982, 2169, 3787])
Epoch: 3484, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3485 - Batch 1 ########################
IDs in batch 1: tensor([1901, 1264, 2075, 4185, 2238, 3127, 4053, 1223, 1428, 3206, 2195, 4120,
        1979, 1128, 1624, 2180])
Epoch: 3485, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3486 - Batch 1 ########################
IDs in batch 1: tensor([3712, 2097, 1491, 2562,  887, 2998, 2107,  937,  234, 3505,   25, 3935,
        2149, 1900, 2763, 3841])
Epoch: 3486, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3487 - Batch 1 ########################
IDs in batch 1: tensor([1257,  828, 1543, 3996, 2551,  777,  199, 2963,  547, 4141, 2196, 2902,
        1219, 2326, 1787,  595])
Epoch: 3487, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3488 - Batch 1 ########################
IDs in batch 1: tensor([3919, 4265, 2998,   49, 3426, 1826, 3353, 1097,  832, 1756,  813,  727,
         306, 2522, 2508, 2363])
Epoch: 3488, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3489 - Batch 1 ########################
IDs in batch 1: tensor([1089, 1328, 1661, 2656, 1927, 1716, 4179, 2363, 2364, 2574,  572, 3184,
        3492, 4101, 3357, 1931])
Epoch: 3489, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3490 - Batch 1 ########################
IDs in batch 1: tensor([1982, 3364, 3409, 1212, 2309, 2504,  777, 1428,  193, 1080, 1786, 3627,
        1377,  172,  365, 2717])
Epoch: 3490, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3491 - Batch 1 ########################
IDs in batch 1: tensor([1070,   56,  482, 4008, 2009, 3537, 3152, 2338, 3415, 1041, 3987, 2880,
        1884, 1599, 1287, 1961])
Epoch: 3491, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3492 - Batch 1 ########################
IDs in batch 1: tensor([2957, 4254, 1070, 1570, 1878, 2376, 1420, 1344, 1439, 1436,  574,  277,
        3862, 1802, 3248, 2688])
Epoch: 3492, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3493 - Batch 1 ########################
IDs in batch 1: tensor([4266, 3921, 3199, 1623, 2275, 2437, 2415, 3732, 2745,  676, 2205, 2420,
        3306, 1623, 3277, 1110])
Epoch: 3493, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3494 - Batch 1 ########################
IDs in batch 1: tensor([2520, 1825, 2188, 3749, 1935, 3176, 3557,   82, 2710, 2672, 3160, 2883,
        1636, 1500, 1397, 2565])
Epoch: 3494, Training Loss: 0.25, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3495 - Batch 1 ########################
IDs in batch 1: tensor([3112, 3541,  918, 3882, 1395, 2346, 2643,  300, 1891, 1988,  957, 3190,
         790, 1994,  411, 3972])
Epoch: 3495, Training Loss: 0.02, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3496 - Batch 1 ########################
IDs in batch 1: tensor([3051, 3199,  388, 1103, 4158, 3440, 1708, 1409, 3496, 2097, 1585, 1285,
        2437,  997, 2610, 4242])
Epoch: 3496, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3497 - Batch 1 ########################
IDs in batch 1: tensor([4018, 3658, 3518, 2493, 2999,  857,  738, 3024, 1286, 1004,  259,  257,
        3885, 3742, 2477, 4227])
Epoch: 3497, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3498 - Batch 1 ########################
IDs in batch 1: tensor([2370,  355,  727, 2751, 2847,  756,  954,  430, 3406, 1139, 3484, 2013,
        2731, 2279, 3235, 1920])
Epoch: 3498, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3499 - Batch 1 ########################
IDs in batch 1: tensor([1324, 4157, 1632,  852, 3661, 1429, 1670, 4100, 4199, 2977,   18, 1087,
        3810, 1895, 1711,   97])
Epoch: 3499, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3500 - Batch 1 ########################
IDs in batch 1: tensor([1524,  704,  915, 1312,  888,  910, 2357, 1320,  842, 2383,  555, 3664,
         437, 4036, 1663, 1047])
Epoch: 3500, Training Loss: 0.81, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3501 - Batch 1 ########################
IDs in batch 1: tensor([ 491, 2631, 1027, 3676, 2235,  872, 3387, 4263,  547, 1050, 3698, 1200,
        4254, 2322, 1478, 1794])
Epoch: 3501, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3502 - Batch 1 ########################
IDs in batch 1: tensor([1419,  140, 2154,  750, 3592, 4217, 2191,  923, 2620, 2761, 2640,  572,
        3439, 1052, 3290,  726])
Epoch: 3502, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3503 - Batch 1 ########################
IDs in batch 1: tensor([1159, 3485, 3421, 3032, 2452,   18, 3698, 3881, 3823, 2153,  394, 1408,
        2241, 2568, 3185, 4057])
Epoch: 3503, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3504 - Batch 1 ########################
IDs in batch 1: tensor([1090, 3036, 2446,  141, 1183,  987,  964, 1139,  177, 2417, 3812, 1345,
        3463, 1049,  303,   39])
Epoch: 3504, Training Loss: 0.37, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3505 - Batch 1 ########################
IDs in batch 1: tensor([1409, 2134, 3760,  918, 3178, 3126,  289, 3438, 2655, 2484, 1863, 3895,
        3881, 1551,  110,  962])
Epoch: 3505, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3506 - Batch 1 ########################
IDs in batch 1: tensor([3072, 2587, 1645, 2509, 3242, 2957,  773, 2942,  804,  532, 2045, 2777,
        2485, 1032, 1067, 1377])
Epoch: 3506, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3507 - Batch 1 ########################
IDs in batch 1: tensor([ 717, 1833, 1686, 1133, 1526, 3837, 3544, 3459, 4037,  552,  131, 3082,
         155,  419, 2442, 2731])
Epoch: 3507, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3508 - Batch 1 ########################
IDs in batch 1: tensor([4154, 3731, 4232, 1789, 3255, 1200, 2008,  159, 1775, 1171, 3570, 1896,
        1592, 2734, 2464, 1825])
Epoch: 3508, Training Loss: 0.02, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3509 - Batch 1 ########################
IDs in batch 1: tensor([ 448,  236, 1602, 3493, 3493, 3865, 3842, 3982,  138,  362,  244, 2173,
        1596, 3970,   98,   27])
Epoch: 3509, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3510 - Batch 1 ########################
IDs in batch 1: tensor([3204, 2965, 2363, 3674, 1752, 3895,  807, 1480,  402,  422, 2341, 1020,
        3904, 2256, 2049, 4060])
Epoch: 3510, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3511 - Batch 1 ########################
IDs in batch 1: tensor([2403,  666, 2822, 2854, 2624, 1255, 2680, 2371, 3701,  470, 2997, 3971,
        1968, 2344, 4000, 3557])
Epoch: 3511, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3512 - Batch 1 ########################
IDs in batch 1: tensor([3628,  159,  266, 1869, 3131, 4256, 2695, 1124,  236, 2041, 2256, 3829,
        2118, 1232,  388, 4133])
Epoch: 3512, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3513 - Batch 1 ########################
IDs in batch 1: tensor([ 534, 3846, 3723, 3306, 4024, 3017,  819,  399, 3985,  662,  704,  405,
        3541, 1357, 2551, 2885])
Epoch: 3513, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3514 - Batch 1 ########################
IDs in batch 1: tensor([3073, 2950, 2895,  422, 3897, 3052, 3818, 3272, 2598, 1118, 2687, 3147,
        3618, 1417,  769, 3243])
Epoch: 3514, Training Loss: 0.18, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3515 - Batch 1 ########################
IDs in batch 1: tensor([2313, 2356,  809, 1375, 1344, 3563, 3552, 1244, 1740, 1010, 3245,  556,
        2281, 3200, 2161,  607])
Epoch: 3515, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3516 - Batch 1 ########################
IDs in batch 1: tensor([2964, 2085,  257,  743, 2796, 2488,  380, 1945, 1497, 2541, 3985, 2119,
         436, 3204,  733,  326])
Epoch: 3516, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3517 - Batch 1 ########################
IDs in batch 1: tensor([2565,  923, 1328, 1596, 4264,  318, 2899, 3353, 2682, 1826, 2264, 3833,
         181, 2040, 1961, 4004])
Epoch: 3517, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3518 - Batch 1 ########################
IDs in batch 1: tensor([ 448, 3813, 1493, 2887, 2739, 2741, 2745, 3573, 3699,  844, 4013, 2646,
        3740, 4149, 2295, 3206])
Epoch: 3518, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3519 - Batch 1 ########################
IDs in batch 1: tensor([3981,  290, 1601, 3486, 1175, 1381, 3907,  379, 2879, 1311, 2104, 3940,
         488, 3495,  302, 2495])
Epoch: 3519, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3520 - Batch 1 ########################
IDs in batch 1: tensor([4180, 1212, 3244,  136, 2572,  245, 3100, 2331, 4016, 3357,  723, 3991,
        3975, 3211, 3409,  723])
Epoch: 3520, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3521 - Batch 1 ########################
IDs in batch 1: tensor([1409, 3246, 1530, 2748, 3395, 2064, 2027, 2207, 2510, 1083,  538, 1166,
        2497, 1266, 3963,  651])
Epoch: 3521, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3522 - Batch 1 ########################
IDs in batch 1: tensor([3980, 3426, 2153, 2390, 3803, 2185, 1283, 2833, 2127, 3994, 1568, 1389,
        1234, 2848,  583, 3526])
Epoch: 3522, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3523 - Batch 1 ########################
IDs in batch 1: tensor([3156, 1039, 1830, 1478, 2337, 2644, 4085, 1041,  842,  574,  109, 3581,
        2961, 1482, 4214, 2957])
Epoch: 3523, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3524 - Batch 1 ########################
IDs in batch 1: tensor([3184,  105,  577, 2034,  481, 3272, 2258, 1731, 2947, 3220, 3236, 2960,
         214,  257, 2406, 2942])
Epoch: 3524, Training Loss: 0.23, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3525 - Batch 1 ########################
IDs in batch 1: tensor([2281,  605, 1026, 2794, 3523, 1968, 2517, 2905, 1613,  437, 3780, 1957,
        3754, 3437, 1623, 3505])
Epoch: 3525, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3526 - Batch 1 ########################
IDs in batch 1: tensor([4203,  871, 3831, 1645, 1399, 2683, 1536, 3127,  454, 3446, 3207, 2400,
        2279, 1168,   85,  466])
Epoch: 3526, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3527 - Batch 1 ########################
IDs in batch 1: tensor([3738, 2286,  159, 4013, 2827, 2858,  766,  139, 2226, 1778, 1122, 1252,
        2034,  149, 1496, 3780])
Epoch: 3527, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3528 - Batch 1 ########################
IDs in batch 1: tensor([ 452, 4046, 3521, 2976,  523,  234, 2690, 3733, 3000, 3133, 4179, 1545,
        1774, 2668,  395, 3197])
Epoch: 3528, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3529 - Batch 1 ########################
IDs in batch 1: tensor([ 960, 1734,  670,  615, 2073,  955, 3387, 2202, 1214, 3997, 1748, 2776,
        1630,  688, 2479, 3707])
Epoch: 3529, Training Loss: 0.24, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3530 - Batch 1 ########################
IDs in batch 1: tensor([1450, 3069, 1089, 3822,  739, 3651, 2812, 1214, 1556,  312, 3135, 1197,
        1480, 3299, 1923,  572])
Epoch: 3530, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3531 - Batch 1 ########################
IDs in batch 1: tensor([3291, 1443,   22, 2085, 3676,  794, 1296, 3781, 1137,  662, 2123,  693,
         261, 1402, 2683, 2789])
Epoch: 3531, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3532 - Batch 1 ########################
IDs in batch 1: tensor([2831, 1124,  269, 3851, 1961, 2135, 2727, 1711, 1548, 2590, 4119,  126,
        1833, 3235, 2066,  200])
Epoch: 3532, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3533 - Batch 1 ########################
IDs in batch 1: tensor([ 971,  787,  442, 1617, 1159, 4251,  471, 1626, 3644, 2004, 3917, 1849,
        2198, 3630, 2278, 2809])
Epoch: 3533, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3534 - Batch 1 ########################
IDs in batch 1: tensor([3439, 4229,  387, 3287,  478, 1490, 2572, 3032, 3563, 3429, 2712,   11,
          85, 3647,  539,  777])
Epoch: 3534, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3535 - Batch 1 ########################
IDs in batch 1: tensor([2969, 3352,  631, 1170,  662, 3181,  471, 4037, 2802, 1775, 1985, 1083,
        2483, 3928, 1858,  518])
Epoch: 3535, Training Loss: 0.02, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3536 - Batch 1 ########################
IDs in batch 1: tensor([3374, 3538, 1862,  239, 2751, 2414,  526, 4154, 1171, 1039, 1942, 1746,
        3226, 1081, 1938, 2456])
Epoch: 3536, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3537 - Batch 1 ########################
IDs in batch 1: tensor([ 257, 3661,  974, 3127, 3002,  519, 1630, 2161, 3940,  899, 1755,  243,
        2337, 1381, 3749,  193])
Epoch: 3537, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3538 - Batch 1 ########################
IDs in batch 1: tensor([ 211, 3600, 4096, 4007, 1481,  583,  968, 1111, 4117, 3451, 1780, 1481,
         550,  488, 2252, 1836])
Epoch: 3538, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 3539 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 2316, 1147, 4039, 1283,  689, 1255, 4127, 1591, 3300, 3451, 1645,
        3185, 2171, 2999, 2730])
Epoch: 3539, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 3540 - Batch 1 ########################
IDs in batch 1: tensor([4080, 1423,  177, 1511,  501, 1417,  838,  422,  718, 1973, 2134, 1772,
         403, 2826, 1325, 3936])
Epoch: 3540, Training Loss: 0.23, Validation Loss: 0.81, accuracy = 0.75
######################## Epoch 3541 - Batch 1 ########################
IDs in batch 1: tensor([3340,  367, 2359, 1030, 1242, 2526,  111,  969, 1994, 2348, 1722,   37,
        1650, 1272,  635, 3428])
Epoch: 3541, Training Loss: 0.51, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 3542 - Batch 1 ########################
IDs in batch 1: tensor([2765,  287, 1297, 2854, 2203, 1067,  924,    5, 2287, 1015, 2672, 2867,
         773, 3040, 2927, 2690])
Epoch: 3542, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3543 - Batch 1 ########################
IDs in batch 1: tensor([1910, 1130, 3973, 3634,  558, 4026,  661, 2161, 1041, 2499,  908,  488,
        2802, 2241, 2202, 2789])
Epoch: 3543, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3544 - Batch 1 ########################
IDs in batch 1: tensor([3337, 2248, 3742, 1393,  909,   59, 2957,  837,  171, 2003, 2947, 1414,
        4185, 3781, 2926, 4000])
Epoch: 3544, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3545 - Batch 1 ########################
IDs in batch 1: tensor([2459, 1736, 2207, 1383, 2517, 4197, 1372, 1679, 1884, 2883, 2770, 2870,
        1130, 3617,  795,   63])
Epoch: 3545, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3546 - Batch 1 ########################
IDs in batch 1: tensor([3330, 4069, 1263,  218, 3655, 4245, 1747,  127, 1062, 4173, 3816, 3830,
         302, 3114, 3707, 3309])
Epoch: 3546, Training Loss: 0.78, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3547 - Batch 1 ########################
IDs in batch 1: tensor([1097, 2334, 3544, 2974, 2912, 3326, 2451,  171, 2742, 3721, 1660, 1420,
        4099, 3514, 2107, 1950])
Epoch: 3547, Training Loss: 0.44, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3548 - Batch 1 ########################
IDs in batch 1: tensor([ 484,  626,  354, 3783, 3751, 2848, 2274, 2561, 3729, 2251, 2452, 3765,
          71, 4190, 1507, 1812])
Epoch: 3548, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3549 - Batch 1 ########################
IDs in batch 1: tensor([2505, 2885,  384,  553, 1183, 4258, 2674, 3391,  978, 1752, 2749, 1571,
        3952, 2680, 1097,  380])
Epoch: 3549, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3550 - Batch 1 ########################
IDs in batch 1: tensor([3055,  914, 3865,  822,   97, 3777,  510, 2202, 1413,  854,  181, 3098,
         101, 1842,  427, 2070])
Epoch: 3550, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3551 - Batch 1 ########################
IDs in batch 1: tensor([2135, 3003, 2915, 2788,  283,  444,  303, 1371,  813,  678, 1054,  733,
        2246, 3535,  555, 1119])
Epoch: 3551, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3552 - Batch 1 ########################
IDs in batch 1: tensor([1916, 2102, 3992,  505, 3398,  119, 2953, 1352, 3108,  454, 2632,  909,
        2648, 2475, 3127, 1895])
Epoch: 3552, Training Loss: 0.23, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3553 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 3053, 3309, 2145, 4075,  198, 4149, 2671, 2746, 3338, 1369, 3290,
        4234,  198,  426, 2681])
Epoch: 3553, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3554 - Batch 1 ########################
IDs in batch 1: tensor([1702, 2788, 2725,  933, 2978,  487, 3410, 1762, 4188, 1778,  709, 3659,
        1952, 2951, 3777,  775])
Epoch: 3554, Training Loss: 0.42, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3555 - Batch 1 ########################
IDs in batch 1: tensor([3441, 2660, 4217, 1030, 2073,  721, 1812, 2879, 2053,  492, 1490,  194,
        2701, 1737, 2643, 2322])
Epoch: 3555, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3556 - Batch 1 ########################
IDs in batch 1: tensor([2400,  823,  258, 1938, 2902, 2278, 2571,  269, 4176,  211,  306,  820,
        3388, 2030, 3695,  275])
Epoch: 3556, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3557 - Batch 1 ########################
IDs in batch 1: tensor([3020,  892, 4226, 1706,  815,  775, 2690,  120, 3505, 2809, 1174, 2355,
          56, 1595, 2365,  849])
Epoch: 3557, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3558 - Batch 1 ########################
IDs in batch 1: tensor([3557, 4220, 3777, 1726, 2420, 1415, 2377,  563, 1371, 4009, 2156, 3182,
        3029,  649, 4058, 1730])
Epoch: 3558, Training Loss: 0.15, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3559 - Batch 1 ########################
IDs in batch 1: tensor([2807,  971, 1665, 3537, 4157,  351, 1645, 2439, 2406, 2787,  150,  758,
        2583,  512, 2682, 3888])
Epoch: 3559, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3560 - Batch 1 ########################
IDs in batch 1: tensor([2334, 3731, 4264,  678,  323, 3557, 1733, 2419, 3150, 2473,  363, 3343,
        3769, 3922,  201, 1900])
Epoch: 3560, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3561 - Batch 1 ########################
IDs in batch 1: tensor([3253, 1289, 3441, 2663, 3692, 1967, 3449, 3132, 2767, 1585, 1947, 2112,
        4076, 1678, 2787, 1537])
Epoch: 3561, Training Loss: 0.22, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3562 - Batch 1 ########################
IDs in batch 1: tensor([ 476,  756,  848, 1146, 3084, 3227, 2244,  788, 1569,  663,  145, 2866,
        1186, 2542, 1432, 2362])
Epoch: 3562, Training Loss: 0.40, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3563 - Batch 1 ########################
IDs in batch 1: tensor([2809, 2109, 2847, 1337,  159,  438,  397, 3902, 1886, 2797,  315, 3726,
        2542, 2205, 2440,  771])
Epoch: 3563, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3564 - Batch 1 ########################
IDs in batch 1: tensor([ 609, 3962, 1673, 1950, 3427, 4076, 3995, 2196, 3514,   96, 3100, 3985,
        1651, 2509,  544,  368])
Epoch: 3564, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3565 - Batch 1 ########################
IDs in batch 1: tensor([2562, 4227, 2401, 2439, 1786,  110, 3058, 1702, 2776,  603, 2281, 4011,
         749, 2575, 1089, 3330])
Epoch: 3565, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3566 - Batch 1 ########################
IDs in batch 1: tensor([3883, 1251, 1272, 1326, 1311, 2914, 2040, 2367, 2457,  188, 1274,  872,
         106, 1196, 1049,  864])
Epoch: 3566, Training Loss: 0.18, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3567 - Batch 1 ########################
IDs in batch 1: tensor([2572, 1967,  594, 3812,  787, 3100,  607, 1566,  408, 3804, 1038, 3382,
        2521, 1375,  816, 2052])
Epoch: 3567, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3568 - Batch 1 ########################
IDs in batch 1: tensor([2886, 3635, 1055, 2804, 2937, 3056,  121, 4163, 1495, 4055,  496,  355,
        3919, 2497, 3179,  623])
Epoch: 3568, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3569 - Batch 1 ########################
IDs in batch 1: tensor([2219, 1882, 1934, 2232,  507, 3723, 2664, 3934, 1760, 2177, 2737, 3813,
        1226, 4018, 2520, 1294])
Epoch: 3569, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3570 - Batch 1 ########################
IDs in batch 1: tensor([2282,  308, 4234, 1994,  775, 1208, 2568, 1821, 3378, 1641,  725, 1751,
        2957, 2085, 4119,   25])
Epoch: 3570, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3571 - Batch 1 ########################
IDs in batch 1: tensor([1152, 3376, 1131, 1252,  137,  639, 2598, 1626, 3480, 1745, 3509, 1025,
          59, 2510, 1271, 3939])
Epoch: 3571, Training Loss: 0.20, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3572 - Batch 1 ########################
IDs in batch 1: tensor([1073,  529, 1910, 2405, 1923, 1082,   46, 2133, 1283, 3168, 4226, 3743,
        1082, 1764, 2248, 3616])
Epoch: 3572, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3573 - Batch 1 ########################
IDs in batch 1: tensor([2712, 3823,  454, 2672, 3992,  950, 3850, 1200, 3410, 3831, 1176,  954,
        3853, 2631, 1684,  869])
Epoch: 3573, Training Loss: 0.22, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3574 - Batch 1 ########################
IDs in batch 1: tensor([3583, 2473, 2375,  977, 3713, 1406, 3543, 2408, 1650, 3202,  897, 4033,
        1274, 2219, 3705, 1974])
Epoch: 3574, Training Loss: 0.26, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3575 - Batch 1 ########################
IDs in batch 1: tensor([1234, 1775, 1518, 1851,  475, 1455,  467, 1490,  477, 1718,  277, 2316,
        4077,  649,  126,  752])
Epoch: 3575, Training Loss: 0.91, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3576 - Batch 1 ########################
IDs in batch 1: tensor([3470, 3650, 4125,  888, 3362,  846, 3387, 2879, 1471, 3539, 1090,   92,
         511, 3469, 1910,  622])
Epoch: 3576, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3577 - Batch 1 ########################
IDs in batch 1: tensor([3038, 2106,  849,  507,  463, 3417,  147,  534, 2498, 3829,  459, 1489,
        2817,    7, 2617, 2356])
Epoch: 3577, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3578 - Batch 1 ########################
IDs in batch 1: tensor([2339, 3374, 2574, 2937, 3850, 3308,  963,  837,  588, 3726, 1070,  282,
        3594,  337,  834, 2509])
Epoch: 3578, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3579 - Batch 1 ########################
IDs in batch 1: tensor([1276, 1459, 2106, 2173,  303, 1959,  828, 3871, 2758, 3368,   34, 3248,
        1737,  934,  833, 1239])
Epoch: 3579, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3580 - Batch 1 ########################
IDs in batch 1: tensor([2145,   70, 2176, 3242, 3663, 2442, 3132, 1031,  287, 3821, 2624, 1501,
        3372, 3681,  572, 3029])
Epoch: 3580, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3581 - Batch 1 ########################
IDs in batch 1: tensor([2648, 3709, 1361, 2337, 2210,  587, 3340, 3709, 2495, 2669,  960, 1575,
        1308, 3367, 3751, 1651])
Epoch: 3581, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3582 - Batch 1 ########################
IDs in batch 1: tensor([2044,  683, 4157, 3536,  333, 4010, 3538, 4139, 3689, 3544, 2526, 1258,
        4133,  320, 2874, 3105])
Epoch: 3582, Training Loss: 0.11, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3583 - Batch 1 ########################
IDs in batch 1: tensor([4174, 1812,  130, 1825, 1902, 2564, 1062, 2338,  287,  673,   24,  515,
        2433, 3808, 2009, 3968])
Epoch: 3583, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3584 - Batch 1 ########################
IDs in batch 1: tensor([2751,  607, 3990, 2292, 3314,  471, 1914,  582, 1090, 1289,   78, 2191,
         245, 3016, 3866, 2700])
Epoch: 3584, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3585 - Batch 1 ########################
IDs in batch 1: tensor([3845, 1612, 2022, 2683, 3792,  956,   18, 2234, 1614, 2518, 1980, 2014,
         762,  977, 3264, 2206])
Epoch: 3585, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3586 - Batch 1 ########################
IDs in batch 1: tensor([2196,   96, 1379, 1619, 3498, 1050, 3406,  432, 2574, 2207, 3308,  652,
        1512, 2727,  321, 3452])
Epoch: 3586, Training Loss: 0.19, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3587 - Batch 1 ########################
IDs in batch 1: tensor([2743, 3270, 3930, 3757, 3448, 1122, 3151, 4261,  449, 1921, 1065, 2586,
        3912,  312, 2305,  343])
Epoch: 3587, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3588 - Batch 1 ########################
IDs in batch 1: tensor([2689, 1231, 2754, 4085, 3977, 3187,   41,  409, 3870, 1249, 2249, 2967,
        2770, 3461, 4088, 2229])
Epoch: 3588, Training Loss: 0.22, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3589 - Batch 1 ########################
IDs in batch 1: tensor([1437, 3339, 3425,  400, 2598, 2692,  472, 1623, 3540, 2506, 3483, 1160,
        1374,  846,  283, 1355])
Epoch: 3589, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3590 - Batch 1 ########################
IDs in batch 1: tensor([3461, 2016, 1880,  605, 1481, 3179, 2671, 1195, 2355, 2498, 1226, 2599,
         276,  342, 1312, 2859])
Epoch: 3590, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3591 - Batch 1 ########################
IDs in batch 1: tensor([3418,   72,  325,  202, 3057,   10,  514,  372, 1509,  989, 1648, 1385,
        2391, 4168, 2352, 4245])
Epoch: 3591, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3592 - Batch 1 ########################
IDs in batch 1: tensor([1933, 2297, 2414, 3479,  895,  553,  670,  456, 1590, 1819,  541, 2192,
        1357,    7,  796,  961])
Epoch: 3592, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3593 - Batch 1 ########################
IDs in batch 1: tensor([ 351,   26, 4033, 2081, 2113, 1645, 3702, 2436, 3101, 3143, 3577, 3472,
        2706, 1347, 3378,  583])
Epoch: 3593, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3594 - Batch 1 ########################
IDs in batch 1: tensor([2290, 3406, 2255, 3671,  355, 3652, 3017, 3326, 2073,  516, 1178, 2099,
         356, 2322,  873, 2253])
Epoch: 3594, Training Loss: 0.22, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3595 - Batch 1 ########################
IDs in batch 1: tensor([4007,   34, 3706, 2157,  672, 2494, 1626, 2691, 2695,  322, 2385, 2895,
         444, 1634, 2338, 3876])
Epoch: 3595, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3596 - Batch 1 ########################
IDs in batch 1: tensor([3976,  928, 1073, 4256, 3803, 2546, 1346, 2666, 2119, 1270, 2488,   42,
         475, 2514,  417, 2738])
Epoch: 3596, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3597 - Batch 1 ########################
IDs in batch 1: tensor([1976, 3261,  871, 3974, 2872, 1057, 3701, 3057,  202, 2332, 1944, 3643,
        3251, 2444, 1642,   13])
Epoch: 3597, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3598 - Batch 1 ########################
IDs in batch 1: tensor([ 343, 2400, 2189, 3785,  767,    4, 2787,   38, 3372, 4176, 1760, 3355,
        1977,  341, 1726,  755])
Epoch: 3598, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3599 - Batch 1 ########################
IDs in batch 1: tensor([3150, 3178, 2874,  440,  535, 4099, 3552, 3400, 1812, 3362, 1225, 2632,
        2810, 3661, 1641, 3188])
Epoch: 3599, Training Loss: 0.25, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3600 - Batch 1 ########################
IDs in batch 1: tensor([4014, 2078, 1312,  430, 4105,  452,  644, 3340, 2841, 3866, 3693,  844,
         601,  757,  439,  603])
Epoch: 3600, Training Loss: 0.14, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3601 - Batch 1 ########################
IDs in batch 1: tensor([4073,  522, 2426, 2326,  360,  850, 3715, 1249, 1882, 2177, 2461, 1174,
         427, 2469, 3781, 2892])
Epoch: 3601, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3602 - Batch 1 ########################
IDs in batch 1: tensor([1232, 3615, 3635, 3318, 4188, 1808, 2066, 2366, 1959, 4246, 1437, 3734,
        1786, 1213, 3852, 3600])
Epoch: 3602, Training Loss: 0.51, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3603 - Batch 1 ########################
IDs in batch 1: tensor([ 934,  354, 2373, 3151, 3415, 1920, 4251, 3312, 4238, 1510, 3199, 1404,
         646, 1231, 1248, 1824])
Epoch: 3603, Training Loss: 0.07, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3604 - Batch 1 ########################
IDs in batch 1: tensor([1397, 2274, 2251, 2004, 3265, 3610,  547, 2199, 1834, 1760, 3081, 2119,
        1473, 2495, 1595, 1347])
Epoch: 3604, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3605 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2234,   43,  308, 1458, 4110, 3714, 1452,  368, 3221, 2856, 1530,
        2190, 2482, 1500, 3830])
Epoch: 3605, Training Loss: 0.21, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3606 - Batch 1 ########################
IDs in batch 1: tensor([  82, 1138, 3303, 1636, 3975, 3251, 3379, 1077, 1955, 3311,   88, 4253,
         234, 3859, 2632, 3058])
Epoch: 3606, Training Loss: 0.05, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3607 - Batch 1 ########################
IDs in batch 1: tensor([2170,  835,  632,  812, 2317, 2908, 2751, 3866, 2571, 2241, 2315, 3780,
        2102,  498, 1199, 3993])
Epoch: 3607, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3608 - Batch 1 ########################
IDs in batch 1: tensor([  26, 4245, 2890, 3601, 1611,  358,  320,  111, 3760, 2749, 2572, 3267,
         391, 2495, 2791,  982])
Epoch: 3608, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3609 - Batch 1 ########################
IDs in batch 1: tensor([4051, 2799,  139, 2572, 2555, 3220, 2256, 2648, 1311, 2088,  701, 1636,
        1223, 1049, 2961, 1060])
Epoch: 3609, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3610 - Batch 1 ########################
IDs in batch 1: tensor([ 779, 1630,  127, 1975, 1309, 3747, 2478, 1803, 1163, 3812, 1444, 1383,
        2663, 1951, 2453, 2348])
Epoch: 3610, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3611 - Batch 1 ########################
IDs in batch 1: tensor([1043, 4033, 4144,  532, 3953, 3642,  910,  122, 3192,  441, 3533,  252,
         809,   50,  435, 2419])
Epoch: 3611, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3612 - Batch 1 ########################
IDs in batch 1: tensor([1186, 2648, 4258,  855, 3147, 4185,  797, 1092,   46, 3243,  219, 2715,
        4078, 2619, 3255, 3985])
Epoch: 3612, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3613 - Batch 1 ########################
IDs in batch 1: tensor([ 960, 1747,   30, 2203, 2926,  245, 4163, 4240, 2957, 3343, 1118, 3473,
        3461, 3373,  606, 1802])
Epoch: 3613, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3614 - Batch 1 ########################
IDs in batch 1: tensor([3594, 3950, 3498, 2546,  352, 3834,  945, 3701,  490, 3353, 3898, 2053,
        1655, 2661, 1341, 2793])
Epoch: 3614, Training Loss: 0.19, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3615 - Batch 1 ########################
IDs in batch 1: tensor([3638,  277, 1073, 1942, 2225, 3727,  740, 4238, 2771, 3480, 3971, 2383,
         109, 1324, 3839, 4170])
Epoch: 3615, Training Loss: 0.44, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3616 - Batch 1 ########################
IDs in batch 1: tensor([ 151, 1343, 2548,  758,  825, 4251, 2970, 3056,  152, 2316, 4084, 3438,
         427,  274,  950,  395])
Epoch: 3616, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3617 - Batch 1 ########################
IDs in batch 1: tensor([3663,  113, 3713, 3640, 2416,  145, 2482, 3952, 1147, 2755, 3912, 1402,
        1590, 2965, 2819, 2825])
Epoch: 3617, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3618 - Batch 1 ########################
IDs in batch 1: tensor([ 512,  604, 3251, 3399, 3124,  455,  687, 2752, 2712, 1775, 2518, 3693,
         652, 2203, 2688,  537])
Epoch: 3618, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3619 - Batch 1 ########################
IDs in batch 1: tensor([2989, 1500, 3549, 3386, 3757,  937,  191,  808, 2003, 2371, 1482, 3547,
         555,  281, 1639, 3601])
Epoch: 3619, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3620 - Batch 1 ########################
IDs in batch 1: tensor([2462, 3407, 2809, 4213, 3573,  128, 2572, 1216,  828, 2278, 1921, 1257,
         484, 3545, 2871, 1459])
Epoch: 3620, Training Loss: 0.29, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3621 - Batch 1 ########################
IDs in batch 1: tensor([1678, 2209,   21,  763, 2824, 2024, 2797, 3607, 4069, 2863, 2730, 2595,
        1601, 2370,  848, 3870])
Epoch: 3621, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3622 - Batch 1 ########################
IDs in batch 1: tensor([3669, 1035, 4011, 3557, 3856, 2564, 1081, 3484,  234,  928, 1981, 4044,
        3863,  896, 1146, 3695])
Epoch: 3622, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3623 - Batch 1 ########################
IDs in batch 1: tensor([1673, 3284, 1745, 1297,  280, 2091, 2423, 2727, 2295,  869, 1707, 3408,
        2892, 2170, 4006, 2597])
Epoch: 3623, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3624 - Batch 1 ########################
IDs in batch 1: tensor([ 459, 2587, 2564, 2290, 2824,  214, 3394, 3039, 3540, 1563,  232, 3466,
        3627, 3200, 1574, 2324])
Epoch: 3624, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3625 - Batch 1 ########################
IDs in batch 1: tensor([2505, 2907, 3715, 2610, 1963,  642,  196, 4009, 1387, 2482, 1649, 1658,
        1056, 1895, 2956, 4024])
Epoch: 3625, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3626 - Batch 1 ########################
IDs in batch 1: tensor([3534, 1651, 1914, 1455, 2666, 2087, 1548, 1049, 3762, 2991, 2272, 3438,
        2648, 1310, 3384, 2745])
Epoch: 3626, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3627 - Batch 1 ########################
IDs in batch 1: tensor([2369,  161, 3476,  225, 3236,  651,   37, 1840, 2833,  289, 2177,  724,
        2178, 1219, 1575, 2144])
Epoch: 3627, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3628 - Batch 1 ########################
IDs in batch 1: tensor([3627, 3234,  149, 3214, 3866, 4078,  437,  557,   18, 3822, 2034,  826,
        1309, 1991, 1730, 2290])
Epoch: 3628, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3629 - Batch 1 ########################
IDs in batch 1: tensor([1611, 2640, 3418,  126,  424,  709, 4148, 2219,  651, 1250, 1580, 2990,
         362, 2564,  679, 3922])
Epoch: 3629, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3630 - Batch 1 ########################
IDs in batch 1: tensor([2700, 3913, 1200, 1152, 2671, 2874, 1736,  484, 2379, 1870, 2791, 2725,
        2947,  121, 2109, 3424])
Epoch: 3630, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3631 - Batch 1 ########################
IDs in batch 1: tensor([2072, 2478,  213, 3922, 3637,  139, 1173, 2031, 1570,  825, 1161, 2587,
        3821, 1990,  921, 4152])
Epoch: 3631, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3632 - Batch 1 ########################
IDs in batch 1: tensor([3845, 1747, 1910, 2997,  346, 2452, 1473, 2063, 2205, 2379, 3954,  407,
        3244, 3634,  379,  496])
Epoch: 3632, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3633 - Batch 1 ########################
IDs in batch 1: tensor([1415,  408, 2142, 2094, 2640, 2488, 2050, 1125, 1878, 4188, 2595, 3940,
         367, 1834,  610, 1388])
Epoch: 3633, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3634 - Batch 1 ########################
IDs in batch 1: tensor([3421,  159, 3370,  837,  790,  756, 2444, 4264, 1004,  781, 1067, 2589,
        1825,  151, 1155, 3471])
Epoch: 3634, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3635 - Batch 1 ########################
IDs in batch 1: tensor([2659, 3865, 3329, 3291,  523, 2173, 1728, 1484, 3721, 4114, 2146, 2177,
         467, 2938,  484, 3100])
Epoch: 3635, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3636 - Batch 1 ########################
IDs in batch 1: tensor([2678, 3874, 1968, 3390, 1575, 2342,  279, 2131, 1425, 1728, 3845, 3992,
        2646, 2236, 2210, 3883])
Epoch: 3636, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3637 - Batch 1 ########################
IDs in batch 1: tensor([ 604, 4165, 1341, 2091, 1419, 3863, 4139, 1496, 1072,  448, 1130, 3483,
        1763,  401, 1313,  777])
Epoch: 3637, Training Loss: 0.60, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3638 - Batch 1 ########################
IDs in batch 1: tensor([1034, 2099,  300, 3638,   93, 3707, 1296, 1645,  672, 2372, 2334,  359,
        1644, 1160, 1423, 2223])
Epoch: 3638, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3639 - Batch 1 ########################
IDs in batch 1: tensor([2696, 1706, 2291, 1328, 3888, 3242, 3558, 2542, 3894, 2285, 2563, 2286,
        3376, 2169,   88, 2126])
Epoch: 3639, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3640 - Batch 1 ########################
IDs in batch 1: tensor([1464, 1417, 2141, 2524, 3389, 1808, 1042, 2565, 3476, 2907, 3753, 3372,
        3935,  822, 4149,  523])
Epoch: 3640, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3641 - Batch 1 ########################
IDs in batch 1: tensor([3075, 1755, 1180, 1767, 2343, 4264,  108, 1410,  391, 3872, 1077, 1182,
         975, 2917, 2428, 1619])
Epoch: 3641, Training Loss: 0.16, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3642 - Batch 1 ########################
IDs in batch 1: tensor([ 969, 3875, 2192, 4263, 3521, 2316, 3866, 3583,  732, 1767, 3072, 2276,
        3501, 2708, 2559, 3785])
Epoch: 3642, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3643 - Batch 1 ########################
IDs in batch 1: tensor([1498, 1787, 1432, 4067, 2371, 1216, 3843, 3303,  117, 3105, 2247, 1642,
        1682, 1834,  387, 3436])
Epoch: 3643, Training Loss: 0.15, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3644 - Batch 1 ########################
IDs in batch 1: tensor([ 862, 4154, 1180, 3778, 2500,  837, 2986, 1657, 3897, 3874, 2091,  275,
        2261, 1655,  159, 2871])
Epoch: 3644, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3645 - Batch 1 ########################
IDs in batch 1: tensor([2740, 2104, 1037, 2578, 2019, 2886, 3180, 3942, 4030, 2499,  606,  961,
        2003,  376,  484,  970])
Epoch: 3645, Training Loss: 0.03, Validation Loss: 0.86, accuracy = 0.73
######################## Epoch 3646 - Batch 1 ########################
IDs in batch 1: tensor([4014, 2627, 2379, 3860, 2879,  367, 2482, 4157, 3985, 2821, 3374, 1005,
        3465,  569, 3950, 3343])
Epoch: 3646, Training Loss: 0.26, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3647 - Batch 1 ########################
IDs in batch 1: tensor([ 953,  445, 1592, 2444, 3843, 2538,  206, 1258, 3548, 2360, 4049, 2400,
         635, 1681,   22, 1982])
Epoch: 3647, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3648 - Batch 1 ########################
IDs in batch 1: tensor([2030, 3951, 1625, 2097, 3585,  566, 1640, 2536, 2442, 2591,  556,  260,
         603, 3782, 2845, 1777])
Epoch: 3648, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3649 - Batch 1 ########################
IDs in batch 1: tensor([1056, 3497, 4113, 3604, 3973, 3160, 2912, 1972, 2782, 4108, 2041, 1488,
         644,  110, 2674, 1171])
Epoch: 3649, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3650 - Batch 1 ########################
IDs in batch 1: tensor([ 777, 2742, 4212, 3904, 3447, 3524, 1562,  844, 3251, 4197, 3821,  343,
         751, 2887, 3010, 3441])
Epoch: 3650, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3651 - Batch 1 ########################
IDs in batch 1: tensor([2180, 3109,  338, 1802, 4110, 2353,  326, 1953, 2016, 2858, 2627, 2417,
        2248, 2919, 4096,  149])
Epoch: 3651, Training Loss: 0.24, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3652 - Batch 1 ########################
IDs in batch 1: tensor([3537, 4128, 3234,  918,  610,  213, 3583, 3003, 2230, 3856,   64, 1285,
        3925, 4157, 3692,   59])
Epoch: 3652, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3653 - Batch 1 ########################
IDs in batch 1: tensor([2116, 1336, 2597, 1044,  377, 1866, 3847, 3767,   30,  181, 3598, 3618,
        1076, 4101, 3289, 3592])
Epoch: 3653, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3654 - Batch 1 ########################
IDs in batch 1: tensor([ 388, 3792,  834,  875, 2075, 1147, 1722, 1345,  424, 3087, 1803, 2592,
         945,  121, 3802, 2586])
Epoch: 3654, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3655 - Batch 1 ########################
IDs in batch 1: tensor([2403, 2402, 2511,  656,  814, 1050,  361, 2526, 2749,  969, 1440,  305,
        3544, 1948, 1944, 2917])
Epoch: 3655, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3656 - Batch 1 ########################
IDs in batch 1: tensor([1590, 3609,  986, 2510, 2745, 3251, 3150, 3767, 1802, 2832,  140, 2371,
        1511, 1387, 2697,  318])
Epoch: 3656, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3657 - Batch 1 ########################
IDs in batch 1: tensor([4038, 2298,  750, 3728, 4124, 2780, 2620,  882, 2285, 3600, 3538,  875,
         983,  918, 2615, 3581])
Epoch: 3657, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3658 - Batch 1 ########################
IDs in batch 1: tensor([3845, 4058, 1357,  578, 1455,  409, 2094,   49, 1708, 2209, 1810, 1496,
        1328,  955, 2298, 2805])
Epoch: 3658, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3659 - Batch 1 ########################
IDs in batch 1: tensor([3481, 1287, 2496, 2204, 3582, 2587, 1175, 3456, 1745, 3115,  639, 1686,
        3157,  965, 3128, 3433])
Epoch: 3659, Training Loss: 0.29, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3660 - Batch 1 ########################
IDs in batch 1: tensor([2856,  207, 1290, 1651, 3375,  219, 1319, 2157, 3279, 3738, 3689, 4126,
         691, 3178, 1065, 4085])
Epoch: 3660, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3661 - Batch 1 ########################
IDs in batch 1: tensor([1894, 3369, 1056,  275, 2617,  132, 3732, 3951,  455, 1186, 1381,  735,
        2281, 3182, 1782,  930])
Epoch: 3661, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3662 - Batch 1 ########################
IDs in batch 1: tensor([3511, 3896,  795, 3607,  955, 1944, 2034, 2917, 3333, 2983, 4113, 2450,
        1640, 3667, 3239, 3711])
Epoch: 3662, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3663 - Batch 1 ########################
IDs in batch 1: tensor([3765, 2429,  869,  652, 2907,  302, 1120, 2609, 3430,  448, 3976, 2829,
        3921, 3637, 3783,  533])
Epoch: 3663, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3664 - Batch 1 ########################
IDs in batch 1: tensor([ 757,  327, 2642,  970, 2252,  343,  281, 4251, 2317, 1566,  300,  391,
         180, 1294,   49, 3975])
Epoch: 3664, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3665 - Batch 1 ########################
IDs in batch 1: tensor([ 809, 2609, 2499, 4203,  603, 1220, 1212, 1643,  292, 1491, 1385,  101,
        2959, 4037, 1249, 4062])
Epoch: 3665, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3666 - Batch 1 ########################
IDs in batch 1: tensor([3016, 2388, 4089,  639, 2377,  603, 1156,  673, 1655, 1086, 2431, 3837,
        1632,  657, 1519, 3259])
Epoch: 3666, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3667 - Batch 1 ########################
IDs in batch 1: tensor([3220, 2886,  689, 2797, 1066, 2655, 4152,   86, 3991,  251,  476, 3374,
         145, 3823, 3458,   78])
Epoch: 3667, Training Loss: 0.02, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3668 - Batch 1 ########################
IDs in batch 1: tensor([1809, 1155, 1221, 1949, 3777, 1232,  135,  955, 1161, 3680,  894, 1677,
        1498,  314, 1294, 1429])
Epoch: 3668, Training Loss: 0.29, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3669 - Batch 1 ########################
IDs in batch 1: tensor([2890,  566, 4175,   95, 1264, 2038,  402, 4135, 4257, 2840,  907, 3554,
         173,  729, 2420, 2989])
Epoch: 3669, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3670 - Batch 1 ########################
IDs in batch 1: tensor([2638,  171, 1968, 2890, 3214,  441,  678, 4087, 3688, 1732, 2171, 1841,
        2659,  809,  441, 2678])
Epoch: 3670, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3671 - Batch 1 ########################
IDs in batch 1: tensor([2856, 2092, 1436, 4141, 1084,  874, 2444, 1999,  766, 2275, 3660, 2712,
        4256, 2069, 3154, 2604])
Epoch: 3671, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3672 - Batch 1 ########################
IDs in batch 1: tensor([ 988, 2601, 1312, 2655, 3131, 3689, 1008, 2248, 3757, 2676, 4040, 3028,
        3113,  282, 2137, 2497])
Epoch: 3672, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3673 - Batch 1 ########################
IDs in batch 1: tensor([3727,  238,  933,  882, 1675, 3499,  159,  257,  689,  983, 1035, 2358,
        1012,  587, 2098, 4108])
Epoch: 3673, Training Loss: 0.30, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3674 - Batch 1 ########################
IDs in batch 1: tensor([ 490,  627,   95, 1134, 2446, 3197, 4157, 3168, 4173, 2890, 2030,  950,
        1075, 2245,  779, 3994])
Epoch: 3674, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3675 - Batch 1 ########################
IDs in batch 1: tensor([ 762, 3299,  880, 3264, 2075, 1067,   56, 3318, 2485, 3374,  398, 1767,
         961,  439,  718, 1090])
Epoch: 3675, Training Loss: 0.25, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3676 - Batch 1 ########################
IDs in batch 1: tensor([3783, 2590, 2150, 3327, 2740, 3549, 3507, 1672, 3711,  343, 4061, 1087,
        3098, 3484, 1693, 1155])
Epoch: 3676, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3677 - Batch 1 ########################
IDs in batch 1: tensor([3833, 2847, 2172, 1141,  848, 1223, 3532, 3407,  476, 4148, 3845, 2074,
        2207, 4214, 3960,  182])
Epoch: 3677, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3678 - Batch 1 ########################
IDs in batch 1: tensor([2177, 1583, 4166,  953, 1872,  101, 2236, 2191, 2464, 1789, 3664, 4110,
         518, 3328, 3997, 2203])
Epoch: 3678, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3679 - Batch 1 ########################
IDs in batch 1: tensor([ 574, 4254, 1370, 2550,  125, 2051, 2914,  167, 2315,  556, 3945,  758,
        3706, 3563, 1026,  514])
Epoch: 3679, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3680 - Batch 1 ########################
IDs in batch 1: tensor([ 129, 4062, 1824, 1107, 2653, 4165, 1955,  343, 3762, 1663, 2070, 2478,
        3009,  344,  135, 1023])
Epoch: 3680, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3681 - Batch 1 ########################
IDs in batch 1: tensor([2440, 3671,  811, 2022, 2545, 3609, 3330, 2666, 3712, 2226, 3922,  358,
        1356, 3479, 4040, 1543])
Epoch: 3681, Training Loss: 0.39, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 3682 - Batch 1 ########################
IDs in batch 1: tensor([4249, 1833, 1325, 1699, 2727, 1869, 1723, 2680,  953, 1624, 2115, 2231,
        2642, 1811,  354, 3537])
Epoch: 3682, Training Loss: 0.29, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 3683 - Batch 1 ########################
IDs in batch 1: tensor([ 555, 3777, 4196, 3537, 2176, 1810,  308, 1826, 3309, 3417,  626, 1495,
        3053, 2291, 1410, 3594])
Epoch: 3683, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.74
######################## Epoch 3684 - Batch 1 ########################
IDs in batch 1: tensor([ 430, 4184, 2206, 1944, 3154,  377, 1067, 3618, 1765, 1601, 2880, 2005,
        2840, 1104, 3368,  449])
Epoch: 3684, Training Loss: 0.02, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3685 - Batch 1 ########################
IDs in batch 1: tensor([2295, 3352,  487, 4267, 2780, 3731, 3695,  436, 1628,  794,  837, 2960,
        2890, 1727,  413, 2701])
Epoch: 3685, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3686 - Batch 1 ########################
IDs in batch 1: tensor([3997, 2271, 2146, 3829, 3098, 2959, 3119, 1519, 2934, 1882, 1851,  547,
        1066,  823,  143, 2244])
Epoch: 3686, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3687 - Batch 1 ########################
IDs in batch 1: tensor([3060, 3385,  890,  613,  667, 1632, 1818, 1413, 3147,  203, 3310, 3144,
        3446, 3952, 1927, 1651])
Epoch: 3687, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3688 - Batch 1 ########################
IDs in batch 1: tensor([  47,  214, 4036, 3643, 3404, 1318, 2275, 3975, 4005, 4265, 1748, 3056,
        1218, 3803, 2833, 3999])
Epoch: 3688, Training Loss: 0.29, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3689 - Batch 1 ########################
IDs in batch 1: tensor([ 221, 3047,  367,  238,  753, 4253,  819, 4101, 3600,   43, 2695, 3119,
        4255, 3151, 2322, 3217])
Epoch: 3689, Training Loss: 0.03, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3690 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 1199, 3617,  661,  346, 1332, 4228, 1517, 1569, 3053, 3664, 1050,
        3312, 3680, 3608, 4006])
Epoch: 3690, Training Loss: 0.35, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3691 - Batch 1 ########################
IDs in batch 1: tensor([3287, 4076, 3786, 4235,  126, 1845,  507, 4072, 2112,  184, 2477, 2548,
        3765,  397, 1673,  141])
Epoch: 3691, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3692 - Batch 1 ########################
IDs in batch 1: tensor([2710, 2574, 2844, 1053, 2246, 1272, 2592, 4220, 3669,  362, 1234, 1057,
         391, 2379, 3031, 3208])
Epoch: 3692, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3693 - Batch 1 ########################
IDs in batch 1: tensor([3764, 3585,  603,  777,  247,  362,  660, 3353, 2315, 3428, 3747, 2386,
        4010,  954,   72, 1682])
Epoch: 3693, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3694 - Batch 1 ########################
IDs in batch 1: tensor([2183, 2014, 3732, 2976,  942, 2589,  472, 1747, 2717, 1961, 1595,  871,
         365, 2627, 1720, 2328])
Epoch: 3694, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3695 - Batch 1 ########################
IDs in batch 1: tensor([2710, 3532, 1808,  219, 3592, 2676, 3437, 2205, 3831, 3370, 3743, 1589,
         470, 1083, 1276,  627])
Epoch: 3695, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3696 - Batch 1 ########################
IDs in batch 1: tensor([4053,  373, 3648, 3238,  851, 2514,  657, 2433, 2309, 2715, 1899, 2913,
        2014,  482, 3052, 3777])
Epoch: 3696, Training Loss: 0.31, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3697 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 2191, 2711,  377, 3991,  804, 3469, 4040, 2346,  237,  340, 3793,
        1833, 2776, 2905,  808])
Epoch: 3697, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3698 - Batch 1 ########################
IDs in batch 1: tensor([1836, 3628, 2366, 3832, 1247,  379,  653, 3771, 2575,  225, 3343,  606,
        1045, 3446,  119, 3459])
Epoch: 3698, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3699 - Batch 1 ########################
IDs in batch 1: tensor([ 828, 2882, 1711,  604, 2995,  676, 1597, 3057, 3874, 1198, 4267, 4096,
         512, 1855, 1189, 1310])
Epoch: 3699, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3700 - Batch 1 ########################
IDs in batch 1: tensor([2121, 2241, 2641, 3123,  436,  117, 2279,  893,  595, 1444, 1007,  563,
        3765, 2571,  685,  181])
Epoch: 3700, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3701 - Batch 1 ########################
IDs in batch 1: tensor([3933,  941, 2025,  183, 2706,  432, 3492, 3340, 3501, 2777, 2135, 3547,
        2417, 1900,  164, 1370])
Epoch: 3701, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3702 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 2142, 4197, 2645,   24, 2706, 3582, 3166,  485,  186,  101,  658,
        3729, 2103,  586, 1128])
Epoch: 3702, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3703 - Batch 1 ########################
IDs in batch 1: tensor([2510, 2121,  434, 3727, 1340, 4196, 3806, 1640,  232, 2795, 3912, 2494,
        2765,  537, 3452, 2119])
Epoch: 3703, Training Loss: 0.03, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3704 - Batch 1 ########################
IDs in batch 1: tensor([ 736, 2591, 3753, 3644, 3718, 2167, 4027, 2394, 4121, 4223, 3797, 3518,
        4236, 2817, 2838, 3344])
Epoch: 3704, Training Loss: 0.82, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3705 - Batch 1 ########################
IDs in batch 1: tensor([2482, 1996,  644,  824, 2643, 3065, 3242, 3516, 3217,  444, 4031, 2272,
        2287, 1334, 3763, 2251])
Epoch: 3705, Training Loss: 0.31, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3706 - Batch 1 ########################
IDs in batch 1: tensor([ 843,  712, 2378,  639, 1993, 1751, 3352, 4158, 3339,  644, 2464, 1804,
         653, 1684, 2951, 3115])
Epoch: 3706, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3707 - Batch 1 ########################
IDs in batch 1: tensor([ 402,  977, 1716, 1596, 1160,   71, 2996, 2258,  194, 2763, 3216, 2426,
        2559, 3945, 1507, 1571])
Epoch: 3707, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3708 - Batch 1 ########################
IDs in batch 1: tensor([1287, 3055, 1281, 3958, 1562, 3258, 4267, 3995, 2624, 2480,   61, 1823,
        2291, 3961, 1636, 1900])
Epoch: 3708, Training Loss: 0.32, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3709 - Batch 1 ########################
IDs in batch 1: tensor([2810, 3851, 1495,  308,  605,  882, 3438, 2938, 3179, 1618, 1445,  434,
        3837, 4205, 1720, 1287])
Epoch: 3709, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3710 - Batch 1 ########################
IDs in batch 1: tensor([4009,  185, 1525,   74, 2494,  103, 1396, 3832,  642, 1670,  238, 1948,
        2102, 1057, 1337, 2839])
Epoch: 3710, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3711 - Batch 1 ########################
IDs in batch 1: tensor([1863, 3404, 3599, 3458,  854, 1733, 1063, 1770, 3841, 3100, 3970, 4073,
        2925, 1174, 3808, 3726])
Epoch: 3711, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3712 - Batch 1 ########################
IDs in batch 1: tensor([1707, 3114, 2882, 1668, 2871,  607, 3081, 2002, 3329, 4190, 3228, 2363,
        2964, 3675,  797, 1632])
Epoch: 3712, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3713 - Batch 1 ########################
IDs in batch 1: tensor([3755, 3071, 2817,  803, 1472, 3079, 1423, 1640, 3142, 1252, 3025,  148,
          96, 1920, 1596, 3144])
Epoch: 3713, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3714 - Batch 1 ########################
IDs in batch 1: tensor([ 779, 3999,   19, 1472, 1213,  371, 1372, 3227,  396, 2617,  569, 3417,
        1651, 1821, 2312,  712])
Epoch: 3714, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3715 - Batch 1 ########################
IDs in batch 1: tensor([2500, 2408, 3882, 2660, 2915, 1220, 2973,  961, 1144, 1388, 1958, 3846,
        3200, 4173, 3471,  904])
Epoch: 3715, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3716 - Batch 1 ########################
IDs in batch 1: tensor([ 928,  131,  639, 2386, 1686, 4258, 4093, 1275, 4245,  827, 1625, 1166,
         351,  147, 2915, 2046])
Epoch: 3716, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3717 - Batch 1 ########################
IDs in batch 1: tensor([3930, 1986,  199, 3421,  848, 3444, 1138, 1770, 3599, 3004, 3663,  766,
        4075, 2869,  539,  438])
Epoch: 3717, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3718 - Batch 1 ########################
IDs in batch 1: tensor([ 325,  327, 1537, 2435, 2179, 2755, 2619, 3753, 1073, 1197, 3329, 3053,
        1580, 1555,   81, 2842])
Epoch: 3718, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3719 - Batch 1 ########################
IDs in batch 1: tensor([ 924, 1923, 3087, 3871,  505, 2506,  993, 2824, 2542,  967, 3514, 2584,
        1996, 3193, 1975, 1597])
Epoch: 3719, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3720 - Batch 1 ########################
IDs in batch 1: tensor([2799, 1295,  371, 2966, 2537, 1278, 3856,   95,  350, 1897,  805,  182,
        2299, 3658, 3543, 1658])
Epoch: 3720, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3721 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 1773, 2177, 2621, 1589, 2631, 2013,  771,  811,   42, 1804, 3415,
        3932, 1334,  825,  923])
Epoch: 3721, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3722 - Batch 1 ########################
IDs in batch 1: tensor([2561, 2832,  172,  843, 1076,  803, 4033, 2023, 3710, 1850, 2193, 4061,
         896,  652,  213, 1281])
Epoch: 3722, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3723 - Batch 1 ########################
IDs in batch 1: tensor([1618,  908, 4199, 3656,   70,  849,    5, 2441, 1216,  161, 1895, 4076,
        3616, 3542, 4144, 1250])
Epoch: 3723, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3724 - Batch 1 ########################
IDs in batch 1: tensor([3018, 2683,  491, 3989, 2428, 1630, 1723, 2743,  630, 1167, 1484, 3221,
        3495,  510, 3094, 3004])
Epoch: 3724, Training Loss: 0.18, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3725 - Batch 1 ########################
IDs in batch 1: tensor([4056,  220, 1563,  388, 1069,  612, 1496, 3374, 3410, 2170, 2848,  605,
        3700, 1008, 1282,   73])
Epoch: 3725, Training Loss: 0.34, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3726 - Batch 1 ########################
IDs in batch 1: tensor([3091, 4058,  656,   85,   20, 1571, 1883, 3793, 1251, 1182, 3568, 1016,
        2497, 1220, 1270, 3151])
Epoch: 3726, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3727 - Batch 1 ########################
IDs in batch 1: tensor([2044, 2099,  584, 4156, 1510, 3000, 1532,  851, 2295, 3455,  937, 4101,
        2286,  323, 2696, 3485])
Epoch: 3727, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3728 - Batch 1 ########################
IDs in batch 1: tensor([3055, 3379, 3635, 2479, 2072, 1409, 2545,   72, 2912,  781, 1927, 3257,
         338, 3692,   62,  474])
Epoch: 3728, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3729 - Batch 1 ########################
IDs in batch 1: tensor([1986, 1575, 2271, 2511, 4075,  434, 2827, 2521, 2420, 1938, 2899, 1925,
        3894, 3860,  606,  819])
Epoch: 3729, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3730 - Batch 1 ########################
IDs in batch 1: tensor([ 496, 1443, 2403, 2482, 1289, 1993, 1601, 2141, 1349, 2016, 3006, 1266,
        3532,  626,  160, 3367])
Epoch: 3730, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3731 - Batch 1 ########################
IDs in batch 1: tensor([ 635, 3339,  804, 3245, 2886, 2244,  401,  858,  226, 4048, 1990, 1051,
        1075, 3888, 3126, 1644])
Epoch: 3731, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3732 - Batch 1 ########################
IDs in batch 1: tensor([3567, 2771, 4078,  627, 2664, 3038,  552, 1153, 3368,  811, 3490,  405,
        2777,  952, 2730, 3112])
Epoch: 3732, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3733 - Batch 1 ########################
IDs in batch 1: tensor([2717, 1751, 2420, 3762, 3935, 2309, 1899, 1809, 1543, 3065, 2359, 1933,
        4205, 3583,  384, 1648])
Epoch: 3733, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3734 - Batch 1 ########################
IDs in batch 1: tensor([1281,  937, 3636, 2207,  369,  822, 3621, 1444, 2190, 4225, 3378,  584,
        1305,  666, 1501, 3185])
Epoch: 3734, Training Loss: 0.25, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3735 - Batch 1 ########################
IDs in batch 1: tensor([3406, 2299, 2177, 3432, 2242,  989,  774,  926, 1808, 1004, 3697,  109,
        2274, 2618, 1602, 2798])
Epoch: 3735, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3736 - Batch 1 ########################
IDs in batch 1: tensor([2190, 1947, 3487, 3151, 2812, 3351, 3400, 2149,  771, 3743, 2740, 2245,
        4267, 1578,   31, 4253])
Epoch: 3736, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3737 - Batch 1 ########################
IDs in batch 1: tensor([1574, 1351, 3894, 3618, 1278, 2230, 2578, 2656, 3377, 2851, 2833, 3913,
        2030, 3692,  689, 3834])
Epoch: 3737, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3738 - Batch 1 ########################
IDs in batch 1: tensor([2663, 3873, 4026, 4033, 1442, 3221,  755, 4133, 3077, 4251, 3244, 2279,
        3496, 4061, 3509, 3202])
Epoch: 3738, Training Loss: 0.41, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3739 - Batch 1 ########################
IDs in batch 1: tensor([1236, 2752, 3709, 3885, 1777, 1089, 2354, 2789,  563,  586, 3972, 2450,
        2417,  844, 2432, 4157])
Epoch: 3739, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3740 - Batch 1 ########################
IDs in batch 1: tensor([2030,  465, 1452, 1638, 3699,  960, 2153, 2379, 1489, 1569, 2984, 3548,
        2046,  814, 3999, 1956])
Epoch: 3740, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3741 - Batch 1 ########################
IDs in batch 1: tensor([1799,  200, 2383, 1563, 2306, 3391, 2317, 3573, 4213, 1639, 3471, 1162,
        1671, 3120, 3837, 2173])
Epoch: 3741, Training Loss: 0.25, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3742 - Batch 1 ########################
IDs in batch 1: tensor([2851, 1704,  494, 1610, 4185,  126, 4093,  384, 3367, 2027, 3920, 2135,
        3037,  923, 1886, 3017])
Epoch: 3742, Training Loss: 0.10, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3743 - Batch 1 ########################
IDs in batch 1: tensor([1017, 3087, 1647, 1440, 3570, 4077, 2059, 4176, 2629,  251,  456, 1570,
        2807, 1041, 1722, 2025])
Epoch: 3743, Training Loss: 0.16, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3744 - Batch 1 ########################
IDs in batch 1: tensor([3704, 2213, 1385, 2210, 2844, 1026, 2632,  152, 3150, 3783, 1146, 4230,
        1313, 1540, 1361, 1442])
Epoch: 3744, Training Loss: 0.05, Validation Loss: 0.89, accuracy = 0.71
######################## Epoch 3745 - Batch 1 ########################
IDs in batch 1: tensor([1239, 3154,  788,  988, 4199, 2024, 4077, 2344, 1913, 3022, 3598, 2867,
        3441, 3969, 3553, 1952])
Epoch: 3745, Training Loss: 0.12, Validation Loss: 0.89, accuracy = 0.71
######################## Epoch 3746 - Batch 1 ########################
IDs in batch 1: tensor([2417, 1146, 3374,  849,  781,  879, 2780, 1979, 1038, 1059, 2049, 2144,
        3357, 1948,  704, 2109])
Epoch: 3746, Training Loss: 0.05, Validation Loss: 0.89, accuracy = 0.71
######################## Epoch 3747 - Batch 1 ########################
IDs in batch 1: tensor([ 160, 1440, 1604, 3942, 2734, 3376,  982, 2383, 1452, 1504,  426,   97,
        2751,  967, 2425, 1645])
Epoch: 3747, Training Loss: 0.09, Validation Loss: 0.92, accuracy = 0.71
######################## Epoch 3748 - Batch 1 ########################
IDs in batch 1: tensor([3932, 1396, 4040, 3740, 1511, 3856,  944, 3143,  546, 4249, 1525,  753,
        3152,  167, 1546, 2845])
Epoch: 3748, Training Loss: 0.12, Validation Loss: 0.95, accuracy = 0.70
######################## Epoch 3749 - Batch 1 ########################
IDs in batch 1: tensor([ 388,  900, 1073, 3607,   73, 1386, 3282, 1949, 2099, 3936,  223, 2178,
        2212, 1993, 1975, 1592])
Epoch: 3749, Training Loss: 0.08, Validation Loss: 0.94, accuracy = 0.70
######################## Epoch 3750 - Batch 1 ########################
IDs in batch 1: tensor([3746,  171, 3000, 3024,  496, 3363,  134, 3536, 2328, 1082,  680, 1166,
         870, 3572, 2235,   61])
Epoch: 3750, Training Loss: 0.12, Validation Loss: 0.94, accuracy = 0.71
######################## Epoch 3751 - Batch 1 ########################
IDs in batch 1: tensor([1090, 3223, 2745,  915, 3570, 1161, 1007,  263,  535, 1101, 1835, 4258,
        1810, 2518,  455,  563])
Epoch: 3751, Training Loss: 0.15, Validation Loss: 0.94, accuracy = 0.71
######################## Epoch 3752 - Batch 1 ########################
IDs in batch 1: tensor([1508, 3037,  989, 1648, 3476, 1219,  735, 1640, 1284, 1376, 2366, 1910,
        1953, 3536, 4103, 1796])
Epoch: 3752, Training Loss: 0.06, Validation Loss: 0.93, accuracy = 0.71
######################## Epoch 3753 - Batch 1 ########################
IDs in batch 1: tensor([ 358, 3276, 2372, 3568,  105,  303,  545, 2582, 2116, 3987,  915, 2742,
        1302, 2024, 1720, 2897])
Epoch: 3753, Training Loss: 0.19, Validation Loss: 0.90, accuracy = 0.71
######################## Epoch 3754 - Batch 1 ########################
IDs in batch 1: tensor([2775, 2053, 1043,  834, 2967, 2656, 3486, 1489, 3127, 3836, 3349, 1232,
        2954, 1005, 3323, 1819])
Epoch: 3754, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3755 - Batch 1 ########################
IDs in batch 1: tensor([1384, 2475, 4115,  770, 1971, 3506,    4,   85, 1755, 4040, 2181, 1965,
        2561,  961, 2120, 3282])
Epoch: 3755, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3756 - Batch 1 ########################
IDs in batch 1: tensor([3874, 3337,  256, 3010,  665, 2984,  841, 1625,  699, 1335, 1320, 3852,
        3003, 1287, 1229, 1819])
Epoch: 3756, Training Loss: 0.21, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3757 - Batch 1 ########################
IDs in batch 1: tensor([2119, 3945, 3117,  523,  617, 1960, 1224,  511,  139,  255, 3049, 1863,
        3369, 2710, 3577, 3542])
Epoch: 3757, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3758 - Batch 1 ########################
IDs in batch 1: tensor([ 577, 2887, 1197,  441,  155, 4122,  229, 2419, 1015, 2907, 2111,  399,
         523, 1409, 1723, 1251])
Epoch: 3758, Training Loss: 0.33, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3759 - Batch 1 ########################
IDs in batch 1: tensor([2898, 3484, 1102,   96, 3234, 4176, 2517,  971, 1464, 1173,  103, 3728,
         201,  226,  661,  412])
Epoch: 3759, Training Loss: 0.45, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3760 - Batch 1 ########################
IDs in batch 1: tensor([2143,   85, 3504, 2591, 1710, 3896, 1787, 3494, 1949, 3259, 1663,   52,
        4084, 3429, 1404, 1097])
Epoch: 3760, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3761 - Batch 1 ########################
IDs in batch 1: tensor([ 350, 2604, 3139, 1970, 2432, 2838,  257,  809, 2669, 3471, 1312, 2578,
        3963, 3563, 3484, 1543])
Epoch: 3761, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3762 - Batch 1 ########################
IDs in batch 1: tensor([1647, 2178,  426, 2464, 3235, 2898,  843, 3098, 1096, 3004, 1896, 3240,
        1450, 2797,  718, 4222])
Epoch: 3762, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3763 - Batch 1 ########################
IDs in batch 1: tensor([1349, 3133,  505, 1880, 4242, 3272, 1231, 1925,   49, 2060, 3930, 4140,
         255, 3314, 1319, 2508])
Epoch: 3763, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3764 - Batch 1 ########################
IDs in batch 1: tensor([1904, 2133, 1887,  292, 2031, 2271, 1248, 1418, 2124, 1228,  527, 2497,
        1716, 2245, 3598, 1450])
Epoch: 3764, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3765 - Batch 1 ########################
IDs in batch 1: tensor([2690, 1445, 3470, 2347, 2925, 3262, 3706, 4139, 2027, 2202, 1900, 1498,
        2968,  555, 1764, 2070])
Epoch: 3765, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3766 - Batch 1 ########################
IDs in batch 1: tensor([1986, 1673, 1869,  826, 3311,  976, 1496, 2986, 1438, 2558,  263, 3006,
        1337, 3907, 3942, 3617])
Epoch: 3766, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3767 - Batch 1 ########################
IDs in batch 1: tensor([4133,   95, 1945,   37, 2414, 4121,  289, 1892, 1781, 3528, 3475, 1671,
        3958, 2467,  824, 1440])
Epoch: 3767, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3768 - Batch 1 ########################
IDs in batch 1: tensor([2754, 2965, 2304,  337, 1935, 2986, 1623, 3389, 2519,  262, 2794, 2360,
        2676,  277, 2986, 3582])
Epoch: 3768, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3769 - Batch 1 ########################
IDs in batch 1: tensor([3731,  837, 3272,  830, 1166, 2332, 3244, 1499, 2926, 4213,  341, 4225,
        1706, 1636, 1231, 4050])
Epoch: 3769, Training Loss: 0.24, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3770 - Batch 1 ########################
IDs in batch 1: tensor([1182, 3004, 1296, 1491, 3527, 3031, 2951, 3388, 3952,  987, 2706, 2590,
        2655, 2817, 1454, 3823])
Epoch: 3770, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3771 - Batch 1 ########################
IDs in batch 1: tensor([4010, 2337, 2366, 4049, 2879, 3467, 3772,  424,  488, 3954,  635, 1153,
        2459, 2369, 1005, 2915])
Epoch: 3771, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3772 - Batch 1 ########################
IDs in batch 1: tensor([1085, 3381, 3003, 3423,  322,  753, 3366,  462, 2262, 4007, 2669, 1502,
        4227, 2497, 1256, 3499])
Epoch: 3772, Training Loss: 0.02, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3773 - Batch 1 ########################
IDs in batch 1: tensor([1432,  409, 4170, 1626, 2676, 3858,  786, 3943,  111, 2726, 3700, 2156,
        1636, 2056, 1168,  360])
Epoch: 3773, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3774 - Batch 1 ########################
IDs in batch 1: tensor([ 100, 3549,   19, 2731, 2587, 1512, 1199, 2564, 1773, 1201, 1426, 2355,
        2553, 1708, 1052, 3706])
Epoch: 3774, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3775 - Batch 1 ########################
IDs in batch 1: tensor([1959, 1537, 1566, 1825,  649, 2829,  609,   93, 3683, 1570, 1075, 1225,
        4212, 1010,   49,  375])
Epoch: 3775, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3776 - Batch 1 ########################
IDs in batch 1: tensor([1418, 3337, 2872, 2053, 2315, 3640, 3259, 2462, 1988, 2825,   41,  103,
        2230,  755, 3242, 4058])
Epoch: 3776, Training Loss: 0.49, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3777 - Batch 1 ########################
IDs in batch 1: tensor([1104, 1467, 3693, 2064, 2480, 1099,  617,   56, 1296, 1633, 1088,  305,
        3671, 2462,  919, 2674])
Epoch: 3777, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3778 - Batch 1 ########################
IDs in batch 1: tensor([ 812, 3251, 2051,  606,  767,  964, 1421, 3767,  117, 3989, 4199,  730,
        2297,  541, 2927, 1289])
Epoch: 3778, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3779 - Batch 1 ########################
IDs in batch 1: tensor([3184, 2300,  575,  449,  717,  530, 2718, 1773, 2574, 4031, 1711,  985,
        3243, 2746, 2482, 2649])
Epoch: 3779, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3780 - Batch 1 ########################
IDs in batch 1: tensor([1568, 1812, 2464,  820,  512, 3832, 3246, 3913,  171, 2764,  281, 3142,
        1023, 3136, 2772, 2947])
Epoch: 3780, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3781 - Batch 1 ########################
IDs in batch 1: tensor([ 244, 3878, 4220, 3376, 1387, 1055, 2583, 1859,  185,  346, 1487, 3017,
         167, 1948, 1789, 1316])
Epoch: 3781, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3782 - Batch 1 ########################
IDs in batch 1: tensor([ 591,  956, 2203, 3832, 1133, 3334, 4056, 1899,  918, 1134,  103,  739,
        3781, 1275, 3942, 2383])
Epoch: 3782, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3783 - Batch 1 ########################
IDs in batch 1: tensor([ 466, 2858, 3534, 3913, 2526, 3651, 2732,  539, 1371, 1643,  516, 3902,
        3039, 3397, 3968, 2230])
Epoch: 3783, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3784 - Batch 1 ########################
IDs in batch 1: tensor([2176, 3882, 3410, 1131, 1156, 2282,  195, 1284, 1143, 2018, 3993,  605,
         407, 2832, 1617, 3493])
Epoch: 3784, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3785 - Batch 1 ########################
IDs in batch 1: tensor([3503, 2715, 2558,  558,  631, 4135, 2245,  350, 3139, 2655,   95, 2153,
        4264,  586, 1180,   85])
Epoch: 3785, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3786 - Batch 1 ########################
IDs in batch 1: tensor([2265,  617, 2437, 4117, 3481, 2648, 1650, 3126,  395, 4030, 1722, 2643,
        4158,  391, 1139,  971])
Epoch: 3786, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3787 - Batch 1 ########################
IDs in batch 1: tensor([ 649, 3156, 4261, 1162, 3698, 4186,  550,  362, 3065,  681, 1624,  573,
        2170,  196, 2802, 3700])
Epoch: 3787, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3788 - Batch 1 ########################
IDs in batch 1: tensor([1950, 1896, 2802, 4110, 4190, 2822, 1571,  977,  892, 1242, 4263, 2167,
        3789,  699, 1423, 1206])
Epoch: 3788, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3789 - Batch 1 ########################
IDs in batch 1: tensor([3035, 1826, 2456, 2646, 3692, 4213, 3689,  497, 3747, 3644, 4040,  494,
        3339, 2523, 3493,  454])
Epoch: 3789, Training Loss: 0.24, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3790 - Batch 1 ########################
IDs in batch 1: tensor([3005,   20, 3243, 2290,  968,  989, 1421,   92, 4220,  593,   70,   34,
        2383, 1786, 2690, 4037])
Epoch: 3790, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3791 - Batch 1 ########################
IDs in batch 1: tensor([3461, 1216, 1075, 1434, 1780, 2353,  993, 3912,  377,  623, 1256, 2235,
        2425, 1504, 3448, 1673])
Epoch: 3791, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3792 - Batch 1 ########################
IDs in batch 1: tensor([1488, 3818, 1212, 3461, 2738,  545,  469,  539,  639, 3949,  773, 4027,
        2292,  244, 3018,  684])
Epoch: 3792, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3793 - Batch 1 ########################
IDs in batch 1: tensor([3436,  258, 3945,  435,   57,  635, 3987, 2339,  554,  494, 1085, 4119,
         795, 1988,  321,  587])
Epoch: 3793, Training Loss: 0.20, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3794 - Batch 1 ########################
IDs in batch 1: tensor([2189, 2652, 2009, 2402, 1488, 2468, 2886, 3434,  229, 2249, 1822, 1180,
        3609,  323,   60, 2056])
Epoch: 3794, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3795 - Batch 1 ########################
IDs in batch 1: tensor([1498, 3792, 4168, 2860, 3267,  762, 1250, 2617,  586, 4116,  805, 3287,
        4117, 1681, 1031,  451])
Epoch: 3795, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3796 - Batch 1 ########################
IDs in batch 1: tensor([1409, 4101, 1972, 2961, 1657, 2059, 2248,   18, 3083,  982, 2980, 3028,
        3804, 2447, 3214, 2519])
Epoch: 3796, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3797 - Batch 1 ########################
IDs in batch 1: tensor([1642, 3121, 3732, 2206, 3501, 1252, 2521,  434,  985,  594,   35, 3486,
        3364,   10,  485,  575])
Epoch: 3797, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3798 - Batch 1 ########################
IDs in batch 1: tensor([3490,  855,  104, 1681, 3663, 2742, 2323,  129, 2218,  947,  870, 1933,
         986,  514, 3264, 1844])
Epoch: 3798, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3799 - Batch 1 ########################
IDs in batch 1: tensor([2518, 1763,  986,  408, 1478, 4085, 4107, 3793, 1154, 1551, 2432, 3124,
        2385, 1767, 1710,  243])
Epoch: 3799, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3800 - Batch 1 ########################
IDs in batch 1: tensor([2487, 2603,  665, 3698, 3858, 4196,  797, 3478, 2760, 1700, 1518, 4238,
        2016, 3344,  376, 4197])
Epoch: 3800, Training Loss: 0.18, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3801 - Batch 1 ########################
IDs in batch 1: tensor([2845, 3384,  981, 2605,  217, 1326,  866,   71,  971,  894, 2839, 3751,
        3732, 1724, 1182,  942])
Epoch: 3801, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3802 - Batch 1 ########################
IDs in batch 1: tensor([3461, 1592, 3239, 1201, 2433, 3441, 1498,   15, 3609, 2251,  666, 2327,
         181, 1237, 1445,  503])
Epoch: 3802, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3803 - Batch 1 ########################
IDs in batch 1: tensor([1009, 3551, 2183, 2238, 2844, 1098,  120, 2296, 1255,  181, 3240, 2796,
         346, 2226, 1032, 4149])
Epoch: 3803, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3804 - Batch 1 ########################
IDs in batch 1: tensor([3490, 3709, 1286, 2742, 2050, 1645, 2898, 3398,  402,  805, 1770, 2788,
        3453, 2822,  264, 4089])
Epoch: 3804, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3805 - Batch 1 ########################
IDs in batch 1: tensor([ 440, 3421,  694, 2217, 1826,   30, 3446, 1381, 3459, 4103, 3179,  324,
        4131, 3458,  278, 1918])
Epoch: 3805, Training Loss: 0.34, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3806 - Batch 1 ########################
IDs in batch 1: tensor([1141, 2829, 4258,  615, 4166, 3029,  332, 3698, 1025, 2025,  194, 3180,
        3548, 3558, 2723, 4263])
Epoch: 3806, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3807 - Batch 1 ########################
IDs in batch 1: tensor([ 221,  201, 2106, 3157, 1332, 3449, 1154,  872,  198, 1630, 3756, 3328,
        4027,  529, 2970, 1367])
Epoch: 3807, Training Loss: 0.24, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3808 - Batch 1 ########################
IDs in batch 1: tensor([2056, 3495, 3345, 2793, 1793, 4258, 1099, 1711, 1891, 1500, 1626, 2524,
        1132,  165, 3503, 2236])
Epoch: 3808, Training Loss: 0.27, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3809 - Batch 1 ########################
IDs in batch 1: tensor([3663,  809, 3466, 2317, 4232, 1176, 4268, 1559, 1388, 1206, 1488, 1860,
         102, 1955, 3136, 1979])
Epoch: 3809, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3810 - Batch 1 ########################
IDs in batch 1: tensor([ 864,  202,  949, 3353, 3644, 2324,  511, 2017, 3202, 4236,  749, 3785,
         318,  237, 3027, 4265])
Epoch: 3810, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3811 - Batch 1 ########################
IDs in batch 1: tensor([ 727, 3268, 3075, 3004, 4184, 2998, 3597, 1510,  321,  626, 2574,  360,
         689,  872, 4225, 2548])
Epoch: 3811, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3812 - Batch 1 ########################
IDs in batch 1: tensor([ 842, 2961,  899, 2036, 2473, 3065, 3538, 3152,  741, 3912,  498, 1037,
        3207,  996, 3179,  367])
Epoch: 3812, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3813 - Batch 1 ########################
IDs in batch 1: tensor([1670,  151, 3378,  604,  524, 3492,  147, 3243, 3506, 3999, 1248, 2706,
        1727, 3257,  790, 1641])
Epoch: 3813, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3814 - Batch 1 ########################
IDs in batch 1: tensor([2546,  279, 2342, 2218,   47, 3187, 3544, 2805,  991,  481, 2798, 3176,
        2483, 3587, 2734,  818])
Epoch: 3814, Training Loss: 0.29, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3815 - Batch 1 ########################
IDs in batch 1: tensor([1830, 1357, 3105, 1143, 2885, 2489, 2379, 3883, 1111,  904, 2432, 2993,
        2371, 1571, 1345, 1793])
Epoch: 3815, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3816 - Batch 1 ########################
IDs in batch 1: tensor([2526,  274, 3642, 4127, 2107, 3039, 3327, 2298, 3513,  180,   31,  306,
        3726, 2466, 3948,  569])
Epoch: 3816, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3817 - Batch 1 ########################
IDs in batch 1: tensor([2346, 3499, 3428, 2809, 2323, 1712, 1623, 1016,  413,  305, 3111,  355,
        2770, 2354,  219, 3471])
Epoch: 3817, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3818 - Batch 1 ########################
IDs in batch 1: tensor([1206, 3549, 2800, 3446, 1762, 3954, 3264, 1787, 2770, 3133, 1453, 1624,
         572, 2451, 1632,  819])
Epoch: 3818, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3819 - Batch 1 ########################
IDs in batch 1: tensor([1308, 2050, 2548, 2407, 2459, 2036, 3018, 1379, 1396, 3617, 1846, 1751,
        3636, 1543,  788, 3126])
Epoch: 3819, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3820 - Batch 1 ########################
IDs in batch 1: tensor([4215, 1283, 4089, 1425, 2408, 1647, 3223, 2034,  584, 1103, 3655, 3449,
        2687, 4168, 2301, 2406])
Epoch: 3820, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3821 - Batch 1 ########################
IDs in batch 1: tensor([2631, 1681, 2726, 2027,   19,  779, 2053, 3202, 4012, 2132, 3071, 1795,
        1655, 1221, 4010, 1887])
Epoch: 3821, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3822 - Batch 1 ########################
IDs in batch 1: tensor([ 355, 3098, 3499,  524,  545, 2689,  280, 1438, 3833, 3767, 3308, 3816,
        1597, 3071, 1176, 4203])
Epoch: 3822, Training Loss: 0.26, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3823 - Batch 1 ########################
IDs in batch 1: tensor([2241, 1005, 1223, 1393, 3404, 2553, 3211, 2038, 3706, 1077,  100, 3632,
        4037,  923, 3277, 2998])
Epoch: 3823, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3824 - Batch 1 ########################
IDs in batch 1: tensor([3069, 3194,  904, 3754, 4036, 1601, 1101,  851, 1950,  949, 2925, 3812,
         605,  333,   70, 3624])
Epoch: 3824, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3825 - Batch 1 ########################
IDs in batch 1: tensor([ 112,  346, 1728,  148,  637, 1059, 2655, 2251,  113, 4257, 1371, 3970,
        2121, 2541,  594,  747])
Epoch: 3825, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3826 - Batch 1 ########################
IDs in batch 1: tensor([2883,  466, 1681, 1624, 3162, 1841, 4140,  314, 2279, 1704, 4114, 1388,
        3369, 3882, 1214, 3888])
Epoch: 3826, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3827 - Batch 1 ########################
IDs in batch 1: tensor([3543, 3962, 4057,  757,  535, 1722, 1315, 2494, 3141, 3598, 2649, 1104,
        3136,  320,  164, 1852])
Epoch: 3827, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3828 - Batch 1 ########################
IDs in batch 1: tensor([ 735, 2115,  177, 3677, 2044,  375, 3006,  488, 2542, 3024,  526, 3489,
         963, 2870, 3152,  913])
Epoch: 3828, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3829 - Batch 1 ########################
IDs in batch 1: tensor([1158, 3162, 3883, 3015, 2275, 3607, 1367,  303, 1139,  854, 3655,  199,
        3142, 2712, 1405, 4049])
Epoch: 3829, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3830 - Batch 1 ########################
IDs in batch 1: tensor([2285, 1140, 3973, 1221, 2026, 2066, 3744,  220, 2291,  749,   59,  351,
        2751, 3589, 3953,  193])
Epoch: 3830, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3831 - Batch 1 ########################
IDs in batch 1: tensor([2257, 4213, 1181,   42,  818,  441, 2899,  439, 1436, 4127, 2018,  478,
        3886, 1638, 2095, 1467])
Epoch: 3831, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3832 - Batch 1 ########################
IDs in batch 1: tensor([3732, 1107, 3073, 1592, 2540, 1136, 2115,  755, 1218, 1137, 3975,   92,
        4070, 1756, 2244, 1726])
Epoch: 3832, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3833 - Batch 1 ########################
IDs in batch 1: tensor([4053, 1310,  970, 3289, 2646, 3022,  978, 1974, 1208, 1798, 3886, 3997,
        2386, 3542, 2124, 1952])
Epoch: 3833, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3834 - Batch 1 ########################
IDs in batch 1: tensor([2521, 2632, 3018, 2605, 3963, 1406, 1014, 4149, 4240, 1450, 2127, 2069,
        1628, 3079, 3094,   99])
Epoch: 3834, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3835 - Batch 1 ########################
IDs in batch 1: tensor([ 282, 1583, 2118, 3257, 3771, 3970, 2577, 2627, 1101,  974, 1041, 4015,
        1076,   88,  497, 3088])
Epoch: 3835, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3836 - Batch 1 ########################
IDs in batch 1: tensor([3594, 2334, 1179, 4017, 2115, 2942, 2595, 1349,   68, 1499, 3377, 1099,
         578, 1710, 1456, 2107])
Epoch: 3836, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3837 - Batch 1 ########################
IDs in batch 1: tensor([ 334, 1279, 3414, 2102, 2550, 3042, 2804, 2733, 1016, 1675, 2109, 2388,
        4100, 3588, 1672,  773])
Epoch: 3837, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3838 - Batch 1 ########################
IDs in batch 1: tensor([3872, 3188, 1313, 3337, 2300, 1573, 2565, 3940, 1094, 1335,  694, 2798,
          11, 3822,  459, 4076])
Epoch: 3838, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3839 - Batch 1 ########################
IDs in batch 1: tensor([2805, 1453, 2212, 1455, 1364, 2898, 4173, 3408, 3535, 4159, 1760, 1495,
        2371,  740,  292,  205])
Epoch: 3839, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3840 - Batch 1 ########################
IDs in batch 1: tensor([3871, 3009,   72,  405,  196, 4174, 1825, 4069, 3943, 2669, 3782,  685,
        3265, 1199, 2565, 2386])
Epoch: 3840, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3841 - Batch 1 ########################
IDs in batch 1: tensor([3894,  582,  345, 4073, 2312, 2050, 4031, 3832,  133,  376, 3648, 2003,
        1579,  302, 2819,  961])
Epoch: 3841, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3842 - Batch 1 ########################
IDs in batch 1: tensor([ 741, 2223, 1093,  471, 2026, 1090, 3486, 3705, 2793,  651,  666, 3407,
        1006,  133, 1042, 2563])
Epoch: 3842, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3843 - Batch 1 ########################
IDs in batch 1: tensor([ 149, 3841, 1853,  607, 2346, 1944, 3607,  883,  442,  459, 4196,  869,
        1710, 1602, 1397, 1751])
Epoch: 3843, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3844 - Batch 1 ########################
IDs in batch 1: tensor([1248, 2450, 1291, 1596,  778, 1780, 2161, 3567,  689,  554, 3621, 3971,
        3930, 3808,  785, 2583])
Epoch: 3844, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3845 - Batch 1 ########################
IDs in batch 1: tensor([3542,  151,  344, 1324,  775, 3821, 3199, 4161, 3112, 4218,  959, 1620,
        1405, 1221, 4016, 1101])
Epoch: 3845, Training Loss: 0.22, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3846 - Batch 1 ########################
IDs in batch 1: tensor([2892, 1087, 3401,  445, 2275,  278, 1012, 3303, 3996, 3110, 2024, 3487,
         981,  352, 2406, 1120])
Epoch: 3846, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3847 - Batch 1 ########################
IDs in batch 1: tensor([3697, 2382, 1646,  967, 2917,  824, 3094, 2297,  367, 3808, 2010, 3409,
        2680, 2264,  378, 2880])
Epoch: 3847, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3848 - Batch 1 ########################
IDs in batch 1: tensor([3363, 2636,  591, 2498,  325, 1233,  771,  498, 3336, 4168, 2575, 3570,
        1470, 1223, 2425, 1140])
Epoch: 3848, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3849 - Batch 1 ########################
IDs in batch 1: tensor([2798, 1484, 3859, 2304,  136, 4256, 1762, 1365, 1858, 3672, 2868, 3357,
        3826, 2346, 2886,   30])
Epoch: 3849, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3850 - Batch 1 ########################
IDs in batch 1: tensor([1299,  844, 1244,  662, 2393, 3764, 1852, 1051, 4157, 4172,  212, 4258,
        3133, 3692,  490,  717])
Epoch: 3850, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3851 - Batch 1 ########################
IDs in batch 1: tensor([1953,  743, 3049, 3516, 1122, 2143, 2544, 2586, 4044, 3756, 4127, 3245,
        4161, 2660,  101, 1390])
Epoch: 3851, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3852 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 1726, 3091,  499, 1849, 2749,  191, 1067, 1189, 4116, 3327,  244,
         106,  354, 2729, 1060])
Epoch: 3852, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3853 - Batch 1 ########################
IDs in batch 1: tensor([2094, 2441,  190, 2666,  519, 1953, 3065, 1225, 4188, 3298, 2297, 4257,
        1434, 1367,  394, 4116])
Epoch: 3853, Training Loss: 0.02, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3854 - Batch 1 ########################
IDs in batch 1: tensor([2282,  205,  517, 1897, 2112,  496,  518, 3310, 2414, 3771, 2857, 2967,
        4140, 1630, 3179,  305])
Epoch: 3854, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3855 - Batch 1 ########################
IDs in batch 1: tensor([4251, 2065, 2386,  315, 1257,  369,   71,  904, 3056, 3808,  994, 1220,
        1799, 2553, 3746, 3488])
Epoch: 3855, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3856 - Batch 1 ########################
IDs in batch 1: tensor([1594,  450,  527, 2257,  403, 1101, 1896,  474, 2176, 3726, 3888, 3803,
        2072, 3845, 3441, 2687])
Epoch: 3856, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3857 - Batch 1 ########################
IDs in batch 1: tensor([2817, 4156,  245, 2403, 2688, 3627, 3072, 3894,  396, 1250, 1811,  976,
         456, 2357,   59, 2176])
Epoch: 3857, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3858 - Batch 1 ########################
IDs in batch 1: tensor([3538, 2592, 2648,  662, 1894,    5, 1316, 1710, 2166,  452, 2356, 4254,
         214,  724, 1354, 1578])
Epoch: 3858, Training Loss: 0.18, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3859 - Batch 1 ########################
IDs in batch 1: tensor([3616, 3985,  478, 3869, 2431, 3156,  356, 1733, 2143, 1632,  673, 2074,
        4005, 1247, 1956, 1122])
Epoch: 3859, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3860 - Batch 1 ########################
IDs in batch 1: tensor([1384, 2362, 3850, 1222,  265, 1961, 1054, 2410, 2475, 3610, 1193, 3872,
        2238, 2016,  873, 3071])
Epoch: 3860, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3861 - Batch 1 ########################
IDs in batch 1: tensor([3377, 3925, 3643,  795,  228,  553, 2144, 2413, 1950, 3876, 3598, 1177,
        2555, 4024, 2234,  623])
Epoch: 3861, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3862 - Batch 1 ########################
IDs in batch 1: tensor([3790, 2760, 3150, 1163, 2965,  289, 1345, 3615,  402, 3549,   24, 2372,
        1826, 2137, 2659, 2099])
Epoch: 3862, Training Loss: 0.18, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3863 - Batch 1 ########################
IDs in batch 1: tensor([3236, 2775,  218, 3333,  679, 2822, 3543, 2370,   18, 3533, 3485,  727,
        2601, 3299, 2984,  990])
Epoch: 3863, Training Loss: 0.28, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3864 - Batch 1 ########################
IDs in batch 1: tensor([1961, 3443, 2073, 4101, 2700, 3342, 4080, 3693, 3349,  960, 3374, 1321,
        2086, 2356, 1960, 2982])
Epoch: 3864, Training Loss: 0.25, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3865 - Batch 1 ########################
IDs in batch 1: tensor([3243, 2332, 3669,  439, 2715,  917, 1571,   73, 4035,  965, 3971,  813,
        4143, 2306,  774,  445])
Epoch: 3865, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3866 - Batch 1 ########################
IDs in batch 1: tensor([ 120, 2591, 2452, 3872, 1439,  781,  673, 2760, 1072, 1244,  814, 3233,
        1630, 3092,  724, 2674])
Epoch: 3866, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3867 - Batch 1 ########################
IDs in batch 1: tensor([ 841, 3518, 3728, 1459, 1022,  636, 2004, 3765, 2976,  816,  167,  245,
        3194,  101, 2417, 2253])
Epoch: 3867, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3868 - Batch 1 ########################
IDs in batch 1: tensor([ 816,  152, 1229, 3410,  368, 3399,  751, 3072, 1121,  919, 2924, 2551,
        2369, 1289, 1060, 2391])
Epoch: 3868, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3869 - Batch 1 ########################
IDs in batch 1: tensor([ 640, 2017, 2300,  767, 3180, 3278,  193, 3375, 1938,  992, 3526, 2969,
        3943, 4062,  891, 3813])
Epoch: 3869, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3870 - Batch 1 ########################
IDs in batch 1: tensor([3501,  989, 3552, 2563, 2428, 3226, 2098, 1454,  250, 3227, 2484, 1225,
        3278, 1945, 3414, 2696])
Epoch: 3870, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3871 - Batch 1 ########################
IDs in batch 1: tensor([2844, 3385, 3128,  781, 2347, 1690, 2521,  586, 1642, 3360, 3218, 4105,
        1842, 1624, 3930, 1313])
Epoch: 3871, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3872 - Batch 1 ########################
IDs in batch 1: tensor([2134, 4125,  718, 1512, 2402, 1639, 1281, 2349,  434, 2709, 2745,  545,
        3378, 2280, 2250,  494])
Epoch: 3872, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3873 - Batch 1 ########################
IDs in batch 1: tensor([2217, 2945, 1499, 1294, 2453,  225, 2095, 3925,  257, 1291, 4196, 2859,
        2511, 2791,  122,  804])
Epoch: 3873, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3874 - Batch 1 ########################
IDs in batch 1: tensor([1085, 3537,  259, 2206, 2839,  221, 2849, 1182,  665,  976, 4036, 1851,
        1390, 2036, 1213, 4224])
Epoch: 3874, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3875 - Batch 1 ########################
IDs in batch 1: tensor([3031, 1786,  263, 1879, 4061,  863, 1798, 2121, 2886, 3521,  854, 1686,
        1672, 3551, 1956,   44])
Epoch: 3875, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3876 - Batch 1 ########################
IDs in batch 1: tensor([2135, 3310,   77,  851, 1706, 1437, 2204,  194, 2448, 1808, 3444, 3226,
        2767, 3922, 4022,  332])
Epoch: 3876, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3877 - Batch 1 ########################
IDs in batch 1: tensor([1597, 2667,  198, 2892,  471,  915,  317, 2627, 2234, 2150, 3461, 1754,
        2650, 1731, 2837, 2339])
Epoch: 3877, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3878 - Batch 1 ########################
IDs in batch 1: tensor([1126, 2957, 3743, 2847, 2687, 3185, 1852,  510, 1752,  120,  397,  894,
        1592,  721, 3200,  949])
Epoch: 3878, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3879 - Batch 1 ########################
IDs in batch 1: tensor([1199,  170, 4158, 1913,  171, 1001, 1488, 4226, 2740, 3112, 3072, 2073,
         626, 3563,  524, 1154])
Epoch: 3879, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3880 - Batch 1 ########################
IDs in batch 1: tensor([1617, 2094, 2601,  128, 1836, 3780,   31,  834, 2407,  645, 2495, 1229,
         259, 1846, 1199,  986])
Epoch: 3880, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3881 - Batch 1 ########################
IDs in batch 1: tensor([3949, 2915, 2730, 4255, 2098, 2674,   50, 3573,  967, 2848, 1982, 1279,
        2825, 2942, 3298, 3239])
Epoch: 3881, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3882 - Batch 1 ########################
IDs in batch 1: tensor([3585, 2940, 3554, 3417, 1443, 1795, 1296, 2353, 4225, 3400, 3010, 2300,
        2688, 1789,  456, 2856])
Epoch: 3882, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3883 - Batch 1 ########################
IDs in batch 1: tensor([2180, 2292, 1803, 1290, 3459,  775, 1686, 3981, 1796, 2390, 1266, 3743,
        2482, 2755, 2806, 4125])
Epoch: 3883, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3884 - Batch 1 ########################
IDs in batch 1: tensor([1918, 1414,  813, 1004, 4082, 1499, 3469, 1417,  359, 3973, 3124, 4004,
         557,  259, 3692, 2775])
Epoch: 3884, Training Loss: 0.22, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3885 - Batch 1 ########################
IDs in batch 1: tensor([ 448, 1955, 2736, 2817, 3507,  832,  444, 4093, 1968, 1067, 1723,  687,
        3545, 1292, 1232,  980])
Epoch: 3885, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3886 - Batch 1 ########################
IDs in batch 1: tensor([3272, 3920, 3290, 3903,  335, 3006, 3604,  129,  924, 1638, 2867,  395,
         739, 1724, 3529, 3459])
Epoch: 3886, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3887 - Batch 1 ########################
IDs in batch 1: tensor([ 462,  105,  897, 2199, 1632, 2692, 1417,  894,   73, 2802, 2095, 3150,
        2368,  165,  236,   22])
Epoch: 3887, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3888 - Batch 1 ########################
IDs in batch 1: tensor([3541,  149, 2983, 1779, 2700,  262, 1130,  814,  198,  357, 3355, 2247,
         538,  488, 2329, 4000])
Epoch: 3888, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3889 - Batch 1 ########################
IDs in batch 1: tensor([ 338, 3815, 1617, 1575,  292, 1271, 1592, 1478,  533,  537, 3447, 2921,
        3712, 1887, 4068, 2539])
Epoch: 3889, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3890 - Batch 1 ########################
IDs in batch 1: tensor([2680, 2656, 1017, 3535, 2921, 2183, 1393, 3577, 3478,    7, 3113, 3291,
        3943,  409,  921, 1566])
Epoch: 3890, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3891 - Batch 1 ########################
IDs in batch 1: tensor([3027, 3948,  824, 3655, 2849, 1059, 3142, 2980, 2550, 1633, 1677, 1087,
        1319, 2550, 2449,  527])
Epoch: 3891, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3892 - Batch 1 ########################
IDs in batch 1: tensor([3079, 2885, 1037, 1396,  779, 2731, 2773, 1087, 3632, 3144, 3434, 1963,
        2447, 4035, 3539, 2065])
Epoch: 3892, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 3893 - Batch 1 ########################
IDs in batch 1: tensor([  74, 3415, 1613, 3447, 2403, 1360, 3049,  956, 3592,  139, 2687, 2871,
        2226,  983, 1103, 1334])
Epoch: 3893, Training Loss: 0.02, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3894 - Batch 1 ########################
IDs in batch 1: tensor([2425, 1282, 1595, 1365,  851,  351, 1223,  522,  851, 3387, 3098, 1777,
         106,  572,  499, 3514])
Epoch: 3894, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3895 - Batch 1 ########################
IDs in batch 1: tensor([ 444, 1802, 1273, 1942, 1419,  811, 3257, 1361, 3268, 2261, 2379, 1008,
        2098, 3032, 3187, 2053])
Epoch: 3895, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3896 - Batch 1 ########################
IDs in batch 1: tensor([4068,  628, 1292, 3552, 3674, 3240, 1139, 1083, 3005, 4163, 2060, 3044,
        1087,  484, 3057, 4077])
Epoch: 3896, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3897 - Batch 1 ########################
IDs in batch 1: tensor([ 826,  393, 4165, 3721, 4013, 3308, 3739, 2653,  966, 1787, 3570, 2583,
        3489,   43, 1072, 3327])
Epoch: 3897, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3898 - Batch 1 ########################
IDs in batch 1: tensor([3440, 2014, 3020, 2845,  594,  568,  582, 1589, 3675,  251, 3099, 3878,
        2170, 3568, 4161,  565])
Epoch: 3898, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3899 - Batch 1 ########################
IDs in batch 1: tensor([4175, 3047, 3803,  546, 4185,  234,  558,  718, 3886, 1042,  110, 1762,
        1409, 2828, 1349, 3900])
Epoch: 3899, Training Loss: 0.42, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3900 - Batch 1 ########################
IDs in batch 1: tensor([1708,  219, 1699,  770, 1999,   72,  815, 1727, 3425, 1855, 2966, 3617,
           7, 1140, 1764, 2505])
Epoch: 3900, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3901 - Batch 1 ########################
IDs in batch 1: tensor([1225,  151, 2840,  322,  340, 2858, 3740,  776,  160,  108, 2793, 1623,
        3362, 3466, 1490, 2777])
Epoch: 3901, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3902 - Batch 1 ########################
IDs in batch 1: tensor([1870,  769,  323, 2898, 1552, 3378, 2373, 2149, 2882, 3534, 3110,  492,
        2151, 1453, 2344, 1299])
Epoch: 3902, Training Loss: 0.34, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3903 - Batch 1 ########################
IDs in batch 1: tensor([3765, 2102, 1965,  104,  452, 2034, 3917, 1968,  177, 3139,  159, 4009,
         712, 4253, 3505,  316])
Epoch: 3903, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3904 - Batch 1 ########################
IDs in batch 1: tensor([3277, 3239, 1596, 3632, 2127, 1464,  699, 1588,  121, 1746, 1201, 2405,
        2583, 3509, 2116, 1369])
Epoch: 3904, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3905 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 1495,   68, 4095, 2403,  238, 1336, 1180, 3699, 2558, 1954,  127,
        3654, 1009, 1237,  281])
Epoch: 3905, Training Loss: 0.13, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3906 - Batch 1 ########################
IDs in batch 1: tensor([1821, 1676, 1124, 2031,  492,  758,  281, 1962, 4198,  397,  539,  357,
        1111, 1707, 2482,  345])
Epoch: 3906, Training Loss: 0.18, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3907 - Batch 1 ########################
IDs in batch 1: tensor([2249,  394,  236, 3552, 2508, 1824, 1977, 3727, 2690, 2614, 2003, 2348,
        2858, 3585, 1176,  750])
Epoch: 3907, Training Loss: 0.30, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3908 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 2341, 1209, 2415, 3441,  330,  832, 4230, 2085, 2375,  466, 1635,
        3351, 3108,  896, 2586])
Epoch: 3908, Training Loss: 0.14, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3909 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 2598, 2331, 3222, 3463, 1970,  685, 1458,  942,  815,  590, 2700,
        3434,  472,  910,  390])
Epoch: 3909, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3910 - Batch 1 ########################
IDs in batch 1: tensor([2331, 3157, 2551,  434, 2031, 1501, 4053,  714, 3950, 4203, 1803, 2329,
        1730, 1728, 2523,  704])
Epoch: 3910, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3911 - Batch 1 ########################
IDs in batch 1: tensor([1450, 1982, 3537, 3962, 3044, 4190, 2499,  437, 2883,  767, 3902, 2112,
         398, 2998, 3357,  878])
Epoch: 3911, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3912 - Batch 1 ########################
IDs in batch 1: tensor([2794, 2339,  687, 2719, 2974, 3002, 3408,  785, 2242, 3717, 3650,  376,
        3340, 3878, 3545, 3992])
Epoch: 3912, Training Loss: 0.66, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3913 - Batch 1 ########################
IDs in batch 1: tensor([1826, 2836,  432, 1698, 2414, 4127,  512, 3003, 4184, 3467, 1389, 2799,
         237, 2863, 2614, 3700])
Epoch: 3913, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3914 - Batch 1 ########################
IDs in batch 1: tensor([1302, 2695, 3982,  606, 1167, 4026, 2925, 1271, 3401, 4069, 1045, 2218,
        3312, 1093, 3351, 1429])
Epoch: 3914, Training Loss: 0.03, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3915 - Batch 1 ########################
IDs in batch 1: tensor([ 287, 1727, 3850, 3239, 2519,  362, 4068,  238, 1448,  631, 3742,  450,
        2420,  733, 3308, 2099])
Epoch: 3915, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3916 - Batch 1 ########################
IDs in batch 1: tensor([2120, 2584, 2771, 1346, 1076, 2601, 1093, 2631, 2957, 2475, 4068, 3650,
         816, 2938, 3553,  476])
Epoch: 3916, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3917 - Batch 1 ########################
IDs in batch 1: tensor([3807, 3896, 3607, 2455, 3500, 2237, 2465,   10,  535, 1349, 3839, 1008,
         183, 1131, 1508,  640])
Epoch: 3917, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3918 - Batch 1 ########################
IDs in batch 1: tensor([1370, 3446, 3977,  866, 1250, 2739, 2523,  478, 2892, 1643, 3588,  335,
        2346, 2142, 3377, 3738])
Epoch: 3918, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3919 - Batch 1 ########################
IDs in batch 1: tensor([2306,  950, 2983, 1418, 1128, 2301, 3351, 2968, 2807, 4175, 1158,   38,
         899, 4222,  757, 1336])
Epoch: 3919, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3920 - Batch 1 ########################
IDs in batch 1: tensor([3830, 2938, 4185, 4161, 1439, 1589, 3375,  132, 3183, 1569, 3476, 3656,
        3790, 2145, 2487, 1953])
Epoch: 3920, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3921 - Batch 1 ########################
IDs in batch 1: tensor([2648, 2514, 1704, 3987,  779, 1931, 3222, 1835, 2196, 2390, 2281,  966,
         127, 3823, 1594, 3597])
Epoch: 3921, Training Loss: 0.32, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3922 - Batch 1 ########################
IDs in batch 1: tensor([3154, 3917, 3256, 1234,  701,  981, 2137, 4199, 2671, 2030,  134, 3905,
        3160, 4232, 1175, 4082])
Epoch: 3922, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3923 - Batch 1 ########################
IDs in batch 1: tensor([ 244, 2290,  651, 2317, 1308, 2429, 1623, 2855, 2791, 3161,  623, 2415,
        1885,  967, 3856, 1779])
Epoch: 3923, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3924 - Batch 1 ########################
IDs in batch 1: tensor([1576, 1264,  795, 1639,  657, 2260,  363, 1817, 1842,  892, 1128,  155,
        2248, 2872, 2823, 3585])
Epoch: 3924, Training Loss: 0.09, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3925 - Batch 1 ########################
IDs in batch 1: tensor([1025,  345,  499, 1133,  137,  430, 2301,  994,  487, 1570,  605, 2114,
        2426,  373, 3047, 2824])
Epoch: 3925, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3926 - Batch 1 ########################
IDs in batch 1: tensor([2444, 3299,  736, 2690, 2112, 3105, 3785, 2703, 1959, 2258, 2242, 3823,
        1773,  936,  471, 3200])
Epoch: 3926, Training Loss: 0.09, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3927 - Batch 1 ########################
IDs in batch 1: tensor([4121, 1108, 1233, 2729, 2418, 4095, 2196, 3938, 2040, 1063, 3878, 2049,
        1067, 3417, 1927, 4115])
Epoch: 3927, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3928 - Batch 1 ########################
IDs in batch 1: tensor([1726, 2800, 2568, 2063, 2399, 2562, 2718, 1119, 3810, 2508, 2375, 1336,
        2968, 3377, 1991, 3148])
Epoch: 3928, Training Loss: 0.53, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3929 - Batch 1 ########################
IDs in batch 1: tensor([2545,  389, 3526, 2461,  787, 3713,  952, 1737, 2913, 1420,  148, 2510,
         854, 1537,  426, 3239])
Epoch: 3929, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3930 - Batch 1 ########################
IDs in batch 1: tensor([2210, 1266, 2044,  837, 3527,  835, 3117, 2452,  305, 1489, 2824, 3826,
         628, 1168, 2506, 1102])
Epoch: 3930, Training Loss: 0.08, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3931 - Batch 1 ########################
IDs in batch 1: tensor([3673, 1247, 1809, 1932,  489, 1702, 1028, 2508,   85, 3181, 2420, 3781,
         721, 2584, 1375, 3069])
Epoch: 3931, Training Loss: 0.17, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3932 - Batch 1 ########################
IDs in batch 1: tensor([1251, 1003, 2354,   44,   42, 4017,  883,  337, 3183, 3934, 2579,  819,
        2770, 3795, 2489, 3197])
Epoch: 3932, Training Loss: 0.13, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3933 - Batch 1 ########################
IDs in batch 1: tensor([3713, 1089, 3851, 2156, 3492, 2091, 2601,  112,  900,  476, 4173,  888,
         191, 4165, 3927, 3658])
Epoch: 3933, Training Loss: 0.44, Validation Loss: 0.89, accuracy = 0.71
######################## Epoch 3934 - Batch 1 ########################
IDs in batch 1: tensor([1959, 2181, 1996,  773,  350, 2313, 1006, 3699, 2495, 2173, 2953, 3953,
        1228, 2908, 1133, 4017])
Epoch: 3934, Training Loss: 0.05, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3935 - Batch 1 ########################
IDs in batch 1: tensor([ 992,  145,  857, 3933, 1221, 1708, 2453, 3318, 1672, 1226,  968, 3006,
        3976, 2510, 3386, 3473])
Epoch: 3935, Training Loss: 0.08, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3936 - Batch 1 ########################
IDs in batch 1: tensor([3444, 2963, 2159, 1102, 2869, 2183, 2563, 1072, 2350, 4166, 1877, 1181,
        1126,  996, 2655, 2126])
Epoch: 3936, Training Loss: 0.09, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3937 - Batch 1 ########################
IDs in batch 1: tensor([3956, 3495, 3911,  172, 2122, 1053, 2050,  155, 3131,  143,  140,  519,
        4186, 3310, 3192, 2859])
Epoch: 3937, Training Loss: 0.10, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3938 - Batch 1 ########################
IDs in batch 1: tensor([1878, 1871, 1251, 2177, 3133, 1346, 1671, 2051, 1480, 2870, 3648, 3265,
        2030, 1389, 3240, 1008])
Epoch: 3938, Training Loss: 0.08, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3939 - Batch 1 ########################
IDs in batch 1: tensor([ 762, 2840,  409, 3837, 2902, 1488, 1260, 2726,  427, 2157, 3329, 2520,
        3440, 3717, 1934,  693])
Epoch: 3939, Training Loss: 0.09, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3940 - Batch 1 ########################
IDs in batch 1: tensor([2339, 1418, 2986, 3468, 2353, 2743, 1136, 1299, 3905, 3781, 2363, 3506,
        1507, 2261,  499, 2036])
Epoch: 3940, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3941 - Batch 1 ########################
IDs in batch 1: tensor([2228, 2833, 2980, 1309, 1546, 4158,  956, 2281,  100, 3439, 1008,  105,
        1545, 2517,  552,  125])
Epoch: 3941, Training Loss: 0.22, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3942 - Batch 1 ########################
IDs in batch 1: tensor([2921, 2590, 2671, 2844, 3538, 2591, 2748, 2111, 1133, 2245, 3202,  892,
         160, 2232, 1082, 1020])
Epoch: 3942, Training Loss: 0.37, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3943 - Batch 1 ########################
IDs in batch 1: tensor([3349,  362, 3553, 2524, 3511, 3432,  424, 3032, 4007, 1521, 2597, 1645,
         522,  572, 4140, 3410])
Epoch: 3943, Training Loss: 0.02, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3944 - Batch 1 ########################
IDs in batch 1: tensor([ 862, 3427, 1388,  508, 4197, 3334, 3326, 1027, 3695,  152, 2362, 1256,
        4264, 1499,  930,  569])
Epoch: 3944, Training Loss: 0.20, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3945 - Batch 1 ########################
IDs in batch 1: tensor([4174, 1006,  651, 2241, 3956, 4249, 1319, 1601, 3702, 1645, 2809, 1853,
         572,  199, 1308, 1574])
Epoch: 3945, Training Loss: 0.30, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3946 - Batch 1 ########################
IDs in batch 1: tensor([1823, 2550, 2761, 3521, 3162, 3079, 1960, 2119, 3976, 2726,  214, 1147,
         612, 3102, 3057, 1284])
Epoch: 3946, Training Loss: 0.26, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3947 - Batch 1 ########################
IDs in batch 1: tensor([3483,  276, 2500, 3091, 2417,  833, 1872, 3632, 4040, 3638, 2564,  334,
        3754, 3894, 1032, 4086])
Epoch: 3947, Training Loss: 0.33, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3948 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 3453, 2782, 3958,  601, 2821, 2103, 3238, 1317, 3042, 4245, 4255,
          96, 3219, 1443, 3558])
Epoch: 3948, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3949 - Batch 1 ########################
IDs in batch 1: tensor([1578, 4199, 4249, 1397,  264, 2124,   57, 3778, 4175, 4127, 3005, 1728,
         985,  276, 1823, 4122])
Epoch: 3949, Training Loss: 0.30, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3950 - Batch 1 ########################
IDs in batch 1: tensor([1177, 3058, 4093,  557,   10, 2806, 3478, 2642, 3156,  897,  679, 1923,
        2959, 3564, 1685, 1349])
Epoch: 3950, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3951 - Batch 1 ########################
IDs in batch 1: tensor([3362, 3375,  546, 3115, 2970, 1645, 1684, 4176,  778, 1635, 2039,  167,
        1657, 3604, 3829, 3488])
Epoch: 3951, Training Loss: 0.02, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3952 - Batch 1 ########################
IDs in batch 1: tensor([ 371, 2014, 3856, 2377, 2170, 2237,   97, 3087, 4117,  603,  262, 1957,
        3056,  395,  340, 4016])
Epoch: 3952, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3953 - Batch 1 ########################
IDs in batch 1: tensor([1752, 2765,  243, 2683, 2074, 3938, 2050,  827,  807, 2118, 1880,  920,
        1088,  346, 3777, 2151])
Epoch: 3953, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3954 - Batch 1 ########################
IDs in batch 1: tensor([ 513,  275, 3970, 2241, 2603, 4089, 3594, 2860, 4226,  582, 2696, 3543,
          31, 1543, 1944, 1942])
Epoch: 3954, Training Loss: 0.02, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3955 - Batch 1 ########################
IDs in batch 1: tensor([ 869,  533, 3853, 3121, 1971, 2415,  279, 2829, 2387, 2342,  996,  344,
         904,  187, 1537, 1850])
Epoch: 3955, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3956 - Batch 1 ########################
IDs in batch 1: tensor([ 292,  365,  399, 1287, 4139,   88, 3834, 4062,  546, 3038, 2035, 2921,
        2106,   30, 3973, 2432])
Epoch: 3956, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3957 - Batch 1 ########################
IDs in batch 1: tensor([1147,  763, 2451, 3548, 2884, 2114, 4194, 2110, 2376, 3261, 2539,  147,
        4121, 2284, 4236, 1324])
Epoch: 3957, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3958 - Batch 1 ########################
IDs in batch 1: tensor([ 640,  550,  269, 3446,  305,  497, 1277, 4120, 3299,  833, 1495,  221,
        3808, 1231, 4158, 3124])
Epoch: 3958, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3959 - Batch 1 ########################
IDs in batch 1: tensor([1597, 3242, 2674,   74, 3300, 4258, 1845, 4030, 2153, 3079,  226, 2125,
        1655, 2117, 2256,  425])
Epoch: 3959, Training Loss: 0.25, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3960 - Batch 1 ########################
IDs in batch 1: tensor([   7, 3440, 1786, 2301, 3147, 2857, 1118,  445, 3852, 2764, 2812, 3290,
        2405,  988, 2199, 1439])
Epoch: 3960, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3961 - Batch 1 ########################
IDs in batch 1: tensor([1410,  407, 1273, 3968, 3988, 3826, 4258, 2066, 3795, 1472, 1902, 2377,
        2118, 1376,  967, 2185])
Epoch: 3961, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3962 - Batch 1 ########################
IDs in batch 1: tensor([ 993, 2851, 1436, 2447, 3746, 2717, 3729,  787, 4027,  264, 1336,  657,
        3878,  387, 1900,  173])
Epoch: 3962, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3963 - Batch 1 ########################
IDs in batch 1: tensor([1517,  844, 2511, 3358, 1726, 1973,  934, 2159, 2938,  863,  183, 3839,
        4254, 3079, 2724, 2114])
Epoch: 3963, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3964 - Batch 1 ########################
IDs in batch 1: tensor([ 245, 3731,  689, 3202,  131, 2516,  667, 3712, 3535, 2760, 1580,  261,
        1962, 1761, 2825, 1049])
Epoch: 3964, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3965 - Batch 1 ########################
IDs in batch 1: tensor([2441, 3222, 2224, 1391, 1578,  251, 1101,  809, 3746, 1913, 2924,  459,
        3656, 3790, 1716, 2203])
Epoch: 3965, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3966 - Batch 1 ########################
IDs in batch 1: tensor([3751, 1118, 2587, 2206, 2763, 1080, 3024,  609, 3504, 1450, 3656,  816,
        1648, 2734,  376, 1916])
Epoch: 3966, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3967 - Batch 1 ########################
IDs in batch 1: tensor([3655, 4203, 1218, 1195, 1618, 3528, 1089,  659, 1232,  595, 1102, 2721,
        3568, 3557, 4086,  191])
Epoch: 3967, Training Loss: 0.45, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3968 - Batch 1 ########################
IDs in batch 1: tensor([1443, 3771, 2049, 2599, 3000, 3166, 3833, 1267,   51, 2298, 3432, 1872,
        1970,  355, 3056, 3818])
Epoch: 3968, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3969 - Batch 1 ########################
IDs in batch 1: tensor([2072, 2535, 2734, 3092, 3240, 3300, 3994, 3676,  496,  717,  830, 3471,
        2990, 1143, 3806, 3399])
Epoch: 3969, Training Loss: 0.24, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3970 - Batch 1 ########################
IDs in batch 1: tensor([ 776, 2636, 3603, 2488,  685,  261,  199, 3680, 2817, 3913, 3426, 3154,
        2264, 1775, 2369, 3537])
Epoch: 3970, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3971 - Batch 1 ########################
IDs in batch 1: tensor([2610, 2908,  982, 3436, 2090, 2982,  758, 1336, 2406, 3693, 2873,  211,
         203, 2362,  355, 2410])
Epoch: 3971, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3972 - Batch 1 ########################
IDs in batch 1: tensor([1305, 3905, 2860, 3203,  827, 1028, 3786, 3707,  190, 1819, 2989, 1635,
        1877, 1328, 2191, 1162])
Epoch: 3972, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3973 - Batch 1 ########################
IDs in batch 1: tensor([3980, 2149,  713, 2857, 3947,  785,  661, 1596,  359, 2648, 1306, 1990,
         818, 2256,  390, 3448])
Epoch: 3973, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3974 - Batch 1 ########################
IDs in batch 1: tensor([1981, 3739, 1487,  234,  212, 3214, 1026, 1108, 2034, 3259,  778, 3610,
        3808,  683, 1022, 2870])
Epoch: 3974, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3975 - Batch 1 ########################
IDs in batch 1: tensor([3329, 2440,  247, 2452, 3354, 1994, 3656, 2847, 1355, 1220, 1747, 3483,
        3000, 4158, 1311, 2674])
Epoch: 3975, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3976 - Batch 1 ########################
IDs in batch 1: tensor([3439, 3363,  882, 3398,  639, 1404, 2674, 3029, 1630, 2555, 2235, 4086,
        3306, 1610, 1824, 2664])
Epoch: 3976, Training Loss: 0.27, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3977 - Batch 1 ########################
IDs in batch 1: tensor([ 807, 2931, 3885, 2275, 1597, 2688, 1625, 1778,  949, 3166, 3072, 1028,
        1258, 3377, 1951, 3843])
Epoch: 3977, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3978 - Batch 1 ########################
IDs in batch 1: tensor([2127,  961, 2010, 3032,  699, 3698, 2132, 3040, 3074,  937, 2451, 3159,
         851, 3954, 4197, 3378])
Epoch: 3978, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3979 - Batch 1 ########################
IDs in batch 1: tensor([ 408, 1241, 1518, 3278, 3250, 2826,  401, 1170, 3632,  134, 1383, 1050,
        3214, 2291, 2997, 1597])
Epoch: 3979, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3980 - Batch 1 ########################
IDs in batch 1: tensor([1911,   22, 1409,  740,  610, 1784,    7, 3028, 2482, 3444,  435, 3035,
        3585, 2767, 3193,  380])
Epoch: 3980, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3981 - Batch 1 ########################
IDs in batch 1: tensor([3414, 3806, 1642,  626, 1686, 1624,   57,  974, 1221, 1879, 1858, 1722,
        3368, 1681, 3968, 1485])
Epoch: 3981, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3982 - Batch 1 ########################
IDs in batch 1: tensor([2260, 3130, 2514,  631,  245, 2009, 2863, 4254, 1583, 4236, 4148, 1711,
         872, 2017, 2030, 1061])
Epoch: 3982, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3983 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 1346,  757,  375, 2614, 3833,  981, 2300, 2338, 1443,  284, 3339,
        4266, 1275, 1641, 3836])
Epoch: 3983, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3984 - Batch 1 ########################
IDs in batch 1: tensor([  22, 1212, 1818, 2265,  883, 3953,  813, 3621, 3135, 4114, 2551, 1501,
        2417, 3240,  218,  778])
Epoch: 3984, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3985 - Batch 1 ########################
IDs in batch 1: tensor([ 182, 4101,  396, 3995, 1526, 3299, 1585, 1418, 3370,  497, 1951, 4050,
        3003, 2743,  393,  862])
Epoch: 3985, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3986 - Batch 1 ########################
IDs in batch 1: tensor([1795, 2391, 3514, 2731, 1779,  811, 2592, 2516, 4000, 1781, 2371, 1786,
        3435, 3894,  164, 4033])
Epoch: 3986, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3987 - Batch 1 ########################
IDs in batch 1: tensor([1267, 1647, 2678,  881, 3094, 3355, 4149, 2776,  713, 2090, 2285,  694,
        3258, 1849, 1355, 3731])
Epoch: 3987, Training Loss: 0.02, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3988 - Batch 1 ########################
IDs in batch 1: tensor([2419, 2056, 3569,  812,  976, 2155, 2133,   81, 2908, 3507,  170, 2649,
        1279,  408, 4096,  182])
Epoch: 3988, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3989 - Batch 1 ########################
IDs in batch 1: tensor([4226,  278,   11, 1852, 3920, 2111, 1869, 2171, 1426, 3182, 1361,  139,
        2725, 2349,  511, 2833])
Epoch: 3989, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3990 - Batch 1 ########################
IDs in batch 1: tensor([ 155, 2773,  226,  335, 2520,  609, 2656, 4184,  110, 1954, 3782,  981,
         774, 1223, 2550, 2350])
Epoch: 3990, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3991 - Batch 1 ########################
IDs in batch 1: tensor([4185, 2287, 3597, 1081, 1975, 2354, 4267, 2426, 2418,  441,  563,  709,
        1618, 4138, 2028, 2210])
Epoch: 3991, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3992 - Batch 1 ########################
IDs in batch 1: tensor([3208, 1693, 2483, 1960, 2644,  886, 4203, 2718, 1690, 1140,  128, 1008,
        4005, 3289, 1118, 1174])
Epoch: 3992, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3993 - Batch 1 ########################
IDs in batch 1: tensor([1379,  250, 1676, 1651,  829, 2372, 3852,  121, 3934, 3261, 3395, 1373,
         318, 1828,  373,  438])
Epoch: 3993, Training Loss: 0.35, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3994 - Batch 1 ########################
IDs in batch 1: tensor([1274, 2895, 2282, 1727, 3543, 3387,  956, 2354, 3471, 3430, 1117, 2372,
         188, 2598,   62, 1834])
Epoch: 3994, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3995 - Batch 1 ########################
IDs in batch 1: tensor([3476,  382, 2936, 1097,  255, 3853,  424, 3336, 3823, 1426, 2476, 3486,
        1014, 3235,  388, 2444])
Epoch: 3995, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3996 - Batch 1 ########################
IDs in batch 1: tensor([3194, 4101, 1773, 3401, 2723,  682, 1731, 1954, 3211, 1982,   35, 4176,
        1822,  398, 3590, 3723])
Epoch: 3996, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3997 - Batch 1 ########################
IDs in batch 1: tensor([2473, 1525, 3564, 3873, 2723, 3926, 3200, 3235, 2262,  913, 3439,  828,
        2487, 1675, 4165,  961])
Epoch: 3997, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3998 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 2002, 1651, 2915,  527, 2869, 3425, 3200, 4255, 4176, 2761, 1153,
        4254, 1208, 2484, 4101])
Epoch: 3998, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3999 - Batch 1 ########################
IDs in batch 1: tensor([3162, 2993, 2860, 3489, 1414,  198, 2842, 3056, 4002, 1808, 3681, 1648,
        3373, 3492, 2172, 3060])
Epoch: 3999, Training Loss: 0.37, Validation Loss: 0.79, accuracy = 0.75
Saved file as breast_probsThresthold_0.95_batch_size_16_batchNumber_1_epochs_4000_ver_0__18525.pkl
Validation accuracy state 1: 0.7667057444314185 @ epoch 1502 
[0.3, 0.3, 0.3, 0.31, 0.31, 0.32, 0.33, 0.33, 0.34, 0.37, 0.39, 0.41, 0.41, 0.43, 0.45, 0.45, 0.45, 0.47, 0.47, 0.48, 0.48, 0.48, 0.47, 0.48, 0.47, 0.48, 0.48, 0.48, 0.49, 0.49, 0.49, 0.49, 0.48, 0.48, 0.47, 0.48, 0.48, 0.48, 0.48, 0.48, 0.47, 0.47, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.49, 0.49, 0.5, 0.49, 0.49, 0.49, 0.49, 0.5, 0.5, 0.51, 0.51, 0.51, 0.51, 0.51, 0.52, 0.51, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.53, 0.52, 0.52, 0.51, 0.51, 0.51, 0.52, 0.52, 0.52, 0.51, 0.52, 0.52, 0.52, 0.53, 0.53, 0.53, 0.53, 0.54, 0.54, 0.54, 0.55, 0.55, 0.56, 0.56, 0.55, 0.56, 0.57, 0.56, 0.57, 0.57, 0.58, 0.57, 0.57, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.57, 0.58, 0.57, 0.58, 0.58, 0.59, 0.59, 0.59, 0.59, 0.59, 0.6, 0.59, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.61, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.59, 0.59, 0.6, 0.6, 0.6, 0.6, 0.6, 0.59, 0.59, 0.6, 0.6, 0.6, 0.61, 0.61, 0.62, 0.61, 0.62, 0.62, 0.62, 0.63, 0.63, 0.63, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.62, 0.62, 0.62, 0.61, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.62, 0.63, 0.63, 0.63, 0.63, 0.63, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.65, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.63, 0.63, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.65, 0.64, 0.64, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.66, 0.65, 0.66, 0.66, 0.66, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.66, 0.66, 0.66, 0.65, 0.64, 0.65, 0.65, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.65, 0.65, 0.65, 0.65, 0.66, 0.65, 0.66, 0.66, 0.65, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.65, 0.65, 0.65, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.65, 0.66, 0.66, 0.65, 0.65, 0.65, 0.65, 0.66, 0.65, 0.65, 0.65, 0.65, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.66, 0.67, 0.66, 0.67, 0.66, 0.67, 0.67, 0.67, 0.67, 0.67, 0.66, 0.66, 0.65, 0.65, 0.65, 0.65, 0.65, 0.64, 0.65, 0.64, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.66, 0.65, 0.66, 0.66, 0.67, 0.67, 0.67, 0.68, 0.68, 0.68, 0.68, 0.68, 0.67, 0.68, 0.68, 0.68, 0.68, 0.68, 0.69, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.68, 0.68, 0.67, 0.67, 0.66, 0.67, 0.67, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.67, 0.67, 0.67, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.68, 0.69, 0.68, 0.68, 0.68, 0.68, 0.67, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.69, 0.69, 0.69, 0.7, 0.69, 0.7, 0.69, 0.69, 0.69, 0.7, 0.69, 0.69, 0.69, 0.69, 0.69, 0.68, 0.69, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.67, 0.66, 0.66, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.68, 0.68, 0.69, 0.68, 0.69, 0.69, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.69, 0.7, 0.7, 0.7, 0.7, 0.69, 0.68, 0.69, 0.68, 0.68, 0.68, 0.69, 0.68, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.7, 0.7, 0.71, 0.7, 0.7, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.69, 0.7, 0.7, 0.69, 0.7, 0.7, 0.7, 0.69, 0.69, 0.7, 0.7, 0.7, 0.69, 0.68, 0.69, 0.68, 0.69, 0.68, 0.69, 0.68, 0.68, 0.68, 0.68, 0.69, 0.68, 0.68, 0.68, 0.68, 0.68, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.7, 0.7, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.71, 0.7, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.71, 0.71, 0.7, 0.71, 0.7, 0.69, 0.7, 0.7, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.72, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.7, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.69, 0.7, 0.69, 0.7, 0.7, 0.69, 0.68, 0.68, 0.67, 0.69, 0.68, 0.67, 0.68, 0.68, 0.67, 0.68, 0.68, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.75, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.71, 0.7, 0.7, 0.7, 0.68, 0.68, 0.68, 0.67, 0.67, 0.68, 0.68, 0.69, 0.69, 0.7, 0.7, 0.69, 0.69, 0.7, 0.7, 0.7, 0.71, 0.7, 0.7, 0.71, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.7, 0.69, 0.68, 0.69, 0.69, 0.68, 0.69, 0.69, 0.69, 0.69, 0.71, 0.71, 0.72, 0.72, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.75, 0.76, 0.75, 0.75, 0.74, 0.75, 0.75, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.76, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.72, 0.71, 0.69, 0.69, 0.69, 0.7, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.7, 0.71, 0.7, 0.7, 0.71, 0.7, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.73, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.72, 0.71, 0.72, 0.71, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.7, 0.7, 0.71, 0.7, 0.71, 0.7, 0.71, 0.71, 0.72, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.71, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.72, 0.72, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.7, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.7, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.71, 0.7, 0.7, 0.69, 0.69, 0.7, 0.7, 0.69, 0.7, 0.71, 0.71, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.7, 0.7, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.71, 0.7, 0.7, 0.7, 0.71, 0.7, 0.71, 0.72, 0.71, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.74, 0.73, 0.73, 0.72, 0.71, 0.7, 0.7, 0.69, 0.7, 0.69, 0.69, 0.69, 0.69, 0.7, 0.69, 0.69, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.71, 0.7, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.73, 0.72, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.75, 0.75, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.7, 0.71, 0.7, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.72, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.74, 0.73, 0.74, 0.74, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.71, 0.72, 0.71, 0.72, 0.73, 0.74, 0.73, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.72, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.73, 0.73, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.73, 0.72, 0.71, 0.71, 0.72, 0.73, 0.72, 0.71, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.72, 0.71, 0.71, 0.7, 0.71, 0.71, 0.72, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75]Using cache found in /home/huong_n_pham01/.cache/torch/hub/pytorch_vision_v0.9.0

Email sent!
{'id': '2169506491110554876',
 'insertTime': '2022-03-03T23:38:59.180-08:00',
 'kind': 'compute#operation',
 'name': 'operation-1646379538860-5d95f9b944ab5-a770e87f-d1a1df68',
 'operationType': 'stop',
 'progress': 0,
 'selfLink': 'https://www.googleapis.com/compute/v1/projects/inlaid-fuze-338203/zones/us-central1-a/operations/operation-1646379538860-5d95f9b944ab5-a770e87f-d1a1df68',
 'startTime': '2022-03-03T23:38:59.200-08:00',
 'status': 'RUNNING',
 'targetId': '6084295428283528738',
 'targetLink': 'https://www.googleapis.com/compute/v1/projects/inlaid-fuze-338203/zones/us-central1-a/instances/pytorch-gpu',
 'user': '471852692592-compute@developer.gserviceaccount.com',
 'zone': 'https://www.googleapis.com/compute/v1/projects/inlaid-fuze-338203/zones/us-central1-a'}
