{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cp5AQIxQOCfC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Update:  \n",
    "Author: Huong N. Pham\n",
    "Classification problem: BreastMass\n",
    "\n",
    "'''\n",
    "from pyLib.sendEmail import send_email\n",
    "from pyLib.stopInstance import stop_instance\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "\n",
    "#################################################################\n",
    "# Default parameters\n",
    "'''\n",
    "\n",
    "'''\n",
    "#################################################################\n",
    "class ImageFolderWithIDs(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithIDs, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (index,))\n",
    "        return tuple_with_path\n",
    "\n",
    "#\"/content/drive/My Drive/Colab Notebooks/Kaggle/DME/val/\"\n",
    "def load_images(directory):\n",
    "    from torchvision import transforms\n",
    "    transforms = transforms.Compose([transforms.Resize([256,256]),transforms.ToTensor(),transforms.Normalize(mean=[0.5394, 0.5394, 0.5394],std=[0.2447, 0.2447, 0.2447])])\n",
    "    data = ImageFolderWithIDs(root=directory, transform=transforms)\n",
    "\n",
    "#    test_data_path = \"/content/drive/My Drive/Colab Notebooks/Kaggle/DogCat/sample/test/\"\n",
    "#    test_data = ImageFolderWithIDs(root=test_data_path, transform=transforms)\n",
    "    return data\n",
    "def get_train_valid_test_loader(args, random_seed, augment = False, valid_size=0.2, test_size=0.1, shuffle=True):\n",
    "    \"\"\"\n",
    "    show_sample=False\n",
    "    pin_memory=False\n",
    "    num_workers=4\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to apply the data augmentation scheme\n",
    "      mentioned in the paper. Only applied on the train split.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.5394, 0.5394, 0.5394],\n",
    "        std=[0.2447, 0.2447, 0.2447],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "                      transforms.Resize([256,256]),\n",
    "                      transforms.ToTensor(),\n",
    "                      normalize,\n",
    "                                        ])\n",
    "    test_transform  = transforms.Compose([\n",
    "                      transforms.Resize([256,256]),\n",
    "                      transforms.ToTensor(),\n",
    "                      normalize,\n",
    "                                        ])\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "                      transforms.Resize([256,256]),\n",
    "                      transforms.RandomCrop(32, padding=4),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.ToTensor(),\n",
    "                      normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "                          transforms.Resize([256,256]),\n",
    "                          transforms.ToTensor(),\n",
    "                          normalize,\n",
    "        ])\n",
    "\n",
    "    # load the dataset with the whole data\n",
    "    train_dataset_transform = ImageFolderWithIDs(root=args.data_path, transform=train_transforms)\n",
    "    valid_dataset_transform = ImageFolderWithIDs(root=args.data_path, transform=valid_transforms)\n",
    "    test_dataset_transform  = ImageFolderWithIDs(root=args.data_path, transform=test_transforms)\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split_valid = int(np.floor(valid_size * num_train))\n",
    "    split_test = int(np.floor(test_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx, test_idx = indices[(split_valid+split_test):], indices[split_test:(split_valid+split_test)], indices[:split_test]\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(train_dataset_transform, train_idx)\n",
    "    valid_dataset = torch.utils.data.Subset(valid_dataset_transform, valid_idx)\n",
    "    test_dataset  = torch.utils.data.Subset(test_dataset_transform , test_idx)\n",
    "    \n",
    "    return (train_dataset, valid_dataset, test_dataset)\n",
    "\n",
    "'''\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "        # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(train_dataset, args.batch_size, shuffle=shuffle,)\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy().transpose([0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "'''\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def extract_data(args):\n",
    "    '''\n",
    "    Translate Image data structure into a data set for training/evaluating a single model\n",
    "    \n",
    "    @param args Argparse object, which contains key information, including train_datapath, \n",
    "            val_data_path, test_data_path\n",
    "            \n",
    "    @return Tensor for training set input/output, \n",
    "            validation set input/output and testing set input/output; and a\n",
    "            dictionary containing the lists of data paths that have been chosen\n",
    "    '''\n",
    "    from torchvision import transforms\n",
    "    # Load data from tensors or images and transforms data to tensor with IDs atttached\n",
    "\n",
    "    train_dataset, valid_dataset, test_dataset = get_train_valid_test_loader(args,\n",
    "                                                                            50,\n",
    "                                                                            False,\n",
    "                                                                            0.2,\n",
    "                                                                            0.1,\n",
    "                                                                            True\n",
    "                                                                            )\n",
    "    \"\"\"test_data_path = \"/content/drive/My Drive/Colab Notebooks/Kaggle/DogCat/sample/test/\"\n",
    "    test_dataset = ImageFolderWithIDs(root=test_data_path, transform=transforms)\"\"\"\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def execute_exp(args=None):\n",
    "    '''\n",
    "    Perform the training and evaluation for a single model\n",
    "    \n",
    "    @args Argparse arguments\n",
    "    '''\n",
    "    # Check the arguments\n",
    "    if args is None:\n",
    "      # Case where no args are given (usually, because we are calling from within Jupyter)\n",
    "      #  In this situation, we just use the default arguments\n",
    "      parser = create_parser()\n",
    "      args = parser.parse_args([])\n",
    "    \n",
    "    # Extract the data sets\n",
    "    train_dataset, val_dataset, test_dataset = extract_data(args)\n",
    "    \n",
    "    # Load model\n",
    "    transfer_model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
    "    optimizer = optim.Adam(transfer_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Freeze parameters\n",
    "    for name, param in transfer_model.named_parameters():\n",
    "      if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace last layer\n",
    "    transfer_model.fc = nn.Sequential(nn.Linear(transfer_model.fc.in_features,500), nn.ReLU(), nn.Dropout(), nn.Linear(500,3))\n",
    "    \n",
    "    # Tune the model\n",
    "    train(args, transfer_model, optimizer, torch.nn.CrossEntropyLoss(), train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    # Report if verbosity is turned on\n",
    "    \"\"\"if args.verbose >= 1:\n",
    "        print(model.summary())\"\"\"\n",
    "def train(args, model, optimizer, loss_fn, train_dataset, val_dataset, test_dataset):\n",
    "    # create file name\n",
    "    fbase = generate_fname(args)\n",
    "    ranID = randrange(100000)\n",
    "    \n",
    "    #check if gpu is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # weight to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    #weight sampler\n",
    "    weights = np.ones(len(train_dataset))\n",
    "\n",
    "    #train_loader = DataLoader(train_data, batch_size=args.batch_size)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=args.batch_size)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    listRemove = []\n",
    "    \n",
    "    training_loss_log = []\n",
    "    validation_loss_log = []\n",
    "    accuracy_log = []\n",
    "\n",
    "    best_acc1 = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for epoch in range(int(args.epochs)):\n",
    "        batchNumber = 0\n",
    "        for i in range(0,args.batchNumber):\n",
    "            training_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            model.train()\n",
    "\n",
    "            sampler = WeightedRandomSampler(weights, args.batch_size)\n",
    "            train_loader = DataLoader(train_dataset, shuffle=(sampler is None),sampler=sampler, batch_size = args.batch_size)\n",
    "            \n",
    "            batch = iter(train_loader).next()\n",
    "            batchNumber += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets, ids = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs) \n",
    "            print(\"######################## Epoch {} - Batch {} ########################\".format(epoch, batchNumber))\n",
    "            print(\"IDs in batch {}: {}\".format(batchNumber,ids))\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "        training_loss /= batchNumber\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets, ids = batch\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            valid_loss += loss.data.item()\n",
    "            correct = torch.eq(torch.max(F.softmax(outputs, dim = 1), dim=1)[1],\n",
    "            targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "\n",
    "            #writer.add_scalar('accuracy', num_correct / num_examples, epoch)\n",
    "            \n",
    "        valid_loss /= len(val_loader)\n",
    "        accuracy = num_correct / num_examples\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss, valid_loss, accuracy))\n",
    "\n",
    "        if accuracy > best_acc1 and accuracy >= 0.85:\n",
    "            best_acc1 = accuracy\n",
    "            best_model_state1 = copy.deepcopy(model.state_dict())\n",
    "            print(\"Save best Model_1 @ epoch {} acc: {}\".format(epoch, best_acc1))\n",
    "            \n",
    "            epochState1 = epoch\n",
    "            best_valid_loss = valid_loss\n",
    "            best_optimizer = optimizer.state_dict()\n",
    "            # Save model when achieve the best\n",
    "            torch.save({\n",
    "                'best_model': best_model_state1,\n",
    "                'optimizer'        : best_optimizer,\n",
    "                'valid_loss_min'   : best_valid_loss,\n",
    "                'accuracy'         : best_acc1,\n",
    "                'epoch'            : epochState1\n",
    "                }, \"%smodel\"%(fbase))\n",
    "        if epoch == 2998:\n",
    "            model_2998 = copy.deepcopy(model.state_dict())\n",
    "            torch.save({'model_2998': model_2998}, \"model_2998\")\n",
    "        # Performance log data\n",
    "        training_loss_log.append(round(training_loss,2))\n",
    "        validation_loss_log.append(round(valid_loss,2))\n",
    "        accuracy_log.append(round(accuracy,2))\n",
    "\n",
    "        if accuracy >= args.probsThresthold:\n",
    "          break\n",
    "\n",
    "    # Generate log data\n",
    "    \n",
    "    \"\"\"results['args'] = args\"\"\"\n",
    "\n",
    "    results['training_loss_log'] = training_loss_log\n",
    "    results['validation_loss_log'] = validation_loss_log\n",
    "    results['accuracy_log'] = accuracy_log\n",
    "\n",
    "    \n",
    "    results['best_acc'] = [best_acc1]\n",
    "    results['epochState'] = [epochState1]\n",
    "    \n",
    "    # Save log files\n",
    "    \n",
    "    print(\"Saved file as %s_%s_%s.pkl\"%(os.path.basename(__file__)[:-3],fbase,ranID))\n",
    "    results['fname_base'] = fbase\n",
    "    fp = open(\"%s_%s_%s.pkl\"%(os.path.basename(__file__)[:-3],fbase,ranID), \"wb\")\n",
    "    pickle.dump(results, fp)\n",
    "    fp.close()\n",
    "    \n",
    "    # Show results\n",
    "    print(\"Validation accuracy state 1: {} @ epoch {} \".format(best_acc1, epochState1))\n",
    "    print(accuracy_log)\n",
    "   \n",
    "\n",
    "    send_email(\"{}\\nMax validation accuracy: {} @ epoch {} pytorch 4\".format(fbase,best_acc1,epochState1))\n",
    "    #stop_instance('inlaid-fuze-338203','us-west4-b','pytorch4')\n",
    "\n",
    "def create_parser():\n",
    "    # Parse the command-line arguments\n",
    "    parser = argparse.ArgumentParser(description='DME classification')\n",
    " \n",
    "    parser.add_argument('-probsThresthold', type=float, default=0.8, help=\"probability threshold min to remove out of training \")\n",
    "    parser.add_argument('-data_path', type=str, default='/home/hpham/Data/DME/train', help='train directory')\n",
    "    parser.add_argument('-batch_size', type=int, default=16, help='batch size')\n",
    "    parser.add_argument('-batchNumber', type=int, default=20, help='number of batches to keep training')\n",
    "    parser.add_argument('-epochs', type=int, default=10, help='Training epochs')\n",
    "    parser.add_argument('-version', type=int, default=0, help='version')\n",
    "    return parser\n",
    "def generate_fname(args):\n",
    "    '''\n",
    "    Generate the base file name for output files/directories.\n",
    "    \n",
    "    The approach is to encode the key experimental parameters in the file name.  This\n",
    "    way, they are unique and easy to identify after the fact.\n",
    "    '''\n",
    "    if args.probsThresthold is None:\n",
    "        probsThresthold_str = ''\n",
    "    else:\n",
    "        probsThresthold_str = 'probsThresthold_%0.2f_'%(args.probsThresthold)\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        batch_size_str = ''\n",
    "    else:\n",
    "        batch_size_str = 'batch_size_%d_'%(args.batch_size)\n",
    "\n",
    "    if args.batchNumber is None:\n",
    "        batchNumber_str = ''\n",
    "    else:\n",
    "        batchNumber_str = 'batchNumber_%d_'%(args.batchNumber)\n",
    "\n",
    "    if args.epochs is None:\n",
    "        epochs_str = ''\n",
    "    else:\n",
    "        epochs_str = 'epochs_%d_'%(args.epochs)\n",
    "    if args.version is None:\n",
    "        version_str = ''\n",
    "    else:\n",
    "        version_str = 'ver_%d_'%(args.version)\n",
    "\n",
    "    # Put it all together, including #of training folds and the experiment rotation\n",
    "    return \"%s%s%s%s%s\"%(\n",
    "                      probsThresthold_str, \n",
    "                      batch_size_str, batchNumber_str, epochs_str, version_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    parser = create_parser()\n",
    "    args = parser.parse_args()\n",
    "    execute_exp(args)\n",
    "# nohup python3 dme_weighted11.py -probsThresthold 0.97 -batchNumber 1 -batch_size 16 -epochs 3000 -data_path '/home/huong_n_pham01/data/idrid/binary_DME01/train' -val_data_path '/home/huong_n_pham01/data/idrid/binary_DME01/val' -test_data_path '/home/huong_n_pham01/data/idrid/binary_DME01/test' > outputBinar0VS2.log &"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "breast.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
